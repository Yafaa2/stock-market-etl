[2025-01-13T00:16:32.919+0000] {processor.py:157} INFO - Started process (PID=20922) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:16:32.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:16:32.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:32.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:16:33.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.108+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:16:33.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.625+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.46610288600004424
[2025-01-13T00:16:33.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.626+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|20922]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:16:33.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.628+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:16:33.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.629+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:16:33.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.630+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:16:33.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.630+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|20922]: It took 0.523s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:16:33.656+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.655+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|20922]: It took 0.025s to build the Airflow DAG.
[2025-01-13T00:16:33.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:16:33.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.736+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:16:33.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:16:33.820+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:16:33.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.985 seconds
[2025-01-13T00:17:04.003+0000] {processor.py:157} INFO - Started process (PID=21002) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:17:04.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:17:04.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:17:04.328+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.327+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:17:04.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.943+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.50773815499997
[2025-01-13T00:17:04.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.958+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21002]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:17:04.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.962+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:17:04.973+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.972+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:17:04.976+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.975+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:17:04.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:04.995+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21002]: It took 0.675s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:17:05.062+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:05.055+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21002]: It took 0.0604s to build the Airflow DAG.
[2025-01-13T00:17:05.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:17:05.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:05.144+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:17:05.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:05.275+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:17:05.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.439 seconds
[2025-01-13T00:17:35.666+0000] {processor.py:157} INFO - Started process (PID=21082) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:17:35.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:17:35.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:35.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:17:35.730+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:35.730+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:17:36.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.079+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3156622579999748
[2025-01-13T00:17:36.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.080+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21082]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:17:36.082+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.082+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:17:36.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.083+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:17:36.084+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.084+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:17:36.085+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.085+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21082]: It took 0.356s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:17:36.102+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.101+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21082]: It took 0.0164s to build the Airflow DAG.
[2025-01-13T00:17:36.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:17:36.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.144+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:17:36.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:17:36.212+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:17:36.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.609 seconds
[2025-01-13T00:18:06.714+0000] {processor.py:157} INFO - Started process (PID=21168) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:18:06.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:18:06.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:18:06.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.740+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:18:06.908+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.908+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15431971900034114
[2025-01-13T00:18:06.908+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.908+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21168]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:18:06.909+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.909+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:18:06.910+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.910+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:18:06.910+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.910+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:18:06.911+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.910+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21168]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:18:06.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.916+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21168]: It took 0.00544s to build the Airflow DAG.
[2025-01-13T00:18:06.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:18:06.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.930+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:18:06.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:06.956+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:18:06.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-13T00:18:37.067+0000] {processor.py:157} INFO - Started process (PID=21255) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:18:37.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:18:37.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:18:37.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.095+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:18:37.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.240+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13166512200041325
[2025-01-13T00:18:37.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.241+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21255]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:18:37.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.241+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:18:37.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.242+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:18:37.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.242+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:18:37.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.243+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21255]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:18:37.247+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.247+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21255]: It took 0.00464s to build the Airflow DAG.
[2025-01-13T00:18:37.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:18:37.262+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.262+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:18:37.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:18:37.284+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:18:37.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-13T00:19:08.125+0000] {processor.py:157} INFO - Started process (PID=21341) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:19:08.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:19:08.128+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:19:08.164+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.164+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:19:08.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.411+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.224957128000824
[2025-01-13T00:19:08.413+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.412+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21341]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:19:08.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.414+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:19:08.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.415+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:19:08.416+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.416+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:19:08.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.417+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21341]: It took 0.253s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:19:08.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.426+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21341]: It took 0.00958s to build the Airflow DAG.
[2025-01-13T00:19:08.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:19:08.455+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.454+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:19:08.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:08.502+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:19:08.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.410 seconds
[2025-01-13T00:19:38.856+0000] {processor.py:157} INFO - Started process (PID=21446) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:19:38.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:19:38.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:38.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:19:38.887+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:38.887+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:19:39.045+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.044+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.142948661000446
[2025-01-13T00:19:39.045+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.045+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21446]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:19:39.046+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.046+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:19:39.046+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.046+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:19:39.047+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.047+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:19:39.047+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.047+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21446]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:19:39.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.051+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21446]: It took 0.00371s to build the Airflow DAG.
[2025-01-13T00:19:39.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:19:39.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.065+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:19:39.086+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:19:39.086+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:19:39.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-13T00:20:09.286+0000] {processor.py:157} INFO - Started process (PID=21532) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:20:09.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:20:09.296+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:20:09.379+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.379+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:20:09.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.797+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3867407239995373
[2025-01-13T00:20:09.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.798+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21532]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:20:09.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.800+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:20:09.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.801+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:20:09.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.801+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:20:09.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.802+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21532]: It took 0.424s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:20:09.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.814+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21532]: It took 0.0115s to build the Airflow DAG.
[2025-01-13T00:20:09.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:20:09.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.849+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:20:09.919+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:09.918+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:20:09.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.690 seconds
[2025-01-13T00:20:40.040+0000] {processor.py:157} INFO - Started process (PID=21619) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:20:40.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:20:40.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:20:40.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.071+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:20:40.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.288+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19892979800079047
[2025-01-13T00:20:40.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.289+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21619]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:20:40.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.290+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:20:40.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.291+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:20:40.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.291+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:20:40.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.292+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21619]: It took 0.221s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:20:40.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.300+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21619]: It took 0.00802s to build the Airflow DAG.
[2025-01-13T00:20:40.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:20:40.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.325+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:20:40.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:20:40.363+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:20:40.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.354 seconds
[2025-01-13T00:21:11.094+0000] {processor.py:157} INFO - Started process (PID=21706) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:21:11.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:21:11.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:21:11.119+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.119+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:21:11.275+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.275+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14206821299922012
[2025-01-13T00:21:11.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.275+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21706]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:21:11.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.276+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:21:11.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.277+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:21:11.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.277+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:21:11.278+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.277+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21706]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:21:11.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.282+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21706]: It took 0.00416s to build the Airflow DAG.
[2025-01-13T00:21:11.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:21:11.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.295+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:21:11.317+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:11.317+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:21:11.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-13T00:21:41.838+0000] {processor.py:157} INFO - Started process (PID=21792) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:21:41.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:21:41.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:41.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:21:41.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:41.881+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:21:42.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.152+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24267657900054473
[2025-01-13T00:21:42.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.153+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21792]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:21:42.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.154+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:21:42.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.154+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:21:42.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.154+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:21:42.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.155+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21792]: It took 0.274s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:21:42.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.159+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21792]: It took 0.00436s to build the Airflow DAG.
[2025-01-13T00:21:42.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:21:42.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.175+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:21:42.206+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:21:42.205+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:21:42.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.390 seconds
[2025-01-13T00:22:12.975+0000] {processor.py:157} INFO - Started process (PID=21897) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:22:12.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:22:12.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:12.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:22:13.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.000+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:22:13.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.193+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17971170199962216
[2025-01-13T00:22:13.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.194+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21897]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:22:13.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.194+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:22:13.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.195+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:22:13.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.195+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:22:13.196+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.196+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21897]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:22:13.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.200+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21897]: It took 0.00412s to build the Airflow DAG.
[2025-01-13T00:22:13.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:22:13.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.216+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:22:13.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:13.243+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:22:13.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-13T00:22:43.332+0000] {processor.py:157} INFO - Started process (PID=21984) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:22:43.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:22:43.334+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:22:43.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.358+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:22:43.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.532+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1622053410001172
[2025-01-13T00:22:43.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.533+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|21984]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:22:43.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.534+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:22:43.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.534+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:22:43.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.534+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:22:43.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.535+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|21984]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:22:43.539+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.539+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|21984]: It took 0.00384s to build the Airflow DAG.
[2025-01-13T00:22:43.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:22:43.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.553+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:22:43.577+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:22:43.576+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:22:43.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.266 seconds
[2025-01-13T00:23:14.355+0000] {processor.py:157} INFO - Started process (PID=22070) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:23:14.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:23:14.357+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:23:14.378+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.378+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:23:14.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.542+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1509332980003819
[2025-01-13T00:23:14.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.542+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22070]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:23:14.543+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.543+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:23:14.543+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.543+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:23:14.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.544+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:23:14.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.544+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22070]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:23:14.548+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.548+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22070]: It took 0.00379s to build the Airflow DAG.
[2025-01-13T00:23:14.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:23:14.566+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.566+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:23:14.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:14.588+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:23:14.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-13T00:23:44.643+0000] {processor.py:157} INFO - Started process (PID=22157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:23:44.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:23:44.645+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:23:44.675+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.675+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:23:44.847+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.846+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15822459299943148
[2025-01-13T00:23:44.848+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.848+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:23:44.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.849+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:23:44.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.850+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:23:44.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.850+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:23:44.851+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.851+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22157]: It took 0.176s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:23:44.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.856+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22157]: It took 0.00553s to build the Airflow DAG.
[2025-01-13T00:23:44.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:23:44.873+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.873+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:23:44.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:23:44.904+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:23:44.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.283 seconds
[2025-01-13T00:24:15.146+0000] {processor.py:157} INFO - Started process (PID=22261) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:24:15.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:24:15.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:24:15.172+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.172+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:24:15.362+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.362+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17697941299957165
[2025-01-13T00:24:15.362+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.362+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22261]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:24:15.363+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.363+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:24:15.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.364+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:24:15.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.364+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:24:15.365+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.365+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22261]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:24:15.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.370+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22261]: It took 0.00512s to build the Airflow DAG.
[2025-01-13T00:24:15.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:24:15.389+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.389+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:24:15.413+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:15.413+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:24:15.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.291 seconds
[2025-01-13T00:24:45.657+0000] {processor.py:157} INFO - Started process (PID=22347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:24:45.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:24:45.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:24:45.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.686+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:24:45.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.833+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13476647100014816
[2025-01-13T00:24:45.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.834+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22347]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:24:45.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.834+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:24:45.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.835+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:24:45.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.835+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:24:45.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.835+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22347]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:24:45.839+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.839+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22347]: It took 0.00394s to build the Airflow DAG.
[2025-01-13T00:24:45.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:24:45.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.856+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:24:45.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:24:45.881+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:24:45.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-13T00:25:15.965+0000] {processor.py:157} INFO - Started process (PID=22434) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:25:15.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:25:15.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:15.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:25:15.991+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:15.991+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:25:16.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.146+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14150904200050718
[2025-01-13T00:25:16.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.147+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22434]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:25:16.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.147+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:25:16.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.148+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:25:16.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.148+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:25:16.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.148+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22434]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:25:16.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.152+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22434]: It took 0.00381s to build the Airflow DAG.
[2025-01-13T00:25:16.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:25:16.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.166+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:25:16.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:16.190+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:25:16.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-13T00:25:46.303+0000] {processor.py:157} INFO - Started process (PID=22522) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:25:46.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:25:46.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:25:46.329+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.329+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:25:46.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.492+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14831418100038718
[2025-01-13T00:25:46.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.493+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22522]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:25:46.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.494+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:25:46.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.494+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:25:46.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.494+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:25:46.495+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.495+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22522]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:25:46.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.498+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22522]: It took 0.00351s to build the Airflow DAG.
[2025-01-13T00:25:46.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:25:46.512+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.512+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:25:46.539+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:25:46.539+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:25:46.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-13T00:26:17.552+0000] {processor.py:157} INFO - Started process (PID=22628) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:26:17.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:26:17.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:26:17.584+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.584+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:26:17.767+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.767+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1682360119993973
[2025-01-13T00:26:17.768+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.768+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22628]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:26:17.769+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.769+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:26:17.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.769+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:26:17.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.770+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:26:17.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.770+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22628]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:26:17.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.776+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22628]: It took 0.00567s to build the Airflow DAG.
[2025-01-13T00:26:17.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:26:17.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.794+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:26:17.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:17.818+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:26:17.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.292 seconds
[2025-01-13T00:26:48.565+0000] {processor.py:157} INFO - Started process (PID=22714) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:26:48.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:26:48.567+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:26:48.597+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.597+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:26:48.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.794+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18157794899980217
[2025-01-13T00:26:48.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.794+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22714]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:26:48.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.795+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:26:48.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.795+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:26:48.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.796+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:26:48.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.796+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22714]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:26:48.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.801+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22714]: It took 0.00434s to build the Airflow DAG.
[2025-01-13T00:26:48.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:26:48.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.818+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:26:48.844+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:26:48.843+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:26:48.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.302 seconds
[2025-01-13T00:27:19.034+0000] {processor.py:157} INFO - Started process (PID=22802) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:27:19.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:27:19.037+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:27:19.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.067+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:27:19.252+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.252+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.168383834999986
[2025-01-13T00:27:19.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.253+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22802]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:27:19.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.254+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:27:19.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.254+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:27:19.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.254+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:27:19.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.255+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22802]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:27:19.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.259+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22802]: It took 0.00463s to build the Airflow DAG.
[2025-01-13T00:27:19.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:27:19.279+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.278+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:27:19.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:19.306+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:27:19.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-13T00:27:49.473+0000] {processor.py:157} INFO - Started process (PID=22899) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:27:49.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:27:49.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:27:49.504+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.503+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:27:49.696+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.696+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17743627700019715
[2025-01-13T00:27:49.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.697+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22899]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:27:49.698+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.698+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:27:49.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.698+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:27:49.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.699+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:27:49.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.700+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22899]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:27:49.705+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.705+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22899]: It took 0.00564s to build the Airflow DAG.
[2025-01-13T00:27:49.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:27:49.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.723+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:27:49.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:27:49.752+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:27:49.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T00:28:20.479+0000] {processor.py:157} INFO - Started process (PID=22996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:28:20.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:28:20.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:28:20.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.508+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:28:20.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.668+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14664375800020935
[2025-01-13T00:28:20.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.668+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|22996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:28:20.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.669+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:28:20.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.669+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:28:20.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.670+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:28:20.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.670+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|22996]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:28:20.674+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.674+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|22996]: It took 0.00387s to build the Airflow DAG.
[2025-01-13T00:28:20.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:28:20.687+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.687+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:28:20.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:20.708+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:28:20.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-13T00:28:50.831+0000] {processor.py:157} INFO - Started process (PID=23084) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:28:50.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:28:50.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:50.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:28:50.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:50.867+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:28:51.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.011+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13159595400065882
[2025-01-13T00:28:51.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.011+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|23084]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:28:51.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.012+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:28:51.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.012+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:28:51.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.013+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:28:51.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.013+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|23084]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:28:51.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.017+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|23084]: It took 0.00351s to build the Airflow DAG.
[2025-01-13T00:28:51.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:28:51.031+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.030+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:28:51.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:28:51.052+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:28:51.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-13T00:29:21.948+0000] {processor.py:157} INFO - Started process (PID=23170) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:29:21.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:29:21.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:21.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:29:21.978+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:21.978+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:29:22.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.144+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15225902200018027
[2025-01-13T00:29:22.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.145+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|23170]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:29:22.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.145+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 499f79fe37ace4dbb7b4464c7403ce9e,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:29:22.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.146+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:29:22.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.146+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:29:22.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.147+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|23170]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:29:22.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.151+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|23170]: It took 0.00439s to build the Airflow DAG.
[2025-01-13T00:29:22.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:29:22.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.169+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:29:22.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:22.194+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:29:22.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-13T00:29:52.638+0000] {processor.py:157} INFO - Started process (PID=23275) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:29:52.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:29:52.640+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:29:52.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.669+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:29:52.855+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.855+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1699299029996837
[2025-01-13T00:29:52.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.855+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T00:29:52.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.856+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T00:29:52.861+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.861+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T00:29:52.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.870+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T00:29:52.872+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.872+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-13T00:29:52.872+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:52.872+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpcd1un4xt --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T00:29:58.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:58.958+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1934438100006446
[2025-01-13T00:29:58.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:58.967+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T00:29:58.973+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:58.973+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:29:58.973+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:58.973+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:29:58.974+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:58.974+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|23275]: It took 6.3s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T00:29:58.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:58.979+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|23275]: It took 0.00576s to build the Airflow DAG.
[2025-01-13T00:29:58.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:29:58.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:58.996+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:29:59.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:29:59.022+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:29:59.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 6.408 seconds
[2025-01-13T00:30:29.129+0000] {processor.py:157} INFO - Started process (PID=23388) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:30:29.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:30:29.131+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:30:29.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.159+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:30:29.354+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.354+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17922310500034655
[2025-01-13T00:30:29.354+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.354+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T00:30:29.355+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.355+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T00:30:29.362+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.361+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T00:30:29.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.369+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T00:30:29.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.371+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-13T00:30:29.372+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:29.372+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpq2g93jjr --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T00:30:35.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.775+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12898592600049597
[2025-01-13T00:30:35.780+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.780+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T00:30:35.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.795+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:30:35.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.796+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:30:35.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.797+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|23388]: It took 6.64s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T00:30:35.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.803+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|23388]: It took 0.00651s to build the Airflow DAG.
[2025-01-13T00:30:35.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:30:35.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.819+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:30:35.845+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:30:35.844+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:30:35.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 6.740 seconds
[2025-01-13T00:31:06.190+0000] {processor.py:157} INFO - Started process (PID=23531) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:31:06.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:31:06.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:31:06.225+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.225+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:31:06.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.480+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2344861920000767
[2025-01-13T00:31:06.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.481+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T00:31:06.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.482+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T00:31:06.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.489+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T00:31:06.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.498+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T00:31:06.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.500+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-13T00:31:06.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:06.501+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpuywl5v39 --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T00:31:24.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:24.813+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6299943829999393
[2025-01-13T00:31:24.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:24.838+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T00:31:24.923+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:24.923+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:31:24.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:24.924+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:31:24.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:24.927+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|23531]: It took 18.7s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T00:31:24.947+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:24.946+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|23531]: It took 0.0196s to build the Airflow DAG.
[2025-01-13T00:31:24.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:31:25.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:25.004+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:31:25.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:31:25.114+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:31:25.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 19.051 seconds
[2025-01-13T00:34:05.476+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:34:05.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:34:05.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:34:05.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.518+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:34:05.747+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.747+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2104925749999893
[2025-01-13T00:34:05.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.747+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|87]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:34:05.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.748+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:34:05.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.749+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:34:05.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.750+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:34:05.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.750+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|87]: It took 0.233s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:34:05.761+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.761+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|87]: It took 0.0103s to build the Airflow DAG.
[2025-01-13T00:34:05.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:34:05.787+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.787+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:34:05.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:05.819+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:34:05.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.374 seconds
[2025-01-13T00:34:36.533+0000] {processor.py:157} INFO - Started process (PID=173) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:34:36.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:34:36.541+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:36.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:34:36.647+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:36.646+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:34:37.103+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.103+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.38915961400016386
[2025-01-13T00:34:37.104+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.104+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|173]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:34:37.105+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.105+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:34:37.106+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.106+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:34:37.107+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.107+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:34:37.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.108+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|173]: It took 0.462s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:34:37.123+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.123+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|173]: It took 0.0148s to build the Airflow DAG.
[2025-01-13T00:34:37.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:34:37.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.175+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:34:37.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:34:37.254+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:34:37.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.771 seconds
[2025-01-13T00:35:08.027+0000] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:35:08.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:35:08.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:35:08.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.143+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:35:08.786+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.786+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6065622170008282
[2025-01-13T00:35:08.788+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.788+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|259]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:35:08.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.792+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:35:08.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.797+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:35:08.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.798+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:35:08.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.800+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|259]: It took 0.657s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:35:08.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.823+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|259]: It took 0.0232s to build the Airflow DAG.
[2025-01-13T00:35:08.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:35:08.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:08.893+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:35:09.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:09.003+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:35:09.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.085 seconds
[2025-01-13T00:35:39.228+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:35:39.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:35:39.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:35:39.266+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.266+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:35:39.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.492+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2106010379993677
[2025-01-13T00:35:39.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.493+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|347]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:35:39.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.494+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:35:39.495+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.495+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:35:39.495+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.495+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:35:39.496+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.496+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|347]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:35:39.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.501+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|347]: It took 0.00547s to build the Airflow DAG.
[2025-01-13T00:35:39.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:35:39.522+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.522+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:35:39.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:35:39.553+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:35:39.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.353 seconds
[2025-01-13T00:36:10.409+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:10.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:36:10.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:10.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.448+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:36:10.680+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.680+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2119914280001467
[2025-01-13T00:36:10.680+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.680+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|433]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:36:10.681+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.681+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:36:10.682+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.682+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:36:10.682+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.682+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:36:10.683+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.682+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|433]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:36:10.687+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.687+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|433]: It took 0.00478s to build the Airflow DAG.
[2025-01-13T00:36:10.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:10.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.708+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:36:10.741+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:10.741+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:36:10.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.359 seconds
[2025-01-13T00:36:26.646+0000] {processor.py:157} INFO - Started process (PID=498) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:26.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:36:26.649+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:26.676+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.676+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:36:26.884+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.884+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1885634159998517
[2025-01-13T00:36:26.885+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.884+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|498]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:36:26.886+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.886+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:36:26.886+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.886+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:36:26.887+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.887+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:36:26.888+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.888+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|498]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:36:26.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.893+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|498]: It took 0.00591s to build the Airflow DAG.
[2025-01-13T00:36:26.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:26.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.950+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_4', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': '158c85e6-4a8f-455a-8ca4-21efcada31f8'}
[2025-01-13T00:36:26.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:26.987+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_4, execution_date=20250113T003056, start_date=20250113T003118, end_date=20250113T003626
[2025-01-13T00:36:27.009+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_4 manual__2025-01-13T00:30:56.829391+00:00 [up_for_retry]> in state up_for_retry
[2025-01-13T00:36:27.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:27.032+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:36:27.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:27.069+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:36:27.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.452 seconds
[2025-01-13T00:36:36.705+0000] {processor.py:157} INFO - Started process (PID=518) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:36.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:36:36.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:36.734+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.734+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:36:36.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.892+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1430383900005836
[2025-01-13T00:36:36.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.892+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|518]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:36:36.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.893+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:36:36.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.894+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:36:36.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.894+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:36:36.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.894+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|518]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:36:36.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.898+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|518]: It took 0.00406s to build the Airflow DAG.
[2025-01-13T00:36:36.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:36.915+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.914+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': 'aa4670dd-eb8a-47bb-93c9-6a5797261540'}
[2025-01-13T00:36:36.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.932+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250113T003056, start_date=20250113T003120, end_date=20250113T003636
[2025-01-13T00:36:36.942+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 manual__2025-01-13T00:30:56.829391+00:00 [up_for_retry]> in state up_for_retry
[2025-01-13T00:36:36.945+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.945+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_5', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': 'f070db18-39e4-45e5-9ea9-b46e889e6d8b'}
[2025-01-13T00:36:36.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.953+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_5, execution_date=20250113T003056, start_date=20250113T003110, end_date=20250113T003636
[2025-01-13T00:36:36.957+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_5 manual__2025-01-13T00:30:56.829391+00:00 [up_for_retry]> in state up_for_retry
[2025-01-13T00:36:36.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.970+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:36:36.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:36.989+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:36:37.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T00:36:46.767+0000] {processor.py:157} INFO - Started process (PID=571) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:46.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:36:46.771+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:46.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.799+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:36:46.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.994+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17754983800023183
[2025-01-13T00:36:46.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.994+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|571]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:36:46.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.995+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:36:46.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.996+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:36:46.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.996+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:36:46.997+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:46.997+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|571]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:36:47.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.001+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|571]: It took 0.00466s to build the Airflow DAG.
[2025-01-13T00:36:47.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:36:47.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.018+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': '28b9b15e-58d7-413a-8f6b-d52c8dd5317f'}
[2025-01-13T00:36:47.037+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.037+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250113T003056, start_date=20250113T003111, end_date=20250113T003647
[2025-01-13T00:36:47.047+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 manual__2025-01-13T00:30:56.829391+00:00 [up_for_retry]> in state up_for_retry
[2025-01-13T00:36:47.050+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.050+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': 'aa4670dd-eb8a-47bb-93c9-6a5797261540'}
[2025-01-13T00:36:47.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.058+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250113T003056, start_date=20250113T003120, end_date=20250113T003647
[2025-01-13T00:36:47.062+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 manual__2025-01-13T00:30:56.829391+00:00 [failed]> in state failed
[2025-01-13T00:36:47.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.064+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': 'a76fd429-5c07-44a3-a508-64f0c8d68f6b'}
[2025-01-13T00:36:47.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.072+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250113T003056, start_date=20250113T003111, end_date=20250113T003647
[2025-01-13T00:36:47.076+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 manual__2025-01-13T00:30:56.829391+00:00 [up_for_retry]> in state up_for_retry
[2025-01-13T00:36:47.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.079+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': '28b9b15e-58d7-413a-8f6b-d52c8dd5317f'}
[2025-01-13T00:36:47.088+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.088+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250113T003056, start_date=20250113T003111, end_date=20250113T003647
[2025-01-13T00:36:47.092+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 manual__2025-01-13T00:30:56.829391+00:00 [failed]> in state failed
[2025-01-13T00:36:47.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.108+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:36:47.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:36:47.130+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:36:47.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.383 seconds
[2025-01-13T00:37:17.510+0000] {processor.py:157} INFO - Started process (PID=650) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:37:17.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:37:17.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:37:17.573+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.572+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:37:17.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.819+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21506107399909524
[2025-01-13T00:37:17.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.821+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|650]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:37:17.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.823+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:37:17.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.823+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:37:17.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.824+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:37:17.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.824+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|650]: It took 0.252s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:37:17.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.833+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|650]: It took 0.00875s to build the Airflow DAG.
[2025-01-13T00:37:17.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:37:17.864+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.864+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'manual__2025-01-13T00:30:56.829391+00:00', 'Hostname': '8e83bd89ed82', 'External Executor Id': 'a76fd429-5c07-44a3-a508-64f0c8d68f6b'}
[2025-01-13T00:37:17.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.915+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250113T003056, start_date=20250113T003111, end_date=20250113T003717
[2025-01-13T00:37:17.939+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 manual__2025-01-13T00:30:56.829391+00:00 [failed]> in state failed
[2025-01-13T00:37:17.971+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:17.971+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:37:18.002+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:18.001+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:37:18.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.519 seconds
[2025-01-13T00:37:48.815+0000] {processor.py:157} INFO - Started process (PID=755) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:37:48.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:37:48.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:48.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:37:48.844+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:48.843+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:37:49.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.071+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21282706199963286
[2025-01-13T00:37:49.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.072+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|755]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:37:49.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.073+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:37:49.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.074+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:37:49.075+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.075+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:37:49.076+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.075+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|755]: It took 0.232s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:37:49.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.082+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|755]: It took 0.00722s to build the Airflow DAG.
[2025-01-13T00:37:49.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:37:49.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.107+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:37:49.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:37:49.161+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:37:49.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.394 seconds
[2025-01-13T00:38:19.475+0000] {processor.py:157} INFO - Started process (PID=841) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:38:19.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:38:19.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:38:19.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.498+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:38:19.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.670+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15738594200047373
[2025-01-13T00:38:19.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.671+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|841]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:38:19.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.671+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:38:19.672+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.672+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:38:19.672+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.672+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:38:19.673+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.673+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|841]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:38:19.677+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.677+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|841]: It took 0.00408s to build the Airflow DAG.
[2025-01-13T00:38:19.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:38:19.693+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.693+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:38:19.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:19.719+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:38:19.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-13T00:38:50.207+0000] {processor.py:157} INFO - Started process (PID=927) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:38:50.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:38:50.211+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:38:50.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.234+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:38:50.420+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.420+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17023029799929645
[2025-01-13T00:38:50.421+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.421+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|927]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:38:50.422+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.422+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:38:50.423+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.423+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:38:50.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.424+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:38:50.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.424+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|927]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:38:50.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.430+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|927]: It took 0.00608s to build the Airflow DAG.
[2025-01-13T00:38:50.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:38:50.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.449+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:38:50.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:38:50.480+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:38:50.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-13T00:39:20.758+0000] {processor.py:157} INFO - Started process (PID=1013) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:39:20.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:39:20.761+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:39:20.782+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.782+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:39:20.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.929+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13395935200060194
[2025-01-13T00:39:20.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.930+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1013]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:39:20.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.931+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:39:20.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.931+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:39:20.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.931+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:39:20.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.932+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1013]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:39:20.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.935+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1013]: It took 0.00371s to build the Airflow DAG.
[2025-01-13T00:39:20.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:39:20.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.952+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:39:20.976+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:20.976+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:39:21.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-13T00:39:51.561+0000] {processor.py:157} INFO - Started process (PID=1099) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:39:51.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:39:51.567+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:39:51.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.599+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:39:51.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.862+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23951147099978698
[2025-01-13T00:39:51.863+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.863+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1099]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:39:51.865+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.865+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:39:51.866+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.866+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:39:51.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.866+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:39:51.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.867+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1099]: It took 0.268s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:39:51.874+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.874+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1099]: It took 0.00645s to build the Airflow DAG.
[2025-01-13T00:39:51.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:39:51.905+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.904+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:39:51.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:39:51.951+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:39:51.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.433 seconds
[2025-01-13T00:40:22.956+0000] {processor.py:157} INFO - Started process (PID=1193) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:40:22.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:40:22.960+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:22.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:40:22.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:22.982+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:40:23.173+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.173+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17460696499983897
[2025-01-13T00:40:23.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.174+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1193]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:40:23.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.174+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:40:23.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.175+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:40:23.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.175+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:40:23.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.176+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1193]: It took 0.194s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:40:23.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.181+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1193]: It took 0.00522s to build the Airflow DAG.
[2025-01-13T00:40:23.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:40:23.197+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.197+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:40:23.224+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:23.224+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:40:23.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.303 seconds
[2025-01-13T00:40:53.397+0000] {processor.py:157} INFO - Started process (PID=1290) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:40:53.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:40:53.402+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:40:53.447+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.446+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:40:53.720+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.720+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2496931660007249
[2025-01-13T00:40:53.721+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.721+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1290]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:40:53.722+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.722+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:40:53.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.723+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:40:53.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.723+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:40:53.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.724+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1290]: It took 0.278s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:40:53.731+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.731+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1290]: It took 0.00699s to build the Airflow DAG.
[2025-01-13T00:40:53.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:40:53.758+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.758+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:40:53.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:40:53.809+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:40:53.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.451 seconds
[2025-01-13T00:41:24.270+0000] {processor.py:157} INFO - Started process (PID=1374) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:41:24.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:41:24.280+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:41:24.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.330+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:41:24.774+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.773+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.40911973799848056
[2025-01-13T00:41:24.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.774+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1374]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:41:24.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.776+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 3768b87c1e98b044a3a6177b3bdd2ff7,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:41:24.779+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.778+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:41:24.781+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.781+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:41:24.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.784+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1374]: It took 0.454s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:41:24.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.814+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1374]: It took 0.0301s to build the Airflow DAG.
[2025-01-13T00:41:24.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:41:24.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.869+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:41:24.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:24.949+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:41:25.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.750 seconds
[2025-01-13T00:41:56.017+0000] {processor.py:157} INFO - Started process (PID=1441) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:41:56.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:41:56.025+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:41:56.090+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.089+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:41:56.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.745+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.614548105000722
[2025-01-13T00:41:56.747+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.746+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T00:41:56.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.748+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T00:41:56.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.763+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T00:41:56.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.800+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T00:41:56.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.802+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-13T00:41:56.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:41:56.804+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpb31p3lk5 --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T00:42:20.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.231+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6309624950008583
[2025-01-13T00:42:20.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.254+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T00:42:20.341+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.340+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:42:20.345+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.344+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:42:20.346+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.346+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1441]: It took 24.2s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T00:42:20.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.363+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1441]: It took 0.0176s to build the Airflow DAG.
[2025-01-13T00:42:20.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:42:20.421+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.420+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:42:20.504+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:20.503+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:42:20.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 24.572 seconds
[2025-01-13T00:42:51.288+0000] {processor.py:157} INFO - Started process (PID=1580) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:42:51.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:42:51.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:42:51.319+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.319+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:42:51.523+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.523+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1888004260017624
[2025-01-13T00:42:51.524+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.524+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1580]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:42:51.525+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.525+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:42:51.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.526+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:42:51.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.526+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:42:51.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.527+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1580]: It took 0.208s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:42:51.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.533+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1580]: It took 0.00651s to build the Airflow DAG.
[2025-01-13T00:42:51.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:42:51.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.552+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:42:51.583+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:42:51.582+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:42:51.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.321 seconds
[2025-01-13T00:43:21.687+0000] {processor.py:157} INFO - Started process (PID=1668) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:43:21.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:43:21.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:43:21.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.718+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:43:21.857+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.856+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12557691399888427
[2025-01-13T00:43:21.857+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.857+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1668]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:43:21.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.858+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:43:21.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.858+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:43:21.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.858+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:43:21.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.859+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1668]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:43:21.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.862+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1668]: It took 0.00355s to build the Airflow DAG.
[2025-01-13T00:43:21.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:43:21.877+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.876+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:43:21.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:21.898+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:43:21.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-13T00:43:52.051+0000] {processor.py:157} INFO - Started process (PID=1752) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:43:52.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:43:52.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:43:52.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.081+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:43:52.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.287+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19138789099997666
[2025-01-13T00:43:52.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.288+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1752]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:43:52.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.289+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:43:52.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.289+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:43:52.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.290+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:43:52.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.290+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1752]: It took 0.209s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:43:52.294+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.294+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1752]: It took 0.00376s to build the Airflow DAG.
[2025-01-13T00:43:52.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:43:52.309+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.309+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:43:52.336+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:43:52.335+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:43:52.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-13T00:44:23.050+0000] {processor.py:157} INFO - Started process (PID=1838) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:44:23.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:44:23.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:44:23.082+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.082+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:44:23.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.291+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1924343789996783
[2025-01-13T00:44:23.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.292+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1838]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:44:23.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.292+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:44:23.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.293+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:44:23.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.293+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:44:23.294+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.294+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1838]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:44:23.299+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.298+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1838]: It took 0.00474s to build the Airflow DAG.
[2025-01-13T00:44:23.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:44:23.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.314+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:44:23.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:23.340+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:44:23.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.314 seconds
[2025-01-13T00:44:53.420+0000] {processor.py:157} INFO - Started process (PID=1931) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:44:53.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:44:53.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:44:53.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.452+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:44:53.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.668+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19919834499887656
[2025-01-13T00:44:53.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.669+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|1931]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:44:53.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.670+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:44:53.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.671+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:44:53.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.671+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:44:53.672+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.672+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|1931]: It took 0.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:44:53.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.678+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|1931]: It took 0.00648s to build the Airflow DAG.
[2025-01-13T00:44:53.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:44:53.696+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.696+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:44:53.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:44:53.726+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:44:53.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.333 seconds
[2025-01-13T00:45:23.863+0000] {processor.py:157} INFO - Started process (PID=2031) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:45:23.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:45:23.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:23.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:45:23.890+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:23.890+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:45:24.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.031+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12766792200091004
[2025-01-13T00:45:24.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.032+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2031]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:45:24.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.033+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:45:24.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.033+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:45:24.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.034+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:45:24.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.034+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2031]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:45:24.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.038+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2031]: It took 0.00444s to build the Airflow DAG.
[2025-01-13T00:45:24.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:45:24.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.055+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:45:24.082+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:24.082+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:45:24.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-13T00:45:54.954+0000] {processor.py:157} INFO - Started process (PID=2117) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:45:54.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:45:54.957+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:54.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:45:54.978+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:54.978+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:45:55.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.148+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1560604329988564
[2025-01-13T00:45:55.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.148+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2117]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:45:55.149+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.149+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:45:55.149+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.149+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:45:55.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.149+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:45:55.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.150+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2117]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:45:55.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.153+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2117]: It took 0.00354s to build the Airflow DAG.
[2025-01-13T00:45:55.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:45:55.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.168+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:45:55.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:45:55.192+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:45:55.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-13T00:46:25.546+0000] {processor.py:157} INFO - Started process (PID=2203) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:46:25.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:46:25.550+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:46:25.574+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.574+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:46:25.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.743+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15512739999940095
[2025-01-13T00:46:25.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.743+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2203]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:46:25.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.744+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:46:25.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.744+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:46:25.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.745+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:46:25.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.745+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2203]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:46:25.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.749+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2203]: It took 0.00368s to build the Airflow DAG.
[2025-01-13T00:46:25.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:46:25.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.763+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:46:25.788+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:25.788+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:46:25.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-13T00:46:55.938+0000] {processor.py:157} INFO - Started process (PID=2292) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:46:55.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:46:55.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:55.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:46:55.971+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:55.971+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:46:56.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.144+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15825430100085214
[2025-01-13T00:46:56.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.145+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2292]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:46:56.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.145+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:46:56.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.146+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:46:56.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.146+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:46:56.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.146+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2292]: It took 0.176s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:46:56.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.151+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2292]: It took 0.00497s to build the Airflow DAG.
[2025-01-13T00:46:56.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:46:56.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.166+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:46:56.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:46:56.190+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:46:56.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-13T00:47:26.486+0000] {processor.py:157} INFO - Started process (PID=2386) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:47:26.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:47:26.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:47:26.528+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.528+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:47:26.706+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.706+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16146814099920448
[2025-01-13T00:47:26.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.707+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2386]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:47:26.708+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.708+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:47:26.708+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.708+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:47:26.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.709+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:47:26.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.709+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2386]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:47:26.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.713+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2386]: It took 0.00435s to build the Airflow DAG.
[2025-01-13T00:47:26.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:47:26.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.733+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:47:26.767+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:26.766+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:47:26.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.311 seconds
[2025-01-13T00:47:56.954+0000] {processor.py:157} INFO - Started process (PID=2484) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:47:56.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:47:56.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:56.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:47:56.987+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:56.987+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:47:57.199+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.199+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19296906499948818
[2025-01-13T00:47:57.199+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.199+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2484]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:47:57.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.200+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:47:57.201+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.201+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:47:57.201+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.201+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:47:57.202+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.201+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2484]: It took 0.215s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:47:57.206+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.206+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2484]: It took 0.00479s to build the Airflow DAG.
[2025-01-13T00:47:57.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:47:57.233+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.232+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:47:57.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:47:57.269+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:47:57.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.344 seconds
[2025-01-13T00:48:28.072+0000] {processor.py:157} INFO - Started process (PID=2570) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:48:28.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:48:28.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:48:28.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.108+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:48:28.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.324+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20019488300022203
[2025-01-13T00:48:28.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.325+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2570]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:48:28.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.326+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:48:28.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.326+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:48:28.327+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.327+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:48:28.327+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.327+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2570]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:48:28.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.332+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2570]: It took 0.00512s to build the Airflow DAG.
[2025-01-13T00:48:28.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:48:28.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.349+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:48:28.378+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:28.378+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:48:28.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.331 seconds
[2025-01-13T00:48:58.485+0000] {processor.py:157} INFO - Started process (PID=2656) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:48:58.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:48:58.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:48:58.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.513+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:48:58.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.678+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15134697500070615
[2025-01-13T00:48:58.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.678+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2656]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:48:58.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.679+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:48:58.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.679+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:48:58.680+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.680+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:48:58.680+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.680+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2656]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:48:58.684+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.684+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2656]: It took 0.00373s to build the Airflow DAG.
[2025-01-13T00:48:58.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:48:58.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.698+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:48:58.721+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:48:58.720+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:48:58.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-13T00:49:29.297+0000] {processor.py:157} INFO - Started process (PID=2742) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:49:29.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:49:29.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:49:29.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.325+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:49:29.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.501+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1572903470005258
[2025-01-13T00:49:29.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.501+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2742]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T00:49:29.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.502+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - b777ddbba1697d266d9b2ce4be675e0a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:49:29.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.502+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:49:29.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.502+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:49:29.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.503+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2742]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:49:29.507+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.507+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2742]: It took 0.00395s to build the Airflow DAG.
[2025-01-13T00:49:29.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:49:29.521+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.521+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:49:29.543+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:49:29.543+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:49:29.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T00:50:00.213+0000] {processor.py:157} INFO - Started process (PID=2836) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:50:00.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:50:00.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:50:00.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.241+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:50:00.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.501+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2456162870003027
[2025-01-13T00:50:00.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.502+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T00:50:00.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.503+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T00:50:00.509+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.509+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T00:50:00.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.518+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T00:50:00.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.519+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-13T00:50:00.520+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:00.519+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmp8hxzdcmt --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T00:50:10.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:10.994+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14687602399862953
[2025-01-13T00:50:10.998+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:10.998+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T00:50:11.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:11.005+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:50:11.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:11.006+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:50:11.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:11.006+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2836]: It took 10.8s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T00:50:11.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:11.012+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2836]: It took 0.00561s to build the Airflow DAG.
[2025-01-13T00:50:11.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:50:11.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:11.028+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:50:11.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:11.051+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:50:11.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 10.860 seconds
[2025-01-13T00:50:41.141+0000] {processor.py:157} INFO - Started process (PID=2996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:50:41.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:50:41.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:50:41.171+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.171+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:50:41.346+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.345+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1617020859994227
[2025-01-13T00:50:41.346+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.346+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|2996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:50:41.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.347+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 681077227cfa046f285286181319839b,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:50:41.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.348+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:50:41.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.348+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:50:41.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.349+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|2996]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:50:41.356+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.356+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|2996]: It took 0.00681s to build the Airflow DAG.
[2025-01-13T00:50:41.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:50:41.379+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.379+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:50:41.410+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:50:41.410+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:50:41.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-13T00:51:12.231+0000] {processor.py:157} INFO - Started process (PID=3101) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:51:12.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:51:12.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:51:12.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.258+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:51:12.454+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.454+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18078016099934757
[2025-01-13T00:51:12.455+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.455+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3101]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:51:12.456+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.456+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 681077227cfa046f285286181319839b,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:51:12.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.457+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:51:12.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.457+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:51:12.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.458+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3101]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:51:12.463+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.463+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3101]: It took 0.00514s to build the Airflow DAG.
[2025-01-13T00:51:12.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:51:12.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.482+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:51:12.511+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:12.511+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:51:12.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.303 seconds
[2025-01-13T00:51:42.734+0000] {processor.py:157} INFO - Started process (PID=3194) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:51:42.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:51:42.738+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:51:42.768+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.767+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:51:42.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.977+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19229934299983142
[2025-01-13T00:51:42.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.977+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T00:51:42.978+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.978+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T00:51:42.983+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.983+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T00:51:42.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.990+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T00:51:42.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.991+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-13T00:51:42.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:42.992+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpv0jv80rs --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T00:51:55.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.073+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.26291038100134756
[2025-01-13T00:51:55.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.083+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T00:51:55.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.096+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:51:55.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.098+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:51:55.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.099+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3194]: It took 12.3s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T00:51:55.110+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.109+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3194]: It took 0.0107s to build the Airflow DAG.
[2025-01-13T00:51:55.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:51:55.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.146+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:51:55.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:51:55.204+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:51:55.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 12.522 seconds
[2025-01-13T00:52:30.743+0000] {processor.py:157} INFO - Started process (PID=3295) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:52:30.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:52:30.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:30.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:52:30.842+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:30.842+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:52:32.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.070+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6080601029989339
[2025-01-13T00:52:32.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.077+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3295]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:52:32.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.080+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:52:32.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.082+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:52:32.088+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.087+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:52:32.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.089+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3295]: It took 1.25s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:52:32.110+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.109+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3295]: It took 0.0208s to build the Airflow DAG.
[2025-01-13T00:52:32.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:52:32.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.169+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:52:32.278+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:52:32.278+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:52:32.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.633 seconds
[2025-01-13T00:53:02.696+0000] {processor.py:157} INFO - Started process (PID=3380) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:53:02.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:53:02.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:53:02.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.726+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:53:02.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.881+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1406499780005106
[2025-01-13T00:53:02.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.881+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3380]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:53:02.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.882+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:53:02.883+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.882+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:53:02.883+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.883+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:53:02.884+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.883+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3380]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:53:02.888+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.888+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3380]: It took 0.00439s to build the Airflow DAG.
[2025-01-13T00:53:02.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:53:02.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.904+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:53:02.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:02.930+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:53:02.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-13T00:53:33.069+0000] {processor.py:157} INFO - Started process (PID=3464) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:53:33.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:53:33.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:53:33.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.114+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:53:33.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.281+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1497299340007885
[2025-01-13T00:53:33.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.282+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3464]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:53:33.283+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.283+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:53:33.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.284+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:53:33.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.284+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:53:33.285+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.284+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3464]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:53:33.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.289+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3464]: It took 0.00466s to build the Airflow DAG.
[2025-01-13T00:53:33.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:53:33.310+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.309+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:53:33.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:53:33.338+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:53:33.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.300 seconds
[2025-01-13T00:54:03.530+0000] {processor.py:157} INFO - Started process (PID=3550) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:54:03.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:54:03.538+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:54:03.571+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.570+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:54:03.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.749+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15995693200056849
[2025-01-13T00:54:03.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.750+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3550]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:54:03.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.751+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:54:03.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.751+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:54:03.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.751+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:54:03.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.752+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3550]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:54:03.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.756+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3550]: It took 0.00458s to build the Airflow DAG.
[2025-01-13T00:54:03.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:54:03.773+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.773+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:54:03.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:03.800+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:54:03.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-13T00:54:34.418+0000] {processor.py:157} INFO - Started process (PID=3636) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:54:34.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:54:34.421+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:54:34.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.445+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:54:34.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.605+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14606800799992925
[2025-01-13T00:54:34.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.605+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3636]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:54:34.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.606+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:54:34.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.606+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:54:34.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.607+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:54:34.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.607+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3636]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:54:34.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.611+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3636]: It took 0.00423s to build the Airflow DAG.
[2025-01-13T00:54:34.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:54:34.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.627+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:54:34.651+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:54:34.651+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:54:34.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-13T00:55:04.792+0000] {processor.py:157} INFO - Started process (PID=3731) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:55:04.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:55:04.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:04.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:55:04.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:04.818+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:55:05.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.020+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1856895370001439
[2025-01-13T00:55:05.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.020+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3731]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:55:05.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.021+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:55:05.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.022+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:55:05.023+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.022+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:55:05.023+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.023+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3731]: It took 0.205s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:55:05.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.028+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3731]: It took 0.0052s to build the Airflow DAG.
[2025-01-13T00:55:05.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:55:05.048+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.048+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:55:05.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:05.080+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:55:05.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.314 seconds
[2025-01-13T00:55:35.262+0000] {processor.py:157} INFO - Started process (PID=3829) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:55:35.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:55:35.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:55:35.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.289+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:55:35.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.491+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18416639499992016
[2025-01-13T00:55:35.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.492+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3829]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:55:35.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.493+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:55:35.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.494+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:55:35.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.494+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:55:35.495+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.495+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3829]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:55:35.499+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.499+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3829]: It took 0.0047s to build the Airflow DAG.
[2025-01-13T00:55:35.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:55:35.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.516+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:55:35.549+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:55:35.549+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:55:35.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-13T00:56:06.007+0000] {processor.py:157} INFO - Started process (PID=3913) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:56:06.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:56:06.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:56:06.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.036+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:56:06.201+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.201+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15082272000108787
[2025-01-13T00:56:06.201+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.201+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3913]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:56:06.202+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.202+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:56:06.203+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.202+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:56:06.203+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.203+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:56:06.203+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.203+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3913]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:56:06.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.207+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3913]: It took 0.00401s to build the Airflow DAG.
[2025-01-13T00:56:06.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:56:06.222+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.222+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:56:06.246+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:06.246+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:56:06.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-13T00:56:36.435+0000] {processor.py:157} INFO - Started process (PID=3999) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:56:36.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:56:36.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:56:36.463+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.463+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:56:36.632+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.631+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15536633299961977
[2025-01-13T00:56:36.632+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.632+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|3999]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:56:36.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.633+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:56:36.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.633+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:56:36.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.633+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:56:36.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.634+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|3999]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:56:36.637+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.637+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|3999]: It took 0.00367s to build the Airflow DAG.
[2025-01-13T00:56:36.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:56:36.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.652+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:56:36.676+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:56:36.676+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:56:36.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-13T00:57:06.851+0000] {processor.py:157} INFO - Started process (PID=4086) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:57:06.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:57:06.854+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:06.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:57:06.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:06.881+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:57:07.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.050+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15589515000101528
[2025-01-13T00:57:07.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.051+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4086]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:57:07.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.052+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:57:07.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.053+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:57:07.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.053+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:57:07.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.054+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4086]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:57:07.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.058+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4086]: It took 0.00462s to build the Airflow DAG.
[2025-01-13T00:57:07.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:57:07.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.073+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:57:07.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:07.098+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:57:07.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-13T00:57:37.236+0000] {processor.py:157} INFO - Started process (PID=4174) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:57:37.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:57:37.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:57:37.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.265+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:57:37.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.442+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16220859000168275
[2025-01-13T00:57:37.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.442+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4174]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:57:37.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.443+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:57:37.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.444+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:57:37.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.444+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:57:37.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.445+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4174]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:57:37.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.450+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4174]: It took 0.00578s to build the Airflow DAG.
[2025-01-13T00:57:37.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:57:37.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.469+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:57:37.497+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:57:37.497+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:57:37.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-13T00:58:07.634+0000] {processor.py:157} INFO - Started process (PID=4261) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:58:07.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:58:07.638+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:58:07.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.658+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:58:07.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.823+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15227537499958999
[2025-01-13T00:58:07.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.824+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4261]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:58:07.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.825+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:58:07.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.825+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:58:07.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.825+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:58:07.826+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.826+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4261]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:58:07.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.829+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4261]: It took 0.00386s to build the Airflow DAG.
[2025-01-13T00:58:07.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:58:07.845+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.845+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:58:07.871+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:07.871+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:58:07.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-13T00:58:38.409+0000] {processor.py:157} INFO - Started process (PID=4343) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:58:38.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:58:38.413+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:58:38.440+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.439+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:58:38.640+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.640+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18230948300151795
[2025-01-13T00:58:38.641+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.641+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4343]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:58:38.642+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.642+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:58:38.642+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.642+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:58:38.642+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.642+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:58:38.643+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.643+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4343]: It took 0.204s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:58:38.648+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.648+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4343]: It took 0.00495s to build the Airflow DAG.
[2025-01-13T00:58:38.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:58:38.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.668+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:58:38.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:58:38.704+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:58:38.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-13T00:59:08.790+0000] {processor.py:157} INFO - Started process (PID=4429) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:59:08.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:59:08.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:08.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:59:08.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:08.823+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:59:09.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.070+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22732390199962538
[2025-01-13T00:59:09.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.071+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4429]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:59:09.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.072+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:59:09.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.073+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:59:09.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.073+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:59:09.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.074+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4429]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:59:09.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.081+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4429]: It took 0.0071s to build the Airflow DAG.
[2025-01-13T00:59:09.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:59:09.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.107+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:59:09.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:09.176+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:59:09.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.433 seconds
[2025-01-13T00:59:40.011+0000] {processor.py:157} INFO - Started process (PID=4534) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:59:40.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T00:59:40.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:59:40.042+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.041+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T00:59:40.301+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.301+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23788091499955044
[2025-01-13T00:59:40.302+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.302+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4534]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T00:59:40.304+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.303+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T00:59:40.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.305+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T00:59:40.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.305+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T00:59:40.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.307+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4534]: It took 0.266s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T00:59:40.320+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.319+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4534]: It took 0.0128s to build the Airflow DAG.
[2025-01-13T00:59:40.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T00:59:40.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.360+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T00:59:40.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T00:59:40.423+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T00:59:40.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.477 seconds
[2025-01-13T01:00:10.576+0000] {processor.py:157} INFO - Started process (PID=4609) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:00:10.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:00:10.581+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:00:10.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.613+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:00:10.831+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.831+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19787904000077106
[2025-01-13T01:00:10.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.832+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4609]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:00:10.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.833+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:00:10.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.833+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:00:10.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.834+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:00:10.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.835+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4609]: It took 0.221s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:00:10.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.841+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4609]: It took 0.00656s to build the Airflow DAG.
[2025-01-13T01:00:10.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:00:10.879+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.878+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:00:10.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:10.928+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:00:10.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.397 seconds
[2025-01-13T01:00:41.432+0000] {processor.py:157} INFO - Started process (PID=4706) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:00:41.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:00:41.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:00:41.467+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.467+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:00:41.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.707+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2192327930006286
[2025-01-13T01:00:41.708+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.707+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4706]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:00:41.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.709+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:00:41.710+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.709+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:00:41.710+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.710+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:00:41.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.711+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4706]: It took 0.244s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:00:41.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.718+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4706]: It took 0.00755s to build the Airflow DAG.
[2025-01-13T01:00:41.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:00:41.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.742+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:00:41.780+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:00:41.780+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:00:41.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.384 seconds
[2025-01-13T01:01:12.125+0000] {processor.py:157} INFO - Started process (PID=4792) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:01:12.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:01:12.129+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:01:12.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.151+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:01:12.346+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.346+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17883335299848113
[2025-01-13T01:01:12.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.347+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4792]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:01:12.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.348+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:01:12.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.348+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:01:12.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.349+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:01:12.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.349+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4792]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:01:12.356+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.355+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4792]: It took 0.0062s to build the Airflow DAG.
[2025-01-13T01:01:12.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:01:12.374+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.373+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:01:12.402+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:12.402+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:01:12.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.303 seconds
[2025-01-13T01:01:42.523+0000] {processor.py:157} INFO - Started process (PID=4878) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:01:42.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:01:42.528+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:01:42.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.554+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:01:42.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.755+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18339637399913045
[2025-01-13T01:01:42.756+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.755+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4878]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:01:42.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.757+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:01:42.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.757+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:01:42.758+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.758+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:01:42.758+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.758+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4878]: It took 0.205s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:01:42.764+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.763+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4878]: It took 0.00524s to build the Airflow DAG.
[2025-01-13T01:01:42.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:01:42.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.782+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:01:42.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:01:42.811+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:01:42.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.314 seconds
[2025-01-13T01:02:13.061+0000] {processor.py:157} INFO - Started process (PID=4964) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:02:13.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:02:13.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:02:13.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.089+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:02:13.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.284+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17897983200055023
[2025-01-13T01:02:13.285+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.285+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|4964]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:02:13.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.286+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:02:13.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.286+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:02:13.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.287+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:02:13.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.287+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|4964]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:02:13.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.292+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|4964]: It took 0.00479s to build the Airflow DAG.
[2025-01-13T01:02:13.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:02:13.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.313+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:02:13.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:13.349+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:02:13.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.314 seconds
[2025-01-13T01:02:43.439+0000] {processor.py:157} INFO - Started process (PID=5050) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:02:43.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:02:43.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:02:43.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.485+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:02:43.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.810+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.29885115299839526
[2025-01-13T01:02:43.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.812+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5050]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:02:43.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.815+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:02:43.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.816+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:02:43.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.817+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:02:43.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.818+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5050]: It took 0.333s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:02:43.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.829+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5050]: It took 0.0113s to build the Airflow DAG.
[2025-01-13T01:02:43.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:02:43.886+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.885+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:02:43.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:02:43.988+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:02:44.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.598 seconds
[2025-01-13T01:03:14.389+0000] {processor.py:157} INFO - Started process (PID=5136) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:03:14.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:03:14.398+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:03:14.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.450+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:03:14.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.756+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.27492984799937403
[2025-01-13T01:03:14.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.757+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5136]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:03:14.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.759+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:03:14.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.759+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:03:14.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.760+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:03:14.761+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.760+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5136]: It took 0.311s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:03:14.769+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.769+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5136]: It took 0.00858s to build the Airflow DAG.
[2025-01-13T01:03:14.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:03:14.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.800+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:03:14.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:14.855+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:03:14.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.515 seconds
[2025-01-13T01:03:45.460+0000] {processor.py:157} INFO - Started process (PID=5222) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:03:45.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:03:45.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:03:45.499+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.499+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:03:45.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.740+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22518609299913805
[2025-01-13T01:03:45.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.740+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5222]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:03:45.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.741+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:03:45.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.742+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:03:45.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.743+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:03:45.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.744+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5222]: It took 0.245s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:03:45.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.749+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5222]: It took 0.00563s to build the Airflow DAG.
[2025-01-13T01:03:45.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:03:45.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.770+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:03:45.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:03:45.802+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:03:45.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.370 seconds
[2025-01-13T01:04:16.192+0000] {processor.py:157} INFO - Started process (PID=5308) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:04:16.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:04:16.197+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:04:16.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.230+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:04:16.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.458+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20817124399945897
[2025-01-13T01:04:16.459+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.458+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5308]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:04:16.459+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.459+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:04:16.460+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.460+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:04:16.461+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.461+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:04:16.462+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.461+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5308]: It took 0.232s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:04:16.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.468+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5308]: It took 0.00634s to build the Airflow DAG.
[2025-01-13T01:04:16.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:04:16.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.490+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:04:16.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:16.519+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:04:16.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.355 seconds
[2025-01-13T01:04:46.591+0000] {processor.py:157} INFO - Started process (PID=5395) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:04:46.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:04:46.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:04:46.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.623+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:04:46.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.813+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17356346799897437
[2025-01-13T01:04:46.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.814+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5395]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:04:46.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.815+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:04:46.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.815+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:04:46.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.815+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:04:46.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.816+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5395]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:04:46.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.821+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5395]: It took 0.00548s to build the Airflow DAG.
[2025-01-13T01:04:46.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:04:46.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.838+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:04:46.864+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:04:46.863+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:04:46.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.296 seconds
[2025-01-13T01:05:16.929+0000] {processor.py:157} INFO - Started process (PID=5502) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:05:16.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:05:16.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:16.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:05:16.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:16.964+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:05:17.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.182+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1977610640005878
[2025-01-13T01:05:17.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.182+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5502]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:05:17.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.183+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:05:17.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.184+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:05:17.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.184+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:05:17.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.185+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5502]: It took 0.221s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:05:17.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.190+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5502]: It took 0.00506s to build the Airflow DAG.
[2025-01-13T01:05:17.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:05:17.208+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.208+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:05:17.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:17.237+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:05:17.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.340 seconds
[2025-01-13T01:05:47.419+0000] {processor.py:157} INFO - Started process (PID=5589) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:05:47.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:05:47.422+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:05:47.448+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.448+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:05:47.636+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.636+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17259618199932447
[2025-01-13T01:05:47.637+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.636+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5589]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:05:47.638+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.637+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:05:47.638+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.638+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:05:47.638+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.638+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:05:47.639+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.639+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5589]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:05:47.643+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.643+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5589]: It took 0.00426s to build the Airflow DAG.
[2025-01-13T01:05:47.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:05:47.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.659+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:05:47.683+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:05:47.683+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:05:47.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-13T01:06:17.793+0000] {processor.py:157} INFO - Started process (PID=5677) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:06:17.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:06:17.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:17.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:06:17.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:17.823+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:06:18.049+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.048+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20911948799948732
[2025-01-13T01:06:18.049+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.049+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5677]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:06:18.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.050+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:06:18.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.051+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:06:18.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.052+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:06:18.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.052+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5677]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:06:18.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.058+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5677]: It took 0.00608s to build the Airflow DAG.
[2025-01-13T01:06:18.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:06:18.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.078+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:06:18.109+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:18.109+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:06:18.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.342 seconds
[2025-01-13T01:06:48.188+0000] {processor.py:157} INFO - Started process (PID=5765) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:06:48.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:06:48.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:06:48.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.219+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:06:48.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.393+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1593330320010864
[2025-01-13T01:06:48.394+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.394+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5765]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:06:48.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.394+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:06:48.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.395+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:06:48.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.395+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:06:48.396+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.396+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5765]: It took 0.176s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:06:48.400+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.400+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5765]: It took 0.00428s to build the Airflow DAG.
[2025-01-13T01:06:48.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:06:48.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.417+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:06:48.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:06:48.444+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:06:48.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-13T01:07:18.590+0000] {processor.py:157} INFO - Started process (PID=5870) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:07:18.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:07:18.593+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:07:18.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.615+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:07:18.781+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.781+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15070250000098895
[2025-01-13T01:07:18.781+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.781+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5870]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:07:18.782+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.782+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:07:18.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.782+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:07:18.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.783+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:07:18.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.783+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5870]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:07:18.788+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.788+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5870]: It took 0.00506s to build the Airflow DAG.
[2025-01-13T01:07:18.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:07:18.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.804+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:07:18.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:18.830+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:07:18.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-13T01:07:48.964+0000] {processor.py:157} INFO - Started process (PID=5957) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:07:48.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:07:48.968+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:48.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:07:48.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:48.992+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:07:49.164+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.164+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15776461899986316
[2025-01-13T01:07:49.165+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.165+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|5957]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4365
[2025-01-13T01:07:49.165+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.165+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 631cee60bcd58662e7cf13f6293519e3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:07:49.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.166+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:07:49.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.166+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:07:49.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.166+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|5957]: It took 0.175s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:07:49.170+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.170+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|5957]: It took 0.00388s to build the Airflow DAG.
[2025-01-13T01:07:49.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:07:49.187+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.187+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:07:49.215+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:07:49.215+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:07:49.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-13T01:08:19.294+0000] {processor.py:157} INFO - Started process (PID=6045) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:08:19.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:08:19.299+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:08:19.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.331+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:08:19.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.587+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23604171099941595
[2025-01-13T01:08:19.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.588+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T01:08:19.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.589+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T01:08:19.597+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.597+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T01:08:19.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.609+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T01:08:19.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.610+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-13T01:08:19.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:19.611+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpjhgmxwj8 --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T01:08:29.642+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.642+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17240633399887884
[2025-01-13T01:08:29.647+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.647+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T01:08:29.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.653+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:08:29.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.654+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:08:29.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.655+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6045]: It took 10.3s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T01:08:29.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.661+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6045]: It took 0.00643s to build the Airflow DAG.
[2025-01-13T01:08:29.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:08:29.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.678+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:08:29.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:08:29.704+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:08:29.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 10.437 seconds
[2025-01-13T01:09:00.662+0000] {processor.py:157} INFO - Started process (PID=6198) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:09:00.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:09:00.665+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:09:00.696+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.696+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:09:00.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.859+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14950947199940856
[2025-01-13T01:09:00.860+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.860+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6198]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:09:00.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.861+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:09:00.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.862+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:09:00.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.862+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:09:00.863+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.863+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6198]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:09:00.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.867+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6198]: It took 0.00441s to build the Airflow DAG.
[2025-01-13T01:09:00.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:09:00.885+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.885+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:09:00.911+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:00.911+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:09:00.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-13T01:09:31.930+0000] {processor.py:157} INFO - Started process (PID=6284) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:09:31.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:09:31.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:31.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:09:31.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:31.955+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:09:32.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.114+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14623742200092238
[2025-01-13T01:09:32.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.114+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6284]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:09:32.115+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.115+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:09:32.116+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.116+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:09:32.116+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.116+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:09:32.117+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.116+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6284]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:09:32.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.120+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6284]: It took 0.00377s to build the Airflow DAG.
[2025-01-13T01:09:32.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:09:32.134+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.134+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:09:32.156+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:09:32.156+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:09:32.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-13T01:10:02.230+0000] {processor.py:157} INFO - Started process (PID=6389) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:10:02.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:10:02.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:10:02.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.260+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:10:02.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.427+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15133402300125454
[2025-01-13T01:10:02.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.427+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6389]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:10:02.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.428+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:10:02.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.428+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:10:02.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.429+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:10:02.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.429+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6389]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:10:02.435+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.434+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6389]: It took 0.00537s to build the Airflow DAG.
[2025-01-13T01:10:02.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:10:02.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.450+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:10:02.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:02.475+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:10:02.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-13T01:10:33.415+0000] {processor.py:157} INFO - Started process (PID=6475) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:10:33.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:10:33.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:10:33.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.442+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:10:33.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.589+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13342046000070695
[2025-01-13T01:10:33.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.589+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6475]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:10:33.590+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.590+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:10:33.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.590+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:10:33.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.591+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:10:33.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.591+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6475]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:10:33.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.595+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6475]: It took 0.0043s to build the Airflow DAG.
[2025-01-13T01:10:33.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:10:33.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.610+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:10:33.632+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:10:33.632+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:10:33.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-13T01:11:04.624+0000] {processor.py:157} INFO - Started process (PID=6561) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:11:04.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:11:04.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:11:04.651+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.651+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:11:04.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.808+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14215140600026643
[2025-01-13T01:11:04.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.808+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6561]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:11:04.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.809+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:11:04.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.809+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:11:04.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.810+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:11:04.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.810+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6561]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:11:04.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.814+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6561]: It took 0.00374s to build the Airflow DAG.
[2025-01-13T01:11:04.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:11:04.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:11:04.855+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:04.855+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:11:04.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-13T01:11:34.996+0000] {processor.py:157} INFO - Started process (PID=6655) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:11:34.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:11:35.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:11:35.029+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.029+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:11:35.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.230+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1857326749995991
[2025-01-13T01:11:35.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.231+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6655]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:11:35.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.232+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:11:35.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.232+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:11:35.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.232+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:11:35.233+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.233+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6655]: It took 0.204s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:11:35.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.237+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6655]: It took 0.00388s to build the Airflow DAG.
[2025-01-13T01:11:35.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:11:35.252+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.252+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:11:35.278+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:11:35.278+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:11:35.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-13T01:12:06.228+0000] {processor.py:157} INFO - Started process (PID=6752) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:12:06.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:12:06.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:12:06.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.254+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:12:06.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.395+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1279159850000724
[2025-01-13T01:12:06.396+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.395+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6752]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:12:06.396+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.396+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:12:06.397+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.397+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:12:06.397+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.397+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:12:06.397+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.397+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6752]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:12:06.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.401+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6752]: It took 0.00373s to build the Airflow DAG.
[2025-01-13T01:12:06.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:12:06.416+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.416+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:12:06.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:06.438+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:12:06.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-13T01:12:37.186+0000] {processor.py:157} INFO - Started process (PID=6838) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:12:37.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:12:37.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:12:37.219+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.219+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:12:37.386+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.386+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15355052999984764
[2025-01-13T01:12:37.386+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.386+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6838]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:12:37.390+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.390+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:12:37.407+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.406+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:12:37.407+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.407+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:12:37.408+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.408+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6838]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:12:37.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.415+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6838]: It took 0.00717s to build the Airflow DAG.
[2025-01-13T01:12:37.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:12:37.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.433+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:12:37.462+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:12:37.461+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:12:37.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.309 seconds
[2025-01-13T01:13:08.423+0000] {processor.py:157} INFO - Started process (PID=6924) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:13:08.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:13:08.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:13:08.450+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.450+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:13:08.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.606+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14321267000013904
[2025-01-13T01:13:08.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.607+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|6924]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:13:08.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.609+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:13:08.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.609+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:13:08.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.610+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:13:08.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.610+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|6924]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:13:08.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.616+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|6924]: It took 0.00586s to build the Airflow DAG.
[2025-01-13T01:13:08.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:13:08.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.633+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:13:08.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:08.660+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:13:08.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-13T01:13:39.693+0000] {processor.py:157} INFO - Started process (PID=7029) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:13:39.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:13:39.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:13:39.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.742+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:13:39.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.895+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1348391259998607
[2025-01-13T01:13:39.896+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.896+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7029]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:13:39.897+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.896+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:13:39.897+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.897+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:13:39.897+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.897+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:13:39.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.898+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7029]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:13:39.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.902+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7029]: It took 0.00393s to build the Airflow DAG.
[2025-01-13T01:13:39.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:13:39.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.916+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:13:39.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:13:39.946+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:13:39.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-13T01:14:10.931+0000] {processor.py:157} INFO - Started process (PID=7116) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:14:10.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:14:10.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:10.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:14:10.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:10.963+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:14:11.107+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.106+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12989955400007602
[2025-01-13T01:14:11.107+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.107+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7116]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:14:11.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.108+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:14:11.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.108+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:14:11.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.108+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:14:11.109+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.109+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7116]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:14:11.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.112+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7116]: It took 0.00354s to build the Airflow DAG.
[2025-01-13T01:14:11.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:14:11.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.126+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:14:11.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:11.147+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:14:11.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-13T01:14:41.356+0000] {processor.py:157} INFO - Started process (PID=7202) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:14:41.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:14:41.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:14:41.384+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.383+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:14:41.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.533+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13704786500056798
[2025-01-13T01:14:41.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.533+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7202]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:14:41.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.534+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:14:41.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.534+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:14:41.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.535+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:14:41.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.535+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7202]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:14:41.539+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.539+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7202]: It took 0.00363s to build the Airflow DAG.
[2025-01-13T01:14:41.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:14:41.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.553+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:14:41.575+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:14:41.575+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:14:41.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-13T01:15:12.600+0000] {processor.py:157} INFO - Started process (PID=7307) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:15:12.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:15:12.604+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:15:12.635+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.635+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:15:12.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.804+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15348998799890978
[2025-01-13T01:15:12.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.804+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7307]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:15:12.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.805+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:15:12.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.805+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:15:12.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.805+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:15:12.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.806+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7307]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:15:12.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.809+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7307]: It took 0.0036s to build the Airflow DAG.
[2025-01-13T01:15:12.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:15:12.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.824+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:15:12.846+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:12.846+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:15:12.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-13T01:15:43.735+0000] {processor.py:157} INFO - Started process (PID=7393) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:15:43.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:15:43.738+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:15:43.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.763+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:15:43.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.893+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11799150799924973
[2025-01-13T01:15:43.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.893+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7393]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:15:43.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.894+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:15:43.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.895+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:15:43.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.895+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:15:43.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.895+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7393]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:15:43.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.899+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7393]: It took 0.00361s to build the Airflow DAG.
[2025-01-13T01:15:43.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:15:43.912+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.912+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:15:43.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:15:43.933+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:15:43.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-13T01:16:14.055+0000] {processor.py:157} INFO - Started process (PID=7479) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:16:14.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:16:14.059+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:16:14.086+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.086+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:16:14.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.243+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14359832199988887
[2025-01-13T01:16:14.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.243+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7479]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:16:14.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.244+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:16:14.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.244+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:16:14.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.244+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:16:14.245+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.245+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7479]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:16:14.249+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.249+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7479]: It took 0.00386s to build the Airflow DAG.
[2025-01-13T01:16:14.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:16:14.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.264+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:16:14.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:14.289+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:16:14.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-13T01:16:44.754+0000] {processor.py:157} INFO - Started process (PID=7584) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:16:44.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:16:44.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:16:44.785+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.785+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:16:44.940+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.940+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14054871400003321
[2025-01-13T01:16:44.941+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.941+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7584]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:16:44.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.942+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:16:44.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.942+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:16:44.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.943+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:16:44.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.943+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7584]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:16:44.947+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.947+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7584]: It took 0.00413s to build the Airflow DAG.
[2025-01-13T01:16:44.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:16:44.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.961+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:16:44.983+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:16:44.983+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:16:45.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-13T01:17:15.964+0000] {processor.py:157} INFO - Started process (PID=7670) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:17:15.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:17:15.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:15.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:17:15.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:15.996+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:17:16.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.158+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14896200800103543
[2025-01-13T01:17:16.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.159+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7670]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:17:16.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.160+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:17:16.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.160+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:17:16.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.161+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:17:16.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.161+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7670]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:17:16.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.166+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7670]: It took 0.0048s to build the Airflow DAG.
[2025-01-13T01:17:16.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:17:16.180+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.180+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:17:16.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:16.200+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:17:16.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-13T01:17:46.899+0000] {processor.py:157} INFO - Started process (PID=7756) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:17:46.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:17:46.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:46.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:17:46.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:46.926+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:17:47.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.079+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14088733999960823
[2025-01-13T01:17:47.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.080+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7756]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:17:47.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.080+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:17:47.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.081+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:17:47.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.081+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:17:47.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.081+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7756]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:17:47.085+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.085+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7756]: It took 0.00354s to build the Airflow DAG.
[2025-01-13T01:17:47.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:17:47.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.098+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:17:47.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:17:47.120+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:17:47.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-13T01:18:17.219+0000] {processor.py:157} INFO - Started process (PID=7851) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:18:17.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:18:17.222+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:18:17.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.254+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:18:17.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.443+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17416862800018862
[2025-01-13T01:18:17.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.444+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7851]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:18:17.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.444+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:18:17.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.445+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:18:17.446+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.446+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:18:17.446+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.446+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7851]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:18:17.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.451+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7851]: It took 0.0048s to build the Airflow DAG.
[2025-01-13T01:18:17.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:18:17.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.469+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:18:17.495+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:17.495+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:18:17.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-13T01:18:47.600+0000] {processor.py:157} INFO - Started process (PID=7948) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:18:47.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:18:47.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:18:47.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.629+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:18:47.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.777+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1356521600009728
[2025-01-13T01:18:47.778+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.778+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|7948]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:18:47.778+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.778+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:18:47.779+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.779+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:18:47.779+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.779+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:18:47.780+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.780+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|7948]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:18:47.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.784+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|7948]: It took 0.00412s to build the Airflow DAG.
[2025-01-13T01:18:47.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:18:47.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.797+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:18:47.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:18:47.818+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:18:47.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-13T01:19:18.872+0000] {processor.py:157} INFO - Started process (PID=8035) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:19:18.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:19:18.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:18.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:19:18.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:18.903+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:19:19.049+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.049+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13305904200024088
[2025-01-13T01:19:19.049+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.049+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8035]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:19:19.050+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.050+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:19:19.050+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.050+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:19:19.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.051+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:19:19.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.051+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8035]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:19:19.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.055+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8035]: It took 0.00367s to build the Airflow DAG.
[2025-01-13T01:19:19.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:19:19.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.069+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:19:19.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:19.092+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:19:19.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-13T01:19:49.179+0000] {processor.py:157} INFO - Started process (PID=8121) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:19:49.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:19:49.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:19:49.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.210+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:19:49.389+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.389+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16631433899965486
[2025-01-13T01:19:49.390+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.390+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8121]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:19:49.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.391+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:19:49.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.391+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:19:49.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.391+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:19:49.392+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.392+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8121]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:19:49.396+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.396+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8121]: It took 0.00449s to build the Airflow DAG.
[2025-01-13T01:19:49.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:19:49.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.412+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:19:49.441+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:19:49.441+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:19:49.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-13T01:20:20.452+0000] {processor.py:157} INFO - Started process (PID=8226) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:20:20.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:20:20.455+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:20:20.477+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.477+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:20:20.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.618+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12902310999925248
[2025-01-13T01:20:20.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.619+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8226]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:20:20.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.619+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:20:20.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.620+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:20:20.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.620+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:20:20.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.620+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8226]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:20:20.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.624+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8226]: It took 0.00343s to build the Airflow DAG.
[2025-01-13T01:20:20.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:20:20.637+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.637+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:20:20.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:20.657+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:20:20.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-13T01:20:50.895+0000] {processor.py:157} INFO - Started process (PID=8312) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:20:50.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:20:50.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:50.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:20:50.922+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:50.922+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:20:51.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.052+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11788286299997708
[2025-01-13T01:20:51.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.053+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8312]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:20:51.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.054+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:20:51.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.054+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:20:51.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.054+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:20:51.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.055+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8312]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:20:51.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.058+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8312]: It took 0.0036s to build the Airflow DAG.
[2025-01-13T01:20:51.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:20:51.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.071+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:20:51.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:20:51.092+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:20:51.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-13T01:21:21.252+0000] {processor.py:157} INFO - Started process (PID=8399) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:21:21.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:21:21.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:21:21.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.282+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:21:21.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.424+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12912692399913794
[2025-01-13T01:21:21.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.424+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8399]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:21:21.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.425+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:21:21.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.425+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:21:21.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.425+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:21:21.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.426+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8399]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:21:21.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.430+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8399]: It took 0.0042s to build the Airflow DAG.
[2025-01-13T01:21:21.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:21:21.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.443+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:21:21.464+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:21.464+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:21:21.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.388 seconds
[2025-01-13T01:21:52.520+0000] {processor.py:157} INFO - Started process (PID=8504) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:21:52.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:21:52.523+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:21:52.552+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.552+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:21:52.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.775+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2108884829995077
[2025-01-13T01:21:52.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.776+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8504]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:21:52.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.777+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:21:52.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.777+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:21:52.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.777+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:21:52.778+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.778+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8504]: It took 0.226s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:21:52.782+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.782+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8504]: It took 0.00408s to build the Airflow DAG.
[2025-01-13T01:21:52.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:21:52.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.796+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:21:52.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:21:52.819+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:21:52.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.320 seconds
[2025-01-13T01:22:22.910+0000] {processor.py:157} INFO - Started process (PID=8590) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:22:22.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:22:22.914+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:22.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:22:22.939+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:22.939+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:22:23.088+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.088+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13621039700046822
[2025-01-13T01:22:23.088+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.088+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8590]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:22:23.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.089+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:22:23.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.089+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:22:23.090+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.090+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:22:23.090+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.090+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8590]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:22:23.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.094+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8590]: It took 0.00353s to build the Airflow DAG.
[2025-01-13T01:22:23.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:22:23.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.112+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:22:23.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:23.143+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:22:23.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-13T01:22:54.116+0000] {processor.py:157} INFO - Started process (PID=8676) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:22:54.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:22:54.119+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:22:54.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.143+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:22:54.275+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.275+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12013757500062638
[2025-01-13T01:22:54.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.276+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8676]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:22:54.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.276+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:22:54.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.277+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:22:54.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.277+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:22:54.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.277+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8676]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:22:54.281+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.281+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8676]: It took 0.00385s to build the Airflow DAG.
[2025-01-13T01:22:54.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:22:54.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.295+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:22:54.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:22:54.487+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:22:54.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.400 seconds
[2025-01-13T01:23:24.705+0000] {processor.py:157} INFO - Started process (PID=8770) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:23:24.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:23:24.712+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:23:24.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.746+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:23:24.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.924+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16382346700083872
[2025-01-13T01:23:24.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.925+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8770]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:23:24.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.926+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:23:24.927+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.927+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:23:24.927+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.927+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:23:24.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.927+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8770]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:23:24.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.933+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8770]: It took 0.00586s to build the Airflow DAG.
[2025-01-13T01:23:24.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:23:24.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.951+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:23:24.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:24.982+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:23:25.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.313 seconds
[2025-01-13T01:23:55.486+0000] {processor.py:157} INFO - Started process (PID=8867) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:23:55.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:23:55.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:23:55.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.514+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:23:55.657+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.657+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13078908999887062
[2025-01-13T01:23:55.657+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.657+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8867]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:23:55.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.658+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:23:55.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.658+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:23:55.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.659+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:23:55.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.659+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8867]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:23:55.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.662+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8867]: It took 0.00351s to build the Airflow DAG.
[2025-01-13T01:23:55.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:23:55.677+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.677+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:23:55.698+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:23:55.698+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:23:55.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-13T01:24:26.623+0000] {processor.py:157} INFO - Started process (PID=8954) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:24:26.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:24:26.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:24:26.651+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.651+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:24:26.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.811+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14658170800066728
[2025-01-13T01:24:26.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.812+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|8954]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:24:26.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.812+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:24:26.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.813+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:24:26.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.813+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:24:26.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.814+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|8954]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:24:26.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.817+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|8954]: It took 0.00379s to build the Airflow DAG.
[2025-01-13T01:24:26.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:24:26.831+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:26.831+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:24:27.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:27.004+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:24:27.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.409 seconds
[2025-01-13T01:24:57.283+0000] {processor.py:157} INFO - Started process (PID=9040) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:24:57.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:24:57.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:24:57.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.324+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:24:57.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.491+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14333571099996334
[2025-01-13T01:24:57.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.492+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9040]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:24:57.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.492+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:24:57.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.493+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:24:57.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.493+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:24:57.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.493+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9040]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:24:57.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.498+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9040]: It took 0.00411s to build the Airflow DAG.
[2025-01-13T01:24:57.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:24:57.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.513+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:24:57.537+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:24:57.537+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:24:57.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-13T01:25:27.872+0000] {processor.py:157} INFO - Started process (PID=9145) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:25:27.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:25:27.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:27.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:25:27.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:27.902+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:25:28.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.053+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13537711900062277
[2025-01-13T01:25:28.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.053+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9145]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:25:28.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.054+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:25:28.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.054+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:25:28.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.055+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:25:28.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.055+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9145]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:25:28.059+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.059+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9145]: It took 0.00369s to build the Airflow DAG.
[2025-01-13T01:25:28.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:25:28.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.072+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:25:28.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:28.093+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:25:28.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-13T01:25:58.850+0000] {processor.py:157} INFO - Started process (PID=9231) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:25:58.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:25:58.853+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:58.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:25:58.876+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:58.875+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:25:59.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.016+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12754078999932972
[2025-01-13T01:25:59.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.016+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9231]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:25:59.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.017+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:25:59.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.017+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:25:59.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.018+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:25:59.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.018+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9231]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:25:59.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.021+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9231]: It took 0.00331s to build the Airflow DAG.
[2025-01-13T01:25:59.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:25:59.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.035+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:25:59.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:25:59.220+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:25:59.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.397 seconds
[2025-01-13T01:26:29.656+0000] {processor.py:157} INFO - Started process (PID=9317) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:26:29.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:26:29.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:26:29.682+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.682+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:26:29.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.835+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1401119040001504
[2025-01-13T01:26:29.836+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.835+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9317]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:26:29.836+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.836+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:26:29.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.837+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:26:29.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.837+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:26:29.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.837+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9317]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:26:29.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.841+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9317]: It took 0.00386s to build the Airflow DAG.
[2025-01-13T01:26:29.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:26:29.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.858+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:26:29.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:26:29.881+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:26:29.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-13T01:27:00.474+0000] {processor.py:157} INFO - Started process (PID=9422) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:27:00.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:27:00.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:27:00.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.503+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:27:00.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.661+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14559990799898515
[2025-01-13T01:27:00.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.662+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9422]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:27:00.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.663+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:27:00.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.663+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:27:00.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.663+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:27:00.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.664+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9422]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:27:00.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.668+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9422]: It took 0.00421s to build the Airflow DAG.
[2025-01-13T01:27:00.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:27:00.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.838+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:27:00.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:00.859+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:27:00.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.406 seconds
[2025-01-13T01:27:30.968+0000] {processor.py:157} INFO - Started process (PID=9509) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:27:30.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:27:30.971+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:30.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:27:30.998+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:30.997+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:27:31.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.136+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12546430099973804
[2025-01-13T01:27:31.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.137+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9509]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:27:31.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.137+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:27:31.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.138+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:27:31.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.138+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:27:31.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.138+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9509]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:27:31.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.142+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9509]: It took 0.00383s to build the Airflow DAG.
[2025-01-13T01:27:31.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:27:31.156+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.156+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:27:31.343+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:27:31.343+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:27:31.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.404 seconds
[2025-01-13T01:28:02.181+0000] {processor.py:157} INFO - Started process (PID=9595) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:28:02.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:28:02.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:28:02.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.210+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:28:02.357+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.357+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13383011600126338
[2025-01-13T01:28:02.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.358+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9595]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:28:02.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.359+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:28:02.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.359+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:28:02.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.359+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:28:02.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.360+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9595]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:28:02.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.364+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9595]: It took 0.00417s to build the Airflow DAG.
[2025-01-13T01:28:02.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:28:02.379+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.379+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:28:02.402+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:02.402+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:28:02.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.396 seconds
[2025-01-13T01:28:32.617+0000] {processor.py:157} INFO - Started process (PID=9689) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:28:32.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:28:32.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:28:32.640+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.640+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:28:32.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.834+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18010095600038767
[2025-01-13T01:28:32.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.834+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9689]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:28:32.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.835+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:28:32.836+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.836+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:28:32.836+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.836+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:28:32.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.837+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9689]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:28:32.843+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.842+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9689]: It took 0.00583s to build the Airflow DAG.
[2025-01-13T01:28:32.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:28:32.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.859+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:28:32.889+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:28:32.888+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:28:32.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.296 seconds
[2025-01-13T01:29:03.422+0000] {processor.py:157} INFO - Started process (PID=9786) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:29:03.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:29:03.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:29:03.448+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.448+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:29:03.602+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.602+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14058746899900143
[2025-01-13T01:29:03.602+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.602+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9786]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:29:03.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.603+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:29:03.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.603+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:29:03.604+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.604+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:29:03.604+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.604+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9786]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:29:03.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.607+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9786]: It took 0.00353s to build the Airflow DAG.
[2025-01-13T01:29:03.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:29:03.780+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.780+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:29:03.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:03.799+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:29:03.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.399 seconds
[2025-01-13T01:29:34.477+0000] {processor.py:157} INFO - Started process (PID=9872) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:29:34.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:29:34.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:29:34.507+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.507+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:29:34.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.664+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14334507399871654
[2025-01-13T01:29:34.665+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.664+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9872]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:29:34.665+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.665+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:29:34.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.666+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:29:34.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.666+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:29:34.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.666+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9872]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:29:34.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.670+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9872]: It took 0.00408s to build the Airflow DAG.
[2025-01-13T01:29:34.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:29:34.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.686+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:29:34.896+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:29:34.896+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:29:34.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.439 seconds
[2025-01-13T01:30:05.042+0000] {processor.py:157} INFO - Started process (PID=9966) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:30:05.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:30:05.045+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:30:05.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.069+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:30:05.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.227+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14267199099958816
[2025-01-13T01:30:05.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.227+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|9966]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:30:05.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.228+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:30:05.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.229+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:30:05.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.229+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:30:05.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.229+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|9966]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:30:05.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.234+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|9966]: It took 0.0045s to build the Airflow DAG.
[2025-01-13T01:30:05.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:30:05.250+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.249+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:30:05.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:05.276+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:30:05.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-13T01:30:35.388+0000] {processor.py:157} INFO - Started process (PID=10063) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:30:35.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:30:35.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:30:35.411+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.411+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:30:35.584+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.583+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15906973500023014
[2025-01-13T01:30:35.584+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.584+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10063]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:30:35.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.584+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:30:35.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.585+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:30:35.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.585+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:30:35.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.585+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10063]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:30:35.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.589+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10063]: It took 0.00396s to build the Airflow DAG.
[2025-01-13T01:30:35.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:30:35.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.603+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:30:35.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:30:35.624+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:30:35.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-13T01:31:06.384+0000] {processor.py:157} INFO - Started process (PID=10150) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:31:06.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:31:06.388+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:31:06.416+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.415+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:31:06.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.610+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18056394499944872
[2025-01-13T01:31:06.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.610+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10150]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:31:06.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.611+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:31:06.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.611+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:31:06.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.612+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:31:06.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.612+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10150]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:31:06.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.616+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10150]: It took 0.00381s to build the Airflow DAG.
[2025-01-13T01:31:06.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:31:06.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.629+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:31:06.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:06.654+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:31:06.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.292 seconds
[2025-01-13T01:31:36.713+0000] {processor.py:157} INFO - Started process (PID=10237) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:31:36.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:31:36.717+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:31:36.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.742+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:31:36.888+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.888+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13268403700021736
[2025-01-13T01:31:36.889+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.888+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10237]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:31:36.889+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.889+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:31:36.890+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.890+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:31:36.890+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.890+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:31:36.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.891+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10237]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:31:36.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.895+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10237]: It took 0.00445s to build the Airflow DAG.
[2025-01-13T01:31:36.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:31:36.909+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.909+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:31:36.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:31:36.935+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:31:36.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-13T01:32:07.106+0000] {processor.py:157} INFO - Started process (PID=10325) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:32:07.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:32:07.110+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:32:07.134+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.133+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:32:07.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.291+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14456867600165424
[2025-01-13T01:32:07.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.292+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10325]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:32:07.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.293+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:32:07.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.293+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:32:07.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.293+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:32:07.294+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.294+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10325]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:32:07.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.297+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10325]: It took 0.00359s to build the Airflow DAG.
[2025-01-13T01:32:07.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:32:07.311+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.311+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:32:07.336+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:07.335+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:32:07.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-13T01:32:37.410+0000] {processor.py:157} INFO - Started process (PID=10431) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:32:37.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:32:37.414+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:32:37.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.442+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:32:37.608+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.608+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1513727880010265
[2025-01-13T01:32:37.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.609+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10431]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:32:37.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.610+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:32:37.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.610+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:32:37.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.611+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:32:37.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.611+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10431]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:32:37.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.615+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10431]: It took 0.00406s to build the Airflow DAG.
[2025-01-13T01:32:37.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:32:37.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.629+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:32:37.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:32:37.651+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:32:37.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-13T01:33:07.917+0000] {processor.py:157} INFO - Started process (PID=10513) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:33:07.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:33:07.920+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:07.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:33:07.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:07.942+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:33:08.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.092+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13751340499948128
[2025-01-13T01:33:08.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.092+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10513]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:33:08.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.093+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:33:08.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.094+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:33:08.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.094+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:33:08.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.094+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10513]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:33:08.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.098+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10513]: It took 0.00395s to build the Airflow DAG.
[2025-01-13T01:33:08.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:33:08.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.112+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:33:08.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:08.135+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:33:08.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-13T01:33:38.734+0000] {processor.py:157} INFO - Started process (PID=10599) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:33:38.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:33:38.738+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:33:38.767+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.767+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:33:38.960+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.960+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18045380400144495
[2025-01-13T01:33:38.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.960+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10599]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:33:38.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.961+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:33:38.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.962+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:33:38.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.962+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:33:38.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.963+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10599]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:33:38.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.967+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10599]: It took 0.00443s to build the Airflow DAG.
[2025-01-13T01:33:38.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:33:38.983+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:38.983+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:33:39.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:33:39.008+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:33:39.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.296 seconds
[2025-01-13T01:34:09.159+0000] {processor.py:157} INFO - Started process (PID=10706) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:34:09.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:34:09.163+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:34:09.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.192+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:34:09.356+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.356+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1527961800002231
[2025-01-13T01:34:09.357+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.357+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10706]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:34:09.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.358+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:34:09.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.358+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:34:09.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.358+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:34:09.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.359+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10706]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:34:09.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.364+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10706]: It took 0.00507s to build the Airflow DAG.
[2025-01-13T01:34:09.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:34:09.380+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.380+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:34:09.403+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:09.403+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:34:09.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-13T01:34:39.468+0000] {processor.py:157} INFO - Started process (PID=10793) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:34:39.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:34:39.471+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:34:39.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.497+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:34:39.650+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.650+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1397271380010352
[2025-01-13T01:34:39.651+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.651+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10793]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:34:39.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.652+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:34:39.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.652+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:34:39.653+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.652+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:34:39.653+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.653+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10793]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:34:39.657+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.657+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10793]: It took 0.00449s to build the Airflow DAG.
[2025-01-13T01:34:39.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:34:39.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.671+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:34:39.692+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:34:39.691+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:34:39.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-13T01:35:09.752+0000] {processor.py:157} INFO - Started process (PID=10880) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:35:09.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:35:09.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:35:09.779+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.779+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:35:09.944+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.944+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14906972399876395
[2025-01-13T01:35:09.945+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.945+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10880]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:35:09.945+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.945+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:35:09.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.946+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:35:09.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.946+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:35:09.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.946+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10880]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:35:09.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.950+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10880]: It took 0.00373s to build the Airflow DAG.
[2025-01-13T01:35:09.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:35:09.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.970+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:35:09.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:09.993+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:35:10.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.272 seconds
[2025-01-13T01:35:40.844+0000] {processor.py:157} INFO - Started process (PID=10974) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:35:40.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:35:40.848+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:40.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:35:40.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:40.897+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:35:41.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.092+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15968495100059954
[2025-01-13T01:35:41.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.093+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|10974]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:35:41.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.094+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:35:41.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.094+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:35:41.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.094+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:35:41.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.095+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|10974]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:35:41.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.099+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|10974]: It took 0.00436s to build the Airflow DAG.
[2025-01-13T01:35:41.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:35:41.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.114+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:35:41.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:35:41.141+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:35:41.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.317 seconds
[2025-01-13T01:36:11.662+0000] {processor.py:157} INFO - Started process (PID=11072) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:36:11.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:36:11.665+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:36:11.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.689+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:36:11.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.828+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1260213539990218
[2025-01-13T01:36:11.829+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.828+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11072]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:36:11.829+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.829+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:36:11.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.829+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:36:11.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.830+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:36:11.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.830+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11072]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:36:11.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.834+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11072]: It took 0.00359s to build the Airflow DAG.
[2025-01-13T01:36:11.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:36:11.847+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.846+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:36:11.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:11.867+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:36:11.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-13T01:36:42.205+0000] {processor.py:157} INFO - Started process (PID=11158) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:36:42.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:36:42.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:36:42.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.235+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:36:42.372+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.372+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12426568500086432
[2025-01-13T01:36:42.373+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.373+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11158]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:36:42.373+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.373+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:36:42.374+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.374+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:36:42.374+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.374+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:36:42.374+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.374+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11158]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:36:42.378+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.377+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11158]: It took 0.00332s to build the Airflow DAG.
[2025-01-13T01:36:42.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:36:42.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.391+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:36:42.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:36:42.411+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:36:42.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-13T01:37:12.913+0000] {processor.py:157} INFO - Started process (PID=11263) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:37:12.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:37:12.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:12.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:37:12.957+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:12.957+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:37:13.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.138+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16769850600030622
[2025-01-13T01:37:13.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.139+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11263]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:37:13.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.140+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:37:13.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.140+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:37:13.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.140+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:37:13.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.140+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11263]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:37:13.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.144+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11263]: It took 0.00365s to build the Airflow DAG.
[2025-01-13T01:37:13.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:37:13.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.158+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:37:13.179+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:13.178+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:37:13.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-13T01:37:43.505+0000] {processor.py:157} INFO - Started process (PID=11349) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:37:43.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:37:43.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:37:43.532+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.532+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:37:43.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.668+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12404794400026731
[2025-01-13T01:37:43.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.669+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11349]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:37:43.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.670+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:37:43.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.670+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:37:43.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.670+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:37:43.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.671+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11349]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:37:43.675+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.675+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11349]: It took 0.00379s to build the Airflow DAG.
[2025-01-13T01:37:43.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:37:43.688+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.688+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:37:43.708+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:37:43.708+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:37:43.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-13T01:38:13.975+0000] {processor.py:157} INFO - Started process (PID=11435) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:38:13.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:38:13.978+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:13.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:38:14.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.001+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:38:14.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.161+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14854569799899764
[2025-01-13T01:38:14.163+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.163+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11435]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:38:14.165+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.164+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:38:14.165+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.165+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:38:14.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.166+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:38:14.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.167+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11435]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:38:14.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.175+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11435]: It took 0.00862s to build the Airflow DAG.
[2025-01-13T01:38:14.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:38:14.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.208+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:38:14.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:14.241+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:38:14.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-13T01:38:44.515+0000] {processor.py:157} INFO - Started process (PID=11529) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:38:44.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:38:44.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:38:44.567+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.567+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:38:44.773+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.773+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1852240719999827
[2025-01-13T01:38:44.774+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.774+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11529]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:38:44.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.775+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:38:44.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.776+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:38:44.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.776+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:38:44.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.777+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11529]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:38:44.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.784+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11529]: It took 0.00675s to build the Airflow DAG.
[2025-01-13T01:38:44.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:38:44.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.808+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:38:44.844+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:38:44.844+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:38:44.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.360 seconds
[2025-01-13T01:39:15.432+0000] {processor.py:157} INFO - Started process (PID=11626) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:39:15.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:39:15.437+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:39:15.461+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.461+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:39:15.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.660+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18352226999923005
[2025-01-13T01:39:15.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.660+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11626]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:39:15.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.662+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:39:15.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.662+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:39:15.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.663+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:39:15.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.664+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11626]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:39:15.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.670+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11626]: It took 0.00677s to build the Airflow DAG.
[2025-01-13T01:39:15.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:39:15.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.690+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:39:15.720+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:15.720+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:39:15.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.319 seconds
[2025-01-13T01:39:45.928+0000] {processor.py:157} INFO - Started process (PID=11712) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:39:45.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:39:45.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:45.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:39:45.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:45.959+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:39:46.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.135+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16137680700012424
[2025-01-13T01:39:46.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.135+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11712]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:39:46.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.136+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:39:46.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.137+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:39:46.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.137+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:39:46.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.137+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11712]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:39:46.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.142+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11712]: It took 0.00416s to build the Airflow DAG.
[2025-01-13T01:39:46.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:39:46.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.161+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:39:46.187+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:39:46.187+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:39:46.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-13T01:40:17.187+0000] {processor.py:157} INFO - Started process (PID=11798) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:40:17.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:40:17.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:40:17.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.218+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:40:17.403+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.403+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17008300999987114
[2025-01-13T01:40:17.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.404+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11798]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:40:17.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.404+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:40:17.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.405+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:40:17.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.405+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:40:17.406+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.406+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11798]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:40:17.411+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.411+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11798]: It took 0.00495s to build the Airflow DAG.
[2025-01-13T01:40:17.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:40:17.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.428+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:40:17.454+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:17.453+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:40:17.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-13T01:40:48.009+0000] {processor.py:157} INFO - Started process (PID=11884) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:40:48.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:40:48.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:40:48.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.079+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:40:48.354+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.354+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24797059199954674
[2025-01-13T01:40:48.355+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.355+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11884]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:40:48.357+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.357+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:40:48.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.358+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:40:48.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.360+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:40:48.361+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.361+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11884]: It took 0.282s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:40:48.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.370+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11884]: It took 0.00969s to build the Airflow DAG.
[2025-01-13T01:40:48.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:40:48.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.404+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:40:48.456+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:40:48.456+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:40:48.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.516 seconds
[2025-01-13T01:41:19.279+0000] {processor.py:157} INFO - Started process (PID=11979) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:41:19.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:41:19.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:41:19.308+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.308+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:41:19.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.516+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19291481599975668
[2025-01-13T01:41:19.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.517+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|11979]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:41:19.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.518+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:41:19.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.518+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:41:19.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.519+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:41:19.520+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.519+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|11979]: It took 0.211s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:41:19.525+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.525+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|11979]: It took 0.00532s to build the Airflow DAG.
[2025-01-13T01:41:19.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:41:19.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.543+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:41:19.571+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:19.571+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:41:19.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.317 seconds
[2025-01-13T01:41:50.581+0000] {processor.py:157} INFO - Started process (PID=12078) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:41:50.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:41:50.586+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:41:50.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.616+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:41:50.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.793+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16341597199971147
[2025-01-13T01:41:50.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.793+0000] {graph.py:519} INFO - Cosmos performance [0ab45cca69c5|12078]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:41:50.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.794+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:41:50.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.795+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:41:50.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.795+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:41:50.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.795+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [0ab45cca69c5|12078]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:41:50.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.800+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [0ab45cca69c5|12078]: It took 0.00455s to build the Airflow DAG.
[2025-01-13T01:41:50.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:41:50.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.818+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:41:50.846+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:41:50.845+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:41:50.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-13T01:43:13.647+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:43:13.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:43:13.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:13.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:43:13.764+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:13.763+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:43:14.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.064+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2702370309998514
[2025-01-13T01:43:14.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.065+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|77]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:43:14.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.066+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:43:14.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.067+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:43:14.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.068+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:43:14.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.068+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|77]: It took 0.305s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:43:14.076+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.076+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|77]: It took 0.00735s to build the Airflow DAG.
[2025-01-13T01:43:14.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:43:14.268+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.268+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:43:14.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:14.313+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:43:14.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.711 seconds
[2025-01-13T01:43:44.496+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:43:44.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:43:44.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:43:44.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.526+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:43:44.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.752+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2080406610002683
[2025-01-13T01:43:44.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.752+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:43:44.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.753+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:43:44.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.754+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:43:44.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.754+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:43:44.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.755+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|157]: It took 0.228s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:43:44.761+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.760+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|157]: It took 0.00592s to build the Airflow DAG.
[2025-01-13T01:43:44.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:43:44.780+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.780+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:43:44.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:43:44.810+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:43:44.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.339 seconds
[2025-01-13T01:44:14.924+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:44:14.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:44:14.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:14.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:44:14.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:14.955+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:44:15.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.134+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1639462029997958
[2025-01-13T01:44:15.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.135+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|252]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:44:15.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.136+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:44:15.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.136+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:44:15.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.137+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:44:15.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.137+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|252]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:44:15.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.142+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|252]: It took 0.00497s to build the Airflow DAG.
[2025-01-13T01:44:15.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:44:15.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.159+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:44:15.186+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:15.186+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:44:15.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-13T01:44:45.544+0000] {processor.py:157} INFO - Started process (PID=346) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:44:45.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:44:45.550+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:45.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:44:45.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:45.600+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:44:46.247+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.247+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6131758809988241
[2025-01-13T01:44:46.249+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.248+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|346]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:44:46.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.257+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:44:46.259+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.259+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:44:46.261+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.260+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:44:46.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.267+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|346]: It took 0.665s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:44:46.302+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.301+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|346]: It took 0.0357s to build the Airflow DAG.
[2025-01-13T01:44:46.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:44:46.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.392+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:44:46.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:44:46.485+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:44:46.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.004 seconds
[2025-01-13T01:45:18.511+0000] {processor.py:157} INFO - Started process (PID=426) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:45:18.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:45:18.521+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:18.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:45:18.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:18.677+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:45:19.334+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.334+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.5338431670006685
[2025-01-13T01:45:19.338+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.338+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|426]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:45:19.344+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.343+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:45:19.345+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.345+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:45:19.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.347+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:45:19.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.348+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|426]: It took 0.682s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:45:19.386+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.386+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|426]: It took 0.0372s to build the Airflow DAG.
[2025-01-13T01:45:19.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:45:19.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.458+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:45:19.569+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:19.569+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:45:19.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.148 seconds
[2025-01-13T01:45:49.830+0000] {processor.py:157} INFO - Started process (PID=513) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:45:49.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:45:49.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:49.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:45:49.889+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:49.889+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:45:50.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.193+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.28042143099992245
[2025-01-13T01:45:50.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.194+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|513]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:45:50.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.195+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:45:50.196+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.196+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:45:50.197+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.196+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:45:50.198+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.197+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|513]: It took 0.309s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:45:50.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.207+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|513]: It took 0.00958s to build the Airflow DAG.
[2025-01-13T01:45:50.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:45:50.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.240+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:45:50.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:45:50.292+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:45:50.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.501 seconds
[2025-01-13T01:46:20.482+0000] {processor.py:157} INFO - Started process (PID=588) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:46:20.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:46:20.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:46:20.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.508+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:46:20.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.724+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19975985800010676
[2025-01-13T01:46:20.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.725+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|588]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:46:20.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.726+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:46:20.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.727+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:46:20.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.727+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:46:20.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.728+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|588]: It took 0.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:46:20.734+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.734+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|588]: It took 0.0056s to build the Airflow DAG.
[2025-01-13T01:46:20.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:46:20.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.751+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:46:20.786+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:20.786+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:46:20.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.332 seconds
[2025-01-13T01:46:50.901+0000] {processor.py:157} INFO - Started process (PID=674) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:46:50.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:46:50.909+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:50.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:46:50.947+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:50.947+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:46:51.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.265+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2882566019998194
[2025-01-13T01:46:51.266+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.266+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|674]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:46:51.268+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.268+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:46:51.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.269+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:46:51.270+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.270+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:46:51.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.271+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|674]: It took 0.324s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:46:51.281+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.280+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|674]: It took 0.00949s to build the Airflow DAG.
[2025-01-13T01:46:51.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:46:51.317+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.317+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:46:51.381+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:46:51.380+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:46:51.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.534 seconds
[2025-01-13T01:47:22.357+0000] {processor.py:157} INFO - Started process (PID=771) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:47:22.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:47:22.362+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:47:22.388+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.388+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:47:22.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.596+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18970136999996612
[2025-01-13T01:47:22.597+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.597+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|771]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:47:22.598+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.598+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:47:22.599+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.599+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:47:22.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.599+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:47:22.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.600+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|771]: It took 0.213s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:47:22.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.606+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|771]: It took 0.0061s to build the Airflow DAG.
[2025-01-13T01:47:22.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:47:22.635+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.635+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:47:22.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:22.668+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:47:22.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.340 seconds
[2025-01-13T01:47:52.738+0000] {processor.py:157} INFO - Started process (PID=857) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:47:52.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:47:52.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:52.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:47:52.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:52.772+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:47:53.003+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.003+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21124444599990966
[2025-01-13T01:47:53.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.004+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|857]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:47:53.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.006+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:47:53.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.007+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:47:53.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.007+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:47:53.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.008+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|857]: It took 0.236s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:47:53.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.015+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|857]: It took 0.00734s to build the Airflow DAG.
[2025-01-13T01:47:53.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:47:53.049+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.049+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:47:53.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:47:53.088+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:47:53.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.383 seconds
[2025-01-13T01:48:24.053+0000] {processor.py:157} INFO - Started process (PID=945) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:48:24.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:48:24.056+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:48:24.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.081+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:48:24.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.227+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13106302699998196
[2025-01-13T01:48:24.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.227+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|945]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:48:24.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.228+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:48:24.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.228+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:48:24.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.228+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:48:24.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.229+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|945]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:48:24.233+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.233+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|945]: It took 0.00394s to build the Airflow DAG.
[2025-01-13T01:48:24.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:48:24.247+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.247+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:48:24.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:24.269+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:48:24.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-13T01:48:54.602+0000] {processor.py:157} INFO - Started process (PID=1031) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:48:54.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:48:54.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:48:54.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.629+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:48:54.829+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.829+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18460851100098807
[2025-01-13T01:48:54.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.829+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1031]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:48:54.831+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.830+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:48:54.831+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.831+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:48:54.831+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.831+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:48:54.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.832+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1031]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:48:54.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.837+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1031]: It took 0.00476s to build the Airflow DAG.
[2025-01-13T01:48:54.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:48:54.855+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.855+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:48:54.880+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:48:54.879+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:48:54.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-13T01:49:25.004+0000] {processor.py:157} INFO - Started process (PID=1119) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:49:25.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:49:25.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:49:25.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.031+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:49:25.180+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.180+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13442346499869018
[2025-01-13T01:49:25.180+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.180+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1119]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:49:25.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.181+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:49:25.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.181+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:49:25.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.182+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:49:25.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.182+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1119]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:49:25.186+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.186+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1119]: It took 0.00344s to build the Airflow DAG.
[2025-01-13T01:49:25.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:49:25.201+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.201+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:49:25.223+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:25.223+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:49:25.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-13T01:49:55.408+0000] {processor.py:157} INFO - Started process (PID=1205) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:49:55.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:49:55.411+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:49:55.435+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.435+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:49:55.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.612+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16104427699974622
[2025-01-13T01:49:55.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.612+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1205]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:49:55.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.613+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:49:55.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.614+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:49:55.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.614+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:49:55.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.615+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1205]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:49:55.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.619+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1205]: It took 0.00475s to build the Airflow DAG.
[2025-01-13T01:49:55.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:49:55.637+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.636+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:49:55.677+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:49:55.677+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:49:55.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-13T01:50:26.616+0000] {processor.py:157} INFO - Started process (PID=1310) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:50:26.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:50:26.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:50:26.646+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.646+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:50:26.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.916+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.252979607999805
[2025-01-13T01:50:26.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.916+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1310]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:50:26.917+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.917+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:50:26.918+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.918+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:50:26.918+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.918+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:50:26.919+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.919+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1310]: It took 0.273s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:50:26.923+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.923+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1310]: It took 0.00426s to build the Airflow DAG.
[2025-01-13T01:50:26.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:50:26.941+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.940+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:50:26.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:26.970+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:50:26.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.379 seconds
[2025-01-13T01:50:57.968+0000] {processor.py:157} INFO - Started process (PID=1398) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:50:57.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:50:57.972+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:57.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:50:58.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.000+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:50:58.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.226+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20941915000003064
[2025-01-13T01:50:58.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.227+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1398]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:50:58.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.228+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:50:58.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.228+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:50:58.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.229+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:50:58.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.229+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1398]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:50:58.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.233+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1398]: It took 0.00437s to build the Airflow DAG.
[2025-01-13T01:50:58.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:50:58.256+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.256+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:50:58.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:50:58.286+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:50:58.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.344 seconds
[2025-01-13T01:51:28.367+0000] {processor.py:157} INFO - Started process (PID=1484) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:51:28.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:51:28.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:51:28.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.393+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:51:28.569+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.569+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1629708689997642
[2025-01-13T01:51:28.570+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.570+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1484]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:51:28.571+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.571+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:51:28.571+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.571+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:51:28.572+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.572+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:51:28.573+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.572+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1484]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:51:28.578+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.578+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1484]: It took 0.00525s to build the Airflow DAG.
[2025-01-13T01:51:28.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:51:28.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.594+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:51:28.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:28.624+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:51:28.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-13T01:51:59.362+0000] {processor.py:157} INFO - Started process (PID=1570) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:51:59.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:51:59.365+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:51:59.389+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.389+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:51:59.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.585+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1803383960013889
[2025-01-13T01:51:59.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.585+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1570]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:51:59.586+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.586+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:51:59.587+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.587+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:51:59.587+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.587+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:51:59.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.588+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1570]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:51:59.593+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.592+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1570]: It took 0.00482s to build the Airflow DAG.
[2025-01-13T01:51:59.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:51:59.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.612+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:51:59.640+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:51:59.640+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:51:59.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T01:52:29.955+0000] {processor.py:157} INFO - Started process (PID=1656) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:52:29.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:52:29.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:29.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:52:29.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:29.986+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:52:30.188+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.188+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18682671200076584
[2025-01-13T01:52:30.188+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.188+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1656]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:52:30.189+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.189+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:52:30.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.190+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:52:30.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.190+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:52:30.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.191+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1656]: It took 0.205s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:52:30.196+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.196+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1656]: It took 0.00525s to build the Airflow DAG.
[2025-01-13T01:52:30.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:52:30.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.216+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:52:30.246+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:52:30.246+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:52:30.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.317 seconds
[2025-01-13T01:53:00.391+0000] {processor.py:157} INFO - Started process (PID=1744) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:53:00.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:53:00.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:53:00.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.427+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:53:00.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.652+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20484039500115614
[2025-01-13T01:53:00.653+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.653+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1744]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:53:00.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.654+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:53:00.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.654+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:53:00.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.655+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:53:00.656+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.655+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1744]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:53:00.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.661+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1744]: It took 0.00593s to build the Airflow DAG.
[2025-01-13T01:53:00.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:53:00.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.686+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:53:00.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:00.723+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:53:00.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.362 seconds
[2025-01-13T01:53:30.907+0000] {processor.py:157} INFO - Started process (PID=1828) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:53:30.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:53:30.910+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:30.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:53:30.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:30.935+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:53:31.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.139+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1865541880015371
[2025-01-13T01:53:31.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.139+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1828]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:53:31.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.140+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:53:31.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.141+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:53:31.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.141+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:53:31.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.142+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1828]: It took 0.207s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:53:31.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.148+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1828]: It took 0.00586s to build the Airflow DAG.
[2025-01-13T01:53:31.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:53:31.173+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.173+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:53:31.225+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:53:31.224+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:53:31.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.355 seconds
[2025-01-13T01:54:01.453+0000] {processor.py:157} INFO - Started process (PID=1916) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:54:01.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:54:01.460+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:54:01.504+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.504+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:54:01.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.967+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.4356357830001798
[2025-01-13T01:54:01.968+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.968+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|1916]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:54:01.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.970+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:54:01.972+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.971+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:54:01.972+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.972+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:54:01.973+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.973+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|1916]: It took 0.469s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:54:01.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:01.989+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|1916]: It took 0.0161s to build the Airflow DAG.
[2025-01-13T01:54:01.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:54:02.070+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:02.070+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:54:02.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:02.146+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:54:02.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.766 seconds
[2025-01-13T01:54:32.470+0000] {processor.py:157} INFO - Started process (PID=2003) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:54:32.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:54:32.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:54:32.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.534+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:54:32.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.898+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3212001229985617
[2025-01-13T01:54:32.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.899+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2003]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:54:32.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.900+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:54:32.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.901+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:54:32.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.902+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:54:32.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.903+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2003]: It took 0.369s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:54:32.912+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.912+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2003]: It took 0.00939s to build the Airflow DAG.
[2025-01-13T01:54:32.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:54:32.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:32.966+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:54:33.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:54:33.042+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:54:33.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.630 seconds
[2025-01-13T01:55:03.844+0000] {processor.py:157} INFO - Started process (PID=2089) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:55:03.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:55:03.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:03.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:55:03.873+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:03.873+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:55:04.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.119+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22994260500126984
[2025-01-13T01:55:04.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.120+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2089]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:55:04.121+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.121+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:55:04.122+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.122+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:55:04.122+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.122+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:55:04.123+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.123+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2089]: It took 0.25s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:55:04.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.130+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2089]: It took 0.00717s to build the Airflow DAG.
[2025-01-13T01:55:04.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:55:04.157+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.157+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:55:04.188+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:04.188+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:55:04.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.371 seconds
[2025-01-13T01:55:34.423+0000] {processor.py:157} INFO - Started process (PID=2175) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:55:34.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:55:34.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:55:34.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.453+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:55:34.642+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.642+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17354763300136256
[2025-01-13T01:55:34.642+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.642+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2175]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:55:34.643+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.643+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:55:34.644+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.644+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:55:34.644+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.644+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:55:34.645+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.645+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2175]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:55:34.650+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.650+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2175]: It took 0.00491s to build the Airflow DAG.
[2025-01-13T01:55:34.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:55:34.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.667+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:55:34.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:55:34.696+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:55:34.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-13T01:56:05.405+0000] {processor.py:157} INFO - Started process (PID=2261) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:56:05.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:56:05.409+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:56:05.440+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.440+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:56:05.651+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.650+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19456867199914996
[2025-01-13T01:56:05.651+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.651+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2261]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:56:05.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.652+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:56:05.653+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.653+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:56:05.653+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.653+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:56:05.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.654+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2261]: It took 0.214s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:56:05.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.659+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2261]: It took 0.00574s to build the Airflow DAG.
[2025-01-13T01:56:05.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:56:05.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.679+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:56:05.710+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:05.710+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:56:05.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.331 seconds
[2025-01-13T01:56:35.859+0000] {processor.py:157} INFO - Started process (PID=2348) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:56:35.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:56:35.863+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:35.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:56:35.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:35.892+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:56:36.091+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.091+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18366110600072716
[2025-01-13T01:56:36.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.092+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2348]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:56:36.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.093+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:56:36.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.093+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:56:36.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.093+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:56:36.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.094+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2348]: It took 0.202s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:56:36.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.098+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2348]: It took 0.00473s to build the Airflow DAG.
[2025-01-13T01:56:36.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:56:36.117+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.117+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:56:36.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:56:36.151+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:56:36.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.317 seconds
[2025-01-13T01:57:07.201+0000] {processor.py:157} INFO - Started process (PID=2453) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:57:07.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:57:07.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:57:07.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.234+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:57:07.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.427+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17420688200036238
[2025-01-13T01:57:07.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.427+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2453]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:57:07.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.428+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:57:07.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.428+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:57:07.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.429+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:57:07.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.429+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2453]: It took 0.195s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:57:07.434+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.433+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2453]: It took 0.00436s to build the Airflow DAG.
[2025-01-13T01:57:07.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:57:07.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.453+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:57:07.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:07.482+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:57:07.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-13T01:57:37.674+0000] {processor.py:157} INFO - Started process (PID=2541) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:57:37.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:57:37.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:57:37.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.707+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:57:37.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.900+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17564965999918059
[2025-01-13T01:57:37.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.900+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2541]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:57:37.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.901+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:57:37.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.901+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:57:37.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.902+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:57:37.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.902+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2541]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:57:37.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.907+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2541]: It took 0.0047s to build the Airflow DAG.
[2025-01-13T01:57:37.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:57:37.924+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.924+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:57:37.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:57:37.951+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:57:37.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-13T01:58:08.176+0000] {processor.py:157} INFO - Started process (PID=2625) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:58:08.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:58:08.180+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:58:08.199+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.199+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:58:08.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.429+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21549066899933678
[2025-01-13T01:58:08.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.429+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2625]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:58:08.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.430+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:58:08.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.431+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:58:08.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.431+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:58:08.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.431+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2625]: It took 0.232s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:58:08.436+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.436+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2625]: It took 0.00428s to build the Airflow DAG.
[2025-01-13T01:58:08.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:58:08.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.453+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:58:08.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:08.483+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:58:08.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-13T01:58:39.347+0000] {processor.py:157} INFO - Started process (PID=2711) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:58:39.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:58:39.351+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:58:39.376+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.376+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:58:39.556+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.556+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16683928500060574
[2025-01-13T01:58:39.557+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.557+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2711]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:58:39.558+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.557+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:58:39.558+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.558+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:58:39.558+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.558+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:58:39.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.559+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2711]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:58:39.563+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.563+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2711]: It took 0.00456s to build the Airflow DAG.
[2025-01-13T01:58:39.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:58:39.583+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.583+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:58:39.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:58:39.620+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:58:39.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.302 seconds
[2025-01-13T01:59:09.765+0000] {processor.py:157} INFO - Started process (PID=2808) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:59:09.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:59:09.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:09.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:59:09.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:09.798+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:59:10.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.013+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19473913999900105
[2025-01-13T01:59:10.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.014+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2808]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:59:10.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.015+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:59:10.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.015+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:59:10.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.016+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:59:10.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.016+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2808]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:59:10.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.022+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2808]: It took 0.00528s to build the Airflow DAG.
[2025-01-13T01:59:10.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:59:10.042+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.042+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:59:10.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:10.072+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:59:10.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-13T01:59:41.071+0000] {processor.py:157} INFO - Started process (PID=2906) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:59:41.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T01:59:41.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:59:41.106+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.105+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T01:59:41.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.306+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18478171200149518
[2025-01-13T01:59:41.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.306+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2906]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T01:59:41.308+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.307+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T01:59:41.308+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.308+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T01:59:41.308+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.308+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T01:59:41.309+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.309+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2906]: It took 0.204s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T01:59:41.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.313+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2906]: It took 0.00472s to build the Airflow DAG.
[2025-01-13T01:59:41.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T01:59:41.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.331+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T01:59:41.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T01:59:41.359+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T01:59:41.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.315 seconds
[2025-01-13T02:00:11.710+0000] {processor.py:157} INFO - Started process (PID=2992) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:00:11.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:00:11.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:00:11.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.750+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:00:11.940+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.940+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16908221899939235
[2025-01-13T02:00:11.941+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.941+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|2992]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:00:11.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.942+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:00:11.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.942+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:00:11.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.943+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:00:11.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.943+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|2992]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:00:11.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.948+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|2992]: It took 0.0052s to build the Airflow DAG.
[2025-01-13T02:00:11.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:00:11.968+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:11.968+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:00:12.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:12.004+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:00:12.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.319 seconds
[2025-01-13T02:00:42.121+0000] {processor.py:157} INFO - Started process (PID=3079) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:00:42.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:00:42.124+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:00:42.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.145+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:00:42.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.324+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16384264399857784
[2025-01-13T02:00:42.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.324+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3079]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:00:42.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.325+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:00:42.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.326+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:00:42.327+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.326+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:00:42.327+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.327+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3079]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:00:42.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.332+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3079]: It took 0.00469s to build the Airflow DAG.
[2025-01-13T02:00:42.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:00:42.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.349+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:00:42.376+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:00:42.376+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:00:42.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-13T02:01:12.572+0000] {processor.py:157} INFO - Started process (PID=3174) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:01:12.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:01:12.575+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:01:12.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.599+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:01:12.788+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.787+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17206430800069938
[2025-01-13T02:01:12.788+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.788+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3174]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:01:12.789+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.789+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:01:12.790+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.789+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:01:12.790+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.790+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:01:12.791+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.790+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3174]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:01:12.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.796+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3174]: It took 0.00541s to build the Airflow DAG.
[2025-01-13T02:01:12.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:01:12.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.816+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:01:12.851+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:12.851+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:01:12.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T02:01:43.088+0000] {processor.py:157} INFO - Started process (PID=3269) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:01:43.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:01:43.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:01:43.116+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.116+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:01:43.309+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.309+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17933637899841415
[2025-01-13T02:01:43.309+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.309+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3269]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:01:43.310+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.310+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:01:43.311+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.311+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:01:43.311+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.311+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:01:43.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.312+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3269]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:01:43.318+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.318+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3269]: It took 0.00584s to build the Airflow DAG.
[2025-01-13T02:01:43.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:01:43.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.339+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:01:43.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:01:43.369+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:01:43.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-13T02:02:13.527+0000] {processor.py:157} INFO - Started process (PID=3355) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:02:13.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:02:13.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:02:13.556+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.556+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:02:13.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.735+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16167865799980063
[2025-01-13T02:02:13.736+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.735+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3355]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:02:13.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.736+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:02:13.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.737+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:02:13.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.737+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:02:13.738+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.738+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3355]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:02:13.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.743+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3355]: It took 0.00534s to build the Airflow DAG.
[2025-01-13T02:02:13.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:02:13.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.760+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:02:13.787+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:13.787+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:02:13.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-13T02:02:43.921+0000] {processor.py:157} INFO - Started process (PID=3441) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:02:43.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:02:43.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:43.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:02:43.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:43.949+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:02:44.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.136+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17242970900042565
[2025-01-13T02:02:44.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.137+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3441]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:02:44.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.138+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:02:44.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.138+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:02:44.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.138+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:02:44.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.139+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3441]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:02:44.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.143+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3441]: It took 0.00456s to build the Airflow DAG.
[2025-01-13T02:02:44.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:02:44.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.160+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:02:44.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:02:44.185+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:02:44.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T02:03:14.478+0000] {processor.py:157} INFO - Started process (PID=3527) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:03:14.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:03:14.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:03:14.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.508+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:03:14.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.677+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15464390799934336
[2025-01-13T02:03:14.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.678+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3527]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:03:14.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.679+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:03:14.680+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.679+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:03:14.680+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.680+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:03:14.681+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.680+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3527]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:03:14.685+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.685+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3527]: It took 0.00469s to build the Airflow DAG.
[2025-01-13T02:03:14.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:03:14.703+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.703+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:03:14.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:14.726+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:03:14.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-13T02:03:44.841+0000] {processor.py:157} INFO - Started process (PID=3633) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:03:44.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:03:44.846+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:44.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:03:44.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:44.869+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:03:45.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.081+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19450093200066476
[2025-01-13T02:03:45.082+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.082+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3633]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:03:45.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.083+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:03:45.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.083+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:03:45.084+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.084+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:03:45.084+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.084+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3633]: It took 0.215s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:03:45.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.089+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3633]: It took 0.00491s to build the Airflow DAG.
[2025-01-13T02:03:45.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:03:45.110+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.110+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:03:45.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:03:45.142+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:03:45.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.332 seconds
[2025-01-13T02:04:15.413+0000] {processor.py:157} INFO - Started process (PID=3721) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:04:15.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:04:15.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:04:15.440+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.440+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:04:15.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.628+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17313353700046719
[2025-01-13T02:04:15.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.629+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3721]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:04:15.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.631+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:04:15.632+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.632+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:04:15.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.632+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:04:15.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.633+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3721]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:04:15.639+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.639+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3721]: It took 0.00625s to build the Airflow DAG.
[2025-01-13T02:04:15.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:04:15.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.663+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:04:15.694+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:15.694+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:04:15.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.309 seconds
[2025-01-13T02:04:45.837+0000] {processor.py:157} INFO - Started process (PID=3809) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:04:45.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:04:45.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:45.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:04:45.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:45.862+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:04:46.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.033+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15774449099990306
[2025-01-13T02:04:46.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.034+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3809]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:04:46.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.035+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:04:46.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.035+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:04:46.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.036+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:04:46.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.036+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3809]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:04:46.040+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.040+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3809]: It took 0.00406s to build the Airflow DAG.
[2025-01-13T02:04:46.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:04:46.056+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.056+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:04:46.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:04:46.081+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:04:46.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T02:05:16.256+0000] {processor.py:157} INFO - Started process (PID=3895) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:05:16.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:05:16.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:05:16.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.282+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:05:16.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.433+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1365608180003619
[2025-01-13T02:05:16.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.433+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3895]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:05:16.434+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.434+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:05:16.435+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.435+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:05:16.435+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.435+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:05:16.436+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.435+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3895]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:05:16.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.439+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3895]: It took 0.00371s to build the Airflow DAG.
[2025-01-13T02:05:16.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:05:16.455+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.455+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:05:16.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:16.477+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:05:16.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-13T02:05:46.560+0000] {processor.py:157} INFO - Started process (PID=3989) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:05:46.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:05:46.564+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:05:46.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.594+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:05:46.791+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.791+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18151880699952017
[2025-01-13T02:05:46.791+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.791+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|3989]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:05:46.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.792+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:05:46.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.792+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:05:46.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.793+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:05:46.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.793+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|3989]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:05:46.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.798+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|3989]: It took 0.00457s to build the Airflow DAG.
[2025-01-13T02:05:46.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:05:46.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.814+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:05:46.839+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:05:46.839+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:05:46.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.303 seconds
[2025-01-13T02:06:17.067+0000] {processor.py:157} INFO - Started process (PID=4086) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:06:17.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:06:17.070+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:06:17.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.094+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:06:17.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.274+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16661159599971143
[2025-01-13T02:06:17.275+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.275+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4086]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:06:17.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.275+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:06:17.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.276+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:06:17.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.276+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:06:17.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.277+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4086]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:06:17.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.283+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4086]: It took 0.00641s to build the Airflow DAG.
[2025-01-13T02:06:17.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:06:17.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.304+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:06:17.338+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:17.337+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:06:17.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-13T02:06:47.708+0000] {processor.py:157} INFO - Started process (PID=4173) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:06:47.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:06:47.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:06:47.741+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.741+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:06:47.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.945+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18903206100003445
[2025-01-13T02:06:47.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.946+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4173]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:06:47.947+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.947+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:06:47.947+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.947+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:06:47.948+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.948+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:06:47.948+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.948+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4173]: It took 0.208s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:06:47.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.953+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4173]: It took 0.0046s to build the Airflow DAG.
[2025-01-13T02:06:47.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:06:47.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.970+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:06:47.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:06:47.996+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:06:48.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.313 seconds
[2025-01-13T02:07:18.984+0000] {processor.py:157} INFO - Started process (PID=4259) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:07:18.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:07:18.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:18.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:07:19.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.016+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:07:19.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.208+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17888911999943957
[2025-01-13T02:07:19.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.209+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4259]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:07:19.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.210+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:07:19.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.210+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:07:19.211+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.211+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:07:19.211+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.211+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4259]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:07:19.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.217+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4259]: It took 0.00647s to build the Airflow DAG.
[2025-01-13T02:07:19.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:07:19.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.240+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:07:19.266+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:19.266+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:07:19.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-13T02:07:49.342+0000] {processor.py:157} INFO - Started process (PID=4366) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:07:49.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:07:49.346+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:07:49.376+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.375+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:07:49.550+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.549+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1587699640003848
[2025-01-13T02:07:49.550+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.550+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4366]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:07:49.551+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.551+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:07:49.552+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.552+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:07:49.552+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.552+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:07:49.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.553+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4366]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:07:49.558+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.558+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4366]: It took 0.00494s to build the Airflow DAG.
[2025-01-13T02:07:49.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:07:49.576+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.576+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:07:49.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:07:49.605+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:07:49.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-13T02:08:20.466+0000] {processor.py:157} INFO - Started process (PID=4452) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:08:20.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:08:20.470+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:08:20.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.494+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:08:20.688+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.687+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17713876900052128
[2025-01-13T02:08:20.688+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.688+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4452]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:08:20.689+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.689+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:08:20.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.690+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:08:20.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.690+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:08:20.691+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.691+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4452]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:08:20.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.697+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4452]: It took 0.00579s to build the Airflow DAG.
[2025-01-13T02:08:20.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:08:20.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.715+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:08:20.747+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:20.747+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:08:20.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-13T02:08:50.900+0000] {processor.py:157} INFO - Started process (PID=4540) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:08:50.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:08:50.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:50.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:08:50.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:50.926+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:08:51.078+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.078+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1380927829995926
[2025-01-13T02:08:51.078+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.078+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4540]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:08:51.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.079+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:08:51.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.079+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:08:51.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.080+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:08:51.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.080+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4540]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:08:51.085+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.085+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4540]: It took 0.00456s to build the Airflow DAG.
[2025-01-13T02:08:51.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:08:51.100+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.099+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:08:51.122+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:08:51.122+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:08:51.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-13T02:09:21.278+0000] {processor.py:157} INFO - Started process (PID=4628) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:09:21.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:09:21.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:09:21.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.306+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:09:21.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.516+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1950809689988091
[2025-01-13T02:09:21.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.516+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4628]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:09:21.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.517+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:09:21.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.518+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:09:21.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.519+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:09:21.520+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.519+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4628]: It took 0.214s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:09:21.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.527+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4628]: It took 0.00734s to build the Airflow DAG.
[2025-01-13T02:09:21.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:09:21.552+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.552+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:09:21.595+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:21.595+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:09:21.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.352 seconds
[2025-01-13T02:09:51.724+0000] {processor.py:157} INFO - Started process (PID=4736) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:09:51.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:09:51.729+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:09:51.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.753+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:09:51.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.961+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19352421700023115
[2025-01-13T02:09:51.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.963+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4736]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:09:51.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.965+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:09:51.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.965+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:09:51.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.966+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:09:51.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.967+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4736]: It took 0.214s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:09:51.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:51.976+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4736]: It took 0.00893s to build the Airflow DAG.
[2025-01-13T02:09:51.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:09:52.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:52.007+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:09:52.048+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:09:52.047+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:09:52.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.353 seconds
[2025-01-13T02:10:22.274+0000] {processor.py:157} INFO - Started process (PID=4824) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:10:22.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:10:22.278+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:10:22.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.312+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:10:22.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.490+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15973664800003462
[2025-01-13T02:10:22.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.490+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4824]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:10:22.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.491+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:10:22.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.492+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:10:22.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.492+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:10:22.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.493+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4824]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:10:22.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.498+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4824]: It took 0.00503s to build the Airflow DAG.
[2025-01-13T02:10:22.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:10:22.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.516+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:10:22.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:22.546+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:10:22.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-13T02:10:53.574+0000] {processor.py:157} INFO - Started process (PID=4910) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:10:53.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:10:53.578+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:10:53.604+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.604+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:10:53.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.798+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17886949499916227
[2025-01-13T02:10:53.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.798+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4910]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:10:53.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.799+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:10:53.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.800+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:10:53.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.800+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:10:53.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.801+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4910]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:10:53.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.806+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4910]: It took 0.00493s to build the Airflow DAG.
[2025-01-13T02:10:53.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:10:53.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.824+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:10:53.853+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:10:53.853+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:10:53.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.306 seconds
[2025-01-13T02:11:24.098+0000] {processor.py:157} INFO - Started process (PID=4996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:11:24.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:11:24.101+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:11:24.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.127+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:11:24.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.290+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14981122900098853
[2025-01-13T02:11:24.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.291+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|4996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:11:24.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.292+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:11:24.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.292+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:11:24.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.292+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:11:24.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.293+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|4996]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:11:24.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.297+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|4996]: It took 0.00414s to build the Airflow DAG.
[2025-01-13T02:11:24.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:11:24.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.312+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:11:24.335+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:24.334+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:11:24.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-13T02:11:54.501+0000] {processor.py:157} INFO - Started process (PID=5101) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:11:54.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:11:54.505+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:11:54.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.534+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:11:54.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.743+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19279180099874793
[2025-01-13T02:11:54.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.744+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5101]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:11:54.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.745+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:11:54.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.745+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:11:54.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.746+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:11:54.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.746+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5101]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:11:54.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.750+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5101]: It took 0.00416s to build the Airflow DAG.
[2025-01-13T02:11:54.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:11:54.766+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.766+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:11:54.790+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:11:54.789+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:11:54.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.313 seconds
[2025-01-13T02:12:24.917+0000] {processor.py:157} INFO - Started process (PID=5187) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:12:24.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:12:24.920+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:24.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:12:24.948+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:24.947+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:12:25.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.145+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17858755999986897
[2025-01-13T02:12:25.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.146+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5187]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:12:25.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.147+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:12:25.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.148+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:12:25.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.148+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:12:25.149+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.149+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5187]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:12:25.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.153+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5187]: It took 0.00466s to build the Airflow DAG.
[2025-01-13T02:12:25.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:12:25.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.168+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:12:25.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:25.193+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:12:25.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-13T02:12:55.344+0000] {processor.py:157} INFO - Started process (PID=5273) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:12:55.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:12:55.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:12:55.376+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.376+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:12:55.551+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.550+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15633809300015855
[2025-01-13T02:12:55.551+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.551+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5273]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:12:55.552+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.552+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:12:55.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.553+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:12:55.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.553+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:12:55.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.554+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5273]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:12:55.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.559+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5273]: It took 0.00501s to build the Airflow DAG.
[2025-01-13T02:12:55.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:12:55.578+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.577+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:12:55.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:12:55.606+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:12:55.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-13T02:13:26.419+0000] {processor.py:157} INFO - Started process (PID=5357) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:13:26.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:13:26.423+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:13:26.448+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.447+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:13:26.622+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.622+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1611512910003512
[2025-01-13T02:13:26.623+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.623+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5357]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:13:26.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.623+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:13:26.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.624+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:13:26.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.624+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:13:26.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.625+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5357]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:13:26.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.628+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5357]: It took 0.00368s to build the Airflow DAG.
[2025-01-13T02:13:26.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:13:26.643+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.643+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:13:26.667+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:26.666+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:13:26.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-13T02:13:56.793+0000] {processor.py:157} INFO - Started process (PID=5464) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:13:56.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:13:56.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:56.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:13:56.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:56.823+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:13:56.997+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:56.997+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15724986500026716
[2025-01-13T02:13:56.998+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:56.998+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5464]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:13:56.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:56.998+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:13:56.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:56.999+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:13:56.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:56.999+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:13:57.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:57.001+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5464]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:13:57.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:57.006+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5464]: It took 0.00516s to build the Airflow DAG.
[2025-01-13T02:13:57.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:13:57.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:57.022+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:13:57.047+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:13:57.047+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:13:57.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-13T02:14:27.915+0000] {processor.py:157} INFO - Started process (PID=5550) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:14:27.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:14:27.919+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:27.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:14:27.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:27.943+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:14:28.149+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.149+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19100127900128427
[2025-01-13T02:14:28.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.150+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5550]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:14:28.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.151+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:14:28.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.151+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:14:28.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.152+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:14:28.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.152+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5550]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:14:28.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.159+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5550]: It took 0.00628s to build the Airflow DAG.
[2025-01-13T02:14:28.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:14:28.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.176+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:14:28.206+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:28.205+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:14:28.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-13T02:14:58.579+0000] {processor.py:157} INFO - Started process (PID=5636) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:14:58.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:14:58.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:14:58.608+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.608+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:14:58.791+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.791+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16605283399985638
[2025-01-13T02:14:58.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.791+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5636]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:14:58.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.792+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:14:58.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.793+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:14:58.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.793+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:14:58.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.794+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5636]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:14:58.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.799+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5636]: It took 0.00481s to build the Airflow DAG.
[2025-01-13T02:14:58.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:14:58.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.818+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:14:58.846+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:14:58.846+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:14:58.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-13T02:15:29.007+0000] {processor.py:157} INFO - Started process (PID=5724) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:15:29.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:15:29.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:15:29.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.032+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:15:29.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.174+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12747881100040104
[2025-01-13T02:15:29.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.174+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5724]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:15:29.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.175+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:15:29.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.175+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:15:29.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.176+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:15:29.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.176+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5724]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:15:29.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.180+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5724]: It took 0.00444s to build the Airflow DAG.
[2025-01-13T02:15:29.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:15:29.196+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.196+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:15:29.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:29.220+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:15:29.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-13T02:15:59.337+0000] {processor.py:157} INFO - Started process (PID=5816) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:15:59.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:15:59.346+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:15:59.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.417+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:15:59.599+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.599+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16619297099896357
[2025-01-13T02:15:59.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.600+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5816]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:15:59.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.601+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:15:59.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.601+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:15:59.602+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.602+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:15:59.602+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.602+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5816]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:15:59.608+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.608+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5816]: It took 0.00609s to build the Airflow DAG.
[2025-01-13T02:15:59.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:15:59.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.624+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:15:59.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:15:59.654+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:15:59.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.347 seconds
[2025-01-13T02:16:29.720+0000] {processor.py:157} INFO - Started process (PID=5913) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:16:29.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:16:29.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:16:29.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.748+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:16:29.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.930+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16737867099982395
[2025-01-13T02:16:29.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.930+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5913]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:16:29.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.931+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:16:29.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.931+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:16:29.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.932+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:16:29.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.932+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5913]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:16:29.937+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.936+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5913]: It took 0.00437s to build the Airflow DAG.
[2025-01-13T02:16:29.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:16:29.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.952+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:16:29.975+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:16:29.974+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:16:29.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.276 seconds
[2025-01-13T02:17:00.387+0000] {processor.py:157} INFO - Started process (PID=5999) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:17:00.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:17:00.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:17:00.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.415+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:17:00.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.605+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17579147899959935
[2025-01-13T02:17:00.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.606+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|5999]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:17:00.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.607+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:17:00.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.607+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:17:00.608+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.608+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:17:00.608+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.608+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|5999]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:17:00.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.613+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|5999]: It took 0.00494s to build the Airflow DAG.
[2025-01-13T02:17:00.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:17:00.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.629+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:17:00.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:00.654+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:17:00.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.294 seconds
[2025-01-13T02:17:30.727+0000] {processor.py:157} INFO - Started process (PID=6085) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:17:30.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:17:30.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:17:30.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.760+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:17:30.927+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.927+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15001236799980688
[2025-01-13T02:17:30.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.928+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6085]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:17:30.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.929+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:17:30.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.929+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:17:30.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.929+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:17:30.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.930+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6085]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:17:30.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.934+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6085]: It took 0.00417s to build the Airflow DAG.
[2025-01-13T02:17:30.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:17:30.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.949+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:17:30.974+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:17:30.973+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:17:30.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-13T02:18:01.129+0000] {processor.py:157} INFO - Started process (PID=6181) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:18:01.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:18:01.133+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:18:01.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.160+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:18:01.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.312+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1371997759997612
[2025-01-13T02:18:01.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.312+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6181]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:18:01.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.313+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:18:01.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.314+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:18:01.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.314+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:18:01.315+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.315+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6181]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:18:01.319+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.319+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6181]: It took 0.00447s to build the Airflow DAG.
[2025-01-13T02:18:01.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:18:01.335+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.335+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:18:01.361+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:01.360+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:18:01.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-13T02:18:32.323+0000] {processor.py:157} INFO - Started process (PID=6278) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:18:32.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:18:32.329+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:18:32.357+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.357+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:18:32.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.594+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21590461200139544
[2025-01-13T02:18:32.595+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.595+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6278]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:18:32.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.596+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:18:32.597+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.597+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:18:32.598+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.598+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:18:32.599+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.598+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6278]: It took 0.241s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:18:32.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.604+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6278]: It took 0.00609s to build the Airflow DAG.
[2025-01-13T02:18:32.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:18:32.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.626+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:18:32.667+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:18:32.666+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:18:32.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.372 seconds
[2025-01-13T02:19:02.727+0000] {processor.py:157} INFO - Started process (PID=6365) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:19:02.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:19:02.731+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:19:02.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.755+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:19:02.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.928+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15762015200016322
[2025-01-13T02:19:02.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.929+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6365]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:19:02.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.930+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:19:02.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.931+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:19:02.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.931+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:19:02.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.931+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6365]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:19:02.938+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.937+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6365]: It took 0.00592s to build the Airflow DAG.
[2025-01-13T02:19:02.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:19:02.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.958+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:19:02.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:02.990+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:19:03.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-13T02:19:33.066+0000] {processor.py:157} INFO - Started process (PID=6459) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:19:33.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:19:33.070+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:19:33.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.095+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:19:33.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.253+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14063504099976853
[2025-01-13T02:19:33.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.253+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6459]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:19:33.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.254+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:19:33.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.254+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:19:33.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.255+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:19:33.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.255+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6459]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:19:33.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.260+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6459]: It took 0.00448s to build the Airflow DAG.
[2025-01-13T02:19:33.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:19:33.278+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.278+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:19:33.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:19:33.307+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:19:33.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.272 seconds
[2025-01-13T02:20:04.323+0000] {processor.py:157} INFO - Started process (PID=6557) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:20:04.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:20:04.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:20:04.351+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.350+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:20:04.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.514+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14931295099995623
[2025-01-13T02:20:04.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.514+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6557]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:20:04.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.515+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:20:04.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.515+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:20:04.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.516+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:20:04.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.516+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6557]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:20:04.521+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.520+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6557]: It took 0.00423s to build the Airflow DAG.
[2025-01-13T02:20:04.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:20:04.537+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.536+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:20:04.561+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:04.561+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:20:04.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-13T02:20:34.752+0000] {processor.py:157} INFO - Started process (PID=6643) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:20:34.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:20:34.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:34.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:20:34.780+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:34.780+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:20:35.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.031+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23450967600001604
[2025-01-13T02:20:35.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.032+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6643]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:20:35.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.034+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:20:35.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.035+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:20:35.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.036+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:20:35.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.036+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6643]: It took 0.256s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:20:35.045+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.045+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6643]: It took 0.0088s to build the Airflow DAG.
[2025-01-13T02:20:35.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:20:35.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.067+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:20:35.100+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:20:35.100+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:20:35.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.378 seconds
[2025-01-13T02:21:05.205+0000] {processor.py:157} INFO - Started process (PID=6729) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:21:05.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:21:05.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:21:05.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.233+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:21:05.447+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.447+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1967935230004514
[2025-01-13T02:21:05.448+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.448+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6729]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:21:05.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.449+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:21:05.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.449+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:21:05.450+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.450+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:21:05.450+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.450+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6729]: It took 0.217s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:21:05.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.456+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6729]: It took 0.00648s to build the Airflow DAG.
[2025-01-13T02:21:05.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:21:05.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.474+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:21:05.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:05.502+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:21:05.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.321 seconds
[2025-01-13T02:21:35.771+0000] {processor.py:157} INFO - Started process (PID=6823) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:21:35.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:21:35.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:21:35.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.805+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:21:35.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.985+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1652307739987009
[2025-01-13T02:21:35.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.986+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6823]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:21:35.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.987+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:21:35.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.988+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:21:35.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.989+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:21:35.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.989+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6823]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:21:35.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:35.995+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6823]: It took 0.00581s to build the Airflow DAG.
[2025-01-13T02:21:35.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:21:36.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:36.015+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:21:36.050+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:21:36.050+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:21:36.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.309 seconds
[2025-01-13T02:22:06.666+0000] {processor.py:157} INFO - Started process (PID=6920) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:22:06.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:22:06.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:22:06.693+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.693+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:22:06.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.875+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1671861649992934
[2025-01-13T02:22:06.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.875+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|6920]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:22:06.876+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.876+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:22:06.877+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.877+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:22:06.877+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.877+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:22:06.878+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.877+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|6920]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:22:06.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.882+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|6920]: It took 0.00426s to build the Airflow DAG.
[2025-01-13T02:22:06.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:22:06.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.898+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:22:06.924+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:06.924+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:22:06.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-13T02:22:37.087+0000] {processor.py:157} INFO - Started process (PID=7006) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:22:37.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:22:37.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:22:37.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.119+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:22:37.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.323+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18906827899991185
[2025-01-13T02:22:37.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.323+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7006]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:22:37.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.324+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:22:37.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.325+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:22:37.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.325+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:22:37.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.326+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7006]: It took 0.207s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:22:37.330+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.330+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7006]: It took 0.00411s to build the Airflow DAG.
[2025-01-13T02:22:37.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:22:37.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.347+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:22:37.377+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:22:37.377+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:22:37.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.318 seconds
[2025-01-13T02:23:07.522+0000] {processor.py:157} INFO - Started process (PID=7092) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:23:07.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:23:07.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:23:07.555+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.555+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:23:07.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.804+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23353750500064052
[2025-01-13T02:23:07.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.805+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7092]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:23:07.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.806+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:23:07.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.807+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:23:07.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.807+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:23:07.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.807+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7092]: It took 0.252s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:23:07.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.813+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7092]: It took 0.00563s to build the Airflow DAG.
[2025-01-13T02:23:07.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:23:07.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.832+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:23:07.866+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:07.866+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:23:07.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.371 seconds
[2025-01-13T02:23:38.762+0000] {processor.py:157} INFO - Started process (PID=7187) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:23:38.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:23:38.766+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:38.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:23:38.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:38.792+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:23:39.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.011+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1981524389993865
[2025-01-13T02:23:39.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.012+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7187]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:23:39.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.013+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:23:39.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.014+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:23:39.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.014+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:23:39.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.015+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7187]: It took 0.223s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:23:39.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.021+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7187]: It took 0.00643s to build the Airflow DAG.
[2025-01-13T02:23:39.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:23:39.046+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.046+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:23:39.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:23:39.080+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:23:39.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.345 seconds
[2025-01-13T02:24:09.511+0000] {processor.py:157} INFO - Started process (PID=7284) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:24:09.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:24:09.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:24:09.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.536+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:24:09.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.726+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17518147199916712
[2025-01-13T02:24:09.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.727+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7284]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:24:09.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.728+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:24:09.729+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.728+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:24:09.729+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.729+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:24:09.730+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.729+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7284]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:24:09.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.735+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7284]: It took 0.0053s to build the Airflow DAG.
[2025-01-13T02:24:09.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:24:09.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.752+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:24:09.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:09.783+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:24:09.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-13T02:24:39.954+0000] {processor.py:157} INFO - Started process (PID=7370) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:24:39.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:24:39.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:39.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:24:39.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:39.979+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:24:40.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.166+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17224325600000157
[2025-01-13T02:24:40.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.166+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7370]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:24:40.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.167+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:24:40.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.167+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:24:40.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.168+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:24:40.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.168+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7370]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:24:40.172+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.172+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7370]: It took 0.00398s to build the Airflow DAG.
[2025-01-13T02:24:40.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:24:40.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.190+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:24:40.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:24:40.217+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:24:40.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-13T02:25:10.365+0000] {processor.py:157} INFO - Started process (PID=7456) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:25:10.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:25:10.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:25:10.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.391+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:25:10.587+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.587+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1808884579986625
[2025-01-13T02:25:10.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.588+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7456]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:25:10.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.589+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:25:10.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.589+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:25:10.590+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.590+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:25:10.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.590+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7456]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:25:10.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.596+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7456]: It took 0.00525s to build the Airflow DAG.
[2025-01-13T02:25:10.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:25:10.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.615+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:25:10.647+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:10.647+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:25:10.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-13T02:25:40.712+0000] {processor.py:157} INFO - Started process (PID=7542) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:25:40.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:25:40.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:25:40.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.736+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:25:40.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.932+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18214248999902338
[2025-01-13T02:25:40.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.933+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7542]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:25:40.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.934+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:25:40.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.934+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:25:40.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.935+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:25:40.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.935+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7542]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:25:40.941+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.941+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7542]: It took 0.0053s to build the Airflow DAG.
[2025-01-13T02:25:40.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:25:40.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.961+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:25:40.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:25:40.989+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:25:41.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-13T02:26:11.090+0000] {processor.py:157} INFO - Started process (PID=7647) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:26:11.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:26:11.094+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:26:11.119+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.119+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:26:11.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.312+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1751536899992061
[2025-01-13T02:26:11.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.312+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7647]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:26:11.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.313+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:26:11.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.314+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:26:11.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.314+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:26:11.315+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.315+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7647]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:26:11.322+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.322+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7647]: It took 0.00702s to build the Airflow DAG.
[2025-01-13T02:26:11.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:26:11.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.339+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:26:11.368+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:11.367+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:26:11.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-13T02:26:41.558+0000] {processor.py:157} INFO - Started process (PID=7733) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:26:41.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:26:41.562+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:26:41.584+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.583+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:26:41.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.751+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15342943399991782
[2025-01-13T02:26:41.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.752+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7733]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:26:41.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.753+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:26:41.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.753+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:26:41.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.753+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:26:41.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.754+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7733]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:26:41.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.757+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7733]: It took 0.00364s to build the Airflow DAG.
[2025-01-13T02:26:41.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:26:41.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.772+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:26:41.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:26:41.795+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:26:41.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-13T02:27:12.206+0000] {processor.py:157} INFO - Started process (PID=7819) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:27:12.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:27:12.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:27:12.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.234+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:27:12.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.415+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16629465299956792
[2025-01-13T02:27:12.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.415+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7819]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:27:12.416+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.416+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:27:12.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.417+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:27:12.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.417+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:27:12.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.418+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7819]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:27:12.423+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.423+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7819]: It took 0.00501s to build the Airflow DAG.
[2025-01-13T02:27:12.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:27:12.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.439+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:27:12.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:12.466+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:27:12.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.523 seconds
[2025-01-13T02:27:42.810+0000] {processor.py:157} INFO - Started process (PID=7911) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:27:42.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:27:42.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:42.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:27:42.842+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:42.841+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:27:43.123+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.123+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.25596411600054125
[2025-01-13T02:27:43.125+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.124+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7911]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:27:43.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.126+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:27:43.128+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.128+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:27:43.129+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.129+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:27:43.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.130+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7911]: It took 0.289s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:27:43.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.137+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7911]: It took 0.00762s to build the Airflow DAG.
[2025-01-13T02:27:43.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:27:43.157+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.157+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:27:43.186+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:27:43.186+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:27:43.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.405 seconds
[2025-01-13T02:28:13.291+0000] {processor.py:157} INFO - Started process (PID=7997) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:28:13.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:28:13.298+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:28:13.330+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.330+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:28:13.557+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.556+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20742523599983542
[2025-01-13T02:28:13.557+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.557+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|7997]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:28:13.558+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.558+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:28:13.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.558+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:28:13.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.559+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:28:13.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.559+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|7997]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:28:13.565+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.565+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|7997]: It took 0.0055s to build the Airflow DAG.
[2025-01-13T02:28:13.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:28:13.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.585+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:28:13.621+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:13.621+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:28:13.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.366 seconds
[2025-01-13T02:28:43.995+0000] {processor.py:157} INFO - Started process (PID=8091) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:28:43.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:28:44.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:28:44.029+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.029+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:28:44.211+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.210+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16550042600101733
[2025-01-13T02:28:44.211+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.211+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8091]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:28:44.212+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.212+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:28:44.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.213+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:28:44.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.213+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:28:44.214+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.214+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8091]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:28:44.219+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.219+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8091]: It took 0.00532s to build the Airflow DAG.
[2025-01-13T02:28:44.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:28:44.239+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.239+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:28:44.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:28:44.277+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:28:44.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.493 seconds
[2025-01-13T02:29:15.138+0000] {processor.py:157} INFO - Started process (PID=8188) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:29:15.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:29:15.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:29:15.170+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.170+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:29:15.385+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.384+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19856804499977443
[2025-01-13T02:29:15.385+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.385+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8188]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:29:15.386+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.386+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:29:15.387+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.387+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:29:15.387+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.387+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:29:15.388+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.388+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8188]: It took 0.218s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:29:15.397+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.397+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8188]: It took 0.00881s to build the Airflow DAG.
[2025-01-13T02:29:15.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:29:15.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.417+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:29:15.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:15.444+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:29:15.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.327 seconds
[2025-01-13T02:29:45.668+0000] {processor.py:157} INFO - Started process (PID=8274) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:29:45.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:29:45.672+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:29:45.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.696+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:29:45.885+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.885+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17579371499959962
[2025-01-13T02:29:45.886+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.886+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8274]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:29:45.886+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.886+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:29:45.887+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.887+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:29:45.887+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.887+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:29:45.887+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.887+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8274]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:29:45.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.891+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8274]: It took 0.00338s to build the Airflow DAG.
[2025-01-13T02:29:45.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:29:45.908+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.908+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:29:45.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:29:45.930+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:29:45.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.291 seconds
[2025-01-13T02:30:16.781+0000] {processor.py:157} INFO - Started process (PID=8360) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:30:16.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:30:16.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:30:16.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.810+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:30:16.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.980+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1541001490004419
[2025-01-13T02:30:16.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.980+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8360]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:30:16.981+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.981+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:30:16.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.981+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:30:16.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.982+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:30:16.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.982+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8360]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:30:16.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:16.986+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8360]: It took 0.00411s to build the Airflow DAG.
[2025-01-13T02:30:16.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:30:17.003+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:17.003+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:30:17.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:17.207+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:30:17.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.449 seconds
[2025-01-13T02:30:47.593+0000] {processor.py:157} INFO - Started process (PID=8446) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:30:47.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:30:47.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:30:47.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.619+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:30:47.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.800+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1665892380005971
[2025-01-13T02:30:47.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.801+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8446]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:30:47.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.801+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:30:47.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.802+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:30:47.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.802+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:30:47.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.802+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8446]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:30:47.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.807+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8446]: It took 0.00424s to build the Airflow DAG.
[2025-01-13T02:30:47.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:30:47.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.822+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:30:47.848+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:30:47.848+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:30:47.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-13T02:31:18.391+0000] {processor.py:157} INFO - Started process (PID=8551) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:31:18.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:31:18.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:31:18.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.424+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:31:18.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.630+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19000911100010853
[2025-01-13T02:31:18.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.631+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8551]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:31:18.632+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.632+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:31:18.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.632+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:31:18.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.633+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:31:18.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.633+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8551]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:31:18.639+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.638+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8551]: It took 0.00506s to build the Airflow DAG.
[2025-01-13T02:31:18.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:31:18.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.659+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:31:18.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:18.689+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:31:18.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.332 seconds
[2025-01-13T02:31:49.290+0000] {processor.py:157} INFO - Started process (PID=8637) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:31:49.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:31:49.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:31:49.316+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.315+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:31:49.462+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.462+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13352440900052898
[2025-01-13T02:31:49.463+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.462+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8637]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:31:49.463+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.463+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:31:49.464+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.464+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:31:49.464+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.464+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:31:49.464+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.464+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8637]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:31:49.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.468+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8637]: It took 0.0035s to build the Airflow DAG.
[2025-01-13T02:31:49.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:31:49.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.482+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:31:49.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:31:49.503+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:31:49.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.396 seconds
[2025-01-13T02:32:20.178+0000] {processor.py:157} INFO - Started process (PID=8723) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:32:20.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:32:20.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:32:20.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.207+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:32:20.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.347+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12591151000015088
[2025-01-13T02:32:20.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.347+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8723]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:32:20.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.348+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:32:20.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.348+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:32:20.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.348+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:32:20.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.349+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8723]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:32:20.353+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.353+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8723]: It took 0.00404s to build the Airflow DAG.
[2025-01-13T02:32:20.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:32:20.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.369+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:32:20.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:20.395+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:32:20.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-13T02:32:50.888+0000] {processor.py:157} INFO - Started process (PID=8809) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:32:50.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:32:50.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:50.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:32:50.921+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:50.921+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:32:51.102+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.101+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16700835300071049
[2025-01-13T02:32:51.102+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.102+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8809]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:32:51.103+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.103+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:32:51.103+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.103+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:32:51.104+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.103+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:32:51.104+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.104+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8809]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:32:51.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.108+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8809]: It took 0.00418s to build the Airflow DAG.
[2025-01-13T02:32:51.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:32:51.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.126+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:32:51.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:32:51.313+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:32:51.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.454 seconds
[2025-01-13T02:33:22.092+0000] {processor.py:157} INFO - Started process (PID=8914) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:33:22.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:33:22.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:33:22.122+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.121+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:33:22.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.285+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15046782399986114
[2025-01-13T02:33:22.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.286+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|8914]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:33:22.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.287+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:33:22.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.287+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:33:22.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.288+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:33:22.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.288+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|8914]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:33:22.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.293+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|8914]: It took 0.00454s to build the Airflow DAG.
[2025-01-13T02:33:22.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:33:22.310+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.309+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:33:22.337+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:22.337+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:33:22.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.435 seconds
[2025-01-13T02:33:52.974+0000] {processor.py:157} INFO - Started process (PID=9000) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:33:52.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:33:52.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:52.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:33:53.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.006+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:33:53.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.229+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2101059919987165
[2025-01-13T02:33:53.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.229+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9000]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:33:53.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.230+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:33:53.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.231+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:33:53.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.231+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:33:53.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.232+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9000]: It took 0.226s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:33:53.239+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.239+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9000]: It took 0.00669s to build the Airflow DAG.
[2025-01-13T02:33:53.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:33:53.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.260+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:33:53.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:33:53.293+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:33:53.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.343 seconds
[2025-01-13T02:34:23.391+0000] {processor.py:157} INFO - Started process (PID=9086) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:34:23.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:34:23.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:34:23.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.415+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:34:23.575+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.575+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14437531000112358
[2025-01-13T02:34:23.575+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.575+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9086]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:34:23.576+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.576+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:34:23.576+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.576+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:34:23.577+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.577+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:34:23.577+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.577+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9086]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:34:23.581+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.581+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9086]: It took 0.00395s to build the Airflow DAG.
[2025-01-13T02:34:23.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:34:23.598+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.598+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:34:23.622+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:23.622+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:34:23.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-13T02:34:53.884+0000] {processor.py:157} INFO - Started process (PID=9173) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:34:53.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:34:53.888+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:53.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:34:53.913+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:53.913+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:34:54.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.072+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14500070700159995
[2025-01-13T02:34:54.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.073+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9173]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:34:54.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.073+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:34:54.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.074+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:34:54.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.074+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:34:54.075+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.075+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9173]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:34:54.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.079+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9173]: It took 0.00423s to build the Airflow DAG.
[2025-01-13T02:34:54.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:34:54.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.096+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:34:54.298+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:34:54.297+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:34:54.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.472 seconds
[2025-01-13T02:35:24.650+0000] {processor.py:157} INFO - Started process (PID=9266) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:35:24.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:35:24.653+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:35:24.680+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.680+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:35:24.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.867+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17420703500101808
[2025-01-13T02:35:24.868+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.868+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9266]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:35:24.869+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.868+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:35:24.869+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.869+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:35:24.869+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.869+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:35:24.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.870+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9266]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:35:24.874+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.874+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9266]: It took 0.00448s to build the Airflow DAG.
[2025-01-13T02:35:24.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:35:24.896+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.896+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:35:24.923+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:24.923+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:35:24.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-13T02:35:55.752+0000] {processor.py:157} INFO - Started process (PID=9364) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:35:55.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:35:55.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:35:55.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.798+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:35:55.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.950+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13804069899924798
[2025-01-13T02:35:55.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.950+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9364]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:35:55.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.951+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:35:55.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.951+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:35:55.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.952+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:35:55.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.952+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9364]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:35:55.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:55.956+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9364]: It took 0.00354s to build the Airflow DAG.
[2025-01-13T02:35:55.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:35:56.124+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:56.124+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:35:56.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:35:56.145+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:35:56.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.422 seconds
[2025-01-13T02:36:27.138+0000] {processor.py:157} INFO - Started process (PID=9450) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:36:27.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:36:27.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:36:27.163+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.163+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:36:27.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.323+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14582927700030268
[2025-01-13T02:36:27.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.324+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9450]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:36:27.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.325+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:36:27.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.325+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:36:27.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.325+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:36:27.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.325+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9450]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:36:27.329+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.329+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9450]: It took 0.00358s to build the Airflow DAG.
[2025-01-13T02:36:27.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:36:27.344+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.344+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:36:27.522+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:27.522+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:36:27.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.415 seconds
[2025-01-13T02:36:57.816+0000] {processor.py:157} INFO - Started process (PID=9536) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:36:57.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:36:57.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:57.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:36:57.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:57.849+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:36:58.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.055+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1892882970005303
[2025-01-13T02:36:58.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.055+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9536]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:36:58.056+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.056+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:36:58.057+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.057+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:36:58.057+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.057+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:36:58.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.058+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9536]: It took 0.209s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:36:58.303+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.303+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9536]: It took 0.246s to build the Airflow DAG.
[2025-01-13T02:36:58.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:36:58.319+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.319+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:36:58.343+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:36:58.342+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:36:58.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.556 seconds
[2025-01-13T02:37:28.532+0000] {processor.py:157} INFO - Started process (PID=9622) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:37:28.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:37:28.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:37:28.566+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.566+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:37:28.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.726+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14590390699959244
[2025-01-13T02:37:28.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.726+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9622]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:37:28.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.727+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:37:28.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.728+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:37:28.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.728+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:37:28.729+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.729+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9622]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:37:28.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.733+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9622]: It took 0.00466s to build the Airflow DAG.
[2025-01-13T02:37:28.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:37:28.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.749+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:37:28.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:28.946+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:37:28.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.444 seconds
[2025-01-13T02:37:59.109+0000] {processor.py:157} INFO - Started process (PID=9727) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:37:59.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:37:59.116+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:37:59.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.139+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:37:59.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.314+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15944038199995703
[2025-01-13T02:37:59.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.314+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9727]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:37:59.315+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.315+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:37:59.315+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.315+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:37:59.316+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.316+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:37:59.316+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.316+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9727]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:37:59.320+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.320+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9727]: It took 0.00429s to build the Airflow DAG.
[2025-01-13T02:37:59.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:37:59.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.340+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:37:59.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:37:59.536+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:37:59.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.452 seconds
[2025-01-13T02:38:29.899+0000] {processor.py:157} INFO - Started process (PID=9813) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:38:29.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:38:29.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:29.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:38:30.105+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.104+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:38:30.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.252+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13596972499908588
[2025-01-13T02:38:30.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.253+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9813]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:38:30.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.254+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:38:30.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.254+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:38:30.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.254+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:38:30.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.254+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9813]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:38:30.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.258+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9813]: It took 0.00338s to build the Airflow DAG.
[2025-01-13T02:38:30.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:38:30.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.274+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:38:30.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:38:30.295+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:38:30.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.421 seconds
[2025-01-13T02:39:01.135+0000] {processor.py:157} INFO - Started process (PID=9899) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:39:01.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:39:01.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:39:01.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.168+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:39:01.352+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.352+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1679746099998738
[2025-01-13T02:39:01.353+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.352+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9899]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:39:01.353+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.353+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:39:01.354+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.354+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:39:01.354+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.354+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:39:01.355+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.354+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9899]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:39:01.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.358+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9899]: It took 0.00367s to build the Airflow DAG.
[2025-01-13T02:39:01.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:39:01.373+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.372+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:39:01.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:01.401+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:39:01.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-13T02:39:31.538+0000] {processor.py:157} INFO - Started process (PID=9985) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:39:31.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:39:31.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:39:31.567+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.566+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:39:31.722+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.722+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14347276700027578
[2025-01-13T02:39:31.722+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.722+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|9985]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:39:31.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.723+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:39:31.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.724+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:39:31.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.724+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:39:31.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.724+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|9985]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:39:31.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.728+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|9985]: It took 0.00374s to build the Airflow DAG.
[2025-01-13T02:39:31.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:39:31.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.742+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:39:31.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:39:31.772+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:39:31.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-13T02:40:01.875+0000] {processor.py:157} INFO - Started process (PID=10090) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:40:01.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:40:01.879+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:01.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:40:01.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:01.905+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:40:02.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.071+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14935367700127244
[2025-01-13T02:40:02.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.072+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10090]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:40:02.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.073+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:40:02.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.073+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:40:02.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.074+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:40:02.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.074+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10090]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:40:02.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.079+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10090]: It took 0.00491s to build the Airflow DAG.
[2025-01-13T02:40:02.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:40:02.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.097+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:40:02.125+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:02.125+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:40:02.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-13T02:40:32.218+0000] {processor.py:157} INFO - Started process (PID=10176) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:40:32.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:40:32.222+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:40:32.245+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.245+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:40:32.397+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.397+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13707847899968328
[2025-01-13T02:40:32.398+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.398+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10176]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:40:32.399+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.399+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:40:32.399+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.399+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:40:32.400+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.400+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:40:32.400+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.400+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10176]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:40:32.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.404+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10176]: It took 0.00445s to build the Airflow DAG.
[2025-01-13T02:40:32.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:40:32.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.419+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:40:32.446+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:40:32.445+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:40:32.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-13T02:41:03.396+0000] {processor.py:157} INFO - Started process (PID=10262) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:41:03.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:41:03.403+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:41:03.441+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.441+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:41:03.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.706+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23961711500123783
[2025-01-13T02:41:03.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.707+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10262]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:41:03.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.709+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:41:03.710+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.710+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:41:03.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.710+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:41:03.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.711+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10262]: It took 0.271s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:41:03.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.719+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10262]: It took 0.00763s to build the Airflow DAG.
[2025-01-13T02:41:03.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:41:03.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.760+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:41:03.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:03.835+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:41:03.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.481 seconds
[2025-01-13T02:41:34.698+0000] {processor.py:157} INFO - Started process (PID=10348) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:41:34.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:41:34.703+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:41:34.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.735+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:41:34.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.900+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1468399799996405
[2025-01-13T02:41:34.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.900+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10348]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:41:34.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.901+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:41:34.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.902+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:41:34.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.902+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:41:34.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.902+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10348]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:41:34.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.906+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10348]: It took 0.00403s to build the Airflow DAG.
[2025-01-13T02:41:34.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:41:34.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.925+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:41:34.954+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:41:34.954+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:41:34.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-13T02:42:05.583+0000] {processor.py:157} INFO - Started process (PID=10453) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:42:05.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:42:05.587+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:42:05.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.611+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:42:05.778+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.777+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1523374619991955
[2025-01-13T02:42:05.779+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.778+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10453]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:42:05.781+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.781+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:42:05.782+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.782+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:42:05.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.784+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:42:05.785+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.785+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10453]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:42:05.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.794+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10453]: It took 0.00911s to build the Airflow DAG.
[2025-01-13T02:42:05.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:42:05.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.813+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:42:05.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:05.837+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:42:05.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-13T02:42:35.980+0000] {processor.py:157} INFO - Started process (PID=10539) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:42:35.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:42:35.985+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:35.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:42:36.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.011+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:42:36.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.174+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14928426100050274
[2025-01-13T02:42:36.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.174+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10539]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:42:36.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.175+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:42:36.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.175+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:42:36.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.176+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:42:36.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.176+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10539]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:42:36.179+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.179+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10539]: It took 0.00342s to build the Airflow DAG.
[2025-01-13T02:42:36.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:42:36.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.195+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:42:36.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:42:36.218+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:42:36.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-13T02:43:06.294+0000] {processor.py:157} INFO - Started process (PID=10625) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:43:06.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:43:06.299+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:43:06.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.332+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:43:06.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.514+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1665444779991958
[2025-01-13T02:43:06.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.514+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10625]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:43:06.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.515+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:43:06.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.515+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:43:06.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.516+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:43:06.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.516+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10625]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:43:06.522+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.521+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10625]: It took 0.00528s to build the Airflow DAG.
[2025-01-13T02:43:06.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:43:06.539+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.539+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:43:06.564+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:06.564+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:43:06.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.303 seconds
[2025-01-13T02:43:37.553+0000] {processor.py:157} INFO - Started process (PID=10718) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:43:37.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:43:37.557+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:43:37.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.582+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:43:37.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.733+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13834078000036243
[2025-01-13T02:43:37.734+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.734+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10718]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:43:37.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.735+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:43:37.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.735+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:43:37.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.735+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:43:37.736+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.736+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10718]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:43:37.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.740+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10718]: It took 0.00449s to build the Airflow DAG.
[2025-01-13T02:43:37.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:43:37.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.759+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:43:37.782+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:43:37.782+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:43:37.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-13T02:44:07.935+0000] {processor.py:157} INFO - Started process (PID=10816) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:44:07.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:44:07.939+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:07.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:44:07.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:07.962+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:44:08.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.138+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16039605699916137
[2025-01-13T02:44:08.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.138+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10816]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:44:08.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.139+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:44:08.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.139+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:44:08.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.140+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:44:08.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.140+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10816]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:44:08.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.144+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10816]: It took 0.00386s to build the Airflow DAG.
[2025-01-13T02:44:08.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:44:08.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.158+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:44:08.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:08.181+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:44:08.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-13T02:44:38.333+0000] {processor.py:157} INFO - Started process (PID=10902) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:44:38.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:44:38.337+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:44:38.365+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.365+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:44:38.524+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.524+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14504509799917287
[2025-01-13T02:44:38.524+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.524+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10902]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:44:38.525+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.525+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:44:38.525+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.525+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:44:38.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.526+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:44:38.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.526+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10902]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:44:38.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.530+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10902]: It took 0.00397s to build the Airflow DAG.
[2025-01-13T02:44:38.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:44:38.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.544+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:44:38.567+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:44:38.566+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:44:38.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-13T02:45:08.733+0000] {processor.py:157} INFO - Started process (PID=10989) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:45:08.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:45:08.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:45:08.766+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.765+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:45:08.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.954+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17355773199960822
[2025-01-13T02:45:08.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.955+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|10989]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:45:08.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.956+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:45:08.957+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.957+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:45:08.957+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.957+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:45:08.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.958+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|10989]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:45:08.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.963+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|10989]: It took 0.00514s to build the Airflow DAG.
[2025-01-13T02:45:08.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:45:08.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:08.981+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:45:09.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:09.008+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:45:09.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-13T02:45:39.131+0000] {processor.py:157} INFO - Started process (PID=11077) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:45:39.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:45:39.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:45:39.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.158+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:45:39.298+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.298+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12307215500004531
[2025-01-13T02:45:39.298+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.298+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11077]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:45:39.299+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.299+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:45:39.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.300+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:45:39.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.300+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:45:39.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.300+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11077]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:45:39.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.305+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11077]: It took 0.00456s to build the Airflow DAG.
[2025-01-13T02:45:39.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:45:39.322+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.321+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:45:39.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:45:39.347+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:45:39.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-13T02:46:09.507+0000] {processor.py:157} INFO - Started process (PID=11182) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:46:09.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:46:09.511+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:46:09.538+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.537+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:46:09.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.725+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1724825109995436
[2025-01-13T02:46:09.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.725+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11182]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:46:09.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.726+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:46:09.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.726+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:46:09.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.727+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:46:09.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.727+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11182]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:46:09.731+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.731+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11182]: It took 0.00379s to build the Airflow DAG.
[2025-01-13T02:46:09.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:46:09.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.746+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:46:09.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:09.772+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:46:09.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T02:46:39.856+0000] {processor.py:157} INFO - Started process (PID=11268) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:46:39.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:46:39.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:39.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:46:39.884+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:39.884+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:46:40.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.033+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1342811590002384
[2025-01-13T02:46:40.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.033+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11268]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:46:40.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.034+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:46:40.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.034+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:46:40.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.035+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:46:40.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.035+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11268]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:46:40.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.038+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11268]: It took 0.00335s to build the Airflow DAG.
[2025-01-13T02:46:40.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:46:40.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.052+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:46:40.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:46:40.074+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:46:40.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-13T02:47:11.022+0000] {processor.py:157} INFO - Started process (PID=11354) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:47:11.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:47:11.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:47:11.048+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.048+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:47:11.215+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.215+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15468921100000443
[2025-01-13T02:47:11.215+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.215+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11354]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:47:11.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.216+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:47:11.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.216+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:47:11.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.217+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:47:11.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.217+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11354]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:47:11.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.221+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11354]: It took 0.00431s to build the Airflow DAG.
[2025-01-13T02:47:11.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:47:11.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.237+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:47:11.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:11.265+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:47:11.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-13T02:47:41.415+0000] {processor.py:157} INFO - Started process (PID=11440) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:47:41.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:47:41.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:47:41.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.443+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:47:41.639+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.638+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1795080149986461
[2025-01-13T02:47:41.639+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.639+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11440]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:47:41.640+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.640+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:47:41.640+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.640+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:47:41.641+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.641+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:47:41.641+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.641+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11440]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:47:41.646+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.646+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11440]: It took 0.00464s to build the Airflow DAG.
[2025-01-13T02:47:41.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:47:41.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.661+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:47:41.689+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:47:41.689+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:47:41.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-13T02:48:11.784+0000] {processor.py:157} INFO - Started process (PID=11547) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:48:11.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:48:11.788+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:48:11.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.814+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:48:11.964+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.964+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13423691600110033
[2025-01-13T02:48:11.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.965+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11547]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:48:11.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.965+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:48:11.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.966+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:48:11.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.966+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:48:11.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.967+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11547]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:48:11.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.970+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11547]: It took 0.00368s to build the Airflow DAG.
[2025-01-13T02:48:11.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:48:11.985+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:11.985+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:48:12.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:12.011+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:48:12.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-13T02:48:42.915+0000] {processor.py:157} INFO - Started process (PID=11633) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:48:42.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:48:42.918+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:42.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:48:42.940+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:42.940+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:48:43.091+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.090+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13685869900109537
[2025-01-13T02:48:43.091+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.091+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11633]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:48:43.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.092+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:48:43.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.092+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:48:43.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.092+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:48:43.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.093+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11633]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:48:43.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.096+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11633]: It took 0.00354s to build the Airflow DAG.
[2025-01-13T02:48:43.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:48:43.111+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.111+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:48:43.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:48:43.135+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:48:43.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-13T02:49:13.547+0000] {processor.py:157} INFO - Started process (PID=11719) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:49:13.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:49:13.551+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:49:13.577+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.576+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:49:13.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.753+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1618030589997943
[2025-01-13T02:49:13.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.754+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11719]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:49:13.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.755+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:49:13.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.755+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:49:13.756+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.756+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:49:13.756+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.756+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11719]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:49:13.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.762+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11719]: It took 0.00622s to build the Airflow DAG.
[2025-01-13T02:49:13.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:49:13.791+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.791+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:49:13.827+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:13.827+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:49:13.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.309 seconds
[2025-01-13T02:49:44.093+0000] {processor.py:157} INFO - Started process (PID=11805) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:49:44.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:49:44.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:49:44.118+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.118+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:49:44.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.284+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15229212999838637
[2025-01-13T02:49:44.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.284+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11805]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:49:44.285+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.285+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:49:44.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.286+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:49:44.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.286+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:49:44.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.286+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11805]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:49:44.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.291+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11805]: It took 0.00473s to build the Airflow DAG.
[2025-01-13T02:49:44.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:49:44.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.307+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:49:44.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:49:44.332+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:49:44.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-13T02:50:14.504+0000] {processor.py:157} INFO - Started process (PID=11910) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:50:14.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:50:14.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:50:14.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.534+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:50:14.712+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.712+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16200344400022004
[2025-01-13T02:50:14.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.713+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11910]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:50:14.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.713+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:50:14.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.714+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:50:14.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.714+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:50:14.715+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.715+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11910]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:50:14.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.719+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11910]: It took 0.00443s to build the Airflow DAG.
[2025-01-13T02:50:14.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:50:14.736+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.735+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:50:14.764+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:14.764+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:50:14.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T02:50:45.702+0000] {processor.py:157} INFO - Started process (PID=11996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:50:45.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:50:45.705+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:50:45.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.728+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:50:45.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.858+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1178697329996794
[2025-01-13T02:50:45.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.859+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|11996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:50:45.860+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.860+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:50:45.860+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.860+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:50:45.861+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.861+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:50:45.861+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.861+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|11996]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:50:45.865+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.864+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|11996]: It took 0.0035s to build the Airflow DAG.
[2025-01-13T02:50:45.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:50:45.878+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.878+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:50:45.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:50:45.899+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:50:45.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-13T02:51:15.999+0000] {processor.py:157} INFO - Started process (PID=12082) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:51:16.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:51:16.002+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:51:16.029+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.029+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:51:16.212+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.212+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16743445199972484
[2025-01-13T02:51:16.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.213+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12082]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:51:16.215+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.215+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:51:16.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.216+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:51:16.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.216+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:51:16.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.217+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12082]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:51:16.226+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.226+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12082]: It took 0.00878s to build the Airflow DAG.
[2025-01-13T02:51:16.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:51:16.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.244+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:51:16.272+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:16.272+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:51:16.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-13T02:51:46.478+0000] {processor.py:157} INFO - Started process (PID=12168) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:51:46.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:51:46.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:51:46.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.512+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:51:46.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.759+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22987211500003468
[2025-01-13T02:51:46.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.760+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12168]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:51:46.762+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.761+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:51:46.762+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.762+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:51:46.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.763+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:51:46.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.763+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12168]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:51:46.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.769+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12168]: It took 0.00614s to build the Airflow DAG.
[2025-01-13T02:51:46.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:51:46.790+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.790+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:51:46.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:51:46.822+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:51:46.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.374 seconds
[2025-01-13T02:52:16.905+0000] {processor.py:157} INFO - Started process (PID=12273) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:52:16.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:52:16.909+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:16.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:52:16.939+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:16.939+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:52:17.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.143+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18470089299989922
[2025-01-13T02:52:17.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.143+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12273]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:52:17.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.144+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:52:17.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.145+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:52:17.145+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.145+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:52:17.146+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.146+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12273]: It took 0.207s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:52:17.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.151+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12273]: It took 0.0056s to build the Airflow DAG.
[2025-01-13T02:52:17.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:52:17.173+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.173+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:52:17.203+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:17.202+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:52:17.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-13T02:52:47.714+0000] {processor.py:157} INFO - Started process (PID=12359) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:52:47.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:52:47.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:52:47.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.743+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:52:47.880+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.879+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12317911900026957
[2025-01-13T02:52:47.880+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.880+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12359]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:52:47.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.881+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:52:47.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.881+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:52:47.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.881+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:52:47.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.882+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12359]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:52:47.885+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.885+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12359]: It took 0.00342s to build the Airflow DAG.
[2025-01-13T02:52:47.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:52:47.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.899+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:52:47.921+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:52:47.921+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:52:47.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-13T02:53:18.506+0000] {processor.py:157} INFO - Started process (PID=12446) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:53:18.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:53:18.511+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:53:18.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.541+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:53:18.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.751+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1916693640014273
[2025-01-13T02:53:18.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.752+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12446]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:53:18.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.753+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:53:18.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.754+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:53:18.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.754+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:53:18.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.755+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12446]: It took 0.214s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:53:18.761+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.760+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12446]: It took 0.00551s to build the Airflow DAG.
[2025-01-13T02:53:18.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:53:18.780+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.779+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:53:18.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:18.808+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:53:18.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.331 seconds
[2025-01-13T02:53:48.916+0000] {processor.py:157} INFO - Started process (PID=12532) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:53:48.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:53:48.922+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:48.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:53:48.957+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:48.957+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:53:49.125+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.125+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15169207099825144
[2025-01-13T02:53:49.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.126+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12532]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:53:49.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.127+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:53:49.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.127+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:53:49.128+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.128+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:53:49.128+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.128+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12532]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:53:49.134+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.133+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12532]: It took 0.00512s to build the Airflow DAG.
[2025-01-13T02:53:49.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:53:49.149+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.149+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:53:49.172+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:53:49.172+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:53:49.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-13T02:54:19.817+0000] {processor.py:157} INFO - Started process (PID=12637) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:54:19.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:54:19.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:19.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:54:19.846+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:19.846+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:54:20.046+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.046+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18378441800086875
[2025-01-13T02:54:20.047+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.047+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12637]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:54:20.047+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.047+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:54:20.048+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.048+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:54:20.048+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.048+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:54:20.049+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.048+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12637]: It took 0.202s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:54:20.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.052+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12637]: It took 0.00363s to build the Airflow DAG.
[2025-01-13T02:54:20.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:54:20.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.067+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:54:20.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:20.092+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:54:20.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.296 seconds
[2025-01-13T02:54:50.576+0000] {processor.py:157} INFO - Started process (PID=12723) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:54:50.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:54:50.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:54:50.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.600+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:54:50.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.749+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13466295000034734
[2025-01-13T02:54:50.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.750+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12723]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:54:50.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.751+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:54:50.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.751+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:54:50.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.751+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:54:50.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.752+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12723]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:54:50.756+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.756+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12723]: It took 0.00398s to build the Airflow DAG.
[2025-01-13T02:54:50.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:54:50.771+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.771+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:54:50.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:54:50.794+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:54:50.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-13T02:55:21.063+0000] {processor.py:157} INFO - Started process (PID=12805) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:55:21.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:55:21.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:55:21.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.158+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:55:21.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.488+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2944207819964504
[2025-01-13T02:55:21.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.490+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12805]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:55:21.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.498+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:55:21.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.500+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:55:21.509+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.507+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:55:21.510+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.510+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12805]: It took 0.352s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:55:21.523+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.523+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12805]: It took 0.0131s to build the Airflow DAG.
[2025-01-13T02:55:21.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:55:21.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.558+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:55:21.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:21.614+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:55:21.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.602 seconds
[2025-01-13T02:55:52.123+0000] {processor.py:157} INFO - Started process (PID=12882) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:55:52.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:55:52.129+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:55:52.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.168+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:55:52.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.741+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.5453259909991175
[2025-01-13T02:55:52.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.743+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12882]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:55:52.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.744+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:55:52.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.745+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:55:52.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.747+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:55:52.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.749+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12882]: It took 0.58s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:55:52.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.760+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12882]: It took 0.0111s to build the Airflow DAG.
[2025-01-13T02:55:52.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:55:52.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.792+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:55:52.853+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:55:52.852+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:55:52.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.777 seconds
[2025-01-13T02:56:23.812+0000] {processor.py:157} INFO - Started process (PID=12968) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:56:23.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:56:23.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:23.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:56:23.842+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:23.842+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:56:24.056+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.056+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19802826699742582
[2025-01-13T02:56:24.057+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.057+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|12968]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:56:24.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.058+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:56:24.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.058+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:56:24.059+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.058+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:56:24.059+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.059+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|12968]: It took 0.217s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:56:24.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.064+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|12968]: It took 0.00486s to build the Airflow DAG.
[2025-01-13T02:56:24.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:56:24.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.083+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:56:24.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:24.112+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:56:24.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.329 seconds
[2025-01-13T02:56:55.126+0000] {processor.py:157} INFO - Started process (PID=13056) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:56:55.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:56:55.131+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:56:55.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.155+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:56:55.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.369+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1978001619972929
[2025-01-13T02:56:55.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.369+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13056]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:56:55.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.370+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:56:55.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.371+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:56:55.372+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.372+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:56:55.372+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.372+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13056]: It took 0.218s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:56:55.378+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.378+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13056]: It took 0.00551s to build the Airflow DAG.
[2025-01-13T02:56:55.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:56:55.397+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.396+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:56:55.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:56:55.425+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:56:55.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.323 seconds
[2025-01-13T02:57:26.257+0000] {processor.py:157} INFO - Started process (PID=13150) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:57:26.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:57:26.262+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:57:26.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.290+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:57:26.505+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.505+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19863166499999352
[2025-01-13T02:57:26.505+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.505+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13150]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:57:26.506+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.506+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:57:26.507+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.507+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:57:26.507+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.507+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:57:26.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.508+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13150]: It took 0.218s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:57:26.512+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.512+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13150]: It took 0.00479s to build the Airflow DAG.
[2025-01-13T02:57:26.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:57:26.531+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.531+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:57:26.560+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:26.560+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:57:26.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.328 seconds
[2025-01-13T02:57:56.622+0000] {processor.py:157} INFO - Started process (PID=13249) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:57:56.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:57:56.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:57:56.650+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.650+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:57:56.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.806+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14282968499901472
[2025-01-13T02:57:56.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.811+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13249]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:57:56.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.812+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:57:56.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.812+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:57:56.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.813+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:57:56.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.814+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13249]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:57:56.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.819+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13249]: It took 0.0056s to build the Airflow DAG.
[2025-01-13T02:57:56.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:57:56.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.834+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:57:56.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:57:56.858+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:57:56.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-13T02:58:26.960+0000] {processor.py:157} INFO - Started process (PID=13334) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:58:26.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:58:26.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:26.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:58:26.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:26.992+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:58:27.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.150+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14520290799919167
[2025-01-13T02:58:27.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.151+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13334]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:58:27.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.152+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:58:27.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.152+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:58:27.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.153+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:58:27.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.153+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13334]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:58:27.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.159+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13334]: It took 0.00638s to build the Airflow DAG.
[2025-01-13T02:58:27.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:58:27.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.176+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:58:27.199+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:27.198+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:58:27.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-13T02:58:57.263+0000] {processor.py:157} INFO - Started process (PID=13422) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:58:57.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:58:57.267+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:58:57.302+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.302+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:58:57.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.534+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20425513699956355
[2025-01-13T02:58:57.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.535+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13422]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:58:57.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.536+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:58:57.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.536+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:58:57.537+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.536+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:58:57.537+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.537+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13422]: It took 0.235s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:58:57.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.541+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13422]: It took 0.00444s to build the Airflow DAG.
[2025-01-13T02:58:57.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:58:57.561+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.561+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:58:57.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:58:57.588+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:58:57.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.348 seconds
[2025-01-13T02:59:28.251+0000] {processor.py:157} INFO - Started process (PID=13521) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:59:28.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:59:28.268+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:59:28.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.341+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T02:59:28.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.989+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6025830159996985
[2025-01-13T02:59:28.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.991+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13521]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T02:59:28.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.994+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T02:59:28.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.995+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T02:59:28.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.996+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T02:59:28.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:28.998+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13521]: It took 0.657s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T02:59:29.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:29.012+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13521]: It took 0.0136s to build the Airflow DAG.
[2025-01-13T02:59:29.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:59:29.060+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:29.060+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T02:59:29.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:29.152+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T02:59:29.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.969 seconds
[2025-01-13T02:59:59.764+0000] {processor.py:157} INFO - Started process (PID=13601) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:59:59.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T02:59:59.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:59.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T02:59:59.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T02:59:59.931+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:00:00.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.490+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.4920191960009106
[2025-01-13T03:00:00.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.492+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13601]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:00:00.497+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.496+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:00:00.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.499+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:00:00.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.501+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:00:00.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.502+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13601]: It took 0.571s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:00:00.520+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.520+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13601]: It took 0.0178s to build the Airflow DAG.
[2025-01-13T03:00:00.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:00:00.579+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.578+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:00:00.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:00.698+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:00:00.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.028 seconds
[2025-01-13T03:00:30.946+0000] {processor.py:157} INFO - Started process (PID=13690) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:00:30.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:00:30.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:30.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:00:30.981+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:30.981+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:00:31.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.181+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18150741300269146
[2025-01-13T03:00:31.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.182+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13690]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:00:31.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.183+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:00:31.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.183+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:00:31.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.184+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:00:31.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.184+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13690]: It took 0.204s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:00:31.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.191+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13690]: It took 0.00673s to build the Airflow DAG.
[2025-01-13T03:00:31.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:00:31.212+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.212+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:00:31.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:00:31.243+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:00:31.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.324 seconds
[2025-01-13T03:01:01.389+0000] {processor.py:157} INFO - Started process (PID=13773) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:01:01.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:01:01.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:01:01.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.418+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:01:01.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.658+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22352016199874924
[2025-01-13T03:01:01.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.658+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13773]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:01:01.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.660+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:01:01.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.660+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:01:01.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.661+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:01:01.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.662+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13773]: It took 0.245s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:01:01.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.668+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13773]: It took 0.00609s to build the Airflow DAG.
[2025-01-13T03:01:01.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:01:01.692+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.692+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:01:01.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:01.728+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:01:01.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.369 seconds
[2025-01-13T03:01:31.803+0000] {processor.py:157} INFO - Started process (PID=13860) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:01:31.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:01:31.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:31.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:01:31.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:31.828+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:01:31.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:31.999+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1574927010005922
[2025-01-13T03:01:32.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.000+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13860]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:01:32.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.000+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:01:32.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.001+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:01:32.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.001+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:01:32.002+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.002+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13860]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:01:32.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.008+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13860]: It took 0.00644s to build the Airflow DAG.
[2025-01-13T03:01:32.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:01:32.025+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.024+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:01:32.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:01:32.067+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:01:32.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-13T03:02:02.186+0000] {processor.py:157} INFO - Started process (PID=13948) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:02:02.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:02:02.189+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:02:02.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.212+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:02:02.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.392+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16409351699985564
[2025-01-13T03:02:02.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.393+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|13948]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:02:02.394+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.394+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:02:02.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.395+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:02:02.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.395+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:02:02.396+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.396+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|13948]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:02:02.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.401+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|13948]: It took 0.00517s to build the Airflow DAG.
[2025-01-13T03:02:02.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:02:02.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.418+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:02:02.446+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:02.445+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:02:02.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-13T03:02:32.604+0000] {processor.py:157} INFO - Started process (PID=14035) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:02:32.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:02:32.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:02:32.635+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.635+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:02:32.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.832+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18185558499681065
[2025-01-13T03:02:32.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.833+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14035]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:02:32.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.834+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:02:32.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.834+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:02:32.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.835+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:02:32.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.835+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14035]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:02:32.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.840+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14035]: It took 0.00522s to build the Airflow DAG.
[2025-01-13T03:02:32.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:02:32.857+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.857+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:02:32.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:02:32.882+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:02:32.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.303 seconds
[2025-01-13T03:03:03.074+0000] {processor.py:157} INFO - Started process (PID=14137) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:03:03.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:03:03.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:03:03.101+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.101+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:03:03.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.287+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17093929200200364
[2025-01-13T03:03:03.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.287+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14137]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:03:03.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.288+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:03:03.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.289+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:03:03.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.290+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:03:03.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.290+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14137]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:03:03.296+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.296+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14137]: It took 0.00546s to build the Airflow DAG.
[2025-01-13T03:03:03.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:03:03.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.312+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:03:03.336+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:03.336+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:03:03.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-13T03:03:33.783+0000] {processor.py:157} INFO - Started process (PID=14223) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:03:33.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:03:33.787+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:03:33.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.809+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:03:33.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.963+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14077677400200628
[2025-01-13T03:03:33.964+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.964+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14223]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:03:33.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.964+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:03:33.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.965+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:03:33.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.965+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:03:33.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.966+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14223]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:03:33.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.969+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14223]: It took 0.00384s to build the Airflow DAG.
[2025-01-13T03:03:33.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:03:33.984+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:33.984+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:03:34.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:03:34.008+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:03:34.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-13T03:04:04.519+0000] {processor.py:157} INFO - Started process (PID=14309) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:04:04.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:04:04.523+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:04:04.547+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.547+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:04:04.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.815+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.25334970200128737
[2025-01-13T03:04:04.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.816+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14309]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:04:04.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.817+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:04:04.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.818+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:04:04.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.822+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:04:04.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.823+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14309]: It took 0.276s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:04:04.831+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.831+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14309]: It took 0.00766s to build the Airflow DAG.
[2025-01-13T03:04:04.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:04:04.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.859+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:04:04.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:04.907+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:04:04.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.423 seconds
[2025-01-13T03:04:35.479+0000] {processor.py:157} INFO - Started process (PID=14395) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:04:35.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:04:35.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:35.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:04:35.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:35.513+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:04:36.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.443+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.9135807720012963
[2025-01-13T03:04:36.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.444+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14395]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:04:36.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.445+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:04:36.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.445+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:04:36.446+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.446+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:04:36.446+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.446+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14395]: It took 0.933s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:04:36.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.451+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14395]: It took 0.00474s to build the Airflow DAG.
[2025-01-13T03:04:36.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:04:36.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.466+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:04:36.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:04:36.487+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:04:36.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.030 seconds
[2025-01-13T03:05:07.066+0000] {processor.py:157} INFO - Started process (PID=14504) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:05:07.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:05:07.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:05:07.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.092+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:05:07.256+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.255+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14936582899827044
[2025-01-13T03:05:07.256+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.256+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14504]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:05:07.257+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.257+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:05:07.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.257+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:05:07.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.258+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:05:07.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.258+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14504]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:05:07.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.263+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14504]: It took 0.00452s to build the Airflow DAG.
[2025-01-13T03:05:07.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:05:07.279+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.279+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:05:07.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:07.305+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:05:07.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-13T03:05:38.207+0000] {processor.py:157} INFO - Started process (PID=14591) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:05:38.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:05:38.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:05:38.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.236+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:05:38.385+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.384+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13373789999968722
[2025-01-13T03:05:38.385+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.385+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14591]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:05:38.386+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.386+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:05:38.386+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.386+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:05:38.386+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.386+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:05:38.387+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.387+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14591]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:05:38.390+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.390+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14591]: It took 0.00347s to build the Airflow DAG.
[2025-01-13T03:05:38.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:05:38.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.404+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:05:38.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:05:38.426+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:05:38.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-13T03:06:08.895+0000] {processor.py:157} INFO - Started process (PID=14677) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:06:08.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:06:08.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:08.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:06:08.924+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:08.924+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:06:09.119+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.118+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1771752690001449
[2025-01-13T03:06:09.119+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.119+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14677]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:06:09.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.120+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:06:09.121+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.121+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:06:09.121+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.121+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:06:09.122+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.122+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14677]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:06:09.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.126+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14677]: It took 0.00442s to build the Airflow DAG.
[2025-01-13T03:06:09.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:06:09.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.143+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:06:09.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:09.173+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:06:09.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.300 seconds
[2025-01-13T03:06:39.396+0000] {processor.py:157} INFO - Started process (PID=14781) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:06:39.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:06:39.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:06:39.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.426+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:06:39.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.616+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17486146099690814
[2025-01-13T03:06:39.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.617+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14781]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:06:39.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.618+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:06:39.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.618+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:06:39.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.619+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:06:39.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.619+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14781]: It took 0.194s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:06:39.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.623+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14781]: It took 0.00456s to build the Airflow DAG.
[2025-01-13T03:06:39.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:06:39.641+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.641+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:06:39.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:06:39.665+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:06:39.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-13T03:07:09.965+0000] {processor.py:157} INFO - Started process (PID=14879) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:07:09.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:07:09.968+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:09.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:07:09.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:09.990+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:07:10.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.153+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14977375299713458
[2025-01-13T03:07:10.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.153+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14879]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:07:10.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.154+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:07:10.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.154+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:07:10.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.155+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:07:10.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.155+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14879]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:07:10.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.158+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14879]: It took 0.00341s to build the Airflow DAG.
[2025-01-13T03:07:10.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:07:10.172+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.172+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:07:10.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:10.194+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:07:10.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-13T03:07:40.527+0000] {processor.py:157} INFO - Started process (PID=14965) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:07:40.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:07:40.531+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:07:40.551+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.551+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:07:40.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.704+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1406535870009975
[2025-01-13T03:07:40.705+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.705+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|14965]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:07:40.706+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.706+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:07:40.706+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.706+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:07:40.706+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.706+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:07:40.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.707+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|14965]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:07:40.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.710+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|14965]: It took 0.00375s to build the Airflow DAG.
[2025-01-13T03:07:40.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:07:40.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.726+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:07:40.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:07:40.750+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:07:40.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-13T03:08:11.250+0000] {processor.py:157} INFO - Started process (PID=15051) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:08:11.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:08:11.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:08:11.279+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.279+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:08:11.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.478+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18319477000113693
[2025-01-13T03:08:11.479+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.479+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15051]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:08:11.479+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.479+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:08:11.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.480+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:08:11.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.480+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:08:11.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.481+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15051]: It took 0.202s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:08:11.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.485+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15051]: It took 0.00455s to build the Airflow DAG.
[2025-01-13T03:08:11.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:08:11.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.502+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:08:11.528+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:11.528+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:08:11.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T03:08:42.046+0000] {processor.py:157} INFO - Started process (PID=15144) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:08:42.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:08:42.050+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:08:42.075+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.075+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:08:42.273+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.273+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18319912300285068
[2025-01-13T03:08:42.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.274+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15144]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:08:42.275+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.275+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:08:42.275+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.275+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:08:42.275+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.275+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:08:42.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.276+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15144]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:08:42.280+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.280+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15144]: It took 0.00408s to build the Airflow DAG.
[2025-01-13T03:08:42.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:08:42.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.297+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:08:42.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:08:42.323+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:08:42.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-13T03:09:12.477+0000] {processor.py:157} INFO - Started process (PID=15243) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:09:12.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:09:12.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:09:12.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.507+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:09:12.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.700+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17310191599972313
[2025-01-13T03:09:12.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.701+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15243]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:09:12.702+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.702+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:09:12.703+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.703+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:09:12.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.703+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:09:12.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.704+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15243]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:09:12.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.709+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15243]: It took 0.00472s to build the Airflow DAG.
[2025-01-13T03:09:12.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:09:12.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.726+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:09:12.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:12.752+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:09:12.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-13T03:09:43.596+0000] {processor.py:157} INFO - Started process (PID=15329) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:09:43.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:09:43.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:09:43.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.627+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:09:43.773+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.773+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1336193640017882
[2025-01-13T03:09:43.774+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.773+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15329]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:09:43.774+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.774+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:09:43.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.775+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:09:43.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.775+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:09:43.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.775+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15329]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:09:43.779+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.779+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15329]: It took 0.00376s to build the Airflow DAG.
[2025-01-13T03:09:43.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:09:43.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.792+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:09:43.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:09:43.815+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:09:43.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-13T03:10:14.818+0000] {processor.py:157} INFO - Started process (PID=15415) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:10:14.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:10:14.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:14.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:10:14.851+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:14.850+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:10:15.102+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.102+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23525937600061297
[2025-01-13T03:10:15.103+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.102+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15415]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:10:15.104+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.104+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:10:15.104+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.104+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:10:15.105+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.105+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:10:15.106+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.105+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15415]: It took 0.255s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:10:15.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.112+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15415]: It took 0.00627s to build the Airflow DAG.
[2025-01-13T03:10:15.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:10:15.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.136+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:10:15.178+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:15.178+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:10:15.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.401 seconds
[2025-01-13T03:10:46.000+0000] {processor.py:157} INFO - Started process (PID=15509) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:10:46.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:10:46.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:10:46.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.028+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:10:46.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.190+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14725338800053578
[2025-01-13T03:10:46.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.191+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15509]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:10:46.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.192+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:10:46.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.192+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:10:46.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.193+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:10:46.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.193+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15509]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:10:46.198+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.198+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15509]: It took 0.00459s to build the Airflow DAG.
[2025-01-13T03:10:46.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:10:46.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.213+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:10:46.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:10:46.237+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:10:46.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T03:11:16.598+0000] {processor.py:157} INFO - Started process (PID=15606) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:11:16.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:11:16.602+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:11:16.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.627+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:11:16.814+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.814+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17342525799904251
[2025-01-13T03:11:16.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.815+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15606]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:11:16.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.816+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:11:16.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.816+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:11:16.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.817+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:11:16.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.817+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15606]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:11:16.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.821+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15606]: It took 0.0045s to build the Airflow DAG.
[2025-01-13T03:11:16.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:11:16.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.837+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:11:16.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:16.862+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:11:16.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T03:11:47.438+0000] {processor.py:157} INFO - Started process (PID=15692) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:11:47.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:11:47.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:11:47.467+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.467+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:11:47.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.615+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13423801599856233
[2025-01-13T03:11:47.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.616+0000] {graph.py:519} INFO - Cosmos performance [75db603020a1|15692]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:11:47.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.617+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:11:47.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.618+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:11:47.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.618+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:11:47.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.619+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [75db603020a1|15692]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:11:47.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.628+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [75db603020a1|15692]: It took 0.00917s to build the Airflow DAG.
[2025-01-13T03:11:47.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:11:47.646+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.646+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:11:47.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:11:47.670+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:11:47.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-13T03:13:19.646+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:13:19.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:13:19.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:13:19.691+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.691+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:13:19.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.946+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.229695095000352
[2025-01-13T03:13:19.947+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.946+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:13:19.948+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.948+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:13:19.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.949+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:13:19.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.949+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:13:19.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.950+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|70]: It took 0.26s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:13:19.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:19.958+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|70]: It took 0.00766s to build the Airflow DAG.
[2025-01-13T03:13:19.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:13:20.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:20.136+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:13:20.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:20.182+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:13:20.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.583 seconds
[2025-01-13T03:13:51.068+0000] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:13:51.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:13:51.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:13:51.101+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.100+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:13:51.296+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.295+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17780000000129803
[2025-01-13T03:13:51.296+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.296+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|165]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:13:51.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.297+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:13:51.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.297+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:13:51.298+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.298+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:13:51.298+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.298+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|165]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:13:51.302+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.302+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|165]: It took 0.00417s to build the Airflow DAG.
[2025-01-13T03:13:51.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:13:51.318+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.318+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:13:51.345+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:13:51.345+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:13:51.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T03:14:21.528+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:14:21.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:14:21.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:14:21.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.559+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:14:21.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.770+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1933568260028551
[2025-01-13T03:14:21.771+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.771+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|262]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:14:21.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.771+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:14:21.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.772+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:14:21.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.772+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:14:21.773+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.773+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|262]: It took 0.214s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:14:21.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.777+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|262]: It took 0.0043s to build the Airflow DAG.
[2025-01-13T03:14:21.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:14:21.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.795+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:14:21.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:21.835+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:14:21.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.336 seconds
[2025-01-13T03:14:52.006+0000] {processor.py:157} INFO - Started process (PID=350) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:14:52.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:14:52.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:14:52.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.038+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:14:52.206+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.206+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15245015199980116
[2025-01-13T03:14:52.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.207+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|350]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:14:52.208+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.208+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:14:52.208+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.208+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:14:52.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.209+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:14:52.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.209+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|350]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:14:52.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.215+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|350]: It took 0.00628s to build the Airflow DAG.
[2025-01-13T03:14:52.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:14:52.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.235+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:14:52.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:14:52.264+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:14:52.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T03:15:22.517+0000] {processor.py:157} INFO - Started process (PID=434) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:15:22.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:15:22.521+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:15:22.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.546+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:15:22.722+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.721+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16143224199913675
[2025-01-13T03:15:22.722+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.722+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|434]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:15:22.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.723+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:15:22.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.723+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:15:22.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.724+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:15:22.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.725+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|434]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:15:22.730+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.730+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|434]: It took 0.00544s to build the Airflow DAG.
[2025-01-13T03:15:22.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:15:22.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.745+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:15:22.768+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:22.768+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:15:22.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-13T03:15:52.879+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:15:52.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:15:52.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:52.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:15:52.905+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:52.905+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:15:53.070+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.070+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15193906000058632
[2025-01-13T03:15:53.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.071+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|520]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:15:53.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.072+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:15:53.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.072+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:15:53.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.073+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:15:53.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.074+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|520]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:15:53.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.078+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|520]: It took 0.00495s to build the Airflow DAG.
[2025-01-13T03:15:53.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:15:53.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.097+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:15:53.121+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:15:53.121+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:15:53.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-13T03:16:23.425+0000] {processor.py:157} INFO - Started process (PID=607) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:16:23.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:16:23.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:16:23.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.453+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:16:23.621+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.620+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15377641599843628
[2025-01-13T03:16:23.621+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.621+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|607]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:16:23.622+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.622+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:16:23.623+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.623+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:16:23.623+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.623+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:16:23.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.624+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|607]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:16:23.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.628+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|607]: It took 0.0045s to build the Airflow DAG.
[2025-01-13T03:16:23.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:16:23.645+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.645+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:16:23.674+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:23.674+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:16:23.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-13T03:16:54.374+0000] {processor.py:157} INFO - Started process (PID=700) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:16:54.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:16:54.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:54.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:16:54.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:54.579+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:16:55.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.443+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.5502265610011818
[2025-01-13T03:16:55.488+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.488+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|700]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:16:55.496+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.496+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:16:55.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.500+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:16:55.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.513+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:16:55.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.517+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|700]: It took 0.938s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:16:55.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.627+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|700]: It took 0.11s to build the Airflow DAG.
[2025-01-13T03:16:55.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:16:55.762+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:55.761+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:16:56.869+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:16:56.867+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:16:57.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 3.086 seconds
[2025-01-13T03:17:27.927+0000] {processor.py:157} INFO - Started process (PID=784) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:17:27.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:17:27.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:27.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:17:27.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:27.994+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:17:28.474+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.473+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.439536935002252
[2025-01-13T03:17:28.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.475+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|784]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:17:28.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.477+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:17:28.479+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.479+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:17:28.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.480+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:17:28.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.482+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|784]: It took 0.488s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:17:28.496+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.495+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|784]: It took 0.0135s to build the Airflow DAG.
[2025-01-13T03:17:28.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:17:28.539+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.539+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:17:28.608+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:28.607+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:17:28.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.747 seconds
[2025-01-13T03:17:58.940+0000] {processor.py:157} INFO - Started process (PID=858) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:17:58.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:17:58.945+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:58.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:17:58.971+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:58.971+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:17:59.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.166+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1781251489992428
[2025-01-13T03:17:59.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.166+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|858]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:17:59.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.167+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:17:59.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.167+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:17:59.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.168+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:17:59.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.169+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|858]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:17:59.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.174+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|858]: It took 0.00503s to build the Airflow DAG.
[2025-01-13T03:17:59.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:17:59.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.190+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:17:59.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:17:59.216+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:17:59.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.303 seconds
[2025-01-13T03:18:29.506+0000] {processor.py:157} INFO - Started process (PID=945) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:18:29.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:18:29.511+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:18:29.541+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.541+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:18:29.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.801+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23962874499920872
[2025-01-13T03:18:29.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.802+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|945]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:18:29.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.805+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:18:29.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.805+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:18:29.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.806+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:18:29.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.807+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|945]: It took 0.267s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:18:29.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.814+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|945]: It took 0.00733s to build the Airflow DAG.
[2025-01-13T03:18:29.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:18:29.843+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.843+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:18:29.888+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:18:29.887+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:18:29.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.419 seconds
[2025-01-13T03:19:00.516+0000] {processor.py:157} INFO - Started process (PID=1042) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:19:00.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:19:00.521+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:19:00.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.553+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:19:00.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.798+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2236347569996724
[2025-01-13T03:19:00.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.799+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1042]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:19:00.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.800+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:19:00.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.801+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:19:00.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.802+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:19:00.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.803+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1042]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:19:00.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.811+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1042]: It took 0.00764s to build the Airflow DAG.
[2025-01-13T03:19:00.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:19:00.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.833+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:19:00.877+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:00.877+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:19:00.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.391 seconds
[2025-01-13T03:19:31.085+0000] {processor.py:157} INFO - Started process (PID=1129) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:19:31.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:19:31.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:19:31.115+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.114+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:19:31.316+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.315+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18314856500001042
[2025-01-13T03:19:31.316+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.316+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1129]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:19:31.317+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.317+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:19:31.318+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.318+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:19:31.318+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.318+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:19:31.319+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.319+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1129]: It took 0.204s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:19:31.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.324+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1129]: It took 0.00501s to build the Airflow DAG.
[2025-01-13T03:19:31.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:19:31.356+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.355+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:19:31.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:19:31.393+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:19:31.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-13T03:20:01.488+0000] {processor.py:157} INFO - Started process (PID=1216) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:20:01.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:20:01.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:20:01.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.517+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:20:01.695+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.694+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16284174199972767
[2025-01-13T03:20:01.695+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.695+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1216]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:20:01.696+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.696+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:20:01.696+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.696+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:20:01.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.697+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:20:01.698+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.698+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1216]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:20:01.703+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.703+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1216]: It took 0.00498s to build the Airflow DAG.
[2025-01-13T03:20:01.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:20:01.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.717+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:20:01.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:01.741+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:20:01.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-13T03:20:31.824+0000] {processor.py:157} INFO - Started process (PID=1302) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:20:31.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:20:31.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:31.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:20:31.851+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:31.851+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:20:32.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.041+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17262903500159155
[2025-01-13T03:20:32.042+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.042+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1302]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:20:32.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.043+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:20:32.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.043+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:20:32.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.043+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:20:32.044+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.044+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1302]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:20:32.048+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.048+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1302]: It took 0.004s to build the Airflow DAG.
[2025-01-13T03:20:32.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:20:32.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:20:32.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:20:32.092+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:20:32.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-13T03:21:02.285+0000] {processor.py:157} INFO - Started process (PID=1397) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:21:02.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:21:02.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:21:02.320+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.320+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:21:02.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.516+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18122431599840638
[2025-01-13T03:21:02.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.517+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1397]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:21:02.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.518+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:21:02.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.518+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:21:02.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.519+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:21:02.520+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.519+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1397]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:21:02.524+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.524+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1397]: It took 0.0045s to build the Airflow DAG.
[2025-01-13T03:21:02.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:21:02.539+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.539+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:21:02.565+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:02.565+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:21:02.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.306 seconds
[2025-01-13T03:21:33.371+0000] {processor.py:157} INFO - Started process (PID=1494) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:21:33.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:21:33.374+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:21:33.400+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.399+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:21:33.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.582+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16860804700263543
[2025-01-13T03:21:33.583+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.583+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1494]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:21:33.584+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.584+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:21:33.584+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.584+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:21:33.584+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.584+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:21:33.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.585+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1494]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:21:33.590+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.590+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1494]: It took 0.00495s to build the Airflow DAG.
[2025-01-13T03:21:33.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:21:33.604+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.604+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:21:33.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:21:33.630+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:21:33.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-13T03:22:03.799+0000] {processor.py:157} INFO - Started process (PID=1582) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:22:03.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T03:22:03.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:03.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:22:03.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:03.828+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T03:22:04.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.008+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1644670159985253
[2025-01-13T03:22:04.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.008+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1582]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T03:22:04.009+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.009+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T03:22:04.010+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.010+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T03:22:04.010+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.010+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T03:22:04.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.011+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1582]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T03:22:04.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.015+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1582]: It took 0.00448s to build the Airflow DAG.
[2025-01-13T03:22:04.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T03:22:04.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.032+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T03:22:04.059+0000] {logging_mixin.py:151} INFO - [2025-01-13T03:22:04.059+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T03:22:04.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-13T06:24:02.911+0000] {processor.py:157} INFO - Started process (PID=1653) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T06:24:02.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T06:24:02.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:02.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T06:24:03.075+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:03.074+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T06:24:04.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.339+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6459804799997073
[2025-01-13T06:24:04.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.340+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1653]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T06:24:04.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.341+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T06:24:04.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.342+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T06:24:04.343+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.343+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T06:24:04.344+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.343+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1653]: It took 1.27s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T06:24:04.352+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.352+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1653]: It took 0.00809s to build the Airflow DAG.
[2025-01-13T06:24:04.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T06:24:04.388+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.388+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T06:24:04.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T06:24:04.441+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T06:24:04.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.866 seconds
[2025-01-13T15:45:22.143+0000] {processor.py:157} INFO - Started process (PID=1731) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T15:45:22.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T15:45:22.177+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T15:45:22.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.305+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T15:45:22.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.820+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.47624181100036367
[2025-01-13T15:45:22.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.821+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1731]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T15:45:22.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.823+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T15:45:22.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.824+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T15:45:22.826+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.826+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T15:45:22.827+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.827+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1731]: It took 0.522s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T15:45:22.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.839+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1731]: It took 0.0127s to build the Airflow DAG.
[2025-01-13T15:45:22.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T15:45:22.879+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.878+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T15:45:22.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:45:22.942+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T15:45:22.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.871 seconds
[2025-01-13T15:59:41.862+0000] {processor.py:157} INFO - Started process (PID=1770) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T15:59:41.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T15:59:41.921+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:41.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T15:59:42.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:42.516+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T15:59:43.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.347+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.7330359270017652
[2025-01-13T15:59:43.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.348+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1770]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T15:59:43.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.349+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T15:59:43.350+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.350+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T15:59:43.351+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.351+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T15:59:43.352+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.351+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1770]: It took 0.835s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T15:59:43.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.363+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1770]: It took 0.012s to build the Airflow DAG.
[2025-01-13T15:59:43.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T15:59:43.397+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.397+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T15:59:43.461+0000] {logging_mixin.py:151} INFO - [2025-01-13T15:59:43.460+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T15:59:43.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.657 seconds
[2025-01-13T16:00:14.063+0000] {processor.py:157} INFO - Started process (PID=1864) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:00:14.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:00:14.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:00:14.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.095+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:00:14.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.324+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21205071499935002
[2025-01-13T16:00:14.325+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.324+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1864]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:00:14.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.326+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:00:14.327+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.326+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:00:14.327+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.327+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:00:14.328+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.327+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1864]: It took 0.233s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:00:14.336+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.336+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1864]: It took 0.0081s to build the Airflow DAG.
[2025-01-13T16:00:14.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:00:14.368+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.367+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:00:14.420+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:14.420+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:00:14.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.397 seconds
[2025-01-13T16:00:45.263+0000] {processor.py:157} INFO - Started process (PID=1952) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:00:45.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:00:45.267+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:00:45.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.297+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:00:45.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.625+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.306878773997596
[2025-01-13T16:00:45.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.626+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1952]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:00:45.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.627+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:00:45.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.627+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:00:45.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.628+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:00:45.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.629+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1952]: It took 0.332s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:00:45.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.634+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1952]: It took 0.00502s to build the Airflow DAG.
[2025-01-13T16:00:45.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:00:45.656+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.655+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:00:45.722+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:00:45.722+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:00:45.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.530 seconds
[2025-01-13T16:01:15.919+0000] {processor.py:157} INFO - Started process (PID=2040) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:01:15.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:01:15.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:15.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:01:15.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:15.965+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:01:16.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.194+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20789990100092837
[2025-01-13T16:01:16.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.195+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2040]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:01:16.197+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.196+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:01:16.197+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.197+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:01:16.198+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.198+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:01:16.198+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.198+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2040]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:01:16.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.204+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2040]: It took 0.00554s to build the Airflow DAG.
[2025-01-13T16:01:16.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:01:16.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.227+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:01:16.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:16.263+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:01:16.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.378 seconds
[2025-01-13T16:01:47.025+0000] {processor.py:157} INFO - Started process (PID=2137) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:01:47.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:01:47.029+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:01:47.061+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.061+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:01:47.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.255+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17640754400053993
[2025-01-13T16:01:47.255+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.255+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2137]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:01:47.256+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.256+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:01:47.257+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.257+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:01:47.257+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.257+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:01:47.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.258+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2137]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:01:47.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.263+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2137]: It took 0.00528s to build the Airflow DAG.
[2025-01-13T16:01:47.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:01:47.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.287+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:01:47.318+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:01:47.318+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:01:47.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.321 seconds
[2025-01-13T16:02:17.508+0000] {processor.py:157} INFO - Started process (PID=2215) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:02:17.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:02:17.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:02:17.538+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.538+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:02:17.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.759+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20336326399774407
[2025-01-13T16:02:17.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.760+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2215]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:02:17.762+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.762+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:02:17.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.762+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:02:17.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.763+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:02:17.764+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.763+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2215]: It took 0.226s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:02:17.768+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.768+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2215]: It took 0.00487s to build the Airflow DAG.
[2025-01-13T16:02:17.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:02:17.787+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.787+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:02:17.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:17.815+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:02:17.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.331 seconds
[2025-01-13T16:02:47.884+0000] {processor.py:157} INFO - Started process (PID=2312) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:02:47.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:02:47.889+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:47.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:02:47.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:47.916+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:02:48.128+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.128+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19272303999969154
[2025-01-13T16:02:48.129+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.129+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2312]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:02:48.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.130+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:02:48.131+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.131+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:02:48.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.131+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:02:48.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.132+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2312]: It took 0.216s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:02:48.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.137+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2312]: It took 0.00534s to build the Airflow DAG.
[2025-01-13T16:02:48.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:02:48.157+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.156+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:02:48.189+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:02:48.189+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:02:48.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.345 seconds
[2025-01-13T16:03:19.190+0000] {processor.py:157} INFO - Started process (PID=2398) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:03:19.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:03:19.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:03:19.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.230+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:03:19.477+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.477+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2304707290022634
[2025-01-13T16:03:19.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.477+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2398]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:03:19.479+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.479+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:03:19.479+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.479+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:03:19.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.480+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:03:19.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.480+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2398]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:03:19.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.487+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2398]: It took 0.00689s to build the Airflow DAG.
[2025-01-13T16:03:19.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:03:19.509+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.509+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:03:19.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:19.545+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:03:19.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.390 seconds
[2025-01-13T16:03:49.675+0000] {processor.py:157} INFO - Started process (PID=2484) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:03:49.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:03:49.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:49.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:03:49.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:49.713+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:03:50.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.012+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.27943450399834546
[2025-01-13T16:03:50.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.013+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2484]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:03:50.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.015+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:03:50.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.016+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:03:50.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.017+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:03:50.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.017+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2484]: It took 0.304s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:03:50.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.028+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2484]: It took 0.0106s to build the Airflow DAG.
[2025-01-13T16:03:50.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:03:50.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:03:50.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:03:50.125+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:03:50.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.501 seconds
[2025-01-13T16:04:20.451+0000] {processor.py:157} INFO - Started process (PID=2572) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:04:20.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:04:20.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:04:20.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.491+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:04:20.756+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.755+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24395877600181848
[2025-01-13T16:04:20.756+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.756+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2572]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:04:20.758+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.758+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:04:20.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.759+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:04:20.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.759+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:04:20.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.760+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2572]: It took 0.27s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:04:20.769+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.769+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2572]: It took 0.00823s to build the Airflow DAG.
[2025-01-13T16:04:20.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:04:20.793+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.793+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:04:20.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:20.827+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:04:20.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.406 seconds
[2025-01-13T16:04:51.011+0000] {processor.py:157} INFO - Started process (PID=2659) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:04:51.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:04:51.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:04:51.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.054+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:04:51.337+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.337+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.25910860000294633
[2025-01-13T16:04:51.338+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.338+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2659]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:04:51.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.339+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:04:51.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.340+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:04:51.341+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.341+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:04:51.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.342+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2659]: It took 0.288s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:04:51.352+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.352+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2659]: It took 0.00979s to build the Airflow DAG.
[2025-01-13T16:04:51.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:04:51.398+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.398+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:04:51.463+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:04:51.463+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:04:51.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.504 seconds
[2025-01-13T16:05:22.505+0000] {processor.py:157} INFO - Started process (PID=2746) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:05:22.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:05:22.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:05:22.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.534+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:05:22.710+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.710+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16189608000058797
[2025-01-13T16:05:22.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.711+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2746]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:05:22.712+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.712+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:05:22.712+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.712+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:05:22.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.713+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:05:22.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.713+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2746]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:05:22.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.718+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2746]: It took 0.00454s to build the Airflow DAG.
[2025-01-13T16:05:22.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:05:22.732+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.732+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:05:22.761+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:22.761+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:05:22.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-13T16:05:53.438+0000] {processor.py:157} INFO - Started process (PID=2840) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:05:53.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:05:53.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:05:53.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.466+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:05:53.687+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.687+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20664370599843096
[2025-01-13T16:05:53.687+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.687+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2840]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:05:53.688+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.688+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:05:53.689+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.688+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:05:53.689+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.689+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:05:53.689+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.689+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2840]: It took 0.223s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:05:53.694+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.694+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2840]: It took 0.0044s to build the Airflow DAG.
[2025-01-13T16:05:53.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:05:53.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.717+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:05:53.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:05:53.753+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:05:53.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.340 seconds
[2025-01-13T16:06:24.055+0000] {processor.py:157} INFO - Started process (PID=2937) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:06:24.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:06:24.060+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:06:24.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.135+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:06:24.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.306+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15192328200282645
[2025-01-13T16:06:24.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.306+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|2937]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:06:24.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.307+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:06:24.308+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.308+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:06:24.309+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.309+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:06:24.310+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.310+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|2937]: It took 0.175s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:06:24.316+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.316+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|2937]: It took 0.00588s to build the Airflow DAG.
[2025-01-13T16:06:24.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:06:24.344+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.344+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:06:24.376+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:24.376+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:06:24.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.348 seconds
[2025-01-13T16:06:54.442+0000] {processor.py:157} INFO - Started process (PID=3023) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:06:54.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:06:54.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:06:54.472+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.471+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:06:54.698+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.698+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2046753649992752
[2025-01-13T16:06:54.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.698+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3023]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:06:54.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.700+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:06:54.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.700+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:06:54.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.701+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:06:54.702+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.701+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3023]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:06:54.708+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.708+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3023]: It took 0.0063s to build the Airflow DAG.
[2025-01-13T16:06:54.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:06:54.732+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.732+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:06:54.766+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:06:54.766+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:06:54.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.354 seconds
[2025-01-13T16:07:24.945+0000] {processor.py:157} INFO - Started process (PID=3111) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:07:24.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:07:24.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:24.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:07:24.975+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:24.975+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:07:25.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.158+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16621920000034152
[2025-01-13T16:07:25.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.159+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3111]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:07:25.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.160+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:07:25.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.160+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:07:25.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.161+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:07:25.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.161+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3111]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:07:25.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.166+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3111]: It took 0.00497s to build the Airflow DAG.
[2025-01-13T16:07:25.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:07:25.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.184+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:07:25.212+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:25.212+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:07:25.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-13T16:07:56.201+0000] {processor.py:157} INFO - Started process (PID=3204) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:07:56.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:07:56.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:07:56.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.228+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:07:56.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.425+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1841564800015476
[2025-01-13T16:07:56.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.426+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3204]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:07:56.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.428+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:07:56.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.428+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:07:56.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.429+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:07:56.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.429+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3204]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:07:56.434+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.434+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3204]: It took 0.00478s to build the Airflow DAG.
[2025-01-13T16:07:56.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:07:56.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.451+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:07:56.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:07:56.481+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:07:56.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.306 seconds
[2025-01-13T16:08:26.675+0000] {processor.py:157} INFO - Started process (PID=3293) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:08:26.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:08:26.681+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:08:26.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.709+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:08:26.983+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.983+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2557209949991375
[2025-01-13T16:08:26.984+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.983+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3293]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:08:26.985+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.985+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:08:26.985+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.985+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:08:26.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.986+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:08:26.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.986+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3293]: It took 0.278s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:08:26.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:26.992+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3293]: It took 0.00544s to build the Airflow DAG.
[2025-01-13T16:08:26.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:08:27.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:27.012+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:08:27.047+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:27.046+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:08:27.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.406 seconds
[2025-01-13T16:08:57.577+0000] {processor.py:157} INFO - Started process (PID=3389) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:08:57.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:08:57.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:08:57.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.611+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:08:57.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.810+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.184758862000308
[2025-01-13T16:08:57.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.810+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3389]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:08:57.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.811+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:08:57.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.812+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:08:57.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.812+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:08:57.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.813+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3389]: It took 0.202s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:08:57.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.820+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3389]: It took 0.00753s to build the Airflow DAG.
[2025-01-13T16:08:57.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:08:57.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.837+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:08:57.865+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:08:57.865+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:08:57.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-13T16:09:27.995+0000] {processor.py:157} INFO - Started process (PID=3477) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:09:27.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:09:28.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:27.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:09:28.031+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.030+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:09:28.266+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.266+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21418065600300906
[2025-01-13T16:09:28.267+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.267+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3477]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:09:28.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.269+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:09:28.270+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.269+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:09:28.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.270+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:09:28.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.271+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3477]: It took 0.241s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:09:28.281+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.280+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3477]: It took 0.00915s to build the Airflow DAG.
[2025-01-13T16:09:28.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:09:28.314+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.314+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:09:28.363+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:28.362+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:09:28.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.407 seconds
[2025-01-13T16:09:58.667+0000] {processor.py:157} INFO - Started process (PID=3561) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:09:58.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:09:58.673+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:09:58.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.745+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:09:58.924+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.924+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15609346099881805
[2025-01-13T16:09:58.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.925+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3561]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:09:58.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.926+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:09:58.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.926+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:09:58.927+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.927+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:09:58.927+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.927+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3561]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:09:58.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.931+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3561]: It took 0.00404s to build the Airflow DAG.
[2025-01-13T16:09:58.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:09:58.947+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.947+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:09:58.976+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:09:58.976+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:09:58.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.337 seconds
[2025-01-13T16:10:29.068+0000] {processor.py:157} INFO - Started process (PID=3648) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:10:29.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:10:29.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:10:29.101+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.101+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:10:29.320+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.319+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20270165300098597
[2025-01-13T16:10:29.320+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.320+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3648]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:10:29.321+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.321+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:10:29.322+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.322+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:10:29.322+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.322+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:10:29.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.323+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3648]: It took 0.222s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:10:29.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.330+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3648]: It took 0.00773s to build the Airflow DAG.
[2025-01-13T16:10:29.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:10:29.368+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.368+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:10:29.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:29.418+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:10:29.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.396 seconds
[2025-01-13T16:10:59.798+0000] {processor.py:157} INFO - Started process (PID=3742) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:10:59.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:10:59.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:59.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:10:59.829+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:10:59.829+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:11:00.026+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.025+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18183826599852182
[2025-01-13T16:11:00.026+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.026+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3742]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:11:00.027+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.027+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:11:00.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.028+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:11:00.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.028+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:11:00.029+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.029+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3742]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:11:00.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.035+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3742]: It took 0.00582s to build the Airflow DAG.
[2025-01-13T16:11:00.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:11:00.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.054+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:11:00.090+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:00.089+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:11:00.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-13T16:11:30.218+0000] {processor.py:157} INFO - Started process (PID=3841) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:11:30.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:11:30.226+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:11:30.262+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.261+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:11:30.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.487+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19902482699762913
[2025-01-13T16:11:30.488+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.487+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3841]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:11:30.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.488+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:11:30.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.489+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:11:30.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.490+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:11:30.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.491+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3841]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:11:30.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.502+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3841]: It took 0.011s to build the Airflow DAG.
[2025-01-13T16:11:30.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:11:30.525+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.524+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:11:30.562+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:11:30.562+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:11:30.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.381 seconds
[2025-01-13T16:12:01.579+0000] {processor.py:157} INFO - Started process (PID=3927) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:12:01.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:12:01.583+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:12:01.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.609+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:12:01.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.804+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17638894699848606
[2025-01-13T16:12:01.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.804+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|3927]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:12:01.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.805+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:12:01.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.806+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:12:01.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.806+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:12:01.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.807+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|3927]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:12:01.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.811+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|3927]: It took 0.00428s to build the Airflow DAG.
[2025-01-13T16:12:01.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:12:01.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.828+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:12:01.857+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:01.857+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:12:01.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T16:12:32.767+0000] {processor.py:157} INFO - Started process (PID=4013) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:12:32.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:12:32.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:32.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:12:32.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:32.798+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:12:33.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.040+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2252579230007541
[2025-01-13T16:12:33.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.041+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4013]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:12:33.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.042+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:12:33.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.043+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:12:33.044+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.044+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:12:33.045+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.044+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4013]: It took 0.246s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:12:33.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.050+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4013]: It took 0.006s to build the Airflow DAG.
[2025-01-13T16:12:33.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:12:33.076+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.076+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:12:33.119+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:12:33.119+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:12:33.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.386 seconds
[2025-01-13T16:13:03.239+0000] {processor.py:157} INFO - Started process (PID=4100) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:13:03.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:13:03.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:13:03.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.274+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:13:03.455+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.455+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16701456499868073
[2025-01-13T16:13:03.456+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.456+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4100]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:13:03.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.457+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:13:03.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.458+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:13:03.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.458+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:13:03.459+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.459+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4100]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:13:03.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.465+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4100]: It took 0.00565s to build the Airflow DAG.
[2025-01-13T16:13:03.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:13:03.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.484+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:13:03.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:03.514+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:13:03.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.300 seconds
[2025-01-13T16:13:33.971+0000] {processor.py:157} INFO - Started process (PID=4203) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:13:33.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:13:33.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:33.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:13:34.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.012+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:13:34.250+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.250+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2205326570001489
[2025-01-13T16:13:34.251+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.251+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4203]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:13:34.252+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.252+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:13:34.252+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.252+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:13:34.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.253+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:13:34.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.253+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4203]: It took 0.242s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:13:34.259+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.259+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4203]: It took 0.00545s to build the Airflow DAG.
[2025-01-13T16:13:34.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:13:34.283+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.283+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:13:34.320+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:13:34.319+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:13:34.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.380 seconds
[2025-01-13T16:14:04.435+0000] {processor.py:157} INFO - Started process (PID=4289) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:14:04.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:14:04.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:14:04.463+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.463+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:14:04.685+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.685+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20593238300352823
[2025-01-13T16:14:04.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.686+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4289]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:14:04.688+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.687+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:14:04.688+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.688+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:14:04.689+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.689+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:14:04.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.690+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4289]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:14:04.696+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.696+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4289]: It took 0.0067s to build the Airflow DAG.
[2025-01-13T16:14:04.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:14:04.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.716+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:14:04.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:04.748+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:14:04.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.344 seconds
[2025-01-13T16:14:34.910+0000] {processor.py:157} INFO - Started process (PID=4377) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:14:34.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:14:34.913+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:34.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:14:34.937+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:34.936+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:14:35.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.132+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17993190400011372
[2025-01-13T16:14:35.133+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.133+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4377]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:14:35.134+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.134+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:14:35.134+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.134+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:14:35.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.135+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:14:35.135+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.135+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4377]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:14:35.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.139+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4377]: It took 0.0041s to build the Airflow DAG.
[2025-01-13T16:14:35.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:14:35.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.154+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:14:35.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:14:35.182+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:14:35.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-13T16:15:05.318+0000] {processor.py:157} INFO - Started process (PID=4465) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:15:05.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:15:05.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:15:05.343+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.343+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:15:05.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.485+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12897396499829483
[2025-01-13T16:15:05.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.486+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4465]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:15:05.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.487+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:15:05.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.487+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:15:05.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.487+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:15:05.488+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.488+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4465]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:15:05.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.491+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4465]: It took 0.00369s to build the Airflow DAG.
[2025-01-13T16:15:05.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:15:05.505+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.505+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:15:05.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:05.526+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:15:05.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-13T16:15:35.627+0000] {processor.py:157} INFO - Started process (PID=4559) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:15:35.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:15:35.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:15:35.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.658+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:15:35.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.823+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14972295299958205
[2025-01-13T16:15:35.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.824+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4559]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:15:35.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.825+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:15:35.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.825+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:15:35.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.825+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:15:35.826+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.826+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4559]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:15:35.831+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.831+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4559]: It took 0.00492s to build the Airflow DAG.
[2025-01-13T16:15:35.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:15:35.846+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.845+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:15:35.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:15:35.870+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:15:35.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T16:16:06.123+0000] {processor.py:157} INFO - Started process (PID=4652) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:16:06.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:16:06.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:16:06.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.150+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:16:06.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.339+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17466292799872463
[2025-01-13T16:16:06.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.339+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4652]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:16:06.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.340+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:16:06.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.340+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:16:06.341+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.341+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:16:06.341+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.341+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4652]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:16:06.346+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.346+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4652]: It took 0.00454s to build the Airflow DAG.
[2025-01-13T16:16:06.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:16:06.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.364+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:16:06.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:06.392+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:16:06.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-13T16:16:36.503+0000] {processor.py:157} INFO - Started process (PID=4740) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:16:36.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:16:36.507+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:16:36.537+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.537+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:16:36.782+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.782+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22849561600014567
[2025-01-13T16:16:36.782+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.782+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4740]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:16:36.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.783+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:16:36.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.783+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:16:36.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.784+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:16:36.785+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.784+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4740]: It took 0.248s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:16:36.789+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.789+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4740]: It took 0.0042s to build the Airflow DAG.
[2025-01-13T16:16:36.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:16:36.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.809+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:16:36.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:16:36.835+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:16:36.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-13T16:17:07.770+0000] {processor.py:157} INFO - Started process (PID=4827) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:17:07.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:17:07.774+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:17:07.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.798+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:17:07.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.959+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14760854699852644
[2025-01-13T16:17:07.960+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.960+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4827]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:17:07.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.961+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:17:07.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.961+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:17:07.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.961+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:17:07.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.962+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4827]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:17:07.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.965+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4827]: It took 0.00396s to build the Airflow DAG.
[2025-01-13T16:17:07.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:17:07.981+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:07.980+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:17:08.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:08.007+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:17:08.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-13T16:17:38.248+0000] {processor.py:157} INFO - Started process (PID=4932) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:17:38.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:17:38.259+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:17:38.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.284+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:17:38.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.482+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1833577459983644
[2025-01-13T16:17:38.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.483+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|4932]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:17:38.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.483+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:17:38.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.484+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:17:38.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.485+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:17:38.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.485+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|4932]: It took 0.202s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:17:38.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.491+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|4932]: It took 0.00588s to build the Airflow DAG.
[2025-01-13T16:17:38.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:17:38.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.513+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:17:38.537+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:17:38.537+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:17:38.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.318 seconds
[2025-01-13T16:18:09.095+0000] {processor.py:157} INFO - Started process (PID=5018) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:18:09.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:18:09.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:18:09.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.126+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:18:09.334+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.334+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19159261499953573
[2025-01-13T16:18:09.335+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.334+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5018]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:18:09.335+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.335+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:18:09.336+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.336+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:18:09.336+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.336+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:18:09.336+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.336+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5018]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:18:09.341+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.341+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5018]: It took 0.00468s to build the Airflow DAG.
[2025-01-13T16:18:09.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:18:09.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.359+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:18:09.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:09.395+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:18:09.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.329 seconds
[2025-01-13T16:18:40.235+0000] {processor.py:157} INFO - Started process (PID=5106) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:18:40.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:18:40.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:18:40.259+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.259+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:18:40.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.442+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16890033500021673
[2025-01-13T16:18:40.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.443+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5106]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:18:40.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.443+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:18:40.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.444+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:18:40.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.444+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:18:40.445+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.445+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5106]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:18:40.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.449+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5106]: It took 0.00423s to build the Airflow DAG.
[2025-01-13T16:18:40.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:18:40.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.466+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:18:40.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:18:40.492+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:18:40.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-13T16:19:10.734+0000] {processor.py:157} INFO - Started process (PID=5192) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:19:10.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:19:10.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:10.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:19:10.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:10.776+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:19:11.061+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.061+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.26217263099897536
[2025-01-13T16:19:11.062+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.062+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5192]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:19:11.063+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.063+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:19:11.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.064+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:19:11.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.064+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:19:11.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.065+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5192]: It took 0.289s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:19:11.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.070+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5192]: It took 0.006s to build the Airflow DAG.
[2025-01-13T16:19:11.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:19:11.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.093+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:19:11.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:11.131+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:19:11.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.434 seconds
[2025-01-13T16:19:41.246+0000] {processor.py:157} INFO - Started process (PID=5287) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:19:41.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:19:41.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:19:41.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.289+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:19:41.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.530+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21855013499953202
[2025-01-13T16:19:41.531+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.531+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5287]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:19:41.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.532+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:19:41.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.533+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:19:41.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.534+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:19:41.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.535+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5287]: It took 0.246s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:19:41.541+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.540+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5287]: It took 0.00586s to build the Airflow DAG.
[2025-01-13T16:19:41.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:19:41.564+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.563+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:19:41.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:19:41.606+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:19:41.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.397 seconds
[2025-01-13T16:20:12.360+0000] {processor.py:157} INFO - Started process (PID=5373) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:20:12.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:20:12.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:20:12.390+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.390+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:20:12.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.587+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18179396800042014
[2025-01-13T16:20:12.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.588+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5373]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:20:12.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.589+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:20:12.590+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.590+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:20:12.590+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.590+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:20:12.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.591+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5373]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:20:12.595+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.595+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5373]: It took 0.00459s to build the Airflow DAG.
[2025-01-13T16:20:12.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:20:12.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.613+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:20:12.678+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:12.678+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:20:12.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.369 seconds
[2025-01-13T16:20:42.775+0000] {processor.py:157} INFO - Started process (PID=5472) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:20:42.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:20:42.779+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:20:42.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.804+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:20:42.960+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.960+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14201135199982673
[2025-01-13T16:20:42.960+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.960+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5472]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:20:42.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.961+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:20:42.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.961+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:20:42.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.962+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:20:42.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.962+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5472]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:20:42.967+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:42.967+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5472]: It took 0.00472s to build the Airflow DAG.
[2025-01-13T16:20:42.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:20:43.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:43.001+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:20:43.030+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:20:43.029+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:20:43.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-13T16:21:13.373+0000] {processor.py:157} INFO - Started process (PID=5556) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:21:13.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:21:13.377+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:21:13.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.405+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:21:13.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.612+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1924289080016024
[2025-01-13T16:21:13.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.613+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5556]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:21:13.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.613+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:21:13.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.614+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:21:13.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.614+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:21:13.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.615+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5556]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:21:13.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.619+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5556]: It took 0.00434s to build the Airflow DAG.
[2025-01-13T16:21:13.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:21:13.635+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.635+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:21:13.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:13.659+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:21:13.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-13T16:21:44.317+0000] {processor.py:157} INFO - Started process (PID=5642) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:21:44.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:21:44.321+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:21:44.353+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.353+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:21:44.579+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.579+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20795835299941245
[2025-01-13T16:21:44.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.580+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5642]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:21:44.581+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.581+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:21:44.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.581+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:21:44.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.582+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:21:44.583+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.583+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5642]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:21:44.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.588+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5642]: It took 0.00555s to build the Airflow DAG.
[2025-01-13T16:21:44.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:21:44.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.610+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:21:44.645+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:21:44.645+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:21:44.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.359 seconds
[2025-01-13T16:22:15.127+0000] {processor.py:157} INFO - Started process (PID=5736) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:22:15.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:22:15.131+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:22:15.157+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.157+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:22:15.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.360+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1874958790031087
[2025-01-13T16:22:15.361+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.360+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5736]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:22:15.362+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.362+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:22:15.362+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.362+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:22:15.363+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.363+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:22:15.363+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.363+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5736]: It took 0.207s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:22:15.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.370+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5736]: It took 0.00625s to build the Airflow DAG.
[2025-01-13T16:22:15.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:22:15.392+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.392+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:22:15.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:15.423+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:22:15.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-13T16:22:45.595+0000] {processor.py:157} INFO - Started process (PID=5835) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:22:45.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:22:45.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:22:45.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.627+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:22:45.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.823+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18039805899752537
[2025-01-13T16:22:45.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.824+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5835]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:22:45.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.825+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:22:45.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.825+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:22:45.826+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.826+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:22:45.826+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.826+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5835]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:22:45.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.830+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5835]: It took 0.00434s to build the Airflow DAG.
[2025-01-13T16:22:45.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:22:45.848+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.847+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:22:45.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:22:45.875+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:22:45.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T16:23:15.976+0000] {processor.py:157} INFO - Started process (PID=5919) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:23:15.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:23:15.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:15.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:23:16.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.006+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:23:16.202+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.202+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18182786700344877
[2025-01-13T16:23:16.203+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.203+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|5919]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:23:16.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.204+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:23:16.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.204+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:23:16.205+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.205+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:23:16.205+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.205+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|5919]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:23:16.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.210+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|5919]: It took 0.00482s to build the Airflow DAG.
[2025-01-13T16:23:16.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:23:16.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.227+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:23:16.256+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:16.256+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:23:16.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-13T16:23:46.422+0000] {processor.py:157} INFO - Started process (PID=6005) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:23:46.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:23:46.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:23:46.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.452+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:23:46.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.658+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18849703099840553
[2025-01-13T16:23:46.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.659+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6005]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:23:46.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.660+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:23:46.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.660+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:23:46.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.661+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:23:46.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.662+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6005]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:23:46.667+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.667+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6005]: It took 0.00553s to build the Airflow DAG.
[2025-01-13T16:23:46.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:23:46.685+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.685+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:23:46.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:23:46.714+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:23:46.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.318 seconds
[2025-01-13T16:24:16.965+0000] {processor.py:157} INFO - Started process (PID=6091) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:24:16.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:24:16.968+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:16.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:24:16.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:16.996+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:24:17.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.193+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17919564900148544
[2025-01-13T16:24:17.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.194+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6091]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:24:17.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.195+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:24:17.195+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.195+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:24:17.196+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.195+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:24:17.196+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.196+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6091]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:24:17.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.200+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6091]: It took 0.00412s to build the Airflow DAG.
[2025-01-13T16:24:17.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:24:17.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.217+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:24:17.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:17.244+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:24:17.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.302 seconds
[2025-01-13T16:24:47.405+0000] {processor.py:157} INFO - Started process (PID=6196) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:24:47.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:24:47.408+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:24:47.434+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.434+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:24:47.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.618+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16968915100005688
[2025-01-13T16:24:47.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.619+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6196]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:24:47.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.620+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:24:47.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.620+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:24:47.621+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.621+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:24:47.621+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.621+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6196]: It took 0.187s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:24:47.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.626+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6196]: It took 0.00511s to build the Airflow DAG.
[2025-01-13T16:24:47.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:24:47.646+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.645+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:24:47.672+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:24:47.672+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:24:47.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-13T16:25:17.839+0000] {processor.py:157} INFO - Started process (PID=6284) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:25:17.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:25:17.844+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:17.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:25:17.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:17.870+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:25:18.119+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.119+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23248916399825248
[2025-01-13T16:25:18.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.119+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6284]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:25:18.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.120+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:25:18.121+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.121+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:25:18.121+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.121+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:25:18.122+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.122+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6284]: It took 0.252s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:25:18.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.127+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6284]: It took 0.00533s to build the Airflow DAG.
[2025-01-13T16:25:18.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:25:18.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.147+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:25:18.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:18.183+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:25:18.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.376 seconds
[2025-01-13T16:25:48.252+0000] {processor.py:157} INFO - Started process (PID=6370) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:25:48.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:25:48.256+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:25:48.281+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.281+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:25:48.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.431+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13586102000044775
[2025-01-13T16:25:48.432+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.432+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6370]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:25:48.432+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.432+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:25:48.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.433+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:25:48.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.433+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:25:48.434+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.434+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6370]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:25:48.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.438+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6370]: It took 0.00478s to build the Airflow DAG.
[2025-01-13T16:25:48.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:25:48.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.453+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:25:48.476+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:25:48.476+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:25:48.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-13T16:26:19.453+0000] {processor.py:157} INFO - Started process (PID=6456) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:26:19.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:26:19.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:26:19.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.482+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:26:19.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.698+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20195646499996656
[2025-01-13T16:26:19.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.699+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6456]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:26:19.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.700+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:26:19.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.700+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:26:19.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.701+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:26:19.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.701+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6456]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:26:19.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.706+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6456]: It took 0.00506s to build the Airflow DAG.
[2025-01-13T16:26:19.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:26:19.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.723+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:26:19.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:19.752+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:26:19.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.326 seconds
[2025-01-13T16:26:49.852+0000] {processor.py:157} INFO - Started process (PID=6552) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:26:49.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:26:49.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:49.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:26:49.878+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:49.878+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:26:50.129+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.129+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2359834859998955
[2025-01-13T16:26:50.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.130+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6552]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:26:50.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.131+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:26:50.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.132+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:26:50.133+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.133+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:26:50.134+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.134+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6552]: It took 0.256s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:26:50.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.143+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6552]: It took 0.009s to build the Airflow DAG.
[2025-01-13T16:26:50.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:26:50.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.200+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:26:50.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:26:50.236+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:26:50.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.410 seconds
[2025-01-13T16:27:20.444+0000] {processor.py:157} INFO - Started process (PID=6651) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:27:20.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:27:20.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:27:20.473+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.473+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:27:20.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.654+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16612600200096495
[2025-01-13T16:27:20.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.655+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6651]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:27:20.656+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.655+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:27:20.656+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.656+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:27:20.656+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.656+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:27:20.657+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.657+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6651]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:27:20.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.661+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6651]: It took 0.00457s to build the Airflow DAG.
[2025-01-13T16:27:20.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:27:20.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.678+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:27:20.705+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:20.705+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:27:20.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T16:27:50.888+0000] {processor.py:157} INFO - Started process (PID=6737) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:27:50.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:27:50.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:50.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:27:50.913+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:50.913+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:27:51.165+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.164+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23592547799853492
[2025-01-13T16:27:51.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.165+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6737]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:27:51.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.167+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:27:51.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.167+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:27:51.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.168+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:27:51.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.168+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6737]: It took 0.255s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:27:51.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.174+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6737]: It took 0.00614s to build the Airflow DAG.
[2025-01-13T16:27:51.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:27:51.196+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.195+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:27:51.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:27:51.237+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:27:51.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.379 seconds
[2025-01-13T16:28:21.386+0000] {processor.py:157} INFO - Started process (PID=6819) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:28:21.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:28:21.398+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:28:21.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.482+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:28:21.991+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.991+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.4722143729995878
[2025-01-13T16:28:21.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.992+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6819]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:28:21.993+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.993+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:28:21.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.994+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:28:21.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.994+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:28:21.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:21.995+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6819]: It took 0.513s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:28:22.002+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:22.002+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6819]: It took 0.0072s to build the Airflow DAG.
[2025-01-13T16:28:22.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:28:22.026+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:22.026+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:28:22.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:22.066+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:28:22.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.716 seconds
[2025-01-13T16:28:52.741+0000] {processor.py:157} INFO - Started process (PID=6907) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:28:52.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:28:52.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:28:52.771+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.771+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:28:52.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.961+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17513719799899263
[2025-01-13T16:28:52.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.962+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|6907]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:28:52.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.963+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:28:52.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.963+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:28:52.964+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.964+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:28:52.964+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.964+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|6907]: It took 0.194s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:28:52.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.970+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|6907]: It took 0.00605s to build the Airflow DAG.
[2025-01-13T16:28:52.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:28:52.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:52.987+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:28:53.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:28:53.015+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:28:53.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.300 seconds
[2025-01-13T16:29:23.467+0000] {processor.py:157} INFO - Started process (PID=7012) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:29:23.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:29:23.476+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:29:23.506+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.506+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:29:23.736+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.736+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21169793500303058
[2025-01-13T16:29:23.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.736+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7012]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:29:23.738+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.738+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:29:23.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.738+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:29:23.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.739+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:29:23.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.740+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7012]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:29:23.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.747+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7012]: It took 0.00742s to build the Airflow DAG.
[2025-01-13T16:29:23.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:29:23.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.772+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:29:23.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:23.806+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:29:23.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.373 seconds
[2025-01-13T16:29:53.897+0000] {processor.py:157} INFO - Started process (PID=7100) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:29:53.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:29:53.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:53.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:29:53.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:53.925+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:29:54.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.096+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1530214390004403
[2025-01-13T16:29:54.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.097+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7100]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:29:54.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.097+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:29:54.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.098+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:29:54.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.098+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:29:54.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.099+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7100]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:29:54.103+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.103+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7100]: It took 0.00424s to build the Airflow DAG.
[2025-01-13T16:29:54.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:29:54.118+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.118+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:29:54.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:29:54.151+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:29:54.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-13T16:30:25.136+0000] {processor.py:157} INFO - Started process (PID=7186) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:30:25.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:30:25.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:30:25.165+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.165+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:30:25.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.358+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17980914700092399
[2025-01-13T16:30:25.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.359+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7186]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:30:25.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.359+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:30:25.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.360+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:30:25.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.360+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:30:25.361+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.361+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7186]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:30:25.366+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.366+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7186]: It took 0.005s to build the Airflow DAG.
[2025-01-13T16:30:25.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:30:25.381+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.381+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:30:25.413+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:25.413+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:30:25.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-13T16:30:55.582+0000] {processor.py:157} INFO - Started process (PID=7274) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:30:55.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:30:55.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:30:55.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.614+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:30:55.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.807+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17869020699799876
[2025-01-13T16:30:55.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.807+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7274]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:30:55.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.808+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:30:55.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.809+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:30:55.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.809+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:30:55.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.810+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7274]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:30:55.816+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.816+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7274]: It took 0.00579s to build the Airflow DAG.
[2025-01-13T16:30:55.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:30:55.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.834+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:30:55.864+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:30:55.864+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:30:55.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.310 seconds
[2025-01-13T16:31:26.068+0000] {processor.py:157} INFO - Started process (PID=7382) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:31:26.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:31:26.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:31:26.106+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.106+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:31:26.330+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.330+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2057723719990463
[2025-01-13T16:31:26.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.331+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7382]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:31:26.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.332+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:31:26.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.332+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:31:26.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.333+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:31:26.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.333+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7382]: It took 0.228s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:31:26.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.339+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7382]: It took 0.00557s to build the Airflow DAG.
[2025-01-13T16:31:26.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:31:26.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.358+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:31:26.391+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:26.390+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:31:26.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.351 seconds
[2025-01-13T16:31:57.212+0000] {processor.py:157} INFO - Started process (PID=7468) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:31:57.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:31:57.215+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:31:57.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.240+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:31:57.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.404+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1503592210028728
[2025-01-13T16:31:57.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.405+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7468]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:31:57.406+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.406+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:31:57.407+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.406+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:31:57.407+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.407+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:31:57.407+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.407+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7468]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:31:57.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.412+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7468]: It took 0.00437s to build the Airflow DAG.
[2025-01-13T16:31:57.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:31:57.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.427+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:31:57.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:31:57.450+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:31:57.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-13T16:32:27.691+0000] {processor.py:157} INFO - Started process (PID=7554) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:32:27.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:32:27.695+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:32:27.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.724+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:32:27.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.958+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21643049400154268
[2025-01-13T16:32:27.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.959+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7554]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:32:27.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.960+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:32:27.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.961+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:32:27.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.962+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:32:27.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.962+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7554]: It took 0.239s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:32:27.969+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.968+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7554]: It took 0.00602s to build the Airflow DAG.
[2025-01-13T16:32:27.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:32:27.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:27.990+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:32:28.023+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:28.023+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:32:28.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.363 seconds
[2025-01-13T16:32:58.329+0000] {processor.py:157} INFO - Started process (PID=7640) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:32:58.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:32:58.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:32:58.363+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.362+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:32:58.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.590+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21118636999744922
[2025-01-13T16:32:58.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.591+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7640]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:32:58.592+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.592+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:32:58.593+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.593+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:32:58.593+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.593+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:32:58.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.594+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7640]: It took 0.231s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:32:58.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.600+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7640]: It took 0.00635s to build the Airflow DAG.
[2025-01-13T16:32:58.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:32:58.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.620+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:32:58.653+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:32:58.652+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:32:58.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-13T16:33:28.848+0000] {processor.py:157} INFO - Started process (PID=7734) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:33:28.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:33:28.852+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:28.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:33:28.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:28.882+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:33:29.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.071+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17508901299879653
[2025-01-13T16:33:29.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.072+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7734]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:33:29.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.073+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:33:29.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.073+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:33:29.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.074+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:33:29.075+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.074+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7734]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:33:29.084+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.083+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7734]: It took 0.00899s to build the Airflow DAG.
[2025-01-13T16:33:29.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:33:29.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.139+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:33:29.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:29.204+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:33:29.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.386 seconds
[2025-01-13T16:33:59.539+0000] {processor.py:157} INFO - Started process (PID=7831) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:33:59.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:33:59.543+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:33:59.572+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.572+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:33:59.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.803+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21655693200227688
[2025-01-13T16:33:59.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.804+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7831]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:33:59.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.805+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:33:59.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.805+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:33:59.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.806+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:33:59.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.806+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7831]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:33:59.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.811+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7831]: It took 0.00508s to build the Airflow DAG.
[2025-01-13T16:33:59.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:33:59.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.835+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:33:59.864+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:33:59.864+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:33:59.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.351 seconds
[2025-01-13T16:34:30.278+0000] {processor.py:157} INFO - Started process (PID=7917) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:34:30.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:34:30.281+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:34:30.308+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.308+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:34:30.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.468+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1439447930024471
[2025-01-13T16:34:30.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.468+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|7917]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:34:30.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.469+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:34:30.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.469+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:34:30.470+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.470+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:34:30.470+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.470+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|7917]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:34:30.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.475+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|7917]: It took 0.00482s to build the Airflow DAG.
[2025-01-13T16:34:30.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:34:30.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.490+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:34:30.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:34:30.513+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:34:30.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-13T16:35:00.702+0000] {processor.py:157} INFO - Started process (PID=8006) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:35:00.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:35:00.705+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:35:00.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.726+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:35:00.924+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.924+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18297670899846707
[2025-01-13T16:35:00.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.924+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8006]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:35:00.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.926+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:35:00.926+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.926+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:35:00.927+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.927+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:35:00.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.927+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8006]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:35:00.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.934+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8006]: It took 0.00637s to build the Airflow DAG.
[2025-01-13T16:35:00.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:35:00.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.959+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:35:00.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:00.996+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:35:01.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.315 seconds
[2025-01-13T16:35:31.231+0000] {processor.py:157} INFO - Started process (PID=8100) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:35:31.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:35:31.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:35:31.280+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.280+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:35:31.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.663+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.36111423499824014
[2025-01-13T16:35:31.667+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.667+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8100]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:35:31.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.669+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:35:31.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.671+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:35:31.672+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.672+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:35:31.673+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.673+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8100]: It took 0.393s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:35:31.689+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.689+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8100]: It took 0.0156s to build the Airflow DAG.
[2025-01-13T16:35:31.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:35:31.734+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.734+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:35:31.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:35:31.804+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:35:31.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.628 seconds
[2025-01-13T16:36:01.907+0000] {processor.py:157} INFO - Started process (PID=8184) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:36:01.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:36:01.910+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:01.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:36:01.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:01.935+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:36:02.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.152+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20160681300330907
[2025-01-13T16:36:02.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.153+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8184]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:36:02.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.154+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:36:02.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.154+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:36:02.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.154+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:36:02.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.155+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8184]: It took 0.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:36:02.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.159+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8184]: It took 0.00459s to build the Airflow DAG.
[2025-01-13T16:36:02.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:36:02.176+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.176+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:36:02.202+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:02.201+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:36:02.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.319 seconds
[2025-01-13T16:36:32.278+0000] {processor.py:157} INFO - Started process (PID=8283) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:36:32.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:36:32.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:36:32.304+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.304+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:36:32.479+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.479+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16062858700024663
[2025-01-13T16:36:32.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.479+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8283]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:36:32.480+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.480+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:36:32.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.481+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:36:32.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.481+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:36:32.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.481+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8283]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:36:32.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.486+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8283]: It took 0.00456s to build the Airflow DAG.
[2025-01-13T16:36:32.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:36:32.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.503+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:36:32.529+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:36:32.529+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:36:32.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.276 seconds
[2025-01-13T16:37:02.762+0000] {processor.py:157} INFO - Started process (PID=8370) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:37:02.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:37:02.767+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:02.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:37:02.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:02.796+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:37:03.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.022+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20318511399818817
[2025-01-13T16:37:03.023+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.023+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8370]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:37:03.024+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.023+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:37:03.024+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.024+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:37:03.025+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.025+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:37:03.026+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.025+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8370]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:37:03.031+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.031+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8370]: It took 0.00565s to build the Airflow DAG.
[2025-01-13T16:37:03.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:37:03.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.054+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:37:03.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:03.080+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:37:03.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.344 seconds
[2025-01-13T16:37:33.297+0000] {processor.py:157} INFO - Started process (PID=8457) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:37:33.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:37:33.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:37:33.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.324+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:37:33.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.498+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15812810599891236
[2025-01-13T16:37:33.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.498+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8457]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:37:33.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.499+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:37:33.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.500+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:37:33.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.500+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:37:33.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.501+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8457]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:37:33.506+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.506+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8457]: It took 0.00481s to build the Airflow DAG.
[2025-01-13T16:37:33.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:37:33.524+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.524+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:37:33.555+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:37:33.555+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:37:33.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-13T16:38:03.785+0000] {processor.py:157} INFO - Started process (PID=8539) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:38:03.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:38:03.791+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:03.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:38:03.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:03.822+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:38:04.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.018+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18104628099899855
[2025-01-13T16:38:04.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.019+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8539]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:38:04.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.020+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:38:04.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.020+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:38:04.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.021+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:38:04.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.021+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8539]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:38:04.027+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.026+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8539]: It took 0.00549s to build the Airflow DAG.
[2025-01-13T16:38:04.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:38:04.045+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.045+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:38:04.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:04.073+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:38:04.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.511 seconds
[2025-01-13T16:38:34.763+0000] {processor.py:157} INFO - Started process (PID=8648) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:38:34.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:38:34.768+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:34.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:38:34.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:34.799+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:38:35.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.037+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21714255700135254
[2025-01-13T16:38:35.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.038+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8648]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:38:35.039+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.039+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:38:35.040+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.040+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:38:35.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.040+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:38:35.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.041+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8648]: It took 0.242s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:38:35.048+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.048+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8648]: It took 0.00692s to build the Airflow DAG.
[2025-01-13T16:38:35.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:38:35.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.073+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:38:35.109+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:38:35.109+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:38:35.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.380 seconds
[2025-01-13T16:39:05.218+0000] {processor.py:157} INFO - Started process (PID=8734) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:39:05.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:39:05.222+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:39:05.250+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.250+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:39:05.437+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.436+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17205886299780104
[2025-01-13T16:39:05.437+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.437+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8734]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:39:05.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.438+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:39:05.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.438+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:39:05.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.438+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:39:05.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.439+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8734]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:39:05.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.444+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8734]: It took 0.00519s to build the Airflow DAG.
[2025-01-13T16:39:05.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:39:05.461+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.461+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:39:05.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:05.662+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:39:05.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.468 seconds
[2025-01-13T16:39:35.975+0000] {processor.py:157} INFO - Started process (PID=8819) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:39:35.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:39:35.979+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:35.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:39:36.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.008+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:39:36.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.235+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20980176200100686
[2025-01-13T16:39:36.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.236+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8819]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:39:36.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.237+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:39:36.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.238+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:39:36.239+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.239+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:39:36.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.240+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8819]: It took 0.232s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:39:36.245+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.245+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8819]: It took 0.00556s to build the Airflow DAG.
[2025-01-13T16:39:36.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:39:36.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.270+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:39:36.304+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:39:36.303+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:39:36.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.361 seconds
[2025-01-13T16:40:06.535+0000] {processor.py:157} INFO - Started process (PID=8904) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:40:06.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:40:06.539+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:40:06.560+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.560+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:40:06.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.739+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1637390329997288
[2025-01-13T16:40:06.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.739+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|8904]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:40:06.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.740+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:40:06.741+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.741+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:40:06.741+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.741+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:40:06.741+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.741+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|8904]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:40:06.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.745+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|8904]: It took 0.00402s to build the Airflow DAG.
[2025-01-13T16:40:06.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:40:06.763+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.763+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:40:06.790+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:06.789+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:40:06.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-13T16:40:36.961+0000] {processor.py:157} INFO - Started process (PID=9000) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:40:36.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:40:36.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:36.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:40:36.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:36.999+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:40:37.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.217+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19936840000082157
[2025-01-13T16:40:37.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.218+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9000]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:40:37.219+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.219+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:40:37.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.220+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:40:37.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.220+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:40:37.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.221+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9000]: It took 0.222s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:40:37.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.227+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9000]: It took 0.00615s to build the Airflow DAG.
[2025-01-13T16:40:37.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:40:37.248+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.248+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:40:37.283+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:40:37.283+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:40:37.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.613 seconds
[2025-01-13T16:41:08.014+0000] {processor.py:157} INFO - Started process (PID=9097) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:41:08.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:41:08.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:41:08.040+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.040+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:41:08.219+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.219+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16449677199852886
[2025-01-13T16:41:08.219+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.219+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9097]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:41:08.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.220+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:41:08.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.220+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:41:08.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.221+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:41:08.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.221+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9097]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:41:08.226+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.226+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9097]: It took 0.00459s to build the Airflow DAG.
[2025-01-13T16:41:08.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:41:08.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.240+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:41:08.264+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:08.264+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:41:08.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-13T16:41:38.682+0000] {processor.py:157} INFO - Started process (PID=9183) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:41:38.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:41:38.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:41:38.710+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.710+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:41:38.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.892+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16671107200090773
[2025-01-13T16:41:38.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.893+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9183]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:41:38.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.894+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:41:38.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.894+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:41:38.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.895+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:41:38.896+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.896+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9183]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:41:38.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.902+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9183]: It took 0.00623s to build the Airflow DAG.
[2025-01-13T16:41:38.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:41:38.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:38.925+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:41:39.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:41:39.136+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:41:39.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.481 seconds
[2025-01-13T16:42:09.224+0000] {processor.py:157} INFO - Started process (PID=9270) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:42:09.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:42:09.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:42:09.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.254+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:42:09.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.425+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15551925299951108
[2025-01-13T16:42:09.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.426+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9270]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:42:09.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.427+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:42:09.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.427+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:42:09.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.427+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:42:09.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.428+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9270]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:42:09.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.433+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9270]: It took 0.00506s to build the Airflow DAG.
[2025-01-13T16:42:09.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:42:09.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.449+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:42:09.474+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:09.474+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:42:09.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.431 seconds
[2025-01-13T16:42:40.498+0000] {processor.py:157} INFO - Started process (PID=9357) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:42:40.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:42:40.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:42:40.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.527+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:42:40.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.711+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17032951600049273
[2025-01-13T16:42:40.712+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.711+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9357]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:42:40.712+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.712+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:42:40.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.713+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:42:40.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.714+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:42:40.714+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.714+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9357]: It took 0.187s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:42:40.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.719+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9357]: It took 0.00504s to build the Airflow DAG.
[2025-01-13T16:42:40.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:42:40.736+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.736+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:42:40.762+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:42:40.762+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:42:40.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T16:43:10.947+0000] {processor.py:157} INFO - Started process (PID=9462) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:43:10.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:43:10.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:10.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:43:10.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:10.977+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:43:11.179+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.179+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1864787439990323
[2025-01-13T16:43:11.180+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.180+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9462]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:43:11.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.181+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:43:11.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.181+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:43:11.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.182+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:43:11.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.182+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9462]: It took 0.205s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:43:11.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.192+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9462]: It took 0.00975s to build the Airflow DAG.
[2025-01-13T16:43:11.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:43:11.410+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.409+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:43:11.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:11.442+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:43:11.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.527 seconds
[2025-01-13T16:43:41.875+0000] {processor.py:157} INFO - Started process (PID=9548) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:43:41.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:43:41.883+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:41.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:43:41.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:41.915+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:43:42.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.162+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22474851600054535
[2025-01-13T16:43:42.163+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.163+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9548]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:43:42.164+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.164+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:43:42.165+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.165+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:43:42.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.166+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:43:42.167+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.166+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9548]: It took 0.252s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:43:42.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.174+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9548]: It took 0.00742s to build the Airflow DAG.
[2025-01-13T16:43:42.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:43:42.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.215+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:43:42.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:43:42.515+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:43:42.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.672 seconds
[2025-01-13T16:44:13.138+0000] {processor.py:157} INFO - Started process (PID=9634) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:44:13.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:44:13.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:44:13.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.168+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:44:13.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.401+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21704756699909922
[2025-01-13T16:44:13.402+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.401+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9634]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:44:13.403+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.402+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:44:13.403+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.403+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:44:13.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.403+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:44:13.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.404+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9634]: It took 0.236s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:44:13.410+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.410+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9634]: It took 0.00568s to build the Airflow DAG.
[2025-01-13T16:44:13.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:44:13.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.433+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:44:13.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:13.465+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:44:13.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-13T16:44:43.686+0000] {processor.py:157} INFO - Started process (PID=9720) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:44:43.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:44:43.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:44:43.720+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.720+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:44:43.877+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.877+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14357473999916692
[2025-01-13T16:44:43.877+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.877+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9720]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:44:43.878+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.878+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:44:43.878+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.878+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:44:43.879+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.879+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:44:43.879+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.879+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9720]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:44:43.883+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:43.883+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9720]: It took 0.00419s to build the Airflow DAG.
[2025-01-13T16:44:43.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:44:44.116+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:44.113+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:44:44.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:44:44.159+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:44:44.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.507 seconds
[2025-01-13T16:45:14.833+0000] {processor.py:157} INFO - Started process (PID=9806) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:45:14.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:45:14.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:14.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:45:14.861+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:14.861+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:45:15.078+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.078+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2011309560002701
[2025-01-13T16:45:15.079+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.079+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9806]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:45:15.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.080+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:45:15.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.080+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:45:15.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.081+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:45:15.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.081+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9806]: It took 0.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:45:15.086+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.086+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9806]: It took 0.00515s to build the Airflow DAG.
[2025-01-13T16:45:15.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:45:15.103+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.103+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:45:15.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:15.312+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:45:15.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.509 seconds
[2025-01-13T16:45:45.876+0000] {processor.py:157} INFO - Started process (PID=9910) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:45:45.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:45:45.880+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:45.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:45:45.910+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:45.910+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:45:46.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.141+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21139372600009665
[2025-01-13T16:45:46.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.142+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9910]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:45:46.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.143+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:45:46.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.143+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:45:46.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.144+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:45:46.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.144+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9910]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:45:46.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.150+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9910]: It took 0.00575s to build the Airflow DAG.
[2025-01-13T16:45:46.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:45:46.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.174+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:45:46.225+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:45:46.225+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:45:46.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.670 seconds
[2025-01-13T16:46:16.651+0000] {processor.py:157} INFO - Started process (PID=9996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:46:16.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:46:16.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:16.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:46:16.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:16.686+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:46:17.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.129+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2256498980023025
[2025-01-13T16:46:17.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.130+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|9996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:46:17.131+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.131+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:46:17.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.131+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:46:17.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.132+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:46:17.133+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.133+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|9996]: It took 0.447s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:46:17.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.139+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|9996]: It took 0.00596s to build the Airflow DAG.
[2025-01-13T16:46:17.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:46:17.163+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.163+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:46:17.198+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:17.198+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:46:17.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.581 seconds
[2025-01-13T16:46:47.787+0000] {processor.py:157} INFO - Started process (PID=10082) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:46:47.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:46:47.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:47.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:46:47.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:47.819+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:46:48.057+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.056+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22151898899755906
[2025-01-13T16:46:48.057+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.057+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10082]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:46:48.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.058+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:46:48.059+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.059+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:46:48.060+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.060+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:46:48.060+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.060+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10082]: It took 0.242s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:46:48.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.066+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10082]: It took 0.00562s to build the Airflow DAG.
[2025-01-13T16:46:48.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:46:48.086+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.086+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:46:48.116+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:46:48.116+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:46:48.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-13T16:47:18.276+0000] {processor.py:157} INFO - Started process (PID=10170) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:47:18.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:47:18.282+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:47:18.309+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.309+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:47:18.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.526+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19992845399974613
[2025-01-13T16:47:18.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.527+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10170]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:47:18.528+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.528+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:47:18.529+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.529+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:47:18.529+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.529+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:47:18.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.530+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10170]: It took 0.221s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:47:18.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.536+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10170]: It took 0.00599s to build the Airflow DAG.
[2025-01-13T16:47:18.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:47:18.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.558+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:47:18.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:18.591+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:47:18.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.344 seconds
[2025-01-13T16:47:49.562+0000] {processor.py:157} INFO - Started process (PID=10256) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:47:49.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:47:49.567+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:47:49.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.594+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:47:49.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.817+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20640894800089882
[2025-01-13T16:47:49.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.818+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10256]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:47:49.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.819+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:47:49.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.819+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:47:49.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.820+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:47:49.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.820+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10256]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:47:49.826+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.825+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10256]: It took 0.00509s to build the Airflow DAG.
[2025-01-13T16:47:49.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:47:49.847+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.847+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:47:49.883+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:47:49.883+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:47:49.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.348 seconds
[2025-01-13T16:48:20.729+0000] {processor.py:157} INFO - Started process (PID=10350) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:48:20.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:48:20.732+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:48:20.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.757+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:48:20.984+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.984+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2129339439998148
[2025-01-13T16:48:20.985+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.985+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10350]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:48:20.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.986+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:48:20.987+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.987+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:48:20.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.988+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:48:20.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.988+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10350]: It took 0.231s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:48:20.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:20.994+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10350]: It took 0.00633s to build the Airflow DAG.
[2025-01-13T16:48:20.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:48:21.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:21.017+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:48:21.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:21.055+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:48:21.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-13T16:48:51.234+0000] {processor.py:157} INFO - Started process (PID=10449) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:48:51.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:48:51.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:48:51.259+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.259+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:48:51.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.425+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15276939800241962
[2025-01-13T16:48:51.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.425+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10449]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:48:51.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.426+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:48:51.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.426+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:48:51.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.427+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:48:51.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.427+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10449]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:48:51.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.431+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10449]: It took 0.00369s to build the Airflow DAG.
[2025-01-13T16:48:51.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:48:51.447+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.447+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:48:51.470+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:48:51.470+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:48:51.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-13T16:49:22.266+0000] {processor.py:157} INFO - Started process (PID=10535) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:49:22.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:49:22.272+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:49:22.301+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.301+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:49:22.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.491+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1705234159999236
[2025-01-13T16:49:22.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.491+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10535]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:49:22.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.492+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:49:22.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.493+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:49:22.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.493+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:49:22.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.494+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10535]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:49:22.499+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.499+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10535]: It took 0.00517s to build the Airflow DAG.
[2025-01-13T16:49:22.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:49:22.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.515+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:49:22.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:22.542+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:49:22.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.302 seconds
[2025-01-13T16:49:52.676+0000] {processor.py:157} INFO - Started process (PID=10621) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:49:52.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:49:52.682+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:49:52.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.713+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:49:52.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.952+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21984181000152603
[2025-01-13T16:49:52.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.953+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10621]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:49:52.954+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.954+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:49:52.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.955+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:49:52.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.955+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:49:52.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.956+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10621]: It took 0.243s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:49:52.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.961+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10621]: It took 0.00571s to build the Airflow DAG.
[2025-01-13T16:49:52.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:49:52.981+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:52.981+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:49:53.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:49:53.013+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:49:53.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.365 seconds
[2025-01-13T16:50:23.871+0000] {processor.py:157} INFO - Started process (PID=10716) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:50:23.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:50:23.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:23.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:50:23.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:23.898+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:50:24.061+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.061+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14940865799871972
[2025-01-13T16:50:24.062+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.062+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10716]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:50:24.063+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.063+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:50:24.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.064+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:50:24.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.064+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:50:24.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.065+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10716]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:50:24.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.069+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10716]: It took 0.00405s to build the Airflow DAG.
[2025-01-13T16:50:24.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:50:24.090+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.089+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:50:24.116+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:24.116+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:50:24.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T16:50:54.279+0000] {processor.py:157} INFO - Started process (PID=10813) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:50:54.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:50:54.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:50:54.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.325+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:50:54.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.615+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.26504704800026957
[2025-01-13T16:50:54.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.616+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10813]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:50:54.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.618+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:50:54.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.619+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:50:54.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.620+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:50:54.621+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.620+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10813]: It took 0.295s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:50:54.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.629+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10813]: It took 0.00878s to build the Airflow DAG.
[2025-01-13T16:50:54.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:50:54.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.658+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:50:54.715+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:50:54.714+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:50:54.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.500 seconds
[2025-01-13T16:51:24.935+0000] {processor.py:157} INFO - Started process (PID=10900) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:51:24.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:51:24.939+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:24.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:51:24.971+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:24.971+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:51:25.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.153+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16932088599787676
[2025-01-13T16:51:25.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.153+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10900]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:51:25.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.154+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:51:25.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.155+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:51:25.156+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.156+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:51:25.156+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.156+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10900]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:51:25.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.161+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10900]: It took 0.00532s to build the Airflow DAG.
[2025-01-13T16:51:25.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:51:25.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.184+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:51:25.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:25.226+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:51:25.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.332 seconds
[2025-01-13T16:51:55.568+0000] {processor.py:157} INFO - Started process (PID=10989) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:51:55.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:51:55.574+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:51:55.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.607+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:51:55.838+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.837+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21042541800125036
[2025-01-13T16:51:55.839+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.838+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|10989]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:51:55.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.840+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:51:55.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.840+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:51:55.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.841+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:51:55.842+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.842+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|10989]: It took 0.236s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:51:55.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.849+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|10989]: It took 0.00718s to build the Airflow DAG.
[2025-01-13T16:51:55.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:51:55.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.891+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:51:55.939+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:51:55.939+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:51:55.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.424 seconds
[2025-01-13T16:52:26.885+0000] {processor.py:157} INFO - Started process (PID=11075) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:52:26.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:52:26.889+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:26.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:52:26.915+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:26.915+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:52:27.111+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.111+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1784620079997694
[2025-01-13T16:52:27.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.112+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11075]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:52:27.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.112+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:52:27.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.113+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:52:27.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.114+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:52:27.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.114+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11075]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:52:27.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.120+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11075]: It took 0.00559s to build the Airflow DAG.
[2025-01-13T16:52:27.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:52:27.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.139+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:52:27.172+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:27.172+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:52:27.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-13T16:52:57.500+0000] {processor.py:157} INFO - Started process (PID=11161) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:52:57.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:52:57.504+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:52:57.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.527+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:52:57.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.700+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1565171639995242
[2025-01-13T16:52:57.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.700+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11161]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:52:57.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.701+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:52:57.702+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.701+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:52:57.702+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.702+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:52:57.702+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.702+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11161]: It took 0.175s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:52:57.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.707+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11161]: It took 0.0044s to build the Airflow DAG.
[2025-01-13T16:52:57.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:52:57.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.725+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:52:57.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:52:57.750+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:52:57.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.272 seconds
[2025-01-13T16:53:27.911+0000] {processor.py:157} INFO - Started process (PID=11266) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:53:27.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:53:27.914+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:27.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:53:27.941+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:27.941+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:53:28.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.141+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1836751209993963
[2025-01-13T16:53:28.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.141+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11266]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:53:28.142+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.142+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:53:28.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.143+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:53:28.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.143+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:53:28.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.144+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11266]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:53:28.149+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.149+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11266]: It took 0.00529s to build the Airflow DAG.
[2025-01-13T16:53:28.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:53:28.168+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.167+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:53:28.198+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:28.197+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:53:28.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.321 seconds
[2025-01-13T16:53:58.814+0000] {processor.py:157} INFO - Started process (PID=11352) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:53:58.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:53:58.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:53:58.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.839+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:53:58.984+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.984+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13096410199796082
[2025-01-13T16:53:58.984+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.984+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11352]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:53:58.985+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.985+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:53:58.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.985+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:53:58.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.986+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:53:58.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.986+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11352]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:53:58.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:58.990+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11352]: It took 0.00374s to build the Airflow DAG.
[2025-01-13T16:53:58.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:53:59.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:59.005+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:53:59.027+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:53:59.027+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:53:59.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-13T16:54:29.769+0000] {processor.py:157} INFO - Started process (PID=11439) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:54:29.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:54:29.773+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:54:29.795+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.794+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:54:29.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.932+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12315302600109135
[2025-01-13T16:54:29.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.932+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11439]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:54:29.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.933+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:54:29.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.934+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:54:29.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.934+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:54:29.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.935+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11439]: It took 0.14s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:54:29.939+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.939+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11439]: It took 0.00425s to build the Airflow DAG.
[2025-01-13T16:54:29.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:54:29.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.953+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:54:29.975+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:54:29.974+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:54:29.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-13T16:55:00.066+0000] {processor.py:157} INFO - Started process (PID=11526) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:55:00.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:55:00.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:55:00.109+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.109+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:55:00.379+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.378+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2472239249982522
[2025-01-13T16:55:00.379+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.379+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11526]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:55:00.381+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.380+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:55:00.381+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.381+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:55:00.382+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.382+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:55:00.382+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.382+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11526]: It took 0.274s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:55:00.388+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.388+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11526]: It took 0.00588s to build the Airflow DAG.
[2025-01-13T16:55:00.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:55:00.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.419+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:55:00.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:00.468+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:55:00.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.437 seconds
[2025-01-13T16:55:30.639+0000] {processor.py:157} INFO - Started process (PID=11611) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:55:30.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:55:30.644+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:55:30.676+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.675+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:55:30.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.930+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23463321000235737
[2025-01-13T16:55:30.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.931+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11611]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:55:30.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.932+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:55:30.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.933+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:55:30.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.933+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:55:30.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.934+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11611]: It took 0.259s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:55:30.941+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.940+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11611]: It took 0.00638s to build the Airflow DAG.
[2025-01-13T16:55:30.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:55:30.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:30.962+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:55:31.003+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:55:31.003+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:55:31.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.394 seconds
[2025-01-13T16:56:01.338+0000] {processor.py:157} INFO - Started process (PID=11705) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:56:01.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:56:01.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:56:01.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.368+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:56:01.572+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.572+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18514721600149642
[2025-01-13T16:56:01.572+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.572+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11705]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:56:01.573+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.573+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:56:01.574+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.573+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:56:01.574+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.574+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:56:01.575+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.575+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11705]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:56:01.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.579+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11705]: It took 0.00483s to build the Airflow DAG.
[2025-01-13T16:56:01.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:56:01.599+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.599+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:56:01.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:01.629+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:56:01.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.326 seconds
[2025-01-13T16:56:31.810+0000] {processor.py:157} INFO - Started process (PID=11802) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:56:31.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:56:31.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:31.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:56:31.839+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:31.838+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:56:32.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.016+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16128734199810424
[2025-01-13T16:56:32.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.017+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11802]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:56:32.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.018+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:56:32.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.018+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:56:32.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.019+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:56:32.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.019+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11802]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:56:32.024+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.024+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11802]: It took 0.00465s to build the Airflow DAG.
[2025-01-13T16:56:32.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:56:32.040+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.040+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:56:32.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:56:32.067+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:56:32.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-13T16:57:02.284+0000] {processor.py:157} INFO - Started process (PID=11888) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:57:02.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:57:02.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:57:02.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.313+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:57:02.472+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.472+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.141973481997411
[2025-01-13T16:57:02.473+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.473+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11888]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:57:02.474+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.474+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:57:02.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.474+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:57:02.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.475+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:57:02.476+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.475+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11888]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:57:02.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.481+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11888]: It took 0.00583s to build the Airflow DAG.
[2025-01-13T16:57:02.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:57:02.522+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.522+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:57:02.568+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:02.567+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:57:02.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.313 seconds
[2025-01-13T16:57:32.711+0000] {processor.py:157} INFO - Started process (PID=11974) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:57:32.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:57:32.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:57:32.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.743+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:57:32.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.892+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1302879489994666
[2025-01-13T16:57:32.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.892+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|11974]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:57:32.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.893+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:57:32.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.893+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:57:32.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.894+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:57:32.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.894+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|11974]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:57:32.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.898+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|11974]: It took 0.00377s to build the Airflow DAG.
[2025-01-13T16:57:32.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:57:32.914+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.914+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:57:32.938+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:57:32.938+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:57:32.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-13T16:58:03.168+0000] {processor.py:157} INFO - Started process (PID=12060) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:58:03.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:58:03.173+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:58:03.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.207+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:58:03.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.414+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18492718899869942
[2025-01-13T16:58:03.416+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.415+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12060]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:58:03.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.417+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:58:03.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.417+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:58:03.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.417+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:58:03.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.418+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12060]: It took 0.211s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:58:03.422+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.422+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12060]: It took 0.00448s to build the Airflow DAG.
[2025-01-13T16:58:03.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:58:03.441+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.440+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:58:03.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:03.469+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:58:03.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.328 seconds
[2025-01-13T16:58:34.043+0000] {processor.py:157} INFO - Started process (PID=12146) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:58:34.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:58:34.047+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:58:34.075+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.075+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:58:34.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.234+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14422529300281894
[2025-01-13T16:58:34.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.235+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12146]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:58:34.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.236+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:58:34.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.236+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:58:34.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.237+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:58:34.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.238+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12146]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:58:34.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.242+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12146]: It took 0.00469s to build the Airflow DAG.
[2025-01-13T16:58:34.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:58:34.259+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.259+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:58:34.283+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:58:34.283+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:58:34.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-13T16:59:04.374+0000] {processor.py:157} INFO - Started process (PID=12242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:59:04.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:59:04.377+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:59:04.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.405+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:59:04.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.554+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1338578700015205
[2025-01-13T16:59:04.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.554+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12242]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:59:04.555+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.555+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:59:04.555+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.555+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:59:04.556+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.556+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:59:04.556+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.556+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12242]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:59:04.560+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.559+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12242]: It took 0.00351s to build the Airflow DAG.
[2025-01-13T16:59:04.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:59:04.573+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.573+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:59:04.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:04.612+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:59:04.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-13T16:59:34.992+0000] {processor.py:157} INFO - Started process (PID=12338) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:59:34.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T16:59:34.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:34.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:59:35.026+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.026+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T16:59:35.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.182+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13884157400025288
[2025-01-13T16:59:35.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.182+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12338]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T16:59:35.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.183+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T16:59:35.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.183+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T16:59:35.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.184+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T16:59:35.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.184+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12338]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T16:59:35.188+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.188+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12338]: It took 0.00409s to build the Airflow DAG.
[2025-01-13T16:59:35.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T16:59:35.205+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.204+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T16:59:35.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T16:59:35.230+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T16:59:35.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-13T17:00:05.835+0000] {processor.py:157} INFO - Started process (PID=12424) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:00:05.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:00:05.839+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:05.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:00:05.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:05.862+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:00:06.031+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.031+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15135898000153247
[2025-01-13T17:00:06.031+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.031+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12424]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:00:06.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.032+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:00:06.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.033+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:00:06.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.033+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:00:06.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.033+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12424]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:00:06.039+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.039+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12424]: It took 0.00527s to build the Airflow DAG.
[2025-01-13T17:00:06.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:00:06.056+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.056+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:00:06.083+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:06.083+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:00:06.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.272 seconds
[2025-01-13T17:00:36.560+0000] {processor.py:157} INFO - Started process (PID=12510) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:00:36.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:00:36.566+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:00:36.597+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.597+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:00:36.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.823+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20557243000075687
[2025-01-13T17:00:36.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.825+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12510]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:00:36.826+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.826+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:00:36.827+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.827+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:00:36.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.828+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:00:36.829+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.828+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12510]: It took 0.231s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:00:36.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.835+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12510]: It took 0.00644s to build the Airflow DAG.
[2025-01-13T17:00:36.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:00:36.855+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.855+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:00:36.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:00:36.895+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:00:36.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-13T17:01:07.832+0000] {processor.py:157} INFO - Started process (PID=12616) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:01:07.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:01:07.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:07.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:01:07.864+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:07.864+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:01:08.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.018+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14148925400149892
[2025-01-13T17:01:08.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.019+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12616]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:01:08.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.020+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:01:08.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.020+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:01:08.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.021+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:01:08.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.021+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12616]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:01:08.026+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.026+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12616]: It took 0.00434s to build the Airflow DAG.
[2025-01-13T17:01:08.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:01:08.044+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.043+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:01:08.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:08.064+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:01:08.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-13T17:01:38.903+0000] {processor.py:157} INFO - Started process (PID=12702) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:01:38.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:01:38.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:38.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:01:38.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:38.931+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:01:39.086+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.086+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14113978299792507
[2025-01-13T17:01:39.087+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.087+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12702]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:01:39.088+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.087+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:01:39.088+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.088+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:01:39.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.088+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:01:39.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.089+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12702]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:01:39.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.093+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12702]: It took 0.00383s to build the Airflow DAG.
[2025-01-13T17:01:39.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:01:39.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.108+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:01:39.131+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:01:39.131+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:01:39.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-13T17:02:10.058+0000] {processor.py:157} INFO - Started process (PID=12788) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:02:10.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:02:10.062+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:02:10.084+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.084+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:02:10.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.240+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13932607699825894
[2025-01-13T17:02:10.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.241+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12788]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:02:10.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.241+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:02:10.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.242+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:02:10.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.242+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:02:10.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.243+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12788]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:02:10.247+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.246+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12788]: It took 0.00389s to build the Airflow DAG.
[2025-01-13T17:02:10.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:02:10.261+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.261+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:02:10.284+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:10.284+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:02:10.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-13T17:02:40.365+0000] {processor.py:157} INFO - Started process (PID=12874) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:02:40.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:02:40.368+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:02:40.389+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.389+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:02:40.525+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.525+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1234713260018907
[2025-01-13T17:02:40.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.526+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12874]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:02:40.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.526+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:02:40.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.527+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:02:40.527+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.527+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:02:40.528+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.527+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12874]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:02:40.531+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.531+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12874]: It took 0.00367s to build the Airflow DAG.
[2025-01-13T17:02:40.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:02:40.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.545+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:02:40.567+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:02:40.566+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:02:40.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-13T17:03:10.933+0000] {processor.py:157} INFO - Started process (PID=12979) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:03:10.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:03:10.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:10.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:03:10.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:10.959+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:03:11.100+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.100+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12842642400210025
[2025-01-13T17:03:11.101+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.101+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|12979]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:03:11.101+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.101+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:03:11.102+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.102+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:03:11.102+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.102+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:03:11.102+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.102+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|12979]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:03:11.106+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.106+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|12979]: It took 0.00366s to build the Airflow DAG.
[2025-01-13T17:03:11.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:03:11.120+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.119+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:03:11.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:11.141+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:03:11.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-13T17:03:41.350+0000] {processor.py:157} INFO - Started process (PID=13065) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:03:41.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:03:41.353+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:03:41.378+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.378+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:03:41.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.516+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12400475299727987
[2025-01-13T17:03:41.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.517+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13065]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:03:41.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.517+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:03:41.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.518+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:03:41.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.518+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:03:41.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.519+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13065]: It took 0.14s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:03:41.522+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.522+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13065]: It took 0.00331s to build the Airflow DAG.
[2025-01-13T17:03:41.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:03:41.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.536+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:03:41.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:03:41.559+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:03:41.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-13T17:04:11.730+0000] {processor.py:157} INFO - Started process (PID=13151) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:04:11.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:04:11.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:11.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:04:11.770+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:11.770+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:04:12.030+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.030+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24502702900281292
[2025-01-13T17:04:12.031+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.030+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13151]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:04:12.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.031+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:04:12.032+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.032+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:04:12.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.033+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:04:12.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.033+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13151]: It took 0.264s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:04:12.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.037+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13151]: It took 0.00441s to build the Airflow DAG.
[2025-01-13T17:04:12.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:04:12.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.053+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:04:12.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:12.077+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:04:12.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.373 seconds
[2025-01-13T17:04:42.337+0000] {processor.py:157} INFO - Started process (PID=13237) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:04:42.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:04:42.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:04:42.367+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.367+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:04:42.528+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.527+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14409970800261362
[2025-01-13T17:04:42.528+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.528+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13237]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:04:42.529+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.529+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:04:42.529+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.529+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:04:42.529+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.529+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:04:42.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.530+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13237]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:04:42.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.533+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13237]: It took 0.00388s to build the Airflow DAG.
[2025-01-13T17:04:42.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:04:42.549+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.549+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:04:42.574+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:04:42.574+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:04:42.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-13T17:05:13.168+0000] {processor.py:157} INFO - Started process (PID=13342) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:05:13.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:05:13.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:05:13.212+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.211+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:05:13.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.466+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2297385790006956
[2025-01-13T17:05:13.467+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.466+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13342]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:05:13.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.468+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:05:13.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.468+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:05:13.470+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.469+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:05:13.471+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.470+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13342]: It took 0.259s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:05:13.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.477+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13342]: It took 0.00717s to build the Airflow DAG.
[2025-01-13T17:05:13.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:05:13.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.498+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:05:13.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:13.534+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:05:13.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.397 seconds
[2025-01-13T17:05:43.872+0000] {processor.py:157} INFO - Started process (PID=13428) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:05:43.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:05:43.876+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:43.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:05:43.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:43.901+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:05:44.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.065+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1499405869981274
[2025-01-13T17:05:44.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.066+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13428]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:05:44.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.067+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:05:44.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.067+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:05:44.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.067+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:05:44.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.068+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13428]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:05:44.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.071+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13428]: It took 0.00359s to build the Airflow DAG.
[2025-01-13T17:05:44.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:05:44.086+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.086+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:05:44.111+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:05:44.111+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:05:44.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-13T17:06:14.717+0000] {processor.py:157} INFO - Started process (PID=13514) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:06:14.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:06:14.720+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:06:14.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.746+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:06:14.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.890+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1311483719982789
[2025-01-13T17:06:14.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.891+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13514]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:06:14.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.892+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:06:14.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.893+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:06:14.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.893+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:06:14.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.894+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13514]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:06:14.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.898+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13514]: It took 0.0042s to build the Airflow DAG.
[2025-01-13T17:06:14.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:06:14.914+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.914+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:06:14.938+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:14.938+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:06:14.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-13T17:06:45.394+0000] {processor.py:157} INFO - Started process (PID=13600) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:06:45.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:06:45.399+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:06:45.440+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.440+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:06:45.599+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.599+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14567317700129934
[2025-01-13T17:06:45.600+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.600+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13600]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:06:45.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.601+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:06:45.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.601+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:06:45.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.601+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:06:45.602+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.602+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13600]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:06:45.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.606+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13600]: It took 0.00392s to build the Airflow DAG.
[2025-01-13T17:06:45.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:06:45.622+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.621+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:06:45.650+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:06:45.650+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:06:45.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-13T17:07:16.199+0000] {processor.py:157} INFO - Started process (PID=13694) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:07:16.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:07:16.203+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:07:16.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.230+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:07:16.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.429+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18231120600103168
[2025-01-13T17:07:16.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.429+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13694]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:07:16.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.430+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:07:16.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.431+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:07:16.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.431+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:07:16.432+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.431+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13694]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:07:16.437+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.437+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13694]: It took 0.00518s to build the Airflow DAG.
[2025-01-13T17:07:16.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:07:16.455+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.455+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:07:16.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:16.483+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:07:16.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-13T17:07:46.681+0000] {processor.py:157} INFO - Started process (PID=13791) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:07:46.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:07:46.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:07:46.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.716+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:07:46.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.891+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15900194699861459
[2025-01-13T17:07:46.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.891+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13791]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:07:46.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.892+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:07:46.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.893+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:07:46.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.893+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:07:46.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.894+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13791]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:07:46.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.898+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13791]: It took 0.00475s to build the Airflow DAG.
[2025-01-13T17:07:46.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:07:46.916+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.915+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:07:46.946+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:07:46.945+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:07:46.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-13T17:08:17.599+0000] {processor.py:157} INFO - Started process (PID=13877) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:08:17.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:08:17.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:08:17.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.630+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:08:17.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.801+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15372629699777463
[2025-01-13T17:08:17.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.802+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13877]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:08:17.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.802+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:08:17.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.803+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:08:17.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.803+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:08:17.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.803+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13877]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:08:17.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.807+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13877]: It took 0.00402s to build the Airflow DAG.
[2025-01-13T17:08:17.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:08:17.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.822+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:08:17.845+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:17.845+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:08:17.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T17:08:48.005+0000] {processor.py:157} INFO - Started process (PID=13963) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:08:48.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:08:48.009+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:08:48.033+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.033+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:08:48.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.207+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15953331399941817
[2025-01-13T17:08:48.208+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.208+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|13963]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:08:48.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.209+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:08:48.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.210+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:08:48.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.210+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:08:48.211+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.211+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|13963]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:08:48.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.218+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|13963]: It took 0.00706s to build the Airflow DAG.
[2025-01-13T17:08:48.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:08:48.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.241+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:08:48.267+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:08:48.267+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:08:48.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-13T17:09:19.175+0000] {processor.py:157} INFO - Started process (PID=14057) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:09:19.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:09:19.179+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:09:19.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.203+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:09:19.392+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.392+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17397524300031364
[2025-01-13T17:09:19.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.393+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14057]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:09:19.394+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.394+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:09:19.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.394+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:09:19.395+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.395+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:09:19.396+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.396+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14057]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:09:19.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.401+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14057]: It took 0.0053s to build the Airflow DAG.
[2025-01-13T17:09:19.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:09:19.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.417+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:09:19.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:19.443+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:09:19.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.291 seconds
[2025-01-13T17:09:49.511+0000] {processor.py:157} INFO - Started process (PID=14156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:09:49.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:09:49.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:09:49.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.545+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:09:49.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.735+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1746884210006101
[2025-01-13T17:09:49.736+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.736+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14156]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:09:49.736+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.736+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:09:49.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.737+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:09:49.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.737+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:09:49.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.737+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14156]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:09:49.741+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.741+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14156]: It took 0.00358s to build the Airflow DAG.
[2025-01-13T17:09:49.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:09:49.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.760+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:09:49.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:09:49.794+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:09:49.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.311 seconds
[2025-01-13T17:10:19.877+0000] {processor.py:157} INFO - Started process (PID=14241) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:10:19.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:10:19.880+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:19.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:10:19.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:19.902+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:10:20.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.066+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1506654350014287
[2025-01-13T17:10:20.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.066+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14241]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:10:20.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.067+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:10:20.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.067+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:10:20.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.068+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:10:20.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.068+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14241]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:10:20.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.073+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14241]: It took 0.00448s to build the Airflow DAG.
[2025-01-13T17:10:20.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:10:20.086+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.086+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:10:20.110+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:20.110+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:10:20.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-13T17:10:50.444+0000] {processor.py:157} INFO - Started process (PID=14327) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:10:50.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:10:50.448+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:10:50.478+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.478+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:10:50.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.724+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22632967000026838
[2025-01-13T17:10:50.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.724+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14327]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:10:50.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.726+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:10:50.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.726+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:10:50.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.727+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:10:50.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.727+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14327]: It took 0.25s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:10:50.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.735+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14327]: It took 0.00717s to build the Airflow DAG.
[2025-01-13T17:10:50.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:10:50.762+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.762+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:10:50.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:10:50.796+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:10:50.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.385 seconds
[2025-01-13T17:11:21.213+0000] {processor.py:157} INFO - Started process (PID=14413) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:11:21.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:11:21.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:11:21.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.243+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:11:21.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.482+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2208393770015391
[2025-01-13T17:11:21.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.482+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14413]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:11:21.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.483+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:11:21.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.484+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:11:21.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.484+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:11:21.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.485+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14413]: It took 0.242s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:11:21.494+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.494+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14413]: It took 0.00899s to build the Airflow DAG.
[2025-01-13T17:11:21.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:11:21.524+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.524+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:11:21.569+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:21.568+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:11:21.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.391 seconds
[2025-01-13T17:11:51.669+0000] {processor.py:157} INFO - Started process (PID=14500) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:11:51.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:11:51.673+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:11:51.702+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.702+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:11:51.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.928+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20880768899951363
[2025-01-13T17:11:51.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.928+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14500]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:11:51.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.929+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:11:51.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.930+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:11:51.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.930+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:11:51.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.931+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14500]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:11:51.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.936+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14500]: It took 0.00516s to build the Airflow DAG.
[2025-01-13T17:11:51.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:11:51.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:51.959+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:11:52.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:11:52.001+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:11:52.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-13T17:12:22.981+0000] {processor.py:157} INFO - Started process (PID=14595) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:12:22.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:12:22.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:22.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:12:23.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.012+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:12:23.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.244+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21225170899924706
[2025-01-13T17:12:23.245+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.245+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14595]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:12:23.246+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.246+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:12:23.247+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.247+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:12:23.248+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.248+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:12:23.249+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.249+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14595]: It took 0.237s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:12:23.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.258+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14595]: It took 0.009s to build the Airflow DAG.
[2025-01-13T17:12:23.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:12:23.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.285+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:12:23.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:23.323+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:12:23.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.373 seconds
[2025-01-13T17:12:53.477+0000] {processor.py:157} INFO - Started process (PID=14694) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:12:53.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:12:53.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:12:53.519+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.519+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:12:53.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.898+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3508181159995729
[2025-01-13T17:12:53.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.899+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14694]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:12:53.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.901+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:12:53.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.902+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:12:53.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.902+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:12:53.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.903+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14694]: It took 0.385s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:12:53.912+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.912+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14694]: It took 0.00834s to build the Airflow DAG.
[2025-01-13T17:12:53.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:12:53.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.949+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:12:53.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:12:53.999+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:12:54.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.563 seconds
[2025-01-13T17:13:24.167+0000] {processor.py:157} INFO - Started process (PID=14780) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:13:24.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:13:24.172+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:13:24.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.204+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:13:24.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.428+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20224233599947183
[2025-01-13T17:13:24.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.429+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14780]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:13:24.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.430+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:13:24.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.431+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:13:24.432+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.432+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:13:24.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.433+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14780]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:13:24.440+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.439+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14780]: It took 0.00664s to build the Airflow DAG.
[2025-01-13T17:13:24.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:13:24.463+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.462+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:13:24.506+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:24.505+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:13:24.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.376 seconds
[2025-01-13T17:13:54.591+0000] {processor.py:157} INFO - Started process (PID=14866) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:13:54.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:13:54.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:13:54.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.627+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:13:54.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.840+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1952773150005669
[2025-01-13T17:13:54.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.841+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14866]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:13:54.842+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.842+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:13:54.842+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.842+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:13:54.843+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.843+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:13:54.843+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.843+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14866]: It took 0.217s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:13:54.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.849+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14866]: It took 0.00532s to build the Airflow DAG.
[2025-01-13T17:13:54.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:13:54.869+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.869+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:13:54.913+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:13:54.912+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:13:54.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.370 seconds
[2025-01-13T17:14:25.262+0000] {processor.py:157} INFO - Started process (PID=14950) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:14:25.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:14:25.266+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:14:25.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.291+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:14:25.512+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.512+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20512205200066091
[2025-01-13T17:14:25.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.513+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|14950]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:14:25.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.514+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:14:25.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.514+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:14:25.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.515+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:14:25.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.515+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|14950]: It took 0.224s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:14:25.521+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.521+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|14950]: It took 0.00542s to build the Airflow DAG.
[2025-01-13T17:14:25.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:14:25.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.541+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:14:25.572+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:25.572+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:14:25.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.343 seconds
[2025-01-13T17:14:55.818+0000] {processor.py:157} INFO - Started process (PID=15036) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:14:55.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:14:55.822+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:55.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:14:55.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:55.855+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:14:56.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.096+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21895537300224532
[2025-01-13T17:14:56.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.096+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15036]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:14:56.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.098+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:14:56.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.098+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:14:56.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.099+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:14:56.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.099+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15036]: It took 0.244s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:14:56.105+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.105+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15036]: It took 0.00529s to build the Airflow DAG.
[2025-01-13T17:14:56.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:14:56.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.125+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:14:56.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:14:56.169+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:14:56.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.384 seconds
[2025-01-13T17:15:26.320+0000] {processor.py:157} INFO - Started process (PID=15124) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:15:26.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:15:26.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:15:26.350+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.350+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:15:26.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.602+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23632605300008436
[2025-01-13T17:15:26.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.603+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15124]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:15:26.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.604+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:15:26.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.605+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:15:26.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.606+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:15:26.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.606+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15124]: It took 0.256s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:15:26.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.614+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15124]: It took 0.00792s to build the Airflow DAG.
[2025-01-13T17:15:26.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:15:26.637+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.637+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:15:26.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:26.669+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:15:26.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.385 seconds
[2025-01-13T17:15:56.758+0000] {processor.py:157} INFO - Started process (PID=15212) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:15:56.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:15:56.762+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:56.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:15:56.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:56.796+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:15:57.009+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.009+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19569023599979118
[2025-01-13T17:15:57.010+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.009+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15212]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:15:57.010+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.010+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:15:57.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.011+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:15:57.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.011+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:15:57.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.012+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15212]: It took 0.215s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:15:57.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.016+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15212]: It took 0.00442s to build the Airflow DAG.
[2025-01-13T17:15:57.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:15:57.034+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.034+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:15:57.062+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:15:57.061+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:15:57.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.329 seconds
[2025-01-13T17:16:27.182+0000] {processor.py:157} INFO - Started process (PID=15298) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:16:27.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:16:27.187+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:16:27.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.218+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:16:27.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.439+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20284106899998733
[2025-01-13T17:16:27.440+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.439+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15298]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:16:27.441+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.440+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:16:27.441+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.441+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:16:27.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.442+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:16:27.443+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.442+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15298]: It took 0.225s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:16:27.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.449+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15298]: It took 0.00649s to build the Airflow DAG.
[2025-01-13T17:16:27.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:16:27.473+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.473+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:16:27.513+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:27.512+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:16:27.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.373 seconds
[2025-01-13T17:16:57.754+0000] {processor.py:157} INFO - Started process (PID=15384) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:16:57.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:16:57.760+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:57.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:16:57.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:57.791+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:16:58.025+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.025+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21581888599757804
[2025-01-13T17:16:58.026+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.026+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15384]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:16:58.027+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.027+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:16:58.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.027+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:16:58.028+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.028+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:16:58.029+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.029+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15384]: It took 0.237s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:16:58.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.035+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15384]: It took 0.00664s to build the Airflow DAG.
[2025-01-13T17:16:58.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:16:58.061+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.061+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:16:58.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:16:58.097+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:16:58.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.376 seconds
[2025-01-13T17:17:28.739+0000] {processor.py:157} INFO - Started process (PID=15472) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:17:28.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:17:28.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:28.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:17:28.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:28.776+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:17:29.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.018+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21992518800107064
[2025-01-13T17:17:29.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.018+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15472]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:17:29.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.020+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:17:29.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.020+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:17:29.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.021+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:17:29.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.022+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15472]: It took 0.245s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:17:29.030+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.030+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15472]: It took 0.00838s to build the Airflow DAG.
[2025-01-13T17:17:29.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:17:29.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:17:29.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:29.113+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:17:29.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.414 seconds
[2025-01-13T17:17:59.206+0000] {processor.py:157} INFO - Started process (PID=15559) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:17:59.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:17:59.212+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:17:59.250+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.249+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:17:59.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.457+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18675806600003853
[2025-01-13T17:17:59.458+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.457+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15559]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:17:59.459+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.458+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:17:59.459+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.459+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:17:59.459+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.459+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:17:59.460+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.460+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15559]: It took 0.211s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:17:59.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.465+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15559]: It took 0.00522s to build the Airflow DAG.
[2025-01-13T17:17:59.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:17:59.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.485+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:17:59.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:17:59.516+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:17:59.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.339 seconds
[2025-01-13T17:18:29.600+0000] {processor.py:157} INFO - Started process (PID=15653) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:18:29.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:18:29.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:18:29.632+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.632+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:18:29.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.832+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18215838100149995
[2025-01-13T17:18:29.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.833+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15653]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:18:29.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.834+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:18:29.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.834+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:18:29.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.834+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:18:29.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.835+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15653]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:18:29.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.840+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15653]: It took 0.005s to build the Airflow DAG.
[2025-01-13T17:18:29.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:18:29.860+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.860+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:18:29.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:29.894+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:18:29.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-13T17:18:59.990+0000] {processor.py:157} INFO - Started process (PID=15740) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:18:59.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:18:59.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:18:59.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:19:00.023+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.023+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:19:00.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.271+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23018340799899306
[2025-01-13T17:19:00.272+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.271+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15740]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:19:00.272+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.272+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:19:00.273+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.273+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:19:00.273+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.273+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:19:00.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.274+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15740]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:19:00.279+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.278+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15740]: It took 0.00478s to build the Airflow DAG.
[2025-01-13T17:19:00.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:19:00.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.297+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:19:00.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:00.325+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:19:00.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.362 seconds
[2025-01-13T17:19:31.126+0000] {processor.py:157} INFO - Started process (PID=15837) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:19:31.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:19:31.129+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:19:31.151+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.150+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:19:31.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.305+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1406457569974009
[2025-01-13T17:19:31.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.305+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15837]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:19:31.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.306+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:19:31.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.306+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:19:31.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.307+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:19:31.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.307+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15837]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:19:31.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.311+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15837]: It took 0.00415s to build the Airflow DAG.
[2025-01-13T17:19:31.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:19:31.328+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.328+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:19:31.351+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:19:31.351+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:19:31.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-13T17:20:01.863+0000] {processor.py:157} INFO - Started process (PID=15924) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:20:01.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:20:01.866+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:01.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:20:01.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:01.891+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:20:02.111+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.111+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2040931379997346
[2025-01-13T17:20:02.111+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.111+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|15924]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:20:02.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.112+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:20:02.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.113+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:20:02.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.113+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:20:02.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.114+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|15924]: It took 0.223s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:20:02.118+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.118+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|15924]: It took 0.00463s to build the Airflow DAG.
[2025-01-13T17:20:02.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:20:02.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.141+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:20:02.171+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:02.171+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:20:02.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.334 seconds
[2025-01-13T17:20:32.434+0000] {processor.py:157} INFO - Started process (PID=16010) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:20:32.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:20:32.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:20:32.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.469+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:20:32.706+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.706+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21895523999774014
[2025-01-13T17:20:32.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.707+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16010]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:20:32.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.709+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:20:32.710+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.710+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:20:32.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.710+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:20:32.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.711+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16010]: It took 0.243s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:20:32.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.718+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16010]: It took 0.00715s to build the Airflow DAG.
[2025-01-13T17:20:32.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:20:32.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.746+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:20:32.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:20:32.792+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:20:32.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.398 seconds
[2025-01-13T17:21:03.727+0000] {processor.py:157} INFO - Started process (PID=16097) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:21:03.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:21:03.730+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:21:03.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.752+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:21:03.987+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.987+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21982974500133423
[2025-01-13T17:21:03.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.988+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16097]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:21:03.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.990+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:21:03.991+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.991+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:21:03.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.991+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:21:03.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:03.992+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16097]: It took 0.24s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:21:04.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:04.000+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16097]: It took 0.00816s to build the Airflow DAG.
[2025-01-13T17:21:04.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:21:04.024+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:04.023+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:21:04.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:04.066+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:21:04.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.370 seconds
[2025-01-13T17:21:34.182+0000] {processor.py:157} INFO - Started process (PID=16184) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:21:34.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:21:34.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:21:34.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.213+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:21:34.369+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.369+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1423218679992715
[2025-01-13T17:21:34.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.369+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16184]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:21:34.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.370+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:21:34.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.370+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:21:34.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.371+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:21:34.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.371+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16184]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:21:34.375+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.374+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16184]: It took 0.00347s to build the Airflow DAG.
[2025-01-13T17:21:34.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:21:34.388+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.388+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:21:34.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:21:34.412+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:21:34.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-13T17:22:05.300+0000] {processor.py:157} INFO - Started process (PID=16270) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:22:05.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:22:05.304+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:22:05.328+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.328+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:22:05.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.486+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1439801519991306
[2025-01-13T17:22:05.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.486+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16270]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:22:05.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.487+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:22:05.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.487+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:22:05.488+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.488+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:22:05.488+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.488+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16270]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:22:05.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.492+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16270]: It took 0.00364s to build the Airflow DAG.
[2025-01-13T17:22:05.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:22:05.506+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.506+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:22:05.540+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:05.540+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:22:05.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-13T17:22:35.626+0000] {processor.py:157} INFO - Started process (PID=16364) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:22:35.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:22:35.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:22:35.658+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.658+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:22:35.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.831+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1571888049984409
[2025-01-13T17:22:35.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.832+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16364]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:22:35.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.833+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:22:35.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.833+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:22:35.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.834+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:22:35.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.834+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16364]: It took 0.176s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:22:35.839+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.839+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16364]: It took 0.00489s to build the Airflow DAG.
[2025-01-13T17:22:35.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:22:35.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.856+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:22:35.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:22:35.882+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:22:35.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-13T17:23:05.978+0000] {processor.py:157} INFO - Started process (PID=16461) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:23:05.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:23:05.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:05.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:23:06.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.005+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:23:06.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.160+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13993310899968492
[2025-01-13T17:23:06.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.161+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16461]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:23:06.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.162+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:23:06.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.162+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:23:06.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.162+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:23:06.163+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.163+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16461]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:23:06.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.166+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16461]: It took 0.00366s to build the Airflow DAG.
[2025-01-13T17:23:06.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:23:06.186+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.186+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:23:06.208+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:06.208+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:23:06.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-13T17:23:36.746+0000] {processor.py:157} INFO - Started process (PID=16547) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:23:36.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:23:36.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:23:36.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.771+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:23:36.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.949+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16469698000219068
[2025-01-13T17:23:36.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.950+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16547]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:23:36.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.951+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:23:36.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.951+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:23:36.951+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.951+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:23:36.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.952+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16547]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:23:36.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.956+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16547]: It took 0.00409s to build the Airflow DAG.
[2025-01-13T17:23:36.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:23:36.971+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.971+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:23:36.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:23:36.994+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:23:37.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-13T17:24:07.335+0000] {processor.py:157} INFO - Started process (PID=16633) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:24:07.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:24:07.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:24:07.365+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.365+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:24:07.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.544+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16544236600020668
[2025-01-13T17:24:07.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.545+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16633]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:24:07.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.546+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:24:07.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.546+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:24:07.547+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.546+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:24:07.547+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.547+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16633]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:24:07.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.553+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16633]: It took 0.00574s to build the Airflow DAG.
[2025-01-13T17:24:07.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:24:07.571+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.571+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:24:07.597+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:07.597+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:24:07.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-13T17:24:37.991+0000] {processor.py:157} INFO - Started process (PID=16719) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:24:37.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:24:37.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:37.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:24:38.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.014+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:24:38.182+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.182+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15209945800233982
[2025-01-13T17:24:38.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.183+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16719]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:24:38.184+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.184+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:24:38.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.185+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:24:38.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.185+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:24:38.186+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.186+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16719]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:24:38.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.190+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16719]: It took 0.00471s to build the Airflow DAG.
[2025-01-13T17:24:38.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:24:38.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.208+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:24:38.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:24:38.238+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:24:38.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-13T17:25:08.553+0000] {processor.py:157} INFO - Started process (PID=16813) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:25:08.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:25:08.557+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:25:08.586+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.586+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:25:08.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.798+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1958567050023703
[2025-01-13T17:25:08.799+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.799+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16813]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:25:08.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.800+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:25:08.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.801+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:25:08.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.801+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:25:08.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.802+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16813]: It took 0.216s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:25:08.809+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.808+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16813]: It took 0.00677s to build the Airflow DAG.
[2025-01-13T17:25:08.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:25:08.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.832+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:25:08.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:08.870+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:25:08.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.345 seconds
[2025-01-13T17:25:38.979+0000] {processor.py:157} INFO - Started process (PID=16913) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:25:38.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:25:38.983+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:38.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:25:39.009+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.009+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:25:39.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.232+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20676853099939763
[2025-01-13T17:25:39.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.232+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16913]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:25:39.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.234+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:25:39.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.234+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:25:39.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.235+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:25:39.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.235+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16913]: It took 0.226s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:25:39.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.241+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16913]: It took 0.00534s to build the Airflow DAG.
[2025-01-13T17:25:39.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:25:39.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.260+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:25:39.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:25:39.290+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:25:39.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.344 seconds
[2025-01-13T17:26:10.114+0000] {processor.py:157} INFO - Started process (PID=16999) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:26:10.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:26:10.118+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:26:10.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.143+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:26:10.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.333+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17700794400298037
[2025-01-13T17:26:10.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.333+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16999]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:26:10.334+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.334+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:26:10.335+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.334+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:26:10.335+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.335+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:26:10.335+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.335+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16999]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:26:10.339+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.339+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16999]: It took 0.00386s to build the Airflow DAG.
[2025-01-13T17:26:10.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:26:10.353+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.353+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:26:10.373+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:10.373+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:26:10.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-13T17:26:40.719+0000] {processor.py:157} INFO - Started process (PID=17085) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:26:40.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:26:40.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:26:40.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.747+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:26:40.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.942+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18173029299941845
[2025-01-13T17:26:40.943+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.943+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17085]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:26:40.944+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.944+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:26:40.945+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.944+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:26:40.945+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.945+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:26:40.945+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.945+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17085]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:26:40.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.950+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17085]: It took 0.00481s to build the Airflow DAG.
[2025-01-13T17:26:40.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:26:40.968+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.967+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:26:40.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:26:40.994+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:26:41.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-13T17:27:11.265+0000] {processor.py:157} INFO - Started process (PID=17171) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:27:11.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:27:11.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:27:11.298+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.298+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:27:11.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.544+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22602976000052877
[2025-01-13T17:27:11.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.545+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17171]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:27:11.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.546+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:27:11.547+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.547+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:27:11.548+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.548+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:27:11.549+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.548+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17171]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:27:11.559+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.558+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17171]: It took 0.00999s to build the Airflow DAG.
[2025-01-13T17:27:11.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:27:11.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.588+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:27:11.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:11.630+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:27:11.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.397 seconds
[2025-01-13T17:27:41.982+0000] {processor.py:157} INFO - Started process (PID=17265) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:27:41.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:27:41.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:41.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:27:42.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.021+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:27:42.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.260+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21934379800222814
[2025-01-13T17:27:42.261+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.260+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17265]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:27:42.262+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.262+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:27:42.262+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.262+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:27:42.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.263+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:27:42.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.263+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17265]: It took 0.243s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:27:42.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.269+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17265]: It took 0.00589s to build the Airflow DAG.
[2025-01-13T17:27:42.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:27:42.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.295+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:27:42.334+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:27:42.333+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:27:42.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.383 seconds
[2025-01-13T17:28:12.453+0000] {processor.py:157} INFO - Started process (PID=17362) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:28:12.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:28:12.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:28:12.481+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.481+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:28:12.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.696+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2005711239980883
[2025-01-13T17:28:12.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.697+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17362]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:28:12.698+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.698+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:28:12.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.699+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:28:12.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.699+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:28:12.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.699+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17362]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:28:12.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.707+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17362]: It took 0.00726s to build the Airflow DAG.
[2025-01-13T17:28:12.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:28:12.730+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.729+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:28:12.767+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:12.767+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:28:12.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.340 seconds
[2025-01-13T17:28:42.836+0000] {processor.py:157} INFO - Started process (PID=17448) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:28:42.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:28:42.840+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:42.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:28:42.872+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:42.872+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:28:43.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.092+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2032930599998508
[2025-01-13T17:28:43.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.093+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17448]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:28:43.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.095+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:28:43.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.096+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:28:43.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.096+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:28:43.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.097+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17448]: It took 0.226s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:28:43.104+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.104+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17448]: It took 0.00661s to build the Airflow DAG.
[2025-01-13T17:28:43.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:28:43.125+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.125+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:28:43.157+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:28:43.157+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:28:43.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.351 seconds
[2025-01-13T17:29:13.281+0000] {processor.py:157} INFO - Started process (PID=17536) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:29:13.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:29:13.285+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:29:13.307+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.307+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:29:13.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.451+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12871811100194464
[2025-01-13T17:29:13.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.451+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17536]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:29:13.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.452+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:29:13.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.452+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:29:13.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.453+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:29:13.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.453+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17536]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:29:13.456+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.456+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17536]: It took 0.00351s to build the Airflow DAG.
[2025-01-13T17:29:13.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:29:13.472+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.472+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:29:13.498+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:13.497+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:29:13.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-13T17:29:44.360+0000] {processor.py:157} INFO - Started process (PID=17622) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:29:44.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:29:44.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:29:44.390+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.390+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:29:44.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.628+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2189740690009785
[2025-01-13T17:29:44.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.628+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17622]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:29:44.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.630+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:29:44.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.630+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:29:44.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.631+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:29:44.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.632+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17622]: It took 0.242s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:29:44.641+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.641+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17622]: It took 0.00914s to build the Airflow DAG.
[2025-01-13T17:29:44.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:29:44.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.666+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:29:44.711+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:29:44.711+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:29:44.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.390 seconds
[2025-01-13T17:30:14.794+0000] {processor.py:157} INFO - Started process (PID=17709) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:30:14.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:30:14.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:14.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:30:14.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:14.829+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:30:15.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.004+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15998384799968335
[2025-01-13T17:30:15.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.005+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17709]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:30:15.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.006+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:30:15.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.006+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:30:15.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.007+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:30:15.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.007+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17709]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:30:15.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.012+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17709]: It took 0.00446s to build the Airflow DAG.
[2025-01-13T17:30:15.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:30:15.029+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.029+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:30:15.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:15.055+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:30:15.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.294 seconds
[2025-01-13T17:30:45.346+0000] {processor.py:157} INFO - Started process (PID=17813) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:30:45.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:30:45.350+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:30:45.377+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.377+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:30:45.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.585+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19335282500105677
[2025-01-13T17:30:45.586+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.586+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17813]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:30:45.587+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.587+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:30:45.587+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.587+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:30:45.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.588+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:30:45.588+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.588+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17813]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:30:45.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.593+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17813]: It took 0.0052s to build the Airflow DAG.
[2025-01-13T17:30:45.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:30:45.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.611+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:30:45.640+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:30:45.640+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:30:45.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.319 seconds
[2025-01-13T17:31:15.827+0000] {processor.py:157} INFO - Started process (PID=17899) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:31:15.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:31:15.830+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:15.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:31:15.855+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:15.855+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:31:16.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.015+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1461654719969374
[2025-01-13T17:31:16.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.016+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17899]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:31:16.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.017+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:31:16.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.017+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:31:16.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.018+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:31:16.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.018+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17899]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:31:16.022+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.022+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17899]: It took 0.00411s to build the Airflow DAG.
[2025-01-13T17:31:16.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:31:16.037+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.037+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:31:16.061+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:16.061+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:31:16.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-13T17:31:46.645+0000] {processor.py:157} INFO - Started process (PID=17985) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:31:46.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:31:46.648+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:31:46.669+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.669+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:31:46.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.819+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13616553600149928
[2025-01-13T17:31:46.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.819+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|17985]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:31:46.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.820+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:31:46.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.820+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:31:46.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.821+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:31:46.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.821+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|17985]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:31:46.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.825+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|17985]: It took 0.00384s to build the Airflow DAG.
[2025-01-13T17:31:46.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:31:46.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.841+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:31:46.865+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:31:46.865+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:31:46.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-13T17:32:17.232+0000] {processor.py:157} INFO - Started process (PID=18071) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:32:17.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:32:17.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:32:17.257+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.257+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:32:17.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.451+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17899010499968426
[2025-01-13T17:32:17.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.451+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18071]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:32:17.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.452+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:32:17.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.452+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:32:17.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.452+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:32:17.453+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.453+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18071]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:32:17.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.457+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18071]: It took 0.0043s to build the Airflow DAG.
[2025-01-13T17:32:17.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:32:17.472+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.472+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:32:17.495+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:17.495+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:32:17.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-13T17:32:48.080+0000] {processor.py:157} INFO - Started process (PID=18157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:32:48.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:32:48.084+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:32:48.110+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.110+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:32:48.340+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.340+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21387217000301462
[2025-01-13T17:32:48.341+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.340+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:32:48.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.342+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:32:48.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.342+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:32:48.343+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.343+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:32:48.343+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.343+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18157]: It took 0.233s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:32:48.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.348+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18157]: It took 0.00521s to build the Airflow DAG.
[2025-01-13T17:32:48.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:32:48.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.370+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:32:48.414+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:32:48.414+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:32:48.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-13T17:33:19.284+0000] {processor.py:157} INFO - Started process (PID=18253) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:33:19.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:33:19.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:33:19.315+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.315+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:33:19.509+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.508+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1774933950000559
[2025-01-13T17:33:19.509+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.509+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18253]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:33:19.510+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.510+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:33:19.511+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.511+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:33:19.511+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.511+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:33:19.512+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.512+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18253]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:33:19.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.516+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18253]: It took 0.00452s to build the Airflow DAG.
[2025-01-13T17:33:19.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:33:19.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.533+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:33:19.560+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:19.560+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:33:19.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.302 seconds
[2025-01-13T17:33:50.486+0000] {processor.py:157} INFO - Started process (PID=18351) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:33:50.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:33:50.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:33:50.510+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.510+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:33:50.665+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.665+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14139928000076907
[2025-01-13T17:33:50.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.666+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18351]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:33:50.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.666+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:33:50.667+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.667+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:33:50.667+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.667+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:33:50.667+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.667+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18351]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:33:50.671+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.671+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18351]: It took 0.00359s to build the Airflow DAG.
[2025-01-13T17:33:50.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:33:50.684+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.684+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:33:50.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:33:50.704+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:33:50.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-13T17:34:20.978+0000] {processor.py:157} INFO - Started process (PID=18437) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:34:20.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:34:20.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:20.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:34:21.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.008+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:34:21.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.218+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19414212799892994
[2025-01-13T17:34:21.218+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.218+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18437]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:34:21.219+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.219+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:34:21.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.220+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:34:21.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.220+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:34:21.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.221+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18437]: It took 0.213s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:34:21.227+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.227+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18437]: It took 0.006s to build the Airflow DAG.
[2025-01-13T17:34:21.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:34:21.246+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.246+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:34:21.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:21.274+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:34:21.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.332 seconds
[2025-01-13T17:34:52.181+0000] {processor.py:157} INFO - Started process (PID=18524) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:34:52.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:34:52.185+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:34:52.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.213+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:34:52.423+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.422+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19486677500026417
[2025-01-13T17:34:52.423+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.423+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18524]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:34:52.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.424+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:34:52.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.425+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:34:52.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.425+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:34:52.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.426+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18524]: It took 0.213s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:34:52.432+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.432+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18524]: It took 0.00622s to build the Airflow DAG.
[2025-01-13T17:34:52.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:34:52.454+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.454+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:34:52.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:34:52.488+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:34:52.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.336 seconds
[2025-01-13T17:35:22.658+0000] {processor.py:157} INFO - Started process (PID=18610) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:35:22.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:35:22.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:35:22.686+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.686+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:35:22.897+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.897+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19534786900112522
[2025-01-13T17:35:22.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.897+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18610]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:35:22.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.899+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:35:22.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.900+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:35:22.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.900+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:35:22.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.901+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18610]: It took 0.215s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:35:22.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.906+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18610]: It took 0.00515s to build the Airflow DAG.
[2025-01-13T17:35:22.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:35:22.925+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.925+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:35:22.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:22.958+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:35:22.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-13T17:35:53.298+0000] {processor.py:157} INFO - Started process (PID=18704) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:35:53.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:35:53.303+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:35:53.329+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.329+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:35:53.552+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.552+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20756284100207267
[2025-01-13T17:35:53.553+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.552+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18704]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:35:53.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.554+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:35:53.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.554+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:35:53.555+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.555+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:35:53.556+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.556+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18704]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:35:53.563+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.563+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18704]: It took 0.00733s to build the Airflow DAG.
[2025-01-13T17:35:53.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:35:53.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.582+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:35:53.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:35:53.611+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:35:53.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.338 seconds
[2025-01-13T17:36:23.751+0000] {processor.py:157} INFO - Started process (PID=18801) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:36:23.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:36:23.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:23.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:36:23.787+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:23.786+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:36:23.997+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:23.997+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19519953400231316
[2025-01-13T17:36:23.998+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:23.998+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18801]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:36:23.999+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:23.999+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:36:24.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:24.000+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:36:24.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:24.000+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:36:24.001+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:24.001+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18801]: It took 0.215s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:36:24.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:24.007+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18801]: It took 0.00583s to build the Airflow DAG.
[2025-01-13T17:36:24.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:36:24.027+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:24.027+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:36:24.055+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:24.055+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:36:24.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-13T17:36:54.266+0000] {processor.py:157} INFO - Started process (PID=18888) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:36:54.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:36:54.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:36:54.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.299+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:36:54.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.514+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19764484900224488
[2025-01-13T17:36:54.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.514+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18888]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:36:54.515+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.515+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:36:54.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.516+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:36:54.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.516+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:36:54.517+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.517+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18888]: It took 0.218s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:36:54.522+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.522+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18888]: It took 0.0053s to build the Airflow DAG.
[2025-01-13T17:36:54.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:36:54.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.542+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:36:54.572+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:36:54.572+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:36:54.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.337 seconds
[2025-01-13T17:37:24.815+0000] {processor.py:157} INFO - Started process (PID=18974) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:37:24.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:37:24.819+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:24.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:37:24.845+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:24.845+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:37:25.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.035+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1754170089989202
[2025-01-13T17:37:25.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.035+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|18974]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:37:25.037+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.037+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:37:25.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.037+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:37:25.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.038+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:37:25.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.038+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|18974]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:37:25.043+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.043+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|18974]: It took 0.00494s to build the Airflow DAG.
[2025-01-13T17:37:25.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:37:25.063+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.062+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:37:25.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:25.092+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:37:25.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-13T17:37:55.270+0000] {processor.py:157} INFO - Started process (PID=19060) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:37:55.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:37:55.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:37:55.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.300+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:37:55.464+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.464+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15059855999788851
[2025-01-13T17:37:55.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.465+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19060]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:37:55.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.465+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:37:55.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.466+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:37:55.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.466+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:37:55.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.466+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19060]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:37:55.470+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.470+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19060]: It took 0.0039s to build the Airflow DAG.
[2025-01-13T17:37:55.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:37:55.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.485+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:37:55.509+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:37:55.508+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:37:55.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-13T17:38:25.808+0000] {processor.py:157} INFO - Started process (PID=19146) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:38:25.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:38:25.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:25.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:38:25.836+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:25.836+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:38:26.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.011+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16046853700026986
[2025-01-13T17:38:26.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.012+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19146]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:38:26.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.012+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:38:26.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.013+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:38:26.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.013+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:38:26.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.014+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19146]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:38:26.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.019+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19146]: It took 0.00582s to build the Airflow DAG.
[2025-01-13T17:38:26.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:38:26.036+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.036+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:38:26.064+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:26.064+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:38:26.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-13T17:38:56.503+0000] {processor.py:157} INFO - Started process (PID=19240) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:38:56.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:38:56.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:38:56.534+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.534+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:38:56.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.719+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16947872799937613
[2025-01-13T17:38:56.720+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.720+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19240]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:38:56.721+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.720+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:38:56.721+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.721+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:38:56.721+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.721+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:38:56.722+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.722+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19240]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:38:56.727+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.727+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19240]: It took 0.00508s to build the Airflow DAG.
[2025-01-13T17:38:56.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:38:56.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.746+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:38:56.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:38:56.775+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:38:56.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-13T17:39:27.031+0000] {processor.py:157} INFO - Started process (PID=19337) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:39:27.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:39:27.035+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:39:27.057+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.057+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:39:27.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.237+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1663622439991741
[2025-01-13T17:39:27.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.237+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19337]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:39:27.238+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.238+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:39:27.239+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.239+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:39:27.239+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.239+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:39:27.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.239+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19337]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:39:27.244+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.244+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19337]: It took 0.00453s to build the Airflow DAG.
[2025-01-13T17:39:27.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:39:27.260+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.260+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:39:27.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:27.286+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:39:27.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-13T17:39:57.433+0000] {processor.py:157} INFO - Started process (PID=19424) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:39:57.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:39:57.437+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:39:57.464+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.464+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:39:57.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.628+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14971041600074386
[2025-01-13T17:39:57.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.628+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19424]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:39:57.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.629+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:39:57.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.629+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:39:57.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.630+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:39:57.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.630+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19424]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:39:57.635+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.635+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19424]: It took 0.00436s to build the Airflow DAG.
[2025-01-13T17:39:57.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:39:57.651+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.650+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:39:57.673+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:39:57.673+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:39:57.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-13T17:40:28.009+0000] {processor.py:157} INFO - Started process (PID=19510) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:40:28.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:40:28.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:40:28.040+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.039+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:40:28.266+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.266+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20904574700034573
[2025-01-13T17:40:28.267+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.267+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19510]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:40:28.268+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.268+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:40:28.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.268+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:40:28.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.269+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:40:28.270+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.270+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19510]: It took 0.231s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:40:28.276+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.276+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19510]: It took 0.00593s to build the Airflow DAG.
[2025-01-13T17:40:28.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:40:28.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.295+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:40:28.326+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:28.326+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:40:28.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.347 seconds
[2025-01-13T17:40:58.546+0000] {processor.py:157} INFO - Started process (PID=19596) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:40:58.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:40:58.551+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:40:58.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.580+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:40:58.832+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.832+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23338313100248342
[2025-01-13T17:40:58.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.832+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19596]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:40:58.834+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.834+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:40:58.835+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.835+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:40:58.836+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.836+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:40:58.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.837+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19596]: It took 0.257s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:40:58.845+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.844+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19596]: It took 0.00771s to build the Airflow DAG.
[2025-01-13T17:40:58.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:40:58.872+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.872+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:40:58.917+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:40:58.917+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:40:58.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.408 seconds
[2025-01-13T17:41:29.035+0000] {processor.py:157} INFO - Started process (PID=19683) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:41:29.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:41:29.040+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:41:29.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.066+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:41:29.270+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.269+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1862710169989441
[2025-01-13T17:41:29.270+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.270+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19683]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:41:29.272+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.272+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:41:29.273+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.272+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:41:29.273+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.273+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:41:29.274+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.274+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19683]: It took 0.208s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:41:29.280+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.280+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19683]: It took 0.00635s to build the Airflow DAG.
[2025-01-13T17:41:29.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:41:29.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.299+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:41:29.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:29.330+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:41:29.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.324 seconds
[2025-01-13T17:41:59.455+0000] {processor.py:157} INFO - Started process (PID=19768) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:41:59.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:41:59.461+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:41:59.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.490+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:41:59.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.716+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20907421700030682
[2025-01-13T17:41:59.717+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.717+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19768]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:41:59.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.718+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:41:59.718+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.718+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:41:59.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.719+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:41:59.719+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.719+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19768]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:41:59.726+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.726+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19768]: It took 0.00627s to build the Airflow DAG.
[2025-01-13T17:41:59.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:41:59.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.751+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:41:59.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:41:59.796+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:41:59.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.378 seconds
[2025-01-13T17:42:29.882+0000] {processor.py:157} INFO - Started process (PID=19861) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:42:29.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:42:29.887+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:29.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:42:29.917+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:29.917+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:42:30.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.141+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20652950699877692
[2025-01-13T17:42:30.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.141+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19861]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:42:30.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.142+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:42:30.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.143+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:42:30.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.143+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:42:30.144+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.144+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19861]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:42:30.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.150+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19861]: It took 0.00622s to build the Airflow DAG.
[2025-01-13T17:42:30.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:42:30.172+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.172+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:42:30.205+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:42:30.205+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:42:30.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.353 seconds
[2025-01-13T17:43:00.624+0000] {processor.py:157} INFO - Started process (PID=19959) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:43:00.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:43:00.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:43:00.660+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.660+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:43:00.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.891+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21234908800033736
[2025-01-13T17:43:00.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.892+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|19959]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:43:00.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.893+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:43:00.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.893+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:43:00.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.894+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:43:00.895+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.895+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|19959]: It took 0.235s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:43:00.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.901+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|19959]: It took 0.00597s to build the Airflow DAG.
[2025-01-13T17:43:00.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:43:00.922+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.922+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:43:00.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:00.962+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:43:00.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.371 seconds
[2025-01-13T17:43:31.127+0000] {processor.py:157} INFO - Started process (PID=20045) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:43:31.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:43:31.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:43:31.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.158+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:43:31.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.411+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23407112999848323
[2025-01-13T17:43:31.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.412+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20045]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:43:31.413+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.413+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:43:31.414+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.414+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:43:31.414+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.414+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:43:31.415+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.415+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20045]: It took 0.257s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:43:31.421+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.421+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20045]: It took 0.00629s to build the Airflow DAG.
[2025-01-13T17:43:31.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:43:31.444+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.444+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:43:31.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:43:31.484+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:43:31.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.396 seconds
[2025-01-13T17:44:01.715+0000] {processor.py:157} INFO - Started process (PID=20131) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:44:01.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:44:01.720+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:44:01.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.745+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:44:01.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.976+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21546660599778988
[2025-01-13T17:44:01.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.977+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20131]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:44:01.978+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.978+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:44:01.979+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.979+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:44:01.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.980+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:44:01.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.980+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20131]: It took 0.236s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:44:01.987+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:01.987+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20131]: It took 0.00656s to build the Airflow DAG.
[2025-01-13T17:44:01.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:44:02.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:02.006+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:44:02.037+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:02.037+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:44:02.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.350 seconds
[2025-01-13T17:44:32.188+0000] {processor.py:157} INFO - Started process (PID=20219) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:44:32.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:44:32.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:44:32.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.215+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:44:32.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.358+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12956266699984553
[2025-01-13T17:44:32.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.358+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20219]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:44:32.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.359+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:44:32.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.359+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:44:32.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.360+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:44:32.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.360+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20219]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:44:32.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.364+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20219]: It took 0.00371s to build the Airflow DAG.
[2025-01-13T17:44:32.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:44:32.378+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.378+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:44:32.400+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:44:32.400+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:44:32.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-13T17:45:03.631+0000] {processor.py:157} INFO - Started process (PID=20305) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:45:03.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:45:03.635+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:03.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:45:03.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:03.659+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:45:05.872+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.872+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 2.198698339998373
[2025-01-13T17:45:05.873+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.873+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20305]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:45:05.874+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.874+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:45:05.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.874+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:45:05.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.875+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:45:05.876+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.876+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20305]: It took 2.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:45:05.882+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.882+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20305]: It took 0.00584s to build the Airflow DAG.
[2025-01-13T17:45:05.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:45:05.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.898+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:45:05.924+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:05.924+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:45:05.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 2.317 seconds
[2025-01-13T17:45:36.863+0000] {processor.py:157} INFO - Started process (PID=20414) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:45:36.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:45:36.867+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:36.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:45:36.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:36.894+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:45:37.109+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.109+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19836257499991916
[2025-01-13T17:45:37.110+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.110+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20414]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:45:37.111+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.111+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:45:37.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.111+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:45:37.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.112+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:45:37.113+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.112+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20414]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:45:37.118+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.118+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20414]: It took 0.0052s to build the Airflow DAG.
[2025-01-13T17:45:37.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:45:37.136+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.136+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:45:37.164+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:45:37.163+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:45:37.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.333 seconds
[2025-01-13T17:46:08.058+0000] {processor.py:157} INFO - Started process (PID=20500) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:46:08.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:46:08.061+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:46:08.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.081+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:46:08.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.230+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13545866400090745
[2025-01-13T17:46:08.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.230+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20500]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:46:08.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.231+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:46:08.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.231+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:46:08.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.232+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:46:08.232+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.232+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20500]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:46:08.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.236+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20500]: It took 0.00433s to build the Airflow DAG.
[2025-01-13T17:46:08.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:46:08.250+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.250+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:46:08.272+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:08.272+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:46:08.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-13T17:46:38.531+0000] {processor.py:157} INFO - Started process (PID=20586) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:46:38.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:46:38.535+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:46:38.562+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.562+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:46:38.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.737+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16037942199909594
[2025-01-13T17:46:38.737+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.737+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20586]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:46:38.738+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.738+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:46:38.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.738+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:46:38.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.739+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:46:38.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.739+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20586]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:46:38.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.744+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20586]: It took 0.00443s to build the Airflow DAG.
[2025-01-13T17:46:38.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:46:38.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.759+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:46:38.784+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:46:38.784+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:46:38.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-13T17:47:09.079+0000] {processor.py:157} INFO - Started process (PID=20672) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:47:09.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:47:09.082+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:47:09.107+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.107+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:47:09.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.295+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1731571329983126
[2025-01-13T17:47:09.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.295+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20672]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:47:09.296+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.296+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:47:09.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.296+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:47:09.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.297+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:47:09.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.297+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20672]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:47:09.301+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.301+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20672]: It took 0.00409s to build the Airflow DAG.
[2025-01-13T17:47:09.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:47:09.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.324+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:47:09.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:09.348+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:47:09.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.294 seconds
[2025-01-13T17:47:39.703+0000] {processor.py:157} INFO - Started process (PID=20772) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:47:39.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:47:39.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:47:39.788+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.788+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:47:39.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.992+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18773879199943622
[2025-01-13T17:47:39.993+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.993+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20772]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:47:39.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.994+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:47:39.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.995+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:47:39.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.995+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:47:39.996+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:39.996+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20772]: It took 0.208s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:47:40.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:40.005+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20772]: It took 0.00839s to build the Airflow DAG.
[2025-01-13T17:47:40.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:47:40.027+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:40.026+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:47:40.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:47:40.068+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:47:40.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.401 seconds
[2025-01-13T17:48:10.286+0000] {processor.py:157} INFO - Started process (PID=20863) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:48:10.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:48:10.289+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:48:10.313+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.312+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:48:10.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.465+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13736291799796163
[2025-01-13T17:48:10.465+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.465+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20863]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:48:10.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.466+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:48:10.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.466+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:48:10.467+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.467+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:48:10.467+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.467+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20863]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:48:10.471+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.471+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20863]: It took 0.00351s to build the Airflow DAG.
[2025-01-13T17:48:10.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:48:10.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.484+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:48:10.505+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:10.505+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:48:10.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-13T17:48:40.750+0000] {processor.py:157} INFO - Started process (PID=20950) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:48:40.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:48:40.755+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:48:40.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.783+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:48:40.992+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.992+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18883953000113252
[2025-01-13T17:48:40.993+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.992+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|20950]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:48:40.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.993+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:48:40.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.994+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:48:40.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.994+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:48:40.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:40.995+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|20950]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:48:41.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:41.000+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|20950]: It took 0.00535s to build the Airflow DAG.
[2025-01-13T17:48:41.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:48:41.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:41.020+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:48:41.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:48:41.051+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:48:41.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.331 seconds
[2025-01-13T17:49:11.917+0000] {processor.py:157} INFO - Started process (PID=21036) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:49:11.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:49:11.921+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:11.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:49:11.948+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:11.948+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:49:12.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.152+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.186324260001129
[2025-01-13T17:49:12.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.153+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21036]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:49:12.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.154+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:49:12.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.155+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:49:12.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.155+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:49:12.156+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.156+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21036]: It took 0.208s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:49:12.161+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.161+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21036]: It took 0.00546s to build the Airflow DAG.
[2025-01-13T17:49:12.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:49:12.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.180+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:49:12.215+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:12.215+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:49:12.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-13T17:49:42.374+0000] {processor.py:157} INFO - Started process (PID=21123) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:49:42.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:49:42.379+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:49:42.408+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.408+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:49:42.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.625+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1995690440016915
[2025-01-13T17:49:42.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.626+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21123]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:49:42.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.627+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:49:42.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.627+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:49:42.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.628+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:49:42.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.629+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21123]: It took 0.221s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:49:42.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.634+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21123]: It took 0.00549s to build the Airflow DAG.
[2025-01-13T17:49:42.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:49:42.656+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.656+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:49:42.692+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:49:42.691+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:49:42.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.348 seconds
[2025-01-13T17:50:12.824+0000] {processor.py:157} INFO - Started process (PID=21210) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:50:12.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:50:12.829+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:12.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:50:12.857+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:12.857+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:50:13.050+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.050+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17618637900159229
[2025-01-13T17:50:13.051+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.050+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21210]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:50:13.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.051+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:50:13.052+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.052+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:50:13.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.052+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:50:13.053+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.053+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21210]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:50:13.058+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.058+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21210]: It took 0.00496s to build the Airflow DAG.
[2025-01-13T17:50:13.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:50:13.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.076+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:50:13.106+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:13.106+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:50:13.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.309 seconds
[2025-01-13T17:50:44.077+0000] {processor.py:157} INFO - Started process (PID=21303) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:50:44.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:50:44.082+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:50:44.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.111+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:50:44.347+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.347+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21877672499977052
[2025-01-13T17:50:44.348+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.347+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21303]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:50:44.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.349+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:50:44.349+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.349+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:50:44.350+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.350+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:50:44.350+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.350+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21303]: It took 0.239s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:50:44.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.357+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21303]: It took 0.00718s to build the Airflow DAG.
[2025-01-13T17:50:44.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:50:44.380+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.380+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:50:44.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:50:44.417+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:50:44.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.372 seconds
[2025-01-13T17:51:14.556+0000] {processor.py:157} INFO - Started process (PID=21391) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:51:14.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:51:14.560+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:51:14.586+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.586+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:51:14.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.800+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19582553999862284
[2025-01-13T17:51:14.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.800+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21391]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:51:14.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.801+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:51:14.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.802+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:51:14.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.802+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:51:14.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.802+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21391]: It took 0.216s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:51:14.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.807+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21391]: It took 0.00488s to build the Airflow DAG.
[2025-01-13T17:51:14.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:51:14.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.825+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:51:14.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:14.858+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:51:14.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.329 seconds
[2025-01-13T17:51:45.811+0000] {processor.py:157} INFO - Started process (PID=21489) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:51:45.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:51:45.815+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:45.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:51:45.841+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:45.841+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:51:46.065+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.065+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20879269999932148
[2025-01-13T17:51:46.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.066+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21489]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:51:46.067+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.067+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:51:46.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.067+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:51:46.068+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.068+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:51:46.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.069+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21489]: It took 0.228s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:51:46.074+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.074+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21489]: It took 0.00529s to build the Airflow DAG.
[2025-01-13T17:51:46.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:51:46.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.093+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:51:46.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:51:46.126+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:51:46.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.343 seconds
[2025-01-13T17:52:16.213+0000] {processor.py:157} INFO - Started process (PID=21577) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:52:16.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:52:16.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:52:16.240+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.240+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:52:16.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.417+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16163961799975368
[2025-01-13T17:52:16.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.418+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21577]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:52:16.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.419+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:52:16.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.419+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:52:16.420+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.420+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:52:16.420+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.420+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21577]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:52:16.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.425+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21577]: It took 0.00485s to build the Airflow DAG.
[2025-01-13T17:52:16.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:52:16.442+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.442+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:52:16.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:16.468+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:52:16.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-13T17:52:46.593+0000] {processor.py:157} INFO - Started process (PID=21664) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:52:46.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:52:46.598+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:52:46.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.628+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:52:46.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.810+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16617992200190201
[2025-01-13T17:52:46.811+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.811+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21664]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:52:46.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.812+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:52:46.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.812+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:52:46.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.813+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:52:46.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.813+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21664]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:52:46.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.818+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21664]: It took 0.005s to build the Airflow DAG.
[2025-01-13T17:52:46.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:52:46.836+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.836+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:52:46.865+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:52:46.865+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:52:46.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-13T17:53:17.259+0000] {processor.py:157} INFO - Started process (PID=21748) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:53:17.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:53:17.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:53:17.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.287+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:53:17.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.485+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1830893289989035
[2025-01-13T17:53:17.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.485+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21748]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:53:17.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.486+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:53:17.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.487+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:53:17.487+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.487+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:53:17.488+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.488+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21748]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:53:17.493+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.493+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21748]: It took 0.00534s to build the Airflow DAG.
[2025-01-13T17:53:17.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:53:17.512+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.512+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:53:17.543+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:17.543+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:53:17.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.309 seconds
[2025-01-13T17:53:47.974+0000] {processor.py:157} INFO - Started process (PID=21842) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:53:47.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:53:47.977+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:47.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:53:48.003+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.003+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:53:48.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.219+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2024815109980409
[2025-01-13T17:53:48.220+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.220+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21842]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:53:48.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.221+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:53:48.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.221+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:53:48.222+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.222+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:53:48.222+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.222+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21842]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:53:48.226+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.226+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21842]: It took 0.00391s to build the Airflow DAG.
[2025-01-13T17:53:48.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:53:48.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.242+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:53:48.268+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:53:48.268+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:53:48.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-13T17:54:18.509+0000] {processor.py:157} INFO - Started process (PID=21939) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:54:18.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:54:18.512+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:54:18.538+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.538+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:54:18.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.742+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18850909100001445
[2025-01-13T17:54:18.742+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.742+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|21939]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:54:18.743+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.743+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:54:18.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.744+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:54:18.744+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.744+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:54:18.745+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.745+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|21939]: It took 0.207s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:54:18.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.750+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|21939]: It took 0.00528s to build the Airflow DAG.
[2025-01-13T17:54:18.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:54:18.769+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.768+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:54:18.797+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:18.796+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:54:18.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.313 seconds
[2025-01-13T17:54:49.328+0000] {processor.py:157} INFO - Started process (PID=22025) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:54:49.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:54:49.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:54:49.360+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.360+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:54:49.574+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.574+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19816906400228618
[2025-01-13T17:54:49.575+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.575+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22025]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:54:49.576+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.576+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:54:49.576+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.576+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:54:49.577+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.577+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:54:49.577+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.577+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22025]: It took 0.218s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:54:49.583+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.583+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22025]: It took 0.00547s to build the Airflow DAG.
[2025-01-13T17:54:49.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:54:49.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.602+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:54:49.636+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:54:49.635+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:54:49.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.332 seconds
[2025-01-13T17:55:19.735+0000] {processor.py:157} INFO - Started process (PID=22114) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:55:19.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:55:19.740+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:55:19.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.772+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:55:19.987+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.987+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2012309070014453
[2025-01-13T17:55:19.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.988+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22114]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:55:19.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.989+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:55:19.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.989+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:55:19.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.989+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:55:19.990+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.990+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22114]: It took 0.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:55:19.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:19.995+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22114]: It took 0.0051s to build the Airflow DAG.
[2025-01-13T17:55:19.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:55:20.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:20.013+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:55:20.044+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:20.044+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:55:20.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.347 seconds
[2025-01-13T17:55:50.770+0000] {processor.py:157} INFO - Started process (PID=22200) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:55:50.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:55:50.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:50.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:55:50.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:50.800+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:55:51.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.013+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19052587799887988
[2025-01-13T17:55:51.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.013+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22200]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:55:51.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.014+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:55:51.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.015+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:55:51.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.015+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:55:51.016+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.016+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22200]: It took 0.216s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:55:51.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.021+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22200]: It took 0.00518s to build the Airflow DAG.
[2025-01-13T17:55:51.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:55:51.042+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.042+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:55:51.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:55:51.079+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:55:51.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.339 seconds
[2025-01-13T17:56:21.581+0000] {processor.py:157} INFO - Started process (PID=22293) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:56:21.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:56:21.585+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:56:21.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.612+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:56:21.847+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.847+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21693658900039736
[2025-01-13T17:56:21.847+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.847+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22293]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4294
[2025-01-13T17:56:21.848+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.848+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d0ab1c667192b1a13d1392484ed4689d,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:56:21.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.849+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:56:21.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.849+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:56:21.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.850+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22293]: It took 0.237s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:56:21.855+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.855+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22293]: It took 0.0056s to build the Airflow DAG.
[2025-01-13T17:56:21.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:56:21.876+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.876+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:56:21.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:21.906+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:56:21.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-13T17:56:52.375+0000] {processor.py:157} INFO - Started process (PID=22380) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:56:52.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:56:52.381+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:56:52.422+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.422+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:56:52.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.906+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.46203573499951744
[2025-01-13T17:56:52.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.907+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T17:56:52.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.907+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T17:56:52.919+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.919+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /opt/airflow/dbt/dbt_stock_project/target/partial_parse.msgpack
[2025-01-13T17:56:52.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.958+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T17:56:52.959+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.959+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T17:56:52.960+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:56:52.960+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmplga6eajp --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T17:57:04.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.611+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2312141080001311
[2025-01-13T17:57:04.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.618+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T17:57:04.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.629+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:57:04.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.630+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:57:04.631+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.631+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22380]: It took 12.2s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T17:57:04.638+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.638+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22380]: It took 0.00704s to build the Airflow DAG.
[2025-01-13T17:57:04.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:57:04.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.663+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:57:04.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:04.704+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:57:04.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 12.365 seconds
[2025-01-13T17:57:34.864+0000] {processor.py:157} INFO - Started process (PID=22516) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:57:34.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:57:34.868+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:34.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:57:34.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:34.893+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:57:35.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.069+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16089385200029938
[2025-01-13T17:57:35.070+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.069+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22516]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T17:57:35.070+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.070+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:57:35.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.071+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:57:35.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.071+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:57:35.072+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.072+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22516]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:57:35.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.077+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22516]: It took 0.00498s to build the Airflow DAG.
[2025-01-13T17:57:35.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:57:35.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.095+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:57:35.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:57:35.126+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:57:35.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-13T17:58:06.154+0000] {processor.py:157} INFO - Started process (PID=22621) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:58:06.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:58:06.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:58:06.187+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.187+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:58:06.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.427+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22194331599894213
[2025-01-13T17:58:06.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.428+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22621]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T17:58:06.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.429+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:58:06.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.430+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:58:06.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.431+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:58:06.432+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.432+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22621]: It took 0.245s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:58:06.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.439+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22621]: It took 0.00675s to build the Airflow DAG.
[2025-01-13T17:58:06.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:58:06.467+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.467+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:58:06.508+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:06.508+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:58:06.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.388 seconds
[2025-01-13T17:58:37.377+0000] {processor.py:157} INFO - Started process (PID=22708) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:58:37.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:58:37.380+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:58:37.402+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.402+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:58:37.568+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.568+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1502642899977218
[2025-01-13T17:58:37.568+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.568+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22708]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T17:58:37.569+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.569+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:58:37.569+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.569+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:58:37.570+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.570+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:58:37.570+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.570+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22708]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:58:37.574+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.574+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22708]: It took 0.00438s to build the Airflow DAG.
[2025-01-13T17:58:37.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:58:37.590+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.590+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:58:37.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:58:37.620+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:58:37.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T17:59:07.865+0000] {processor.py:157} INFO - Started process (PID=22794) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:59:07.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:59:07.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:07.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:59:07.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:07.899+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:59:08.123+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.122+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20607233599730534
[2025-01-13T17:59:08.123+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.123+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22794]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T17:59:08.125+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.124+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:59:08.125+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.125+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:59:08.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.125+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:59:08.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.126+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22794]: It took 0.228s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:59:08.133+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.133+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22794]: It took 0.00679s to build the Airflow DAG.
[2025-01-13T17:59:08.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:59:08.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.155+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:59:08.201+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:08.201+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:59:08.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.369 seconds
[2025-01-13T17:59:38.622+0000] {processor.py:157} INFO - Started process (PID=22880) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:59:38.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T17:59:38.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:59:38.657+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.657+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T17:59:38.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.904+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23085424099917873
[2025-01-13T17:59:38.905+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.905+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22880]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T17:59:38.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.906+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T17:59:38.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.906+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T17:59:38.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.907+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T17:59:38.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.907+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22880]: It took 0.25s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T17:59:38.913+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.913+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22880]: It took 0.00555s to build the Airflow DAG.
[2025-01-13T17:59:38.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T17:59:38.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.935+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T17:59:38.969+0000] {logging_mixin.py:151} INFO - [2025-01-13T17:59:38.969+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T17:59:38.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.377 seconds
[2025-01-13T18:00:09.175+0000] {processor.py:157} INFO - Started process (PID=22968) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:00:09.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:00:09.180+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:00:09.212+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.212+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:00:09.446+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.445+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21418330799860996
[2025-01-13T18:00:09.447+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.446+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|22968]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T18:00:09.448+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.448+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:00:09.449+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.449+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:00:09.450+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.450+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:00:09.451+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.451+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|22968]: It took 0.239s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:00:09.459+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.458+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|22968]: It took 0.00744s to build the Airflow DAG.
[2025-01-13T18:00:09.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:00:09.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.482+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:00:09.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:09.529+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:00:09.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.392 seconds
[2025-01-13T18:00:39.629+0000] {processor.py:157} INFO - Started process (PID=23055) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:00:39.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:00:39.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:00:39.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.659+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:00:39.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.904+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22668029999840655
[2025-01-13T18:00:39.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.904+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|23055]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T18:00:39.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.905+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:00:39.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.906+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:00:39.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.906+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:00:39.907+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.907+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|23055]: It took 0.248s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:00:39.913+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.913+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|23055]: It took 0.00583s to build the Airflow DAG.
[2025-01-13T18:00:39.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:00:39.937+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.936+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:00:39.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:00:39.980+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:00:40.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.399 seconds
[2025-01-13T18:01:10.912+0000] {processor.py:157} INFO - Started process (PID=23150) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:01:10.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:01:10.915+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:10.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:01:10.940+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:10.940+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:01:11.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.153+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1973452249985712
[2025-01-13T18:01:11.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.153+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|23150]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4373
[2025-01-13T18:01:11.154+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.154+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 09ceaaa51e29f8e282945cfa9e303df3,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:01:11.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.155+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:01:11.155+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.155+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:01:11.156+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.156+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|23150]: It took 0.216s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:01:11.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.162+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|23150]: It took 0.0057s to build the Airflow DAG.
[2025-01-13T18:01:11.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:01:11.180+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.180+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:01:11.214+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:11.213+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:01:11.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-13T18:01:41.284+0000] {processor.py:157} INFO - Started process (PID=23247) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:01:41.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:01:41.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:01:41.322+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.322+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:01:41.602+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.601+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.25878438600193476
[2025-01-13T18:01:41.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.602+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:01:41.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.603+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:01:41.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.610+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:01:41.622+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.622+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:01:41.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.624+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:01:41.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:41.625+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmp0mia9wbm --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:01:49.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:01:48.994+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 612, in load_via_dbt_ls_without_cache
    nodes = self.run_dbt_ls(dbt_cmd, self.project_path, tmpdir_path, env)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 474, in run_dbt_ls
    stdout = run_command(ls_command, tmp_dir, env_vars)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 184, in run_command
    raise CosmosLoadDbtException(f"Unable to run {command} due to the error:\n{details}")
cosmos.dbt.graph.CosmosLoadDbtException: Unable to run ['/home/airflow/.local/bin/dbt', 'ls', '--output', 'json', '--project-dir', '/tmp/tmp0mia9wbm', '--profiles-dir', '/opt/airflow/dbt/profiles', '--profile', 'default', '--target', 'dev'] due to the error:
stderr: 
stdout: 18:01:46  Running with dbt=1.5.11
18:01:47  Registered adapter: bigquery=1.5.9
18:01:47  Encountered an error:
Compilation Error in model stocks (models/stocks.sql)
  unexpected '}'
    line 18
      {%}
[2025-01-13T18:01:49.005+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:01:49.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 7.742 seconds
[2025-01-13T18:02:19.188+0000] {processor.py:157} INFO - Started process (PID=23364) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:02:19.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:02:19.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:02:19.224+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.223+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:02:19.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.418+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17891317600151524
[2025-01-13T18:02:19.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.418+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:02:19.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.419+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:02:19.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.425+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:02:19.436+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.436+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:02:19.438+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.438+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:02:19.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:19.439+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpttu_j0cm --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:02:27.133+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:27.127+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 612, in load_via_dbt_ls_without_cache
    nodes = self.run_dbt_ls(dbt_cmd, self.project_path, tmpdir_path, env)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 474, in run_dbt_ls
    stdout = run_command(ls_command, tmp_dir, env_vars)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 184, in run_command
    raise CosmosLoadDbtException(f"Unable to run {command} due to the error:\n{details}")
cosmos.dbt.graph.CosmosLoadDbtException: Unable to run ['/home/airflow/.local/bin/dbt', 'ls', '--output', 'json', '--project-dir', '/tmp/tmpttu_j0cm', '--profiles-dir', '/opt/airflow/dbt/profiles', '--profile', 'default', '--target', 'dev'] due to the error:
stderr: 
stdout: 18:02:24  Running with dbt=1.5.11
18:02:25  Registered adapter: bigquery=1.5.9
18:02:26  Encountered an error:
Compilation Error in model stocks (models/stocks.sql)
  unexpected '}'
    line 18
      {%}
[2025-01-13T18:02:27.134+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:02:27.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 7.961 seconds
[2025-01-13T18:02:57.445+0000] {processor.py:157} INFO - Started process (PID=23491) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:02:57.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:02:57.448+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:02:57.471+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.471+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:02:57.684+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.684+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19831351500033634
[2025-01-13T18:02:57.684+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.684+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:02:57.685+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.685+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:02:57.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.690+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:02:57.697+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.697+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:02:57.700+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.700+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:02:57.701+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:02:57.700+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpjfa756ot --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:03:04.581+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:04.574+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 612, in load_via_dbt_ls_without_cache
    nodes = self.run_dbt_ls(dbt_cmd, self.project_path, tmpdir_path, env)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 474, in run_dbt_ls
    stdout = run_command(ls_command, tmp_dir, env_vars)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 184, in run_command
    raise CosmosLoadDbtException(f"Unable to run {command} due to the error:\n{details}")
cosmos.dbt.graph.CosmosLoadDbtException: Unable to run ['/home/airflow/.local/bin/dbt', 'ls', '--output', 'json', '--project-dir', '/tmp/tmpjfa756ot', '--profiles-dir', '/opt/airflow/dbt/profiles', '--profile', 'default', '--target', 'dev'] due to the error:
stderr: 
stdout: 18:03:02  Running with dbt=1.5.11
18:03:03  Registered adapter: bigquery=1.5.9
18:03:03  Encountered an error:
Compilation Error in model stocks (models/stocks.sql)
  unexpected '}'
    line 18
      {%}
[2025-01-13T18:03:04.582+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:03:04.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 7.161 seconds
[2025-01-13T18:03:34.675+0000] {processor.py:157} INFO - Started process (PID=23610) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:03:34.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:03:34.677+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:34.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:03:34.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:34.708+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:03:34.993+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:34.993+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2669411660026526
[2025-01-13T18:03:34.994+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:34.994+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:03:34.995+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:34.995+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:03:35.003+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:35.002+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:03:35.012+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:35.012+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:03:35.014+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:35.014+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:03:35.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:35.014+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmptxq0duea --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:03:41.598+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:03:41.591+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 612, in load_via_dbt_ls_without_cache
    nodes = self.run_dbt_ls(dbt_cmd, self.project_path, tmpdir_path, env)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 474, in run_dbt_ls
    stdout = run_command(ls_command, tmp_dir, env_vars)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 184, in run_command
    raise CosmosLoadDbtException(f"Unable to run {command} due to the error:\n{details}")
cosmos.dbt.graph.CosmosLoadDbtException: Unable to run ['/home/airflow/.local/bin/dbt', 'ls', '--output', 'json', '--project-dir', '/tmp/tmptxq0duea', '--profiles-dir', '/opt/airflow/dbt/profiles', '--profile', 'default', '--target', 'dev'] due to the error:
stderr: 
stdout: 18:03:39  Running with dbt=1.5.11
18:03:40  Registered adapter: bigquery=1.5.9
18:03:40  Encountered an error:
Compilation Error in model stocks (models/stocks.sql)
  unexpected '}'
    line 18
      {%}
[2025-01-13T18:03:41.599+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:03:41.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 6.946 seconds
[2025-01-13T18:04:12.512+0000] {processor.py:157} INFO - Started process (PID=23729) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:04:12.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:04:12.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:04:12.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.536+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:04:12.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.752+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20003379600166227
[2025-01-13T18:04:12.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.753+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:04:12.753+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.753+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:04:12.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.759+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:04:12.766+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.766+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:04:12.768+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.767+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:04:12.768+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:12.768+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmprgxg0qit --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:04:20.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:20.177+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 612, in load_via_dbt_ls_without_cache
    nodes = self.run_dbt_ls(dbt_cmd, self.project_path, tmpdir_path, env)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 474, in run_dbt_ls
    stdout = run_command(ls_command, tmp_dir, env_vars)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 184, in run_command
    raise CosmosLoadDbtException(f"Unable to run {command} due to the error:\n{details}")
cosmos.dbt.graph.CosmosLoadDbtException: Unable to run ['/home/airflow/.local/bin/dbt', 'ls', '--output', 'json', '--project-dir', '/tmp/tmprgxg0qit', '--profiles-dir', '/opt/airflow/dbt/profiles', '--profile', 'default', '--target', 'dev'] due to the error:
stderr: 
stdout: 18:04:17  Running with dbt=1.5.11
18:04:18  Registered adapter: bigquery=1.5.9
18:04:19  Encountered an error:
Compilation Error in model stocks (models/stocks.sql)
  Unexpected end of template. Jinja was looking for the following tags: 'elif' or 'else' or 'endif'. The innermost block that needs to be closed is 'if'.
    line 21
      {%if is_incremental%}
[2025-01-13T18:04:20.184+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:04:20.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 7.687 seconds
[2025-01-13T18:04:50.907+0000] {processor.py:157} INFO - Started process (PID=23869) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:04:50.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:04:50.909+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:50.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:04:50.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:50.935+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:04:51.137+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:51.137+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18777887300166185
[2025-01-13T18:04:51.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:51.138+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:04:51.138+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:51.138+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:04:51.143+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:51.143+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:04:51.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:51.150+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:04:51.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:51.152+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:04:51.153+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:51.153+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmp1v8m1ozd --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:04:57.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.605+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13023367500136374
[2025-01-13T18:04:57.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.610+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T18:04:57.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.617+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:04:57.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.618+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:04:57.619+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.619+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|23869]: It took 6.68s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T18:04:57.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.624+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|23869]: It took 0.00591s to build the Airflow DAG.
[2025-01-13T18:04:57.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:04:57.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.698+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:04:57.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:04:57.722+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:04:57.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 6.841 seconds
[2025-01-13T18:05:28.604+0000] {processor.py:157} INFO - Started process (PID=23995) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:05:28.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:05:28.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:05:28.629+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.629+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:05:28.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.805+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15945933799957857
[2025-01-13T18:05:28.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.805+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|23995]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:05:28.806+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.806+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - ac256acd0de2c0b267a8ed13e2a2c4dd,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:05:28.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.807+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:05:28.807+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.807+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:05:28.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.808+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|23995]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:05:28.813+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.813+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|23995]: It took 0.00552s to build the Airflow DAG.
[2025-01-13T18:05:28.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:05:28.837+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.836+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:05:28.869+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:28.869+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:05:28.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-13T18:05:58.959+0000] {processor.py:157} INFO - Started process (PID=24081) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:05:58.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:05:58.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:58.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:05:58.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:58.988+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:05:59.177+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.177+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17225953899833257
[2025-01-13T18:05:59.178+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.178+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24081]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:05:59.178+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.178+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - ac256acd0de2c0b267a8ed13e2a2c4dd,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:05:59.179+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.179+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:05:59.179+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.179+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:05:59.179+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.179+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24081]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:05:59.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.183+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24081]: It took 0.0038s to build the Airflow DAG.
[2025-01-13T18:05:59.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:05:59.199+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.199+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:05:59.224+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:05:59.224+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:05:59.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-13T18:06:29.531+0000] {processor.py:157} INFO - Started process (PID=24167) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:06:29.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:06:29.533+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:06:29.562+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.561+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:06:29.732+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.732+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15509692499836092
[2025-01-13T18:06:29.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.733+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24167]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:06:29.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.733+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - ac256acd0de2c0b267a8ed13e2a2c4dd,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:06:29.734+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.734+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:06:29.734+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.734+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:06:29.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.734+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24167]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:06:29.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.739+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24167]: It took 0.00426s to build the Airflow DAG.
[2025-01-13T18:06:29.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:06:29.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.754+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:06:29.777+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:29.777+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:06:29.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-13T18:06:59.976+0000] {processor.py:157} INFO - Started process (PID=24253) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:06:59.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:06:59.979+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:06:59.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:07:00.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.004+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:07:00.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.234+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2104468790021201
[2025-01-13T18:07:00.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.235+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:07:00.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.235+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:07:00.242+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.242+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:07:00.250+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.250+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:07:00.252+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.251+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:07:00.252+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:00.252+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmp4bpxox__ --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:07:08.413+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.412+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19514533300025505
[2025-01-13T18:07:08.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.418+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T18:07:08.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.430+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:07:08.431+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.430+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:07:08.432+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.431+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24253]: It took 8.43s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T18:07:08.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.439+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24253]: It took 0.00742s to build the Airflow DAG.
[2025-01-13T18:07:08.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:07:08.460+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.460+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:07:08.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:08.492+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:07:08.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 8.543 seconds
[2025-01-13T18:07:38.560+0000] {processor.py:157} INFO - Started process (PID=24384) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:07:38.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:07:38.563+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:07:38.599+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.599+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:07:38.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.802+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18511025499901734
[2025-01-13T18:07:38.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.802+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24384]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:07:38.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.803+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d73b9b91ff3996fa47b81d08328cbc56,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:07:38.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.804+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:07:38.804+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.804+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:07:38.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.805+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24384]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:07:38.810+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.810+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24384]: It took 0.00503s to build the Airflow DAG.
[2025-01-13T18:07:38.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:07:38.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.827+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:07:38.855+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:07:38.855+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:07:38.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-13T18:08:09.706+0000] {processor.py:157} INFO - Started process (PID=24470) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:08:09.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:08:09.708+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:08:09.732+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.732+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:08:09.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.935+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18952901100055897
[2025-01-13T18:08:09.935+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.935+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24470]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:08:09.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.936+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d73b9b91ff3996fa47b81d08328cbc56,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:08:09.937+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.936+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:08:09.937+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.937+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:08:09.937+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.937+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24470]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:08:09.941+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.941+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24470]: It took 0.00415s to build the Airflow DAG.
[2025-01-13T18:08:09.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:08:09.958+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.957+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:08:09.984+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:09.984+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:08:10.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-13T18:08:40.069+0000] {processor.py:157} INFO - Started process (PID=24558) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:08:40.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:08:40.071+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:08:40.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.098+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:08:40.285+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.285+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17203223799879197
[2025-01-13T18:08:40.285+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.285+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24558]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:08:40.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.286+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - d73b9b91ff3996fa47b81d08328cbc56,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:08:40.286+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.286+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:08:40.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.287+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:08:40.287+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.287+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24558]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:08:40.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.291+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24558]: It took 0.00414s to build the Airflow DAG.
[2025-01-13T18:08:40.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:08:40.308+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.307+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:08:40.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:08:40.333+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:08:40.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-13T18:09:10.596+0000] {processor.py:157} INFO - Started process (PID=24642) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:09:10.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:09:10.598+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:09:10.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.628+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:09:10.843+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.842+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19833700000162935
[2025-01-13T18:09:10.843+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.843+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:09:10.844+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.844+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:09:10.853+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.852+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /opt/airflow/dbt/dbt_stock_project/target/partial_parse.msgpack
[2025-01-13T18:09:10.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.901+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:09:10.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.928+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:09:10.948+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:10.948+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmp6vw9dkyn --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:09:20.148+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.147+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14179406900075264
[2025-01-13T18:09:20.152+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.152+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T18:09:20.158+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.158+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:09:20.159+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.159+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:09:20.160+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.160+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24642]: It took 9.53s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T18:09:20.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.166+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24642]: It took 0.00647s to build the Airflow DAG.
[2025-01-13T18:09:20.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:09:20.181+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.181+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:09:20.205+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:20.205+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:09:20.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 9.634 seconds
[2025-01-13T18:09:50.292+0000] {processor.py:157} INFO - Started process (PID=24777) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:09:50.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:09:50.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:09:50.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.331+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:09:50.579+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.578+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22865486099908594
[2025-01-13T18:09:50.579+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.579+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24777]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4399
[2025-01-13T18:09:50.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.580+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 80efbbc334f9d0828fbb51c2fea52e83,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:09:50.581+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.581+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:09:50.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.582+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:09:50.583+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.583+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24777]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:09:50.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.591+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24777]: It took 0.00808s to build the Airflow DAG.
[2025-01-13T18:09:50.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:09:50.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.614+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:09:50.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:09:50.664+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:09:50.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.411 seconds
[2025-01-13T18:10:20.847+0000] {processor.py:157} INFO - Started process (PID=24858) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:10:20.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:10:20.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:20.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:10:20.872+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:20.872+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:10:21.077+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.077+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19071335699845804
[2025-01-13T18:10:21.078+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.078+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24858]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4399
[2025-01-13T18:10:21.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.079+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 80efbbc334f9d0828fbb51c2fea52e83,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:10:21.080+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.080+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:10:21.081+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.081+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:10:21.082+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.082+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24858]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:10:21.090+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.089+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24858]: It took 0.0079s to build the Airflow DAG.
[2025-01-13T18:10:21.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:10:21.115+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.115+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:10:21.162+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:21.161+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:10:21.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.349 seconds
[2025-01-13T18:10:51.259+0000] {processor.py:157} INFO - Started process (PID=24944) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:10:51.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:10:51.262+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:10:51.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.293+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:10:51.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.502+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19144061299812165
[2025-01-13T18:10:51.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.502+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|24944]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4399
[2025-01-13T18:10:51.504+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.504+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 80efbbc334f9d0828fbb51c2fea52e83,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:10:51.504+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.504+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:10:51.505+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.505+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:10:51.505+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.505+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|24944]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:10:51.511+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.511+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|24944]: It took 0.00581s to build the Airflow DAG.
[2025-01-13T18:10:51.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:10:51.531+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.531+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:10:51.564+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:10:51.564+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:10:51.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-13T18:11:21.700+0000] {processor.py:157} INFO - Started process (PID=25032) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:11:21.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:11:21.702+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:11:21.735+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.735+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:11:21.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.951+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1985720599986962
[2025-01-13T18:11:21.952+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.952+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25032]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4399
[2025-01-13T18:11:21.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.953+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 80efbbc334f9d0828fbb51c2fea52e83,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:11:21.954+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.954+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:11:21.954+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.954+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:11:21.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.955+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25032]: It took 0.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:11:21.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.961+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25032]: It took 0.00607s to build the Airflow DAG.
[2025-01-13T18:11:21.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:11:21.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:21.986+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:11:22.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:22.018+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:11:22.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.346 seconds
[2025-01-13T18:11:52.264+0000] {processor.py:157} INFO - Started process (PID=25116) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:11:52.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:11:52.266+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:11:52.294+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.293+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:11:52.488+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.488+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17879152800014708
[2025-01-13T18:11:52.489+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.488+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25116]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4399
[2025-01-13T18:11:52.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.490+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 80efbbc334f9d0828fbb51c2fea52e83,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:11:52.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.490+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:11:52.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.491+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:11:52.492+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.491+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25116]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:11:52.497+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.497+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25116]: It took 0.00549s to build the Airflow DAG.
[2025-01-13T18:11:52.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:11:52.518+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.517+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:11:52.548+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:11:52.548+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:11:52.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.310 seconds
[2025-01-13T18:12:22.652+0000] {processor.py:157} INFO - Started process (PID=25202) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:12:22.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:12:22.655+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:22.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:12:22.685+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:22.685+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:12:22.980+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:22.980+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.27882312099973205
[2025-01-13T18:12:22.981+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:22.981+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:12:22.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:22.982+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:12:22.989+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:22.989+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:12:22.998+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:22.998+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:12:23.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:23.000+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:12:23.000+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:23.000+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpqsbqszbb --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:12:33.250+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.249+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19059920300060185
[2025-01-13T18:12:33.254+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.254+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T18:12:33.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.263+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:12:33.264+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.264+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:12:33.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.264+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25202]: It took 10.6s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T18:12:33.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.271+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25202]: It took 0.00622s to build the Airflow DAG.
[2025-01-13T18:12:33.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:12:33.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.289+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:12:33.321+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:12:33.321+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:12:33.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 10.696 seconds
[2025-01-13T18:13:03.846+0000] {processor.py:157} INFO - Started process (PID=25344) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:13:03.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:13:03.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:03.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:13:03.881+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:03.880+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:13:04.095+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:04.095+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19665696400261368
[2025-01-13T18:13:04.096+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:04.096+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-13T18:13:04.097+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:04.096+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-13T18:13:04.104+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:04.104+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-13T18:13:04.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:04.112+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-13T18:13:04.114+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:04.114+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-13T18:13:04.115+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:04.115+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpgiblw25x --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-13T18:13:13.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.707+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1909448459991836
[2025-01-13T18:13:13.713+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.713+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-13T18:13:13.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.723+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:13:13.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.724+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:13:13.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.725+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25344]: It took 9.84s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-13T18:13:13.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.732+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25344]: It took 0.00742s to build the Airflow DAG.
[2025-01-13T18:13:13.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:13:13.757+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.757+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:13:13.798+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:13.798+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:13:13.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 9.984 seconds
[2025-01-13T18:13:44.483+0000] {processor.py:157} INFO - Started process (PID=25476) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:13:44.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:13:44.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:13:44.516+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.516+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:13:44.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.746+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21299805100352387
[2025-01-13T18:13:44.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.746+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25476]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:13:44.747+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.747+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:13:44.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.748+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:13:44.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.748+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:13:44.749+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.749+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25476]: It took 0.233s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:13:44.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.754+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25476]: It took 0.00498s to build the Airflow DAG.
[2025-01-13T18:13:44.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:13:44.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.775+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:13:44.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:13:44.804+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:13:44.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.345 seconds
[2025-01-13T18:14:15.752+0000] {processor.py:157} INFO - Started process (PID=25564) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:14:15.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:14:15.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:14:15.775+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.775+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:14:15.927+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.927+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13770243600083631
[2025-01-13T18:14:15.928+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.928+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25564]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:14:15.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.928+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:14:15.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.929+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:14:15.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.929+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:14:15.930+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.930+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25564]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:14:15.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.934+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25564]: It took 0.00405s to build the Airflow DAG.
[2025-01-13T18:14:15.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:14:15.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.950+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:14:15.975+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:15.975+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:14:16.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-13T18:14:46.560+0000] {processor.py:157} INFO - Started process (PID=25650) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:14:46.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:14:46.562+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:14:46.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.588+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:14:46.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.745+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14216440599921043
[2025-01-13T18:14:46.746+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.746+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25650]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:14:46.747+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.747+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:14:46.747+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.747+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:14:46.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.748+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:14:46.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.748+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25650]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:14:46.754+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.754+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25650]: It took 0.00546s to build the Airflow DAG.
[2025-01-13T18:14:46.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:14:46.771+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.771+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:14:46.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:14:46.796+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:14:46.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-13T18:15:16.872+0000] {processor.py:157} INFO - Started process (PID=25737) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:15:16.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:15:16.875+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:16.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:15:16.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:16.899+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:15:17.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.097+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1811692800001765
[2025-01-13T18:15:17.098+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.098+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25737]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:15:17.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.099+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:15:17.100+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.100+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:15:17.100+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.100+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:15:17.101+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.101+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25737]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:15:17.107+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.107+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25737]: It took 0.00598s to build the Airflow DAG.
[2025-01-13T18:15:17.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:15:17.128+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.128+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:15:17.163+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:17.163+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:15:17.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-13T18:15:47.962+0000] {processor.py:157} INFO - Started process (PID=25831) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:15:47.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:15:47.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:47.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:15:48.002+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.002+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:15:48.228+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.228+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20376616900102817
[2025-01-13T18:15:48.229+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.228+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25831]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:15:48.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.230+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:15:48.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.230+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:15:48.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.231+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:15:48.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.231+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25831]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:15:48.237+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.237+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25831]: It took 0.00592s to build the Airflow DAG.
[2025-01-13T18:15:48.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:15:48.258+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.257+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:15:48.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:15:48.291+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:15:48.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.536 seconds
[2025-01-13T18:16:18.603+0000] {processor.py:157} INFO - Started process (PID=25917) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:16:18.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:16:18.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:16:18.636+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.636+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:16:18.847+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.847+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19334735600205022
[2025-01-13T18:16:18.848+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.848+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|25917]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:16:18.849+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.849+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:16:18.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.850+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:16:18.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.850+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:16:18.851+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.851+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|25917]: It took 0.215s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:16:18.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.856+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|25917]: It took 0.00522s to build the Airflow DAG.
[2025-01-13T18:16:18.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:16:18.874+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.874+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:16:18.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:18.902+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:16:18.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.328 seconds
[2025-01-13T18:16:49.328+0000] {processor.py:157} INFO - Started process (PID=26014) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:16:49.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:16:49.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:16:49.361+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.360+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:16:49.589+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.589+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21020205999957398
[2025-01-13T18:16:49.590+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.590+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26014]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:16:49.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.591+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:16:49.591+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.591+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:16:49.592+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.592+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:16:49.592+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.592+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26014]: It took 0.232s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:16:49.598+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.597+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26014]: It took 0.00505s to build the Airflow DAG.
[2025-01-13T18:16:49.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:16:49.618+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.618+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:16:49.654+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:16:49.654+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:16:49.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.366 seconds
[2025-01-13T18:17:20.561+0000] {processor.py:157} INFO - Started process (PID=26101) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:17:20.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:17:20.564+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:17:20.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.593+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:17:20.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.800+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19130385000244132
[2025-01-13T18:17:20.801+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.801+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26101]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:17:20.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.802+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:17:20.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.802+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:17:20.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.803+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:17:20.803+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.803+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26101]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:17:20.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.807+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26101]: It took 0.00458s to build the Airflow DAG.
[2025-01-13T18:17:20.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:17:20.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.824+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:17:20.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:20.850+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:17:21.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.477 seconds
[2025-01-13T18:17:51.769+0000] {processor.py:157} INFO - Started process (PID=26188) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:17:51.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:17:51.772+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:17:51.802+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.802+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:17:51.972+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.971+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15614419300254667
[2025-01-13T18:17:51.972+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.972+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26188]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:17:51.973+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.973+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:17:51.973+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.973+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:17:51.974+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.974+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:17:51.974+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.974+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26188]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:17:51.978+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.978+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26188]: It took 0.00408s to build the Airflow DAG.
[2025-01-13T18:17:51.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:17:51.997+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:51.997+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:17:52.024+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:17:52.024+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:17:52.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-13T18:18:22.212+0000] {processor.py:157} INFO - Started process (PID=26274) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:18:22.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:18:22.214+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:18:22.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.236+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:18:22.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.425+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17319092900288524
[2025-01-13T18:18:22.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.426+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26274]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:18:22.427+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.427+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:18:22.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.428+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:18:22.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.428+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:18:22.429+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.428+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26274]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:18:22.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.433+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26274]: It took 0.00487s to build the Airflow DAG.
[2025-01-13T18:18:22.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:18:22.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.451+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:18:22.666+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:22.666+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:18:22.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.485 seconds
[2025-01-13T18:18:53.370+0000] {processor.py:157} INFO - Started process (PID=26360) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:18:53.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:18:53.372+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:18:53.401+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.400+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:18:53.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.593+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1770817979995627
[2025-01-13T18:18:53.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.594+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26360]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:18:53.595+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.595+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:18:53.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.595+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:18:53.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.596+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:18:53.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.596+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26360]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:18:53.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.601+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26360]: It took 0.00494s to build the Airflow DAG.
[2025-01-13T18:18:53.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:18:53.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.620+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:18:53.650+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:18:53.650+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:18:53.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.317 seconds
[2025-01-13T18:19:24.372+0000] {processor.py:157} INFO - Started process (PID=26453) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:19:24.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:19:24.374+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:19:24.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.405+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:19:24.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.613+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19110578700201586
[2025-01-13T18:19:24.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.614+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26453]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:19:24.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.615+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:19:24.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.615+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:19:24.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.616+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:19:24.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.617+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26453]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:19:24.622+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.622+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26453]: It took 0.00559s to build the Airflow DAG.
[2025-01-13T18:19:24.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:19:24.644+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.643+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:19:24.866+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:24.866+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:19:24.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.522 seconds
[2025-01-13T18:19:55.170+0000] {processor.py:157} INFO - Started process (PID=26540) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:19:55.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:19:55.173+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:19:55.199+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.199+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:19:55.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.417+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2025057939972612
[2025-01-13T18:19:55.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.418+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26540]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:19:55.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.419+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:19:55.420+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.419+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:19:55.420+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.420+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:19:55.421+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.420+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26540]: It took 0.222s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:19:55.426+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.426+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26540]: It took 0.00525s to build the Airflow DAG.
[2025-01-13T18:19:55.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:19:55.456+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.456+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:19:55.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:19:55.490+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:19:55.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.542 seconds
[2025-01-13T18:20:25.933+0000] {processor.py:157} INFO - Started process (PID=26640) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:20:25.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:20:25.936+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:25.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:20:25.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:25.970+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:20:26.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.199+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20642894900083775
[2025-01-13T18:20:26.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.200+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26640]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:20:26.202+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.201+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:20:26.202+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.202+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:20:26.203+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.203+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:20:26.204+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.203+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26640]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:20:26.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.210+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26640]: It took 0.00655s to build the Airflow DAG.
[2025-01-13T18:20:26.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:20:26.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.231+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:20:26.265+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:26.265+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:20:26.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-13T18:20:56.601+0000] {processor.py:157} INFO - Started process (PID=26723) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:20:56.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:20:56.603+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:20:56.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.634+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:20:56.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.890+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23830073600038304
[2025-01-13T18:20:56.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.891+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26723]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:20:56.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.892+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:20:56.893+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.893+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:20:56.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.894+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:20:56.894+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.894+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26723]: It took 0.261s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:20:56.901+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.901+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26723]: It took 0.00641s to build the Airflow DAG.
[2025-01-13T18:20:56.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:20:56.924+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:56.923+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:20:57.169+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:20:57.169+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:20:57.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.610 seconds
[2025-01-13T18:21:27.798+0000] {processor.py:157} INFO - Started process (PID=26809) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:21:27.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:21:27.800+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:27.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:21:27.825+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:27.825+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:21:28.017+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.017+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17742489600277622
[2025-01-13T18:21:28.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.017+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26809]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:21:28.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.018+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:21:28.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.019+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:21:28.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.019+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:21:28.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.020+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26809]: It took 0.195s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:21:28.024+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.024+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26809]: It took 0.00443s to build the Airflow DAG.
[2025-01-13T18:21:28.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:21:28.044+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.044+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:21:28.073+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:28.073+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:21:28.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.306 seconds
[2025-01-13T18:21:58.657+0000] {processor.py:157} INFO - Started process (PID=26895) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:21:58.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:21:58.659+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:21:58.687+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.687+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:21:58.931+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.931+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22782194100000197
[2025-01-13T18:21:58.932+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.931+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26895]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:21:58.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.933+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:21:58.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.933+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:21:58.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.934+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:21:58.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.934+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26895]: It took 0.247s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:21:58.940+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:58.940+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26895]: It took 0.00563s to build the Airflow DAG.
[2025-01-13T18:21:58.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:21:59.150+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:59.149+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:21:59.183+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:21:59.182+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:21:59.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.554 seconds
[2025-01-13T18:22:29.390+0000] {processor.py:157} INFO - Started process (PID=26982) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:22:29.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:22:29.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:22:29.424+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.424+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:22:29.673+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.673+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2299031959992135
[2025-01-13T18:22:29.674+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.673+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|26982]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:22:29.675+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.674+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:22:29.675+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.675+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:22:29.676+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.675+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:22:29.676+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.676+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|26982]: It took 0.252s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:22:29.684+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.683+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|26982]: It took 0.00738s to build the Airflow DAG.
[2025-01-13T18:22:29.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:22:29.706+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.706+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:22:29.950+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:22:29.949+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:22:29.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.591 seconds
[2025-01-13T18:23:00.328+0000] {processor.py:157} INFO - Started process (PID=27067) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:23:00.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:23:00.331+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:23:00.364+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.363+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:23:00.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.593+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.210939808999683
[2025-01-13T18:23:00.594+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.594+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27067]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:23:00.595+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.595+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:23:00.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.595+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:23:00.596+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.596+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:23:00.597+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.596+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27067]: It took 0.233s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:23:00.604+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.604+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27067]: It took 0.00746s to build the Airflow DAG.
[2025-01-13T18:23:00.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:23:00.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.627+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:23:00.665+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:00.665+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:23:00.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.605 seconds
[2025-01-13T18:23:31.003+0000] {processor.py:157} INFO - Started process (PID=27153) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:23:31.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:23:31.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:23:31.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.040+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:23:31.288+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.288+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2270710990014777
[2025-01-13T18:23:31.290+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.289+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27153]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:23:31.291+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.291+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:23:31.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.292+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:23:31.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.292+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:23:31.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.293+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27153]: It took 0.253s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:23:31.299+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.299+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27153]: It took 0.00592s to build the Airflow DAG.
[2025-01-13T18:23:31.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:23:31.324+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.324+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:23:31.363+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:23:31.362+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:23:31.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.396 seconds
[2025-01-13T18:24:02.097+0000] {processor.py:157} INFO - Started process (PID=27247) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:24:02.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:24:02.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:24:02.123+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.122+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:24:02.303+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.302+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1655897519995051
[2025-01-13T18:24:02.303+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.303+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27247]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:24:02.304+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.304+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:24:02.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.304+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:24:02.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.305+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:24:02.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.306+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27247]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:24:02.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.312+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27247]: It took 0.00611s to build the Airflow DAG.
[2025-01-13T18:24:02.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:24:02.497+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.497+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:24:02.523+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:02.523+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:24:02.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.451 seconds
[2025-01-13T18:24:32.769+0000] {processor.py:157} INFO - Started process (PID=27344) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:24:32.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:24:32.771+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:24:32.796+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.796+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:24:32.985+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.985+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17440981999970973
[2025-01-13T18:24:32.986+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.986+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27344]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:24:32.987+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.987+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:24:32.987+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.987+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:24:32.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.987+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:24:32.988+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.988+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27344]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:24:32.993+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:32.993+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27344]: It took 0.00521s to build the Airflow DAG.
[2025-01-13T18:24:32.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:24:33.011+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:33.011+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:24:33.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:24:33.041+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:24:33.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-13T18:25:03.120+0000] {processor.py:157} INFO - Started process (PID=27430) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:25:03.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:25:03.123+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:25:03.157+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.156+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:25:03.379+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.379+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20311360199775663
[2025-01-13T18:25:03.380+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.379+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27430]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:25:03.381+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.381+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:25:03.382+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.382+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:25:03.383+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.382+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:25:03.383+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.383+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27430]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:25:03.390+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.389+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27430]: It took 0.00635s to build the Airflow DAG.
[2025-01-13T18:25:03.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:25:03.411+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.411+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:25:03.452+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:03.451+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:25:03.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-13T18:25:33.533+0000] {processor.py:157} INFO - Started process (PID=27517) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:25:33.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:25:33.536+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:25:33.564+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.564+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:25:33.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.782+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2019360330014024
[2025-01-13T18:25:33.783+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.783+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27517]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:25:33.785+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.784+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:25:33.785+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.785+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:25:33.786+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.786+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:25:33.787+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.786+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27517]: It took 0.223s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:25:33.792+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.792+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27517]: It took 0.00574s to build the Airflow DAG.
[2025-01-13T18:25:33.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:25:33.812+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.812+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:25:33.842+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:25:33.842+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:25:33.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.340 seconds
[2025-01-13T18:26:03.932+0000] {processor.py:157} INFO - Started process (PID=27603) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:26:03.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:26:03.934+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:03.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:26:03.960+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:03.959+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:26:04.190+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.190+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21302110100077698
[2025-01-13T18:26:04.191+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.191+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27603]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:26:04.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.192+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:26:04.192+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.192+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:26:04.193+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.193+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:26:04.194+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.193+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27603]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:26:04.200+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.200+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27603]: It took 0.0061s to build the Airflow DAG.
[2025-01-13T18:26:04.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:26:04.221+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.220+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:26:04.253+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:04.253+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:26:04.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.350 seconds
[2025-01-13T18:26:34.339+0000] {processor.py:157} INFO - Started process (PID=27688) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:26:34.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:26:34.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:26:34.370+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.370+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:26:34.610+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.610+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.222845062999113
[2025-01-13T18:26:34.611+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.611+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27688]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:26:34.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.612+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:26:34.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.612+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:26:34.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.613+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:26:34.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.614+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27688]: It took 0.244s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:26:34.620+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.619+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27688]: It took 0.00561s to build the Airflow DAG.
[2025-01-13T18:26:34.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:26:34.641+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.641+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:26:34.674+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:26:34.674+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:26:34.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.368 seconds
[2025-01-13T18:27:04.816+0000] {processor.py:157} INFO - Started process (PID=27775) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:27:04.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:27:04.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:04.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:27:04.850+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:04.850+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:27:05.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.089+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2175990389987419
[2025-01-13T18:27:05.089+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.089+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27775]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:27:05.091+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.091+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:27:05.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.092+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:27:05.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.092+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:27:05.093+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.093+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27775]: It took 0.243s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:27:05.099+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.099+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27775]: It took 0.00636s to build the Airflow DAG.
[2025-01-13T18:27:05.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:27:05.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.126+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:27:05.174+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:05.174+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:27:05.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.391 seconds
[2025-01-13T18:27:35.340+0000] {processor.py:157} INFO - Started process (PID=27869) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:27:35.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:27:35.342+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:27:35.374+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.374+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:27:35.612+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.612+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22011946600105148
[2025-01-13T18:27:35.613+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.613+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27869]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:27:35.615+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.615+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:27:35.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.616+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:27:35.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.616+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:27:35.617+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.617+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27869]: It took 0.243s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:27:35.623+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.623+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27869]: It took 0.00605s to build the Airflow DAG.
[2025-01-13T18:27:35.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:27:35.652+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.652+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:27:35.690+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:27:35.689+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:27:35.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.383 seconds
[2025-01-13T18:28:05.895+0000] {processor.py:157} INFO - Started process (PID=27957) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:28:05.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:28:05.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:05.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:28:05.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:05.933+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:28:06.230+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.230+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2725622920006572
[2025-01-13T18:28:06.231+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.231+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|27957]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:28:06.233+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.233+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:28:06.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.233+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:28:06.234+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.234+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:28:06.235+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.235+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|27957]: It took 0.302s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:28:06.241+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.240+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|27957]: It took 0.00585s to build the Airflow DAG.
[2025-01-13T18:28:06.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:28:06.261+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.261+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:28:06.301+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:06.301+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:28:06.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.436 seconds
[2025-01-13T18:28:36.700+0000] {processor.py:157} INFO - Started process (PID=28055) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:28:36.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:28:36.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:36.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:28:36.738+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:36.738+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:28:37.004+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.003+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2475477209991368
[2025-01-13T18:28:37.005+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.004+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28055]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:28:37.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.006+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:28:37.007+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.007+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:28:37.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.007+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:28:37.008+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.008+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28055]: It took 0.27s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:28:37.015+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.015+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28055]: It took 0.00669s to build the Airflow DAG.
[2025-01-13T18:28:37.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:28:37.054+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.054+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:28:37.109+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:28:37.109+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:28:37.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.449 seconds
[2025-01-13T18:29:08.038+0000] {processor.py:157} INFO - Started process (PID=28141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:29:08.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:29:08.041+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:29:08.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.066+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:29:08.267+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.267+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18538475999957882
[2025-01-13T18:29:08.268+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.268+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28141]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:29:08.269+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.269+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:29:08.270+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.270+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:29:08.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.270+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:29:08.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.271+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28141]: It took 0.205s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:29:08.277+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.277+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28141]: It took 0.0057s to build the Airflow DAG.
[2025-01-13T18:29:08.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:29:08.296+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.296+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:29:08.327+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:08.327+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:29:08.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.315 seconds
[2025-01-13T18:29:38.425+0000] {processor.py:157} INFO - Started process (PID=28228) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:29:38.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:29:38.428+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:29:38.460+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.459+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:29:38.720+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.720+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2395980690016586
[2025-01-13T18:29:38.721+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.721+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28228]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:29:38.723+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.722+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:29:38.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.723+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:29:38.724+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.724+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:29:38.725+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.725+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28228]: It took 0.266s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:29:38.734+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.734+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28228]: It took 0.00904s to build the Airflow DAG.
[2025-01-13T18:29:38.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:29:38.759+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.759+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:29:38.794+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:29:38.794+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:29:38.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.401 seconds
[2025-01-13T18:30:08.902+0000] {processor.py:157} INFO - Started process (PID=28313) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:30:08.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:30:08.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:08.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:30:08.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:08.928+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:30:09.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.138+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19513195300169173
[2025-01-13T18:30:09.139+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.139+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28313]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:30:09.140+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.140+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:30:09.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.140+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:30:09.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.141+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:30:09.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.141+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28313]: It took 0.213s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:30:09.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.147+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28313]: It took 0.006s to build the Airflow DAG.
[2025-01-13T18:30:09.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:30:09.166+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.166+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:30:09.197+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:09.197+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:30:09.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.324 seconds
[2025-01-13T18:30:39.437+0000] {processor.py:157} INFO - Started process (PID=28399) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:30:39.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:30:39.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:30:39.472+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.472+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:30:39.703+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.703+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2143219549980131
[2025-01-13T18:30:39.704+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.704+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28399]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:30:39.705+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.705+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:30:39.706+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.706+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:30:39.707+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.707+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:30:39.708+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.708+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28399]: It took 0.236s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:30:39.716+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.716+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28399]: It took 0.00814s to build the Airflow DAG.
[2025-01-13T18:30:39.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:30:39.739+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.739+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:30:39.776+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:30:39.775+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:30:39.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.373 seconds
[2025-01-13T18:31:09.965+0000] {processor.py:157} INFO - Started process (PID=28487) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:31:09.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:31:09.968+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:09.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:31:09.998+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:09.998+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:31:10.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.212+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1971490050018474
[2025-01-13T18:31:10.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.213+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28487]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:31:10.215+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.215+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:31:10.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.216+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:31:10.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.216+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:31:10.217+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.217+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28487]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:31:10.223+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.223+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28487]: It took 0.00565s to build the Airflow DAG.
[2025-01-13T18:31:10.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:31:10.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.242+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:31:10.275+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:10.275+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:31:10.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.346 seconds
[2025-01-13T18:31:40.512+0000] {processor.py:157} INFO - Started process (PID=28574) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:31:40.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:31:40.514+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:31:40.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.546+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:31:40.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.747+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18341291300021112
[2025-01-13T18:31:40.748+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.748+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28574]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:31:40.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.750+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:31:40.750+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.750+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:31:40.751+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.751+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:31:40.752+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.752+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28574]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:31:40.758+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.758+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28574]: It took 0.00632s to build the Airflow DAG.
[2025-01-13T18:31:40.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:31:40.778+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.778+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:31:40.808+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:31:40.808+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:31:40.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.324 seconds
[2025-01-13T18:32:11.642+0000] {processor.py:157} INFO - Started process (PID=28660) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:32:11.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:32:11.644+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:32:11.676+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.676+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:32:11.888+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.888+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19405259999984992
[2025-01-13T18:32:11.889+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.889+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28660]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:32:11.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.890+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:32:11.891+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.891+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:32:11.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.892+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:32:11.892+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.892+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28660]: It took 0.216s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:32:11.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.898+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28660]: It took 0.00607s to build the Airflow DAG.
[2025-01-13T18:32:11.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:32:11.920+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.920+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:32:11.954+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:11.954+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:32:11.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.342 seconds
[2025-01-13T18:32:42.105+0000] {processor.py:157} INFO - Started process (PID=28746) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:32:42.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:32:42.108+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:32:42.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.147+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:32:42.416+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.416+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23451031500007957
[2025-01-13T18:32:42.417+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.417+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28746]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:32:42.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.418+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:32:42.418+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.418+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:32:42.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.419+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:32:42.419+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.419+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28746]: It took 0.273s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:32:42.425+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.425+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28746]: It took 0.00561s to build the Airflow DAG.
[2025-01-13T18:32:42.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:32:42.455+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.455+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:32:42.490+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:32:42.490+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:32:42.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.421 seconds
[2025-01-13T18:33:13.373+0000] {processor.py:157} INFO - Started process (PID=28840) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:33:13.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:33:13.376+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:33:13.406+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.406+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:33:13.636+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.636+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2116277019995323
[2025-01-13T18:33:13.637+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.637+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28840]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:33:13.638+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.638+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:33:13.638+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.638+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:33:13.639+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.639+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:33:13.639+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.639+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28840]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:33:13.645+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.645+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28840]: It took 0.00551s to build the Airflow DAG.
[2025-01-13T18:33:13.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:33:13.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.664+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:33:13.699+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:13.698+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:33:13.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-13T18:33:44.320+0000] {processor.py:157} INFO - Started process (PID=28938) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:33:44.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:33:44.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:33:44.350+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.350+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:33:44.542+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.542+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17569689199808636
[2025-01-13T18:33:44.543+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.543+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|28938]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:33:44.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.544+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:33:44.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.545+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:33:44.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.545+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:33:44.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.545+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|28938]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:33:44.551+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.550+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|28938]: It took 0.00493s to build the Airflow DAG.
[2025-01-13T18:33:44.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:33:44.569+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.569+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:33:44.601+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:33:44.601+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:33:44.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.318 seconds
[2025-01-13T18:34:14.927+0000] {processor.py:157} INFO - Started process (PID=29024) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:34:14.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:34:14.929+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:14.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:34:14.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:14.953+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:34:15.124+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.124+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15693251600168878
[2025-01-13T18:34:15.124+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.124+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29024]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:34:15.125+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.125+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:34:15.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.126+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:34:15.126+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.126+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:34:15.127+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.126+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29024]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:34:15.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.132+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29024]: It took 0.00525s to build the Airflow DAG.
[2025-01-13T18:34:15.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:34:15.147+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.147+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:34:15.171+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:15.171+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:34:15.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-13T18:34:45.510+0000] {processor.py:157} INFO - Started process (PID=29110) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:34:45.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:34:45.512+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:34:45.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.543+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:34:45.817+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.817+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.254712682999525
[2025-01-13T18:34:45.818+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.818+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29110]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:34:45.820+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.819+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:34:45.821+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.820+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:34:45.823+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.822+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:34:45.824+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.824+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29110]: It took 0.28s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:34:45.833+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.832+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29110]: It took 0.00896s to build the Airflow DAG.
[2025-01-13T18:34:45.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:34:45.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.858+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:34:45.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:34:45.897+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:34:45.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.420 seconds
[2025-01-13T18:35:15.994+0000] {processor.py:157} INFO - Started process (PID=29198) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:35:15.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:35:15.997+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:15.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:35:16.024+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.023+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:35:16.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.206+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1680168919992866
[2025-01-13T18:35:16.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.207+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29198]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:35:16.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.208+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:35:16.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.209+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:35:16.210+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.210+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:35:16.211+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.211+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29198]: It took 0.187s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:35:16.216+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.216+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29198]: It took 0.00565s to build the Airflow DAG.
[2025-01-13T18:35:16.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:35:16.236+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.236+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:35:16.271+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:16.270+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:35:16.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-13T18:35:47.184+0000] {processor.py:157} INFO - Started process (PID=29284) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:35:47.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:35:47.186+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:35:47.209+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.209+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:35:47.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.404+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1790791490020638
[2025-01-13T18:35:47.404+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.404+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29284]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:35:47.405+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.405+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:35:47.406+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.406+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:35:47.406+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.406+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:35:47.407+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.407+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29284]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:35:47.412+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.412+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29284]: It took 0.00536s to build the Airflow DAG.
[2025-01-13T18:35:47.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:35:47.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.430+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:35:47.457+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:35:47.457+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:35:47.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-13T18:36:17.678+0000] {processor.py:157} INFO - Started process (PID=29378) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:36:17.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:36:17.681+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:36:17.709+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.708+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:36:17.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.961+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2361424779992376
[2025-01-13T18:36:17.961+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.961+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29378]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:36:17.963+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.963+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:36:17.964+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.963+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:36:17.964+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.964+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:36:17.965+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.965+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29378]: It took 0.256s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:36:17.970+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.970+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29378]: It took 0.00566s to build the Airflow DAG.
[2025-01-13T18:36:17.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:36:17.991+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:17.991+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:36:18.025+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:18.025+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:36:18.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.379 seconds
[2025-01-13T18:36:48.210+0000] {processor.py:157} INFO - Started process (PID=29477) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:36:48.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:36:48.213+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:36:48.243+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.243+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:36:48.482+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.482+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2195898190002481
[2025-01-13T18:36:48.483+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.483+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29477]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:36:48.484+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.484+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:36:48.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.484+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:36:48.485+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.485+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:36:48.486+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.486+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29477]: It took 0.243s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:36:48.491+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.491+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29477]: It took 0.00547s to build the Airflow DAG.
[2025-01-13T18:36:48.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:36:48.510+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.509+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:36:48.538+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:36:48.538+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:36:48.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.355 seconds
[2025-01-13T18:37:19.448+0000] {processor.py:157} INFO - Started process (PID=29564) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:37:19.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:37:19.450+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:37:19.475+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.475+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:37:19.623+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.623+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13427587900150684
[2025-01-13T18:37:19.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.623+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29564]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:37:19.624+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.624+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:37:19.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.625+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:37:19.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.625+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:37:19.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.626+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29564]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:37:19.630+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.630+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29564]: It took 0.00457s to build the Airflow DAG.
[2025-01-13T18:37:19.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:37:19.647+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.646+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:37:19.677+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:19.677+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:37:19.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-13T18:37:50.036+0000] {processor.py:157} INFO - Started process (PID=29650) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:37:50.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:37:50.038+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:37:50.069+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.069+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:37:50.302+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.302+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21389289400030975
[2025-01-13T18:37:50.303+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.303+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29650]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:37:50.304+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.304+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:37:50.305+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.305+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:37:50.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.305+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:37:50.306+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.306+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29650]: It took 0.237s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:37:50.312+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.311+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29650]: It took 0.00531s to build the Airflow DAG.
[2025-01-13T18:37:50.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:37:50.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.333+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:37:50.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:37:50.371+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:37:50.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.363 seconds
[2025-01-13T18:38:21.330+0000] {processor.py:157} INFO - Started process (PID=29737) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:38:21.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:38:21.332+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:38:21.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.358+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:38:21.529+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.529+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15747496300173225
[2025-01-13T18:38:21.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.529+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29737]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:38:21.530+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.530+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:38:21.531+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.531+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:38:21.531+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.531+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:38:21.532+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.532+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29737]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:38:21.537+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.536+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29737]: It took 0.0048s to build the Airflow DAG.
[2025-01-13T18:38:21.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:38:21.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.554+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:38:21.580+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:21.580+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:38:21.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-13T18:38:51.666+0000] {processor.py:157} INFO - Started process (PID=29824) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:38:51.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:38:51.668+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:38:51.698+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.697+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:38:51.899+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.899+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18802667600175482
[2025-01-13T18:38:51.900+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.900+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29824]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:38:51.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.902+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:38:51.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.902+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:38:51.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.903+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:38:51.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.904+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29824]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:38:51.912+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.911+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29824]: It took 0.00771s to build the Airflow DAG.
[2025-01-13T18:38:51.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:38:51.933+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.932+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:38:51.966+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:38:51.966+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:38:51.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.334 seconds
[2025-01-13T18:39:22.405+0000] {processor.py:157} INFO - Started process (PID=29909) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:39:22.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:39:22.406+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:39:22.433+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.433+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:39:22.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.625+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17345889599891962
[2025-01-13T18:39:22.625+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.625+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29909]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:39:22.626+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.626+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:39:22.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.627+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:39:22.627+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.627+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:39:22.628+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.628+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29909]: It took 0.195s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:39:22.633+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.633+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29909]: It took 0.00496s to build the Airflow DAG.
[2025-01-13T18:39:22.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:39:22.650+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.650+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:39:22.679+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:22.678+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:39:22.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.300 seconds
[2025-01-13T18:39:52.803+0000] {processor.py:157} INFO - Started process (PID=29995) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:39:52.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:39:52.805+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:52.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:39:52.828+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:52.828+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:39:53.018+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.018+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17488858999786316
[2025-01-13T18:39:53.019+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.018+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|29995]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:39:53.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.019+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:39:53.020+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.020+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:39:53.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.020+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:39:53.021+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.021+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|29995]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:39:53.027+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.027+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|29995]: It took 0.00586s to build the Airflow DAG.
[2025-01-13T18:39:53.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:39:53.045+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.045+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:39:53.076+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:39:53.076+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:39:53.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.300 seconds
[2025-01-13T18:40:23.390+0000] {processor.py:157} INFO - Started process (PID=30081) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:40:23.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:40:23.393+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:40:23.430+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.430+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:40:23.661+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.661+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.213688739000645
[2025-01-13T18:40:23.662+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.661+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30081]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:40:23.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.662+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:40:23.663+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.663+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:40:23.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.663+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:40:23.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.664+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30081]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:40:23.670+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.670+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30081]: It took 0.00557s to build the Airflow DAG.
[2025-01-13T18:40:23.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:40:23.693+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.692+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:40:23.728+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:23.728+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:40:23.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.370 seconds
[2025-01-13T18:40:54.063+0000] {processor.py:157} INFO - Started process (PID=30167) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:40:54.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:40:54.066+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:40:54.092+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.091+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:40:54.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.292+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18357623200063244
[2025-01-13T18:40:54.292+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.292+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30167]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:40:54.293+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.293+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:40:54.294+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.294+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:40:54.294+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.294+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:40:54.295+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.295+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30167]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:40:54.300+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.300+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30167]: It took 0.0055s to build the Airflow DAG.
[2025-01-13T18:40:54.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:40:54.321+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.321+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:40:54.353+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:40:54.352+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:40:54.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-13T18:41:24.529+0000] {processor.py:157} INFO - Started process (PID=30254) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:41:24.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:41:24.532+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:41:24.564+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.563+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:41:24.856+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.856+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.26912011000240454
[2025-01-13T18:41:24.857+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.856+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30254]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:41:24.858+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.858+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:41:24.859+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.859+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:41:24.860+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.860+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:41:24.861+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.861+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30254]: It took 0.297s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:41:24.868+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.868+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30254]: It took 0.0072s to build the Airflow DAG.
[2025-01-13T18:41:24.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:41:24.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.897+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:41:24.949+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:24.949+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:41:24.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.458 seconds
[2025-01-13T18:41:55.331+0000] {processor.py:157} INFO - Started process (PID=30337) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:41:55.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:41:55.333+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:41:55.371+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.371+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:41:55.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.604+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2111468020011671
[2025-01-13T18:41:55.606+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.605+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30337]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:41:55.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.607+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:41:55.607+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.607+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:41:55.608+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.608+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:41:55.609+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.608+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30337]: It took 0.238s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:41:55.614+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.614+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30337]: It took 0.00569s to build the Airflow DAG.
[2025-01-13T18:41:55.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:41:55.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.634+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:41:55.664+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:41:55.664+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:41:55.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.378 seconds
[2025-01-13T18:42:25.881+0000] {processor.py:157} INFO - Started process (PID=30433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:42:25.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:42:25.884+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:25.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:42:25.912+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:25.912+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:42:26.128+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.128+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19921361000160687
[2025-01-13T18:42:26.129+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.129+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30433]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:42:26.130+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.130+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:42:26.131+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.131+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:42:26.132+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.132+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:42:26.133+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.133+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30433]: It took 0.221s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:42:26.141+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.141+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30433]: It took 0.00831s to build the Airflow DAG.
[2025-01-13T18:42:26.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:42:26.175+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.174+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:42:26.224+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:26.223+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:42:26.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.383 seconds
[2025-01-13T18:42:56.980+0000] {processor.py:157} INFO - Started process (PID=30530) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:42:56.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:42:56.981+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:56.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:42:57.006+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.005+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:42:57.205+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.204+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18164427200099453
[2025-01-13T18:42:57.205+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.205+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30530]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:42:57.206+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.206+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:42:57.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.206+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:42:57.207+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.207+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:42:57.208+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.208+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30530]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:42:57.214+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.213+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30530]: It took 0.00571s to build the Airflow DAG.
[2025-01-13T18:42:57.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:42:57.233+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.233+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:42:57.263+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:42:57.263+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:42:57.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-13T18:43:28.295+0000] {processor.py:157} INFO - Started process (PID=30617) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:43:28.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:43:28.297+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:43:28.323+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.323+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:43:28.500+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.500+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16326218500034884
[2025-01-13T18:43:28.501+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.501+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30617]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:43:28.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.501+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:43:28.502+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.502+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:43:28.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.502+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:43:28.503+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.503+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30617]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:43:28.510+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.509+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30617]: It took 0.00667s to build the Airflow DAG.
[2025-01-13T18:43:28.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:43:28.526+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.526+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:43:28.557+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:28.556+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:43:28.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-13T18:43:59.082+0000] {processor.py:157} INFO - Started process (PID=30704) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:43:59.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:43:59.085+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:43:59.112+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.112+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:43:59.355+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.355+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22397773400007281
[2025-01-13T18:43:59.356+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.356+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30704]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:43:59.357+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.357+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:43:59.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.358+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:43:59.358+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.358+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:43:59.359+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.359+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30704]: It took 0.247s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:43:59.367+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.367+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30704]: It took 0.0084s to build the Airflow DAG.
[2025-01-13T18:43:59.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:43:59.396+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.396+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:43:59.439+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:43:59.439+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:43:59.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.389 seconds
[2025-01-13T18:44:29.685+0000] {processor.py:157} INFO - Started process (PID=30790) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:44:29.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:44:29.687+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:44:29.715+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.715+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:44:29.902+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.902+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1699112980022619
[2025-01-13T18:44:29.903+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.903+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30790]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:44:29.904+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.904+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:44:29.905+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.905+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:44:29.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.906+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:44:29.906+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.906+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30790]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:44:29.912+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.912+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30790]: It took 0.00564s to build the Airflow DAG.
[2025-01-13T18:44:29.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:44:29.942+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.941+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:44:29.984+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:44:29.984+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:44:30.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-13T18:45:00.319+0000] {processor.py:157} INFO - Started process (PID=30876) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:45:00.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:45:00.322+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:45:00.345+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.345+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:45:00.543+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.543+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1827923099990585
[2025-01-13T18:45:00.544+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.544+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30876]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:45:00.545+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.545+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:45:00.546+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.546+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:45:00.547+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.547+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:45:00.548+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.548+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30876]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:45:00.554+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.554+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30876]: It took 0.00627s to build the Airflow DAG.
[2025-01-13T18:45:00.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:45:00.582+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.582+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:45:00.616+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:00.615+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:45:00.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.323 seconds
[2025-01-13T18:45:30.730+0000] {processor.py:157} INFO - Started process (PID=30964) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:45:30.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:45:30.733+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:45:30.761+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.760+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:45:30.953+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.953+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17590987099902122
[2025-01-13T18:45:30.954+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.954+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|30964]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:45:30.955+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.955+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:45:30.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.955+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:45:30.956+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.956+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:45:30.957+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.957+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|30964]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:45:30.962+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.962+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|30964]: It took 0.00549s to build the Airflow DAG.
[2025-01-13T18:45:30.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:45:30.982+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:30.982+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:45:31.013+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:45:31.012+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:45:31.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.311 seconds
[2025-01-13T18:46:01.243+0000] {processor.py:157} INFO - Started process (PID=31048) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:46:01.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:46:01.245+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:46:01.270+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.270+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:46:01.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.466+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17775327100025606
[2025-01-13T18:46:01.466+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.466+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|31048]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:46:01.467+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.467+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:46:01.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.468+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:46:01.468+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.468+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:46:01.469+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.469+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|31048]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:46:01.474+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.474+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|31048]: It took 0.00558s to build the Airflow DAG.
[2025-01-13T18:46:01.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:46:01.495+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.494+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:46:01.532+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:01.532+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:46:01.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.319 seconds
[2025-01-13T18:46:31.603+0000] {processor.py:157} INFO - Started process (PID=31141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:46:31.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-13T18:46:31.605+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:46:31.634+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.633+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-13T18:46:31.860+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.860+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21016749299815274
[2025-01-13T18:46:31.860+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.860+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|31141]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-13T18:46:31.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.861+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 53a7198c1a1ad59d9972e2652a497cbe,d41d8cd98f00b204e9800998ecf8427e
[2025-01-13T18:46:31.862+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.862+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-13T18:46:31.863+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.863+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-13T18:46:31.864+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.863+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|31141]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-13T18:46:31.870+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.869+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|31141]: It took 0.00619s to build the Airflow DAG.
[2025-01-13T18:46:31.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-13T18:46:31.898+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.898+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-13T18:46:31.938+0000] {logging_mixin.py:151} INFO - [2025-01-13T18:46:31.938+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-13T00:00:00+00:00, run_after=2025-01-14T00:00:00+00:00
[2025-01-13T18:46:31.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.369 seconds
