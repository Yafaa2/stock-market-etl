[2025-01-09T00:00:24.340+0000] {processor.py:153} INFO - Started process (PID=2535) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:00:24.342+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:00:24.346+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:00:24.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:00:24.730+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:00:24,729] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:00:24.800+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:00:24,799] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:00:24.800+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:00:24,800] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:00:24.812+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:00:24.853+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:00:24.853+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:00:24.912+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:00:24.911+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:00:24.956+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.623 seconds
[2025-01-09T00:00:55.097+0000] {processor.py:153} INFO - Started process (PID=2617) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:00:55.098+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:00:55.099+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:00:55.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:00:55.237+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:00:55,237] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:00:55.289+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:00:55,288] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:00:55.289+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:00:55,289] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:00:55.300+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:00:55.329+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:00:55.328+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:00:55.364+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:00:55.364+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:00:55.428+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-09T00:01:25.954+0000] {processor.py:153} INFO - Started process (PID=2697) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:01:25.955+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:01:25.956+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:01:25.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:01:26.085+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:01:26,085] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:01:26.139+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:01:26,138] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:01:26.139+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:01:26,139] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:01:26.148+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:01:26.180+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:01:26.180+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:01:26.222+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:01:26.222+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:01:26.402+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.451 seconds
[2025-01-09T00:01:56.495+0000] {processor.py:153} INFO - Started process (PID=2797) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:01:56.495+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:01:56.496+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:01:56.496+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:01:56.614+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:01:56,614] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:01:56.652+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:01:56,652] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:01:56.652+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:01:56,652] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:01:56.660+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:01:56.685+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:01:56.685+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:01:56.716+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:01:56.716+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:01:56.743+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-09T00:02:26.951+0000] {processor.py:153} INFO - Started process (PID=2878) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:02:26.952+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:02:26.953+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:02:26.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:02:27.066+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:02:27,066] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:02:27.106+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:02:27,106] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:02:27.106+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:02:27,106] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:02:27.115+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:02:27.150+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:02:27.150+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:02:27.180+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:02:27.180+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:02:27.219+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-09T00:02:57.271+0000] {processor.py:153} INFO - Started process (PID=2968) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:02:57.272+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:02:57.273+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:02:57.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:02:57.390+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:02:57,390] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:02:57.438+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:02:57,438] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:02:57.439+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:02:57,439] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:02:57.448+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:02:57.474+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:02:57.474+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:02:57.503+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:02:57.503+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:02:57.531+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-09T00:03:27.601+0000] {processor.py:153} INFO - Started process (PID=3059) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:03:27.602+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:03:27.603+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:03:27.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:03:27.724+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:03:27,724] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:03:27.761+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:03:27,761] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:03:27.761+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:03:27,761] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:03:27.769+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:03:27.792+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:03:27.792+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:03:27.817+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:03:27.817+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:03:27.849+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-09T00:03:58.112+0000] {processor.py:153} INFO - Started process (PID=3144) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:03:58.113+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:03:58.114+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:03:58.114+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:03:58.233+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:03:58,233] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:03:58.282+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:03:58,282] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:03:58.282+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:03:58,282] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:03:58.291+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:03:58.319+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:03:58.319+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:03:58.350+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:03:58.350+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:03:58.380+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-09T00:04:28.489+0000] {processor.py:153} INFO - Started process (PID=3237) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:04:28.490+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:04:28.491+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:04:28.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:04:28.596+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:04:28,596] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:04:28.645+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:04:28,645] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:04:28.645+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:04:28,645] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:04:28.653+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:04:28.681+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:04:28.681+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:04:28.710+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:04:28.710+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:04:28.736+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-09T00:04:58.919+0000] {processor.py:153} INFO - Started process (PID=3318) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:04:58.922+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:04:58.926+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:04:58.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:04:59.051+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:04:59,051] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:04:59.093+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:04:59,093] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:04:59.094+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:04:59,094] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:04:59.103+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:04:59.130+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:04:59.130+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:04:59.171+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:04:59.171+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:04:59.200+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-09T00:05:29.488+0000] {processor.py:153} INFO - Started process (PID=3417) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:05:29.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:05:29.490+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:05:29.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:05:29.620+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:05:29,619] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:05:29.685+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:05:29,685] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:05:29.686+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:05:29,686] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:05:29.704+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:05:29.759+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:05:29.759+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:05:29.800+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:05:29.800+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:05:29.825+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.340 seconds
[2025-01-09T00:05:59.908+0000] {processor.py:153} INFO - Started process (PID=3498) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:05:59.909+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:05:59.910+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:05:59.909+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:06:00.025+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:06:00,025] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:06:00.067+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:06:00,066] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:06:00.067+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:06:00,067] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:06:00.076+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:06:00.105+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:06:00.105+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:06:00.135+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:06:00.135+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:06:00.160+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-09T00:06:30.432+0000] {processor.py:153} INFO - Started process (PID=3597) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:06:30.433+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:06:30.434+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:06:30.434+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:06:30.584+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:06:30,584] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:06:30.635+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:06:30,635] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:06:30.635+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:06:30,635] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:06:30.646+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:06:30.675+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:06:30.674+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:06:30.712+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:06:30.712+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:06:30.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.314 seconds
[2025-01-09T00:07:01.579+0000] {processor.py:153} INFO - Started process (PID=3677) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:07:01.580+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:07:01.580+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:07:01.580+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:07:01.691+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:07:01,690] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:07:01.737+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:07:01,737] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:07:01.737+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:07:01,737] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:07:01.746+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:07:01.770+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:07:01.770+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:07:01.802+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:07:01.802+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:07:01.835+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-09T00:07:32.055+0000] {processor.py:153} INFO - Started process (PID=3767) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:07:32.056+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:07:32.058+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:07:32.057+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:07:32.202+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:07:32,202] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:07:32.262+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:07:32,261] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:07:32.262+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:07:32,262] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:07:32.272+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:07:32.301+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:07:32.301+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:07:32.335+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:07:32.335+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:07:32.361+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-09T00:08:02.432+0000] {processor.py:153} INFO - Started process (PID=3858) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:08:02.433+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:08:02.434+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:08:02.434+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:08:02.550+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:08:02,550] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:08:02.593+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:08:02,593] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:08:02.593+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:08:02,593] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:08:02.602+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:08:02.635+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:08:02.635+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:08:02.662+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:08:02.662+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:08:02.686+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-09T00:08:32.783+0000] {processor.py:153} INFO - Started process (PID=3938) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:08:32.784+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:08:32.785+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:08:32.785+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:08:32.889+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:08:32,889] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:08:32.937+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:08:32,937] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:08:32.937+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:08:32,937] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:08:32.946+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:08:32.969+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:08:32.969+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:08:32.995+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:08:32.995+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:08:33.021+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T00:09:03.148+0000] {processor.py:153} INFO - Started process (PID=4039) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:09:03.149+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:09:03.150+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:09:03.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:09:03.262+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:09:03,262] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:09:03.299+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:09:03,299] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:09:03.300+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:09:03,299] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:09:03.307+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:09:03.331+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:09:03.331+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:09:03.358+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:09:03.358+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:09:03.381+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-09T00:09:33.433+0000] {processor.py:153} INFO - Started process (PID=4120) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:09:33.434+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:09:33.435+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:09:33.435+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:09:33.575+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:09:33,575] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:09:33.631+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:09:33,631] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:09:33.632+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:09:33,632] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:09:33.642+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:09:33.669+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:09:33.669+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:09:33.700+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:09:33.700+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:09:33.728+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-09T00:10:03.786+0000] {processor.py:153} INFO - Started process (PID=4218) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:10:03.787+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:10:03.788+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:10:03.788+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:10:03.905+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:10:03,904] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:10:03.957+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:10:03,957] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:10:03.957+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:10:03,957] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:10:03.967+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:10:03.995+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:10:03.995+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:10:04.029+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:10:04.029+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:10:04.056+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-09T00:10:34.237+0000] {processor.py:153} INFO - Started process (PID=4299) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:10:34.238+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:10:34.239+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:10:34.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:10:34.362+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:10:34,361] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:10:34.407+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:10:34,406] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:10:34.407+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:10:34,407] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:10:34.417+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:10:34.444+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:10:34.444+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:10:34.476+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:10:34.476+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:10:34.507+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-09T00:11:04.667+0000] {processor.py:153} INFO - Started process (PID=4398) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:11:04.668+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:11:04.670+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:11:04.669+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:11:04.788+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:11:04,788] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:11:04.846+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:11:04,846] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:11:04.846+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:11:04,846] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:11:04.856+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:11:04.885+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:11:04.885+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:11:04.913+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:11:04.913+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:11:04.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.276 seconds
[2025-01-09T00:11:35.041+0000] {processor.py:153} INFO - Started process (PID=4478) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:11:35.042+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:11:35.042+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:11:35.042+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:11:35.156+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:11:35,156] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:11:35.214+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:11:35,214] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:11:35.215+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:11:35,215] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:11:35.224+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:11:35.251+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:11:35.251+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:11:35.280+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:11:35.280+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:11:35.311+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-09T00:12:05.490+0000] {processor.py:153} INFO - Started process (PID=4579) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:12:05.491+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:12:05.491+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:12:05.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:12:05.612+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:12:05,612] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:12:05.655+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:12:05,655] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:12:05.656+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:12:05,656] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:12:05.665+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:12:05.691+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:12:05.691+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:12:05.723+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:12:05.723+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:12:05.754+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-09T00:12:35.816+0000] {processor.py:153} INFO - Started process (PID=4660) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:12:35.817+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:12:35.819+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:12:35.819+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:12:35.955+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:12:35,955] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:12:36.002+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:12:36,001] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:12:36.002+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:12:36,002] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:12:36.011+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:12:36.038+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:12:36.038+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:12:36.070+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:12:36.070+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:12:36.099+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-09T00:13:06.159+0000] {processor.py:153} INFO - Started process (PID=4750) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:13:06.160+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:13:06.161+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:13:06.161+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:13:06.280+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:13:06,279] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:13:06.324+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:13:06,324] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:13:06.325+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:13:06,325] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:13:06.334+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:13:06.360+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:13:06.360+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:13:06.388+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:13:06.388+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:13:06.417+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-09T00:13:36.571+0000] {processor.py:153} INFO - Started process (PID=4842) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:13:36.572+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:13:36.573+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:13:36.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:13:36.681+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:13:36,680] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:13:36.725+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:13:36,725] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:13:36.726+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:13:36,725] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:13:36.733+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:13:36.756+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:13:36.756+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:13:36.785+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:13:36.784+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:13:36.810+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-09T00:14:07.216+0000] {processor.py:153} INFO - Started process (PID=4919) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:14:07.217+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:14:07.218+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:14:07.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:14:07.358+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:14:07,358] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:14:07.427+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:14:07,426] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:14:07.427+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:14:07,427] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:14:07.443+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:14:07.474+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:14:07.474+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:14:07.509+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:14:07.509+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:14:07.551+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.340 seconds
[2025-01-09T00:14:37.731+0000] {processor.py:153} INFO - Started process (PID=5019) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:14:37.733+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:14:37.734+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:14:37.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:14:37.892+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:14:37,892] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:14:37.940+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:14:37,940] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:14:37.941+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:14:37,941] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:14:37.953+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:14:37.987+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:14:37.987+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:14:38.031+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:14:38.031+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:14:38.065+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.339 seconds
[2025-01-09T00:15:08.572+0000] {processor.py:153} INFO - Started process (PID=5099) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:15:08.573+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:15:08.574+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:15:08.574+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:15:08.719+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:15:08,719] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:15:08.767+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:15:08,767] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:15:08.767+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:15:08,767] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:15:08.780+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:15:08.806+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:15:08.806+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:15:08.841+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:15:08.841+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:15:08.875+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-09T00:15:39.394+0000] {processor.py:153} INFO - Started process (PID=5189) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:15:39.395+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:15:39.396+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:15:39.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:15:39.568+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:15:39,568] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:15:39.632+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:15:39,632] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:15:39.633+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:15:39,632] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:15:39.646+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:15:39.680+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:15:39.680+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:15:39.727+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:15:39.727+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:15:39.762+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.373 seconds
[2025-01-09T00:16:09.897+0000] {processor.py:153} INFO - Started process (PID=5280) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:16:09.898+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:16:09.899+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:16:09.899+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:16:10.018+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:16:10,018] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:16:10.070+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:16:10,069] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:16:10.071+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:16:10,070] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:16:10.084+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:16:10.114+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:16:10.114+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:16:10.146+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:16:10.146+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:16:10.176+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-09T00:16:40.604+0000] {processor.py:153} INFO - Started process (PID=5360) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:16:40.605+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:16:40.606+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:16:40.605+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:16:40.730+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:16:40,730] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:16:40.771+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:16:40,771] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:16:40.772+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:16:40,772] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:16:40.781+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:16:40.807+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:16:40.807+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:16:40.841+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:16:40.841+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:16:40.871+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.272 seconds
[2025-01-09T00:17:11.065+0000] {processor.py:153} INFO - Started process (PID=5441) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:17:11.066+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:17:11.067+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:17:11.067+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:17:11.254+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:17:11,253] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:17:11.302+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:17:11,302] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:17:11.302+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:17:11,302] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:17:11.327+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:17:11.402+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:17:11.401+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:17:11.450+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:17:11.450+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:17:11.482+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.423 seconds
[2025-01-09T00:17:42.171+0000] {processor.py:153} INFO - Started process (PID=5541) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:17:42.183+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:17:42.184+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:17:42.184+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:17:42.411+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:17:42,406] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:17:42.457+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:17:42,457] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:17:42.457+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:17:42,457] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:17:42.466+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:17:42.493+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:17:42.493+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:17:42.522+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:17:42.522+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:17:42.548+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.383 seconds
[2025-01-09T00:18:12.730+0000] {processor.py:153} INFO - Started process (PID=5622) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:18:12.731+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:18:12.732+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:18:12.732+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:18:12.883+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:18:12,882] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:18:12.927+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:18:12,927] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:18:12.927+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:18:12,927] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:18:12.937+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:18:12.973+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:18:12.972+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:18:13.010+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:18:13.010+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:18:13.043+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-09T00:18:43.352+0000] {processor.py:153} INFO - Started process (PID=5722) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:18:43.353+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:18:43.354+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:18:43.354+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:18:43.479+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:18:43,479] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:18:43.536+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:18:43,536] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:18:43.537+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:18:43,537] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:18:43.548+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:18:43.579+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:18:43.579+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:18:43.616+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:18:43.616+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:18:43.651+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.302 seconds
[2025-01-09T00:19:13.716+0000] {processor.py:153} INFO - Started process (PID=5802) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:19:13.717+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:19:13.718+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:19:13.718+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:19:13.856+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:19:13,855] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:19:13.920+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:19:13,919] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:19:13.920+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:19:13,920] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:19:13.958+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:19:14.031+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:19:14.031+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:19:14.078+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:19:14.078+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:19:14.116+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.404 seconds
[2025-01-09T00:19:44.299+0000] {processor.py:153} INFO - Started process (PID=5892) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:19:44.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:19:44.301+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:19:44.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:19:44.439+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:19:44,439] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:19:44.491+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:19:44,490] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:19:44.491+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:19:44,491] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:19:44.513+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:19:44.570+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:19:44.570+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:19:44.626+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:19:44.625+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:19:44.656+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.361 seconds
[2025-01-09T00:20:14.758+0000] {processor.py:153} INFO - Started process (PID=5982) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:20:14.759+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:20:14.760+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:20:14.760+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:20:14.880+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:20:14,880] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:20:14.924+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:20:14,923] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:20:14.924+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:20:14,924] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:20:14.932+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:20:14.959+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:20:14.959+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:20:15.003+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:20:15.003+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:20:15.037+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-09T00:20:45.225+0000] {processor.py:153} INFO - Started process (PID=6062) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:20:45.226+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:20:45.227+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:20:45.227+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:20:45.341+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:20:45,341] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:20:45.383+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:20:45,383] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:20:45.383+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:20:45,383] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:20:45.391+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:20:45.414+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:20:45.414+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:20:45.442+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:20:45.442+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:20:45.466+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-09T00:21:16.028+0000] {processor.py:153} INFO - Started process (PID=6162) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:21:16.029+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:21:16.029+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:21:16.029+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:21:16.134+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:21:16,134] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:21:16.178+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:21:16,178] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:21:16.179+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:21:16,179] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:21:16.187+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:21:16.210+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:21:16.210+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:21:16.236+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:21:16.236+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:21:16.260+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-09T00:21:46.404+0000] {processor.py:153} INFO - Started process (PID=6243) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:21:46.405+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:21:46.405+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:21:46.405+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:21:46.515+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:21:46,515] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:21:46.554+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:21:46,554] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:21:46.554+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:21:46,554] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:21:46.562+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:21:46.585+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:21:46.585+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:21:46.613+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:21:46.613+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:21:46.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-09T00:22:17.018+0000] {processor.py:153} INFO - Started process (PID=6342) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:22:17.018+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:22:17.019+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:22:17.019+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:22:17.163+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:22:17,163] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-09T00:22:17.220+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:22:17,220] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-09T00:22:17.220+0000] {logging_mixin.py:137} WARNING - [2025-01-09 00:22:17,220] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-09T00:22:17.229+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:22:17.256+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:22:17.256+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-09T00:22:17.289+0000] {logging_mixin.py:137} INFO - [2025-01-09T00:22:17.289+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T00:22:17.314+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-09T00:28:49.772+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:28:49.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:28:49.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:28:49.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:28:49.818+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:28:49.818+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:28:49.835+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:28:49.835+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:28:49.841+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:28:49.836+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:28:49.841+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:28:49.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.087 seconds
[2025-01-09T00:29:20.015+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:29:20.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:29:20.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:20.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:29:20.057+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:20.057+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:29:20.072+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:20.072+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:29:20.079+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:20.073+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:29:20.080+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:29:20.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.081 seconds
[2025-01-09T00:29:50.291+0000] {processor.py:157} INFO - Started process (PID=248) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:29:50.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:29:50.295+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:50.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:29:50.319+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:50.318+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:29:50.333+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:50.333+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:29:50.338+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:29:50.334+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:29:50.339+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:29:50.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.061 seconds
[2025-01-09T00:30:20.389+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:30:20.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:30:20.393+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:20.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:30:20.420+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:20.420+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:30:20.435+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:20.435+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:30:20.441+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:20.436+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:30:20.442+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:30:20.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.076 seconds
[2025-01-09T00:30:50.536+0000] {processor.py:157} INFO - Started process (PID=444) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:30:50.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:30:50.540+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:50.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:30:50.567+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:50.567+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:30:50.581+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:50.581+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:30:50.588+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:30:50.582+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:30:50.589+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:30:50.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.072 seconds
[2025-01-09T00:31:21.083+0000] {processor.py:157} INFO - Started process (PID=530) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:31:21.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:31:21.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:21.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:31:21.116+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:21.115+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:31:21.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:21.130+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:31:21.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:21.131+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:31:21.138+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:31:21.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.068 seconds
[2025-01-09T00:31:51.675+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:31:51.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:31:51.678+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:51.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:31:51.701+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:51.701+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:31:51.714+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:51.714+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:31:51.720+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:31:51.715+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:31:51.720+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:31:51.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.057 seconds
[2025-01-09T00:32:21.892+0000] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:32:21.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:32:21.896+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:21.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:32:21.918+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:21.918+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:32:21.931+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:21.931+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:32:21.938+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:21.932+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:32:21.939+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:32:21.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.059 seconds
[2025-01-09T00:32:52.141+0000] {processor.py:157} INFO - Started process (PID=789) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:32:52.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:32:52.145+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:52.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:32:52.169+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:52.169+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:32:52.181+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:52.181+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:32:52.187+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:32:52.182+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:32:52.187+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:32:52.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.077 seconds
[2025-01-09T00:33:22.485+0000] {processor.py:157} INFO - Started process (PID=894) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:33:22.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:33:22.489+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:33:22.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:33:22.515+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:33:22.515+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:33:22.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:33:22.530+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:41:21.982+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:41:21.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:41:21.988+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:21.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:41:22.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:22.018+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:41:22.036+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:22.035+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:41:22.047+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:22.036+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:41:22.047+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:41:22.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.082 seconds
[2025-01-09T00:41:52.888+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:41:52.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:41:52.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:52.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:41:52.919+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:52.919+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:41:52.934+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:52.934+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:41:52.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:41:52.934+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:41:52.939+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:41:52.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.068 seconds
[2025-01-09T00:42:23.448+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:42:23.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:42:23.451+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:23.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:42:23.480+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:23.479+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:42:23.493+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:23.493+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:42:23.500+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:23.494+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:42:23.500+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:42:23.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.066 seconds
[2025-01-09T00:42:53.784+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:42:53.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:42:53.788+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:53.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:42:53.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:53.812+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:42:53.826+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:53.826+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:42:53.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:42:53.827+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:42:53.833+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:42:53.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.085 seconds
[2025-01-09T00:43:23.964+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:43:23.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:43:23.968+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:23.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:43:23.993+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:23.993+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:43:24.007+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:24.007+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:43:24.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:24.008+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:43:24.016+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:43:24.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T00:43:54.455+0000] {processor.py:157} INFO - Started process (PID=500) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:43:54.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:43:54.458+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:54.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:43:54.485+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:54.485+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:43:54.498+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:54.498+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:43:54.504+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:43:54.499+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:43:54.505+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:43:54.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.070 seconds
[2025-01-09T00:44:25.073+0000] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:44:25.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:44:25.076+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:25.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:44:25.100+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:25.100+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:44:25.113+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:25.113+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:44:25.120+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:25.114+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:44:25.121+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:44:25.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.068 seconds
[2025-01-09T00:44:55.473+0000] {processor.py:157} INFO - Started process (PID=673) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:44:55.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:44:55.477+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:55.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:44:55.502+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:55.502+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:44:55.520+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:55.520+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:44:55.526+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:44:55.521+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:44:55.527+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:44:55.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.078 seconds
[2025-01-09T00:45:25.785+0000] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:45:25.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:45:25.794+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:45:25.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:45:25.848+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:45:25.848+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:45:25.877+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:45:25.876+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:45:25.886+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:45:25.878+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:45:25.887+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:45:25.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.129 seconds
[2025-01-09T00:46:15.382+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:46:15.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:46:15.392+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:15.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:46:15.436+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:15.436+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:46:15.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:15.462+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:46:15.472+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:15.464+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:46:15.473+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:46:15.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.120 seconds
[2025-01-09T00:46:45.625+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:46:45.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:46:45.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:45.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:46:45.653+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:45.653+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:46:45.665+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:45.665+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:46:45.671+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:46:45.666+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:46:45.671+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:46:45.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T00:47:15.759+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:47:15.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:47:15.762+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:15.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:47:15.791+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:15.791+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:47:15.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:15.802+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:47:15.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:15.803+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:47:15.812+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:47:15.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.066 seconds
[2025-01-09T00:47:46.403+0000] {processor.py:157} INFO - Started process (PID=336) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:47:46.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:47:46.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:46.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:47:46.434+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:46.434+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:47:46.448+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:46.448+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:47:46.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:47:46.449+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:47:46.464+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:47:46.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.073 seconds
[2025-01-09T00:48:16.653+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:48:16.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:48:16.656+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:16.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:48:16.690+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:16.690+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:48:16.707+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:16.706+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:48:16.711+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:16.707+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:48:16.711+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:48:16.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.071 seconds
[2025-01-09T00:48:47.343+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:48:47.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:48:47.346+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:47.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:48:47.372+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:47.371+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:48:47.386+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:47.386+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:48:47.392+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:48:47.386+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:48:47.393+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:48:47.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.063 seconds
[2025-01-09T00:49:17.497+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:49:17.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:49:17.501+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:17.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:49:17.523+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:17.522+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:49:17.534+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:17.534+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:49:17.540+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:17.535+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:49:17.540+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:49:17.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.068 seconds
[2025-01-09T00:49:47.744+0000] {processor.py:157} INFO - Started process (PID=692) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:49:47.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:49:47.747+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:47.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:49:47.770+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:47.770+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:49:47.781+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:47.781+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:49:47.788+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:49:47.782+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:49:47.788+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:49:47.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.063 seconds
[2025-01-09T00:50:18.613+0000] {processor.py:157} INFO - Started process (PID=786) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:50:18.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:50:18.617+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:18.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:50:18.642+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:18.642+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:50:18.658+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:18.658+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:50:18.664+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:18.659+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:50:18.665+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:50:18.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.087 seconds
[2025-01-09T00:50:49.411+0000] {processor.py:157} INFO - Started process (PID=883) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:50:49.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:50:49.414+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:49.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:50:49.437+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:49.436+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:50:49.449+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:49.449+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:50:49.455+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:50:49.450+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:50:49.456+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:50:49.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.057 seconds
[2025-01-09T00:51:19.995+0000] {processor.py:157} INFO - Started process (PID=969) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:51:19.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:51:19.998+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:19.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:51:20.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:20.018+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:51:20.033+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:20.033+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:51:20.040+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:20.034+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:51:20.041+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:51:20.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.058 seconds
[2025-01-09T00:51:50.148+0000] {processor.py:157} INFO - Started process (PID=1055) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:51:50.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:51:50.151+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:50.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:51:50.175+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:50.174+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:51:50.188+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:50.188+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:51:50.194+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:51:50.189+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:51:50.194+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:51:50.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.059 seconds
[2025-01-09T00:52:20.488+0000] {processor.py:157} INFO - Started process (PID=1141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:52:20.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:52:20.492+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:20.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:52:20.511+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:20.511+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:52:20.525+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:20.525+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:52:20.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:20.526+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:52:20.531+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:52:20.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.055 seconds
[2025-01-09T00:52:50.591+0000] {processor.py:157} INFO - Started process (PID=1235) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:52:50.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:52:50.595+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:50.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:52:50.619+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:50.619+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:52:50.635+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:50.635+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:52:50.641+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:52:50.636+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:52:50.642+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:52:50.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T00:53:29.391+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:53:29.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:53:29.397+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:29.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:53:29.431+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:29.431+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:53:29.452+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:29.451+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:53:29.460+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:29.453+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:53:29.461+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:53:29.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.088 seconds
[2025-01-09T00:53:59.843+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:53:59.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:53:59.846+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:59.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:53:59.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:59.872+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:53:59.884+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:59.884+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:53:59.891+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:53:59.885+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:53:59.891+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:53:59.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T00:54:30.045+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:54:30.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:54:30.051+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:54:30.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:54:30.079+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:54:30.078+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:54:30.091+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:54:30.091+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:54:30.098+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:54:30.092+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:54:30.099+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:54:30.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.069 seconds
[2025-01-09T00:55:00.183+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:55:00.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:55:00.186+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:00.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:55:00.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:00.210+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:55:00.222+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:00.222+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:55:00.229+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:00.223+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:55:00.229+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:55:00.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T00:55:30.578+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:55:30.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:55:30.583+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:30.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:55:30.610+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:30.610+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:55:30.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:30.626+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:55:30.633+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:55:30.628+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:55:30.634+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:55:30.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.075 seconds
[2025-01-09T00:56:01.046+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:56:01.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:56:01.050+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:01.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:56:01.071+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:01.071+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:56:01.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:01.083+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:56:01.090+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:01.084+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:56:01.091+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:56:01.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.063 seconds
[2025-01-09T00:56:42.273+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:56:42.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:56:42.278+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:42.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:56:42.306+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:42.305+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:56:42.320+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:42.320+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:56:42.327+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:56:42.321+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:56:42.328+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:56:42.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.070 seconds
[2025-01-09T00:57:12.511+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:57:12.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:57:12.514+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:12.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:57:12.538+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:12.538+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:57:12.550+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:12.550+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:57:12.557+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:12.551+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:57:12.557+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:57:12.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.064 seconds
[2025-01-09T00:57:43.351+0000] {processor.py:157} INFO - Started process (PID=243) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:57:43.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:57:43.356+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:43.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:57:43.379+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:43.379+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:57:43.394+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:43.394+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:57:43.401+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:57:43.395+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:57:43.402+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:57:43.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.063 seconds
[2025-01-09T00:58:13.479+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:58:13.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:58:13.483+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:13.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:58:13.508+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:13.508+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:58:13.520+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:13.520+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:58:13.526+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:13.521+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:58:13.526+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:58:13.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T00:58:43.922+0000] {processor.py:157} INFO - Started process (PID=434) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:58:43.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:58:43.926+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:43.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:58:43.947+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:43.947+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:58:43.960+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:43.960+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:58:43.965+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:58:43.961+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:58:43.966+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:58:43.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.057 seconds
[2025-01-09T00:59:14.044+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:59:14.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:59:14.047+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:14.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:59:14.078+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:14.078+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:59:14.090+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:14.089+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:59:14.096+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:14.090+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:59:14.097+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:59:14.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.066 seconds
[2025-01-09T00:59:44.289+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:59:44.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T00:59:44.292+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:44.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:59:44.321+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:44.321+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T00:59:44.334+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:44.334+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T00:59:44.341+0000] {logging_mixin.py:151} INFO - [2025-01-09T00:59:44.335+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T00:59:44.341+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T00:59:44.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.064 seconds
[2025-01-09T01:00:14.434+0000] {processor.py:157} INFO - Started process (PID=692) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:00:14.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:00:14.438+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:14.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:00:14.465+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:14.465+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:00:14.479+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:14.479+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:00:14.485+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:14.480+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:00:14.486+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:00:14.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T01:00:44.737+0000] {processor.py:157} INFO - Started process (PID=786) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:00:44.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:00:44.741+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:44.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:00:44.767+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:44.767+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:00:44.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:44.780+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:00:44.787+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:00:44.781+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:00:44.788+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:00:44.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.071 seconds
[2025-01-09T01:01:15.003+0000] {processor.py:157} INFO - Started process (PID=883) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:01:15.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:01:15.007+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:15.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:01:15.033+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:15.033+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:01:15.051+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:15.051+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:01:15.058+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:15.052+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:01:15.059+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:01:15.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.071 seconds
[2025-01-09T01:01:45.157+0000] {processor.py:157} INFO - Started process (PID=969) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:01:45.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:01:45.160+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:45.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:01:45.184+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:45.184+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:01:45.196+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:45.196+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:01:45.202+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:01:45.197+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:01:45.203+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:01:45.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.057 seconds
[2025-01-09T01:02:15.445+0000] {processor.py:157} INFO - Started process (PID=1055) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:02:15.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:02:15.448+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:02:15.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:02:15.477+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:02:15.477+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:02:15.491+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:02:15.491+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:02:15.498+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:02:15.492+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:02:15.499+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:02:15.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.075 seconds
[2025-01-09T01:05:27.760+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:05:27.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:05:27.766+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:27.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:05:27.798+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:27.798+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:05:27.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:27.814+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:05:27.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:27.815+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:05:27.823+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:05:27.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.082 seconds
[2025-01-09T01:05:58.328+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:05:58.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:05:58.332+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:58.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:05:58.359+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:58.359+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:05:58.375+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:58.375+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:05:58.382+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:05:58.376+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:05:58.383+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:05:58.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.074 seconds
[2025-01-09T01:06:28.832+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:06:28.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:06:28.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:06:28.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:06:28.868+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:06:28.867+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:06:28.888+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:06:28.887+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:06:28.894+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:06:28.889+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:06:28.895+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:06:28.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.082 seconds
[2025-01-09T01:08:04.832+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:08:04.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:08:04.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:04.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:08:04.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:04.875+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:08:04.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:04.900+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:08:04.910+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:04.901+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:08:04.911+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:08:04.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.103 seconds
[2025-01-09T01:08:35.174+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:08:35.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:08:35.177+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:35.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:08:35.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:35.200+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:08:35.212+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:35.212+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:08:35.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:08:35.213+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:08:35.217+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:08:35.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T01:09:05.927+0000] {processor.py:157} INFO - Started process (PID=243) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:09:05.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:09:05.930+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:05.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:09:05.956+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:05.956+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:09:05.970+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:05.970+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:09:05.977+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:05.971+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:09:05.977+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:09:05.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T01:09:36.454+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:09:36.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:09:36.458+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:36.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:09:36.483+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:36.483+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:09:36.498+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:36.498+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:09:36.504+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:09:36.499+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:09:36.505+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:09:36.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T01:10:07.152+0000] {processor.py:157} INFO - Started process (PID=415) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:10:07.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:10:07.156+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:10:07.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:10:07.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:10:07.182+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:10:07.198+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:10:07.198+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:10:07.205+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:10:07.199+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:10:07.206+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:10:07.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T01:10:37.469+0000] {processor.py:157} INFO - Started process (PID=501) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:10:37.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:10:37.473+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:10:37.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:10:37.499+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:10:37.498+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:17:13.587+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:17:13.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:17:13.592+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:13.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:17:13.615+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:13.615+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:17:13.630+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:13.630+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:17:13.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:13.631+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:17:13.640+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:17:13.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.073 seconds
[2025-01-09T01:17:44.549+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:17:44.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:17:44.552+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:44.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:17:44.571+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:44.570+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:17:44.584+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:44.584+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:17:44.590+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:17:44.585+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:17:44.590+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:17:44.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.060 seconds
[2025-01-09T01:18:14.674+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:18:14.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:18:14.680+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:14.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:18:14.709+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:14.709+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:18:14.722+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:14.722+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:18:14.727+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:14.723+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:18:14.728+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:18:14.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.087 seconds
[2025-01-09T01:18:44.825+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:18:44.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:18:44.829+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:44.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:18:44.860+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:44.859+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:18:44.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:44.875+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:18:44.879+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:18:44.875+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:18:44.880+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:18:44.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.068 seconds
[2025-01-09T01:19:15.039+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:19:15.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:19:15.043+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:15.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:19:15.066+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:15.065+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:19:15.077+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:15.077+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:19:15.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:15.078+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:19:15.083+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:19:15.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.063 seconds
[2025-01-09T01:19:45.316+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:19:45.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:19:45.321+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:45.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:19:45.353+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:45.353+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:19:45.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:45.377+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:19:45.384+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:19:45.378+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:19:45.385+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:19:45.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.085 seconds
[2025-01-09T01:20:15.677+0000] {processor.py:157} INFO - Started process (PID=605) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:20:15.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:20:15.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:20:15.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:20:15.840+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:20:15.840+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:20:15.898+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:20:15.898+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:20:15.961+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:20:15.903+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:20:15.964+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:20:15.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.338 seconds
[2025-01-09T01:21:30.106+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:21:30.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:21:30.116+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:21:30.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:21:30.152+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:21:30.152+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:21:30.168+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:21:30.168+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:21:30.174+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:21:30.169+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:21:30.175+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:21:30.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.091 seconds
[2025-01-09T01:22:00.497+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:22:00.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:22:00.501+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:00.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:22:00.523+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:00.523+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:22:00.538+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:00.538+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:22:00.546+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:00.539+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:22:00.547+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:22:00.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T01:22:30.796+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:22:30.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:22:30.799+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:30.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:22:30.878+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:30.878+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:22:30.897+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:30.896+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:22:30.903+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:22:30.897+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:22:30.904+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:22:30.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.128 seconds
[2025-01-09T01:23:01.200+0000] {processor.py:157} INFO - Started process (PID=337) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:23:01.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:23:01.205+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:01.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:23:01.237+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:01.237+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:23:01.255+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:01.255+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:23:01.261+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:01.256+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:23:01.262+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:23:01.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.079 seconds
[2025-01-09T01:23:31.482+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:23:31.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:23:31.489+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:31.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:23:31.551+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:31.542+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:23:31.587+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:31.587+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:23:31.599+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:23:31.588+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:23:31.600+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:23:31.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.171 seconds
[2025-01-09T01:24:02.251+0000] {processor.py:157} INFO - Started process (PID=500) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:24:02.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:24:02.258+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:24:02.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:24:02.303+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:24:02.302+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:24:02.330+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:24:02.330+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:24:33.813+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:24:33.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T01:24:33.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:24:33.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:24:33.836+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:24:33.835+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T01:24:33.848+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:24:33.848+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T01:24:33.854+0000] {logging_mixin.py:151} INFO - [2025-01-09T01:24:33.849+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T01:24:33.855+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T01:24:33.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.053 seconds
[2025-01-09T13:38:54.912+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:38:54.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:38:54.919+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:38:54.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:38:54.962+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:38:54.961+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:38:54.984+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:38:54.984+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:38:55.000+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:38:54.986+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:38:55.001+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:38:55.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.117 seconds
[2025-01-09T13:39:25.515+0000] {processor.py:157} INFO - Started process (PID=163) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:39:25.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:39:25.528+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:25.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:39:25.607+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:25.607+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:39:25.636+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:25.636+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:39:25.646+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:25.638+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:39:25.647+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:39:25.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.163 seconds
[2025-01-09T13:39:55.911+0000] {processor.py:157} INFO - Started process (PID=243) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:39:55.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:39:55.919+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:55.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:39:55.963+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:55.962+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:39:55.991+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:55.991+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:39:56.001+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:39:55.994+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:39:56.003+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:39:56.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.123 seconds
[2025-01-09T13:40:26.135+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:40:26.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:40:26.139+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:26.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:40:26.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:26.164+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:40:26.179+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:26.179+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:40:26.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:26.180+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:40:26.186+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:40:26.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-09T13:40:56.354+0000] {processor.py:157} INFO - Started process (PID=415) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:40:56.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:40:56.358+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:56.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:40:56.382+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:56.382+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:40:56.394+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:56.394+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:40:56.401+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:40:56.395+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:40:56.402+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:40:56.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.059 seconds
[2025-01-09T13:41:26.576+0000] {processor.py:157} INFO - Started process (PID=501) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:41:26.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:41:26.580+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:26.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:41:26.611+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:26.610+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:41:26.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:26.628+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:41:26.635+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:26.629+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:41:26.636+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:41:26.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.076 seconds
[2025-01-09T13:41:57.116+0000] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:41:57.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:41:57.120+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:57.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:41:57.148+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:57.148+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:41:57.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:57.164+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:41:57.171+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:41:57.165+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:41:57.172+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:41:57.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.072 seconds
[2025-01-09T13:42:27.690+0000] {processor.py:157} INFO - Started process (PID=673) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:42:27.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:42:27.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:27.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:42:27.724+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:27.724+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:42:27.741+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:27.741+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:42:27.747+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:27.742+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:42:27.748+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:42:27.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.071 seconds
[2025-01-09T13:42:58.021+0000] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:42:58.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:42:58.025+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:58.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:42:58.054+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:58.054+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:42:58.076+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:58.076+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:42:58.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:42:58.077+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:42:58.084+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:42:58.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.085 seconds
[2025-01-09T13:43:28.293+0000] {processor.py:157} INFO - Started process (PID=845) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:43:28.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:43:28.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:28.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:43:28.352+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:28.351+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:43:28.382+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:28.380+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:43:28.392+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:28.384+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:43:28.394+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:43:28.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.148 seconds
[2025-01-09T13:43:58.883+0000] {processor.py:157} INFO - Started process (PID=931) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:43:58.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:43:58.887+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:58.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:43:58.909+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:58.909+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:43:58.926+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:58.926+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:43:58.935+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:43:58.926+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:43:58.935+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:43:58.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T13:44:29.017+0000] {processor.py:157} INFO - Started process (PID=1018) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:44:29.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:44:29.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:29.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:44:29.050+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:29.050+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:44:29.064+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:29.064+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:44:29.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:29.065+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:44:29.071+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:44:29.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.074 seconds
[2025-01-09T13:44:59.564+0000] {processor.py:157} INFO - Started process (PID=1103) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:44:59.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:44:59.567+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:59.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:44:59.590+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:59.590+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:44:59.602+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:59.602+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:44:59.608+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:44:59.603+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:44:59.609+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:44:59.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.064 seconds
[2025-01-09T13:45:29.720+0000] {processor.py:157} INFO - Started process (PID=1189) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:45:29.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:45:29.724+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:45:29.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:45:29.749+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:45:29.749+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:45:29.761+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:45:29.761+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:45:29.767+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:45:29.762+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:45:29.768+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:45:29.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T13:45:59.975+0000] {processor.py:157} INFO - Started process (PID=1294) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:45:59.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:45:59.986+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:45:59.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:46:00.029+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:46:00.028+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:46:00.045+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:46:00.045+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:46:00.049+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:46:00.046+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:46:00.050+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:46:00.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.091 seconds
[2025-01-09T13:46:30.768+0000] {processor.py:157} INFO - Started process (PID=1380) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:46:30.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:46:30.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:46:30.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:46:30.792+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:46:30.792+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:46:30.804+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:46:30.804+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:46:30.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:46:30.805+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:46:30.811+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:46:30.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.052 seconds
[2025-01-09T13:47:00.886+0000] {processor.py:157} INFO - Started process (PID=1467) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:47:00.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:47:00.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:00.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:47:00.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:00.927+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:47:00.952+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:00.951+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:47:00.958+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:00.952+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:47:00.958+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:47:00.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.090 seconds
[2025-01-09T13:47:31.500+0000] {processor.py:157} INFO - Started process (PID=1553) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:47:31.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:47:31.507+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:31.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:47:31.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:31.582+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:47:31.625+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:31.624+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:47:31.650+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:47:31.627+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:47:31.652+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:47:31.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.194 seconds
[2025-01-09T13:48:02.024+0000] {processor.py:157} INFO - Started process (PID=1638) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:48:02.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:48:02.028+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:02.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:48:02.049+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:02.049+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:48:02.061+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:02.061+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:48:02.067+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:02.062+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:48:02.068+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:48:02.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.055 seconds
[2025-01-09T13:48:41.008+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:48:41.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:48:41.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:41.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:48:41.046+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:41.046+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:48:41.069+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:41.069+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:48:41.076+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:48:41.070+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:48:41.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:48:41.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.086 seconds
[2025-01-09T13:49:11.374+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:49:11.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:49:11.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:11.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:49:11.401+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:11.401+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:49:11.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:11.413+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:49:11.419+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:11.414+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:49:11.420+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:49:11.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.058 seconds
[2025-01-09T13:49:41.602+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:49:41.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:49:41.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:41.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:49:41.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:41.626+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:49:41.639+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:41.639+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:49:41.646+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:49:41.640+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:49:41.646+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:49:41.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.056 seconds
[2025-01-09T13:50:11.739+0000] {processor.py:157} INFO - Started process (PID=335) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:50:11.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:50:11.743+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:11.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:50:11.768+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:11.768+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:50:11.786+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:11.786+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:50:11.792+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:11.787+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:50:11.793+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:50:11.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T13:50:42.128+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:50:42.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:50:42.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:42.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:50:42.156+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:42.156+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:50:42.170+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:42.170+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:50:42.177+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:50:42.171+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:50:42.178+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:50:42.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.070 seconds
[2025-01-09T13:51:12.371+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:51:12.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:51:12.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:12.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:51:12.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:12.406+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:51:12.423+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:12.423+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:51:12.429+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:12.424+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:51:12.430+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:51:12.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.083 seconds
[2025-01-09T13:51:42.699+0000] {processor.py:157} INFO - Started process (PID=605) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:51:42.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:51:42.702+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:42.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:51:42.728+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:42.728+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:51:42.749+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:42.749+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:51:42.757+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:51:42.750+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:51:42.759+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:51:42.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.078 seconds
[2025-01-09T13:52:13.045+0000] {processor.py:157} INFO - Started process (PID=691) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:52:13.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:52:13.051+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:13.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:52:13.080+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:13.080+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:52:13.096+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:13.096+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:52:13.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:13.097+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:52:13.105+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:52:13.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.076 seconds
[2025-01-09T13:52:43.373+0000] {processor.py:157} INFO - Started process (PID=777) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:52:43.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:52:43.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:43.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:52:43.399+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:43.399+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:52:43.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:43.411+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:52:43.417+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:52:43.412+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:52:43.418+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:52:43.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.057 seconds
[2025-01-09T13:53:13.720+0000] {processor.py:157} INFO - Started process (PID=871) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:53:13.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:53:13.724+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:13.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:53:13.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:13.763+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:53:13.784+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:13.784+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:53:13.795+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:13.785+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:53:13.796+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:53:13.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.115 seconds
[2025-01-09T13:53:44.078+0000] {processor.py:157} INFO - Started process (PID=968) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:53:44.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:53:44.082+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:44.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:53:44.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:44.107+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:53:44.121+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:44.121+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:53:44.128+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:53:44.122+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:53:44.129+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:53:44.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.064 seconds
[2025-01-09T13:54:34.772+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:54:34.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:54:34.777+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:54:34.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:54:34.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:54:34.814+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:54:34.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:54:34.831+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:54:34.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:54:34.832+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:54:34.839+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:54:34.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.084 seconds
[2025-01-09T13:55:05.584+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:55:05.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:55:05.587+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:05.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:55:05.612+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:05.611+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:55:05.623+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:05.623+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:55:05.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:05.624+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:55:05.630+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:55:05.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.066 seconds
[2025-01-09T13:55:36.021+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:55:36.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:55:36.024+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:36.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:55:36.055+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:36.055+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:55:36.069+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:36.068+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:55:36.075+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:55:36.069+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:55:36.076+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:55:36.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T13:57:03.443+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:57:03.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:57:03.450+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:03.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:57:03.495+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:03.495+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:57:03.527+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:03.527+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:57:03.539+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:03.530+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:57:03.541+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:57:03.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.124 seconds
[2025-01-09T13:57:33.883+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:57:33.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:57:33.887+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:33.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:57:33.913+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:33.913+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:57:33.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:33.928+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:57:33.935+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:57:33.929+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:57:33.936+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:57:33.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.069 seconds
[2025-01-09T13:58:04.019+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:58:04.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:58:04.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:04.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:58:04.047+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:04.047+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:58:04.063+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:04.063+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:58:04.073+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:04.064+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:58:04.074+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:58:04.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.070 seconds
[2025-01-09T13:58:34.218+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:58:34.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:58:34.222+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:34.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:58:34.247+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:34.247+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:58:34.258+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:34.258+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:58:34.266+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:58:34.259+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:58:34.267+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:58:34.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.070 seconds
[2025-01-09T13:59:05.107+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:59:05.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:59:05.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:05.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:59:05.133+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:05.133+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:59:05.148+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:05.148+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:59:05.154+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:05.149+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:59:05.155+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:59:05.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.061 seconds
[2025-01-09T13:59:35.512+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:59:35.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T13:59:35.517+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:35.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:59:35.546+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:35.545+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T13:59:35.565+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:35.565+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T13:59:35.571+0000] {logging_mixin.py:151} INFO - [2025-01-09T13:59:35.566+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T13:59:35.572+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T13:59:35.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.079 seconds
[2025-01-09T14:00:05.762+0000] {processor.py:157} INFO - Started process (PID=605) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:00:05.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:00:05.767+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:05.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:00:05.791+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:05.791+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:00:05.804+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:05.804+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:00:05.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:05.805+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T14:00:05.811+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:00:05.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.062 seconds
[2025-01-09T14:00:35.936+0000] {processor.py:157} INFO - Started process (PID=691) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:00:35.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:00:35.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:35.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:00:35.962+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:35.962+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:00:35.975+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:35.974+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:00:35.981+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:00:35.975+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T14:00:35.982+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:00:35.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.058 seconds
[2025-01-09T14:01:05.659+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:01:05.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:01:05.667+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:05.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:01:05.724+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:05.724+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:01:05.756+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:05.756+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:01:05.768+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:05.758+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T14:01:05.769+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:01:05.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.132 seconds
[2025-01-09T14:01:36.415+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:01:36.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:01:36.422+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:36.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:01:36.449+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:36.448+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:01:36.464+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:36.464+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:01:36.473+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:01:36.465+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T14:01:36.474+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:01:36.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.086 seconds
[2025-01-09T14:02:06.856+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:02:06.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:02:06.861+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:06.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:02:06.887+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:06.886+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:02:06.902+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:06.901+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:02:06.908+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:06.902+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T14:02:06.909+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:02:06.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-09T14:02:37.808+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:02:37.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:02:37.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:37.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:02:37.834+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:37.834+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:02:37.849+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:37.848+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:02:37.856+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:02:37.850+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T14:02:37.856+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:02:37.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.061 seconds
[2025-01-09T14:03:08.169+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:03:08.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:03:08.173+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:03:08.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:03:08.196+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:03:08.196+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:03:08.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:03:08.209+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:03:08.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:03:08.210+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 556, in load_via_dbt_ls_without_cache
    self.render_config.validate_dbt_command(fallback_cmd=self.execution_config.dbt_executable_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 120, in validate_dbt_command
    raise CosmosConfigException(
cosmos.config.CosmosConfigException: Unable to find the dbt executable, attempted: <dbt> and </home/airflow/.local/bin/dbt>.
[2025-01-09T14:03:08.217+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:03:08.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.068 seconds
[2025-01-09T14:11:19.985+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:11:19.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:11:19.992+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:19.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:11:20.036+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:20.035+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:11:20.059+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:20.058+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T14:11:20.059+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:20.059+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-09T14:11:20.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:20.069+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /opt/airflow/dbt/dbt_stock_project/target/partial_parse.msgpack
[2025-01-09T14:11:20.148+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:20.148+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-09T14:11:20.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:20.150+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-09T14:11:20.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:20.150+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpt7etnym_ --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-09T14:11:33.353+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.353+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6994017280001117
[2025-01-09T14:11:33.364+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.364+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-09T14:11:33.374+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.374+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:11:33.375+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.375+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:11:33.376+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.375+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|70]: It took 13.3s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-09T14:11:33.380+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.380+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|70]: It took 0.00493s to build the Airflow DAG.
[2025-01-09T14:11:33.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:11:33.452+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.452+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:PolygonAPI_to_BigQuery
[2025-01-09T14:11:33.462+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.462+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:PolygonAPI_to_BigQuery
[2025-01-09T14:11:33.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.469+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:PolygonAPI_to_BigQuery
[2025-01-09T14:11:33.483+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.483+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:11:33.494+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.494+0000] {dag.py:2929} INFO - Creating ORM DAG for PolygonAPI_to_BigQuery
[2025-01-09T14:11:33.506+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:11:33.506+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:11:33.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 13.553 seconds
[2025-01-09T14:12:03.843+0000] {processor.py:157} INFO - Started process (PID=248) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:12:03.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:12:03.846+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:12:03.870+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.870+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:12:03.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.995+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11206454800003485
[2025-01-09T14:12:03.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.995+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|248]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:12:03.996+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.996+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:12:03.996+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.996+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:12:03.996+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.996+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:12:03.997+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.996+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|248]: It took 0.127s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:12:03.999+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:03.999+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|248]: It took 0.00225s to build the Airflow DAG.
[2025-01-09T14:12:04.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:12:04.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:04.012+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:12:04.033+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:04.032+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:12:04.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-09T14:12:34.584+0000] {processor.py:157} INFO - Started process (PID=353) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:12:34.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:12:34.587+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:12:34.612+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.612+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:12:34.774+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.774+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14820195499987676
[2025-01-09T14:12:34.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.775+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|353]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:12:34.776+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.776+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:12:34.777+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.777+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:12:34.777+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.777+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:12:34.778+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.778+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|353]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:12:34.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.782+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|353]: It took 0.00406s to build the Airflow DAG.
[2025-01-09T14:12:34.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:12:34.804+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.804+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:12:34.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:12:34.832+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:12:34.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-09T14:13:05.295+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:13:05.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:13:05.298+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:13:05.323+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.323+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:13:05.460+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.459+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12236292999978104
[2025-01-09T14:13:05.460+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.460+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|439]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:13:05.460+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.460+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:13:05.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.461+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:13:05.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.461+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:13:05.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.461+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|439]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:13:05.464+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.464+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|439]: It took 0.00237s to build the Airflow DAG.
[2025-01-09T14:13:05.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:13:05.477+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.477+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:13:05.498+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:05.498+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:13:05.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T14:13:35.655+0000] {processor.py:157} INFO - Started process (PID=525) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:13:35.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:13:35.658+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:13:35.680+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.680+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:13:35.836+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.836+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14108415100008642
[2025-01-09T14:13:35.836+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.836+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|525]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:13:35.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.837+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:13:35.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.837+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:13:35.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.837+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:13:35.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.837+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|525]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:13:35.840+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.840+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|525]: It took 0.00243s to build the Airflow DAG.
[2025-01-09T14:13:35.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:13:35.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.854+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:13:35.877+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:13:35.877+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:13:35.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T14:14:06.515+0000] {processor.py:157} INFO - Started process (PID=611) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:14:06.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:14:06.518+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:14:06.539+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.539+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:14:06.669+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.669+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11677878299997246
[2025-01-09T14:14:06.669+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.669+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|611]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:14:06.670+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.670+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:14:06.670+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.670+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:14:06.670+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.670+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:14:06.671+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.671+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|611]: It took 0.132s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:14:06.673+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.673+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|611]: It took 0.0022s to build the Airflow DAG.
[2025-01-09T14:14:06.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:14:06.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.694+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:14:06.716+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:06.715+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:14:06.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-09T14:14:37.492+0000] {processor.py:157} INFO - Started process (PID=697) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:14:37.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:14:37.496+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:14:37.523+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.523+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:14:37.650+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.649+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11352735799982838
[2025-01-09T14:14:37.650+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.650+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|697]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:14:37.650+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.650+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:14:37.651+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.651+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:14:37.651+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.651+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:14:37.651+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.651+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|697]: It took 0.128s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:14:37.654+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.654+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|697]: It took 0.00237s to build the Airflow DAG.
[2025-01-09T14:14:37.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:14:37.667+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.667+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:14:37.688+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:14:37.688+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:14:37.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.220 seconds
[2025-01-09T14:15:07.835+0000] {processor.py:157} INFO - Started process (PID=792) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:15:07.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:15:07.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:15:07.857+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.857+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:15:07.993+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.993+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12317235999989862
[2025-01-09T14:15:07.994+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.994+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|792]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:15:07.994+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.994+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:15:07.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.995+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:15:07.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.995+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:15:07.996+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.995+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|792]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:15:07.999+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:07.999+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|792]: It took 0.0035s to build the Airflow DAG.
[2025-01-09T14:15:08.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:15:08.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:08.016+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:15:08.041+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:08.040+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:15:08.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-09T14:15:38.717+0000] {processor.py:157} INFO - Started process (PID=889) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:15:38.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:15:38.720+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:15:38.742+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.741+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:15:38.860+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.859+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10474407600031554
[2025-01-09T14:15:38.860+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.860+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|889]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:15:38.861+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.861+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:15:38.861+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.861+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:15:38.861+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.861+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:15:38.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.862+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|889]: It took 0.12s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:15:38.865+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.865+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|889]: It took 0.00285s to build the Airflow DAG.
[2025-01-09T14:15:38.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:15:38.879+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.878+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:15:38.901+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:15:38.901+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T14:15:38.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.206 seconds
[2025-01-09T14:16:09.517+0000] {processor.py:157} INFO - Started process (PID=982) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:16:09.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:16:09.521+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:16:09.553+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.553+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:16:09.740+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.739+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1665338069997233
[2025-01-09T14:16:09.740+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.740+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|982]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:16:09.741+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.741+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:16:09.741+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.741+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:16:09.742+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.741+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:16:09.742+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.742+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|982]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:16:09.746+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.745+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|982]: It took 0.00346s to build the Airflow DAG.
[2025-01-09T14:16:09.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:16:09.765+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.765+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:16:09.798+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:09.797+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:16:09.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-09T14:16:39.992+0000] {processor.py:157} INFO - Started process (PID=1068) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:16:39.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:16:39.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:39.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:16:40.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.018+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:16:40.162+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.162+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1306544539997958
[2025-01-09T14:16:40.162+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.162+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1068]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:16:40.163+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.163+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:16:40.163+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.163+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:16:40.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.164+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:16:40.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.164+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1068]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:16:40.167+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.167+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1068]: It took 0.00266s to build the Airflow DAG.
[2025-01-09T14:16:40.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:16:40.184+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.184+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:16:40.219+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:16:40.219+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:16:40.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-09T14:17:10.371+0000] {processor.py:157} INFO - Started process (PID=1155) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:17:10.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:17:10.374+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:17:10.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.396+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:17:10.529+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.529+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12049629700004516
[2025-01-09T14:17:10.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.530+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1155]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:17:10.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.530+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:17:10.531+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.531+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:17:10.531+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.531+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:17:10.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.532+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1155]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:17:10.534+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.534+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1155]: It took 0.00242s to build the Airflow DAG.
[2025-01-09T14:17:10.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:17:10.547+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.547+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:17:10.570+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:10.570+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:17:10.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.220 seconds
[2025-01-09T14:17:40.689+0000] {processor.py:157} INFO - Started process (PID=1248) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:17:40.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:17:40.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:17:40.719+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.719+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:17:40.898+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.898+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16140984499998012
[2025-01-09T14:17:40.899+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.898+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1248]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:17:40.899+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.899+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:17:40.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.900+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:17:40.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.900+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:17:40.901+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.901+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1248]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:17:40.906+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.906+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1248]: It took 0.00503s to build the Airflow DAG.
[2025-01-09T14:17:40.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:17:40.925+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.925+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:17:40.954+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:17:40.953+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:17:40.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-09T14:18:11.409+0000] {processor.py:157} INFO - Started process (PID=1347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:18:11.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:18:11.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:18:11.441+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.441+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:18:11.580+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.580+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1237152460003017
[2025-01-09T14:18:11.581+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.580+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1347]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:18:11.581+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.581+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:18:11.581+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.581+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:18:11.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.582+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:18:11.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.582+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1347]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:18:11.584+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.584+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1347]: It took 0.00234s to build the Airflow DAG.
[2025-01-09T14:18:11.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:18:11.598+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.598+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:18:11.625+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:11.625+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:18:11.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T14:18:42.325+0000] {processor.py:157} INFO - Started process (PID=1433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:18:42.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:18:42.329+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:18:42.353+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.353+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:18:42.485+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.485+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11880662500016115
[2025-01-09T14:18:42.486+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.486+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1433]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:18:42.487+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.486+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:18:42.487+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.487+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:18:42.487+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.487+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:18:42.488+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.488+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1433]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:18:42.491+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.490+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1433]: It took 0.00281s to build the Airflow DAG.
[2025-01-09T14:18:42.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:18:42.505+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.505+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:18:42.527+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:18:42.527+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:18:42.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T14:19:13.033+0000] {processor.py:157} INFO - Started process (PID=1519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:19:13.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:19:13.037+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:19:13.066+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.065+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:19:13.206+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.206+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12704129200028547
[2025-01-09T14:19:13.206+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.206+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1519]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:19:13.207+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.207+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:19:13.207+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.207+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:19:13.208+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.207+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:19:13.208+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.208+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1519]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:19:13.211+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.211+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1519]: It took 0.00338s to build the Airflow DAG.
[2025-01-09T14:19:13.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:19:13.226+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.226+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:19:13.250+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:13.250+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:19:13.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-09T14:19:43.421+0000] {processor.py:157} INFO - Started process (PID=1605) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:19:43.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:19:43.424+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:19:43.447+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.447+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:19:43.592+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.592+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13140328500003307
[2025-01-09T14:19:43.592+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.592+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1605]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:19:43.593+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.593+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:19:43.594+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.593+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:19:43.594+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.594+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:19:43.595+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.594+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1605]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:19:43.598+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.598+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1605]: It took 0.0032s to build the Airflow DAG.
[2025-01-09T14:19:43.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:19:43.616+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.616+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:19:43.653+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:19:43.653+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:19:43.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-09T14:20:14.014+0000] {processor.py:157} INFO - Started process (PID=1691) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:20:14.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:20:14.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:20:14.042+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.042+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:20:14.239+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.238+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1808936350003023
[2025-01-09T14:20:14.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.239+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1691]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:20:14.241+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.240+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:20:14.241+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.241+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:20:14.242+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.242+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:20:14.242+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.242+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1691]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:20:14.247+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.246+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1691]: It took 0.00402s to build the Airflow DAG.
[2025-01-09T14:20:14.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:20:14.271+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.271+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:20:14.332+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:14.332+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:20:14.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.348 seconds
[2025-01-09T14:20:44.561+0000] {processor.py:157} INFO - Started process (PID=1783) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:20:44.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:20:44.566+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:20:44.598+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.598+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:20:44.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.814+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18782192500020756
[2025-01-09T14:20:44.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.814+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1783]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:20:44.815+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.815+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:20:44.816+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.816+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:20:44.816+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.816+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:20:44.817+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.817+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1783]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:20:44.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.822+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1783]: It took 0.0048s to build the Airflow DAG.
[2025-01-09T14:20:44.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:20:44.844+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.844+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:20:44.879+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:20:44.879+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:20:44.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.346 seconds
[2025-01-09T14:21:15.179+0000] {processor.py:157} INFO - Started process (PID=1883) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:21:15.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:21:15.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:21:15.213+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.213+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:21:15.375+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.375+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14388491399995473
[2025-01-09T14:21:15.375+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.375+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1883]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:21:15.376+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.376+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:21:15.376+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.376+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:21:15.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.376+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:21:15.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.377+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1883]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:21:15.380+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.379+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1883]: It took 0.0026s to build the Airflow DAG.
[2025-01-09T14:21:15.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:21:15.395+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.394+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:21:15.421+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:15.421+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:21:15.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-09T14:21:45.787+0000] {processor.py:157} INFO - Started process (PID=1987) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:21:45.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:21:45.790+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:21:45.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.812+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:21:45.967+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.967+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13804243799995675
[2025-01-09T14:21:45.968+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.967+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|1987]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:21:45.968+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.968+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:21:45.969+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.969+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:21:45.969+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.969+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:21:45.970+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.970+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|1987]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:21:45.974+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.974+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|1987]: It took 0.00403s to build the Airflow DAG.
[2025-01-09T14:21:45.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:21:45.991+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:45.991+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:21:46.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:21:46.020+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:21:46.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-09T14:22:16.922+0000] {processor.py:157} INFO - Started process (PID=2074) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:22:16.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:22:16.926+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:16.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:22:16.948+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:16.947+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:22:17.069+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.069+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1081574769996223
[2025-01-09T14:22:17.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.070+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2074]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:22:17.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.070+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:22:17.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.070+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:22:17.071+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.071+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:22:17.071+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.071+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2074]: It took 0.124s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:22:17.073+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.073+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2074]: It took 0.00238s to build the Airflow DAG.
[2025-01-09T14:22:17.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:22:17.086+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.086+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:22:17.109+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:17.109+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:22:17.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-09T14:22:47.612+0000] {processor.py:157} INFO - Started process (PID=2160) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:22:47.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:22:47.616+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:22:47.642+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.641+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:22:47.808+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.808+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15182630299977973
[2025-01-09T14:22:47.809+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.809+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2160]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:22:47.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.809+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:22:47.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.810+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:22:47.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.810+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:22:47.811+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.811+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2160]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:22:47.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.814+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2160]: It took 0.00307s to build the Airflow DAG.
[2025-01-09T14:22:47.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:22:47.830+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:22:47.858+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:22:47.858+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:22:47.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-09T14:23:18.578+0000] {processor.py:157} INFO - Started process (PID=2246) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:23:18.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:23:18.589+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:23:18.620+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.620+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:23:18.921+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.920+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.26791524899999786
[2025-01-09T14:23:18.921+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.921+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2246]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:23:18.922+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.922+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:23:18.923+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.923+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:23:18.923+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.923+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:23:18.924+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.924+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2246]: It took 0.304s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:23:18.929+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.928+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2246]: It took 0.00463s to build the Airflow DAG.
[2025-01-09T14:23:18.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:23:18.953+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:18.953+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:23:19.000+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:19.000+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:23:19.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.460 seconds
[2025-01-09T14:23:49.834+0000] {processor.py:157} INFO - Started process (PID=2333) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:23:49.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:23:49.839+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:49.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:23:49.867+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:49.867+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:23:50.161+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.161+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.271114815999681
[2025-01-09T14:23:50.162+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.162+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2333]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:23:50.163+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.163+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:23:50.169+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.163+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:23:50.170+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.170+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:23:50.171+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.171+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2333]: It took 0.304s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:23:50.176+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.176+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2333]: It took 0.00525s to build the Airflow DAG.
[2025-01-09T14:23:50.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:23:50.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.243+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:23:50.333+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:23:50.333+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:23:50.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.588 seconds
[2025-01-09T14:24:21.068+0000] {processor.py:157} INFO - Started process (PID=2427) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:24:21.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:24:21.071+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:24:21.095+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.095+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:24:21.295+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.295+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1859764890000406
[2025-01-09T14:24:21.296+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.296+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2427]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:24:21.297+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.297+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:24:21.297+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.297+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:24:21.298+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.298+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:24:21.298+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.298+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2427]: It took 0.204s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:24:21.303+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.303+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2427]: It took 0.00452s to build the Airflow DAG.
[2025-01-09T14:24:21.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:24:21.331+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.330+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:24:21.375+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:21.375+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:24:21.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.344 seconds
[2025-01-09T14:24:51.536+0000] {processor.py:157} INFO - Started process (PID=2524) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:24:51.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:24:51.540+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:24:51.569+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.569+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:24:51.716+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.716+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1322246710001309
[2025-01-09T14:24:51.716+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.716+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2524]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:24:51.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.717+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:24:51.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.717+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:24:51.718+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.718+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:24:51.718+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.718+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2524]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:24:51.720+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.720+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2524]: It took 0.00246s to build the Airflow DAG.
[2025-01-09T14:24:51.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:24:51.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.735+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:24:51.758+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:24:51.758+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:24:51.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-09T14:25:21.828+0000] {processor.py:157} INFO - Started process (PID=2610) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:25:21.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:25:21.833+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:21.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:25:21.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:21.863+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:25:22.000+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.000+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12301817500019752
[2025-01-09T14:25:22.000+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.000+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2610]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:25:22.001+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.001+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:25:22.001+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.001+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:25:22.001+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.001+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:25:22.002+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.002+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2610]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:25:22.004+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.004+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2610]: It took 0.00249s to build the Airflow DAG.
[2025-01-09T14:25:22.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:25:22.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.019+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:25:22.043+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:22.042+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:25:22.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-09T14:25:52.275+0000] {processor.py:157} INFO - Started process (PID=2703) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:25:52.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:25:52.286+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:25:52.320+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.320+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:25:52.534+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.533+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19414291300017794
[2025-01-09T14:25:52.534+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.534+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2703]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:25:52.535+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.535+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:25:52.536+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.536+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:25:52.537+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.537+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:25:52.538+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.537+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2703]: It took 0.218s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:25:52.543+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.542+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2703]: It took 0.00491s to build the Airflow DAG.
[2025-01-09T14:25:52.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:25:52.567+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.567+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:25:52.607+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:25:52.606+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:25:52.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-09T14:26:22.780+0000] {processor.py:157} INFO - Started process (PID=2789) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:26:22.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:26:22.785+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:22.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:26:22.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:22.812+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:26:23.017+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.016+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18821674399987387
[2025-01-09T14:26:23.017+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.017+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2789]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:26:23.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.018+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:26:23.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.019+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:26:23.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.019+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:26:23.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.020+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2789]: It took 0.207s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:26:23.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.023+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2789]: It took 0.00365s to build the Airflow DAG.
[2025-01-09T14:26:23.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:26:23.043+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.043+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:26:23.076+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:23.075+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:26:23.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.323 seconds
[2025-01-09T14:26:53.434+0000] {processor.py:157} INFO - Started process (PID=2881) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:26:53.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:26:53.438+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:26:53.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.461+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:26:53.613+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.613+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1373651180001616
[2025-01-09T14:26:53.614+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.613+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2881]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:26:53.615+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.614+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:26:53.615+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.615+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:26:53.616+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.616+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:26:53.617+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.617+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2881]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:26:53.621+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.621+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2881]: It took 0.00455s to build the Airflow DAG.
[2025-01-09T14:26:53.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:26:53.641+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.641+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:26:53.681+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:26:53.681+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:26:53.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.283 seconds
[2025-01-09T14:27:23.894+0000] {processor.py:157} INFO - Started process (PID=2986) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:27:23.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:27:23.898+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:23.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:27:23.924+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:23.924+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:27:24.133+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.132+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19263202899992393
[2025-01-09T14:27:24.134+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.133+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|2986]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:27:24.135+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.135+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:27:24.136+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.135+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:27:24.136+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.136+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:27:24.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.137+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|2986]: It took 0.213s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:27:24.143+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.143+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|2986]: It took 0.00589s to build the Airflow DAG.
[2025-01-09T14:27:24.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:27:24.173+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.173+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:27:24.223+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:24.222+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:27:24.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.366 seconds
[2025-01-09T14:27:54.379+0000] {processor.py:157} INFO - Started process (PID=3079) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:27:54.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:27:54.383+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:27:54.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.406+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:27:54.536+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.536+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11582588500004931
[2025-01-09T14:27:54.536+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.536+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3079]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:27:54.537+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.537+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:27:54.537+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.537+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:27:54.537+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.537+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:27:54.538+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.538+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3079]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:27:54.540+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.540+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3079]: It took 0.00238s to build the Airflow DAG.
[2025-01-09T14:27:54.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:27:54.557+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.556+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:27:54.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:27:54.582+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:27:54.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-09T14:28:24.711+0000] {processor.py:157} INFO - Started process (PID=3165) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:28:24.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:28:24.728+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:28:24.759+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.759+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:28:24.955+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.955+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1776782980000462
[2025-01-09T14:28:24.956+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.956+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3165]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:28:24.956+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.956+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:28:24.957+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.957+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:28:24.958+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.958+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:28:24.959+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.959+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3165]: It took 0.2s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:28:24.963+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.962+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3165]: It took 0.00364s to build the Airflow DAG.
[2025-01-09T14:28:24.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:28:24.983+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:24.983+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:28:25.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:25.015+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:28:25.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-09T14:28:55.457+0000] {processor.py:157} INFO - Started process (PID=3251) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:28:55.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:28:55.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:28:55.490+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.490+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:28:55.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.604+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10164648999989367
[2025-01-09T14:28:55.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.605+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3251]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:28:55.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.605+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:28:55.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.606+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:28:55.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.606+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:28:55.607+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.606+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3251]: It took 0.116s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:28:55.609+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.609+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3251]: It took 0.00216s to build the Airflow DAG.
[2025-01-09T14:28:55.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:28:55.621+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.621+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:28:55.642+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:28:55.642+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:28:55.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.205 seconds
[2025-01-09T14:29:25.847+0000] {processor.py:157} INFO - Started process (PID=3345) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:29:25.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:29:25.850+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:25.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:29:25.876+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:25.875+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:29:26.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.011+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12273751499969876
[2025-01-09T14:29:26.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.012+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3345]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:29:26.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.012+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:29:26.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.013+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:29:26.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.013+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:29:26.014+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.013+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3345]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:29:26.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.016+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3345]: It took 0.00282s to build the Airflow DAG.
[2025-01-09T14:29:26.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:29:26.032+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.032+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:29:26.085+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:26.085+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:29:26.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-09T14:29:57.143+0000] {processor.py:157} INFO - Started process (PID=3442) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:29:57.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:29:57.146+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:29:57.168+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.168+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:29:57.299+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.299+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11777337900002749
[2025-01-09T14:29:57.300+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.300+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3442]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:29:57.300+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.300+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:29:57.301+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.301+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:29:57.301+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.301+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:29:57.301+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.301+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3442]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:29:57.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.304+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3442]: It took 0.00235s to build the Airflow DAG.
[2025-01-09T14:29:57.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:29:57.317+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.317+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:29:57.340+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:29:57.340+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:29:57.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.219 seconds
[2025-01-09T14:30:27.433+0000] {processor.py:157} INFO - Started process (PID=3528) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:30:27.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:30:27.436+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:30:27.462+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.462+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:30:27.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.624+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14842273500016745
[2025-01-09T14:30:27.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.624+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3528]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:30:27.625+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.625+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:30:27.625+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.625+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:30:27.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.626+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:30:27.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.626+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3528]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:30:27.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.629+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3528]: It took 0.00291s to build the Airflow DAG.
[2025-01-09T14:30:27.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:30:27.642+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.642+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:30:27.666+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:27.666+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:30:27.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-09T14:30:58.125+0000] {processor.py:157} INFO - Started process (PID=3614) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:30:58.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:30:58.129+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:30:58.149+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.149+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:30:58.321+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.320+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15823302599983435
[2025-01-09T14:30:58.321+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.321+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3614]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:30:58.321+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.321+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:30:58.322+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.322+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:30:58.322+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.322+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:30:58.322+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.322+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3614]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:30:58.325+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.325+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3614]: It took 0.00234s to build the Airflow DAG.
[2025-01-09T14:30:58.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:30:58.339+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.339+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:30:58.363+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:30:58.363+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:30:58.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-09T14:31:28.963+0000] {processor.py:157} INFO - Started process (PID=3720) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:31:28.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:31:28.967+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:28.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:31:28.990+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:28.990+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:31:29.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.164+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15994999000031385
[2025-01-09T14:31:29.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.164+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3720]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:31:29.165+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.165+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:31:29.166+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.166+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:31:29.166+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.166+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:31:29.167+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.166+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3720]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:31:29.170+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.170+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3720]: It took 0.00341s to build the Airflow DAG.
[2025-01-09T14:31:29.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:31:29.188+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.188+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:31:29.219+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:29.218+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:31:29.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-09T14:31:59.590+0000] {processor.py:157} INFO - Started process (PID=3806) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:31:59.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:31:59.593+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:31:59.616+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.616+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:31:59.771+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.771+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14153142200029833
[2025-01-09T14:31:59.771+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.771+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3806]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:31:59.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.772+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:31:59.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.772+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:31:59.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.772+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:31:59.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.773+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3806]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:31:59.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.775+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3806]: It took 0.0024s to build the Airflow DAG.
[2025-01-09T14:31:59.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:31:59.789+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.789+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:31:59.811+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:31:59.811+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:31:59.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-09T14:32:29.877+0000] {processor.py:157} INFO - Started process (PID=3901) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:32:29.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:32:29.881+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:29.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:32:29.909+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:29.909+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:32:30.063+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.062+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13881300500042926
[2025-01-09T14:32:30.063+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.063+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3901]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:32:30.064+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.064+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:32:30.064+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.064+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:32:30.065+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.065+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:32:30.065+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.065+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3901]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:32:30.068+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.068+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3901]: It took 0.003s to build the Airflow DAG.
[2025-01-09T14:32:30.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:32:30.085+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.085+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:32:30.113+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:32:30.113+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:32:30.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.266 seconds
[2025-01-09T14:33:00.981+0000] {processor.py:157} INFO - Started process (PID=3987) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:33:00.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:33:00.984+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:00.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:33:01.008+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.007+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:33:01.176+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.176+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15502827099999195
[2025-01-09T14:33:01.176+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.176+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|3987]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:33:01.177+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.177+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:33:01.177+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.177+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:33:01.178+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.177+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:33:01.178+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.178+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|3987]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:33:01.180+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.180+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|3987]: It took 0.00251s to build the Airflow DAG.
[2025-01-09T14:33:01.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:33:01.197+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.196+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:33:01.220+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:01.220+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:33:01.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-09T14:33:31.918+0000] {processor.py:157} INFO - Started process (PID=4092) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:33:31.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:33:31.921+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:31.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:33:31.946+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:31.945+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:33:32.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.070+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1120228549998501
[2025-01-09T14:33:32.071+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.071+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4092]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:33:32.071+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.071+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:33:32.072+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.072+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:33:32.072+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.072+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:33:32.072+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.072+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4092]: It took 0.127s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:33:32.075+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.075+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4092]: It took 0.00227s to build the Airflow DAG.
[2025-01-09T14:33:32.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:33:32.088+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.087+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:33:32.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:33:32.111+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:33:32.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T14:34:02.849+0000] {processor.py:157} INFO - Started process (PID=4179) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:34:02.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:34:02.853+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:02.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:34:02.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:02.873+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:34:03.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.015+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.128724911000063
[2025-01-09T14:34:03.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.015+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4179]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:34:03.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.016+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:34:03.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.016+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:34:03.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.016+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:34:03.017+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.017+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4179]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:34:03.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.019+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4179]: It took 0.0025s to build the Airflow DAG.
[2025-01-09T14:34:03.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:34:03.041+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.040+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:34:03.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:03.087+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:34:03.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-09T14:34:33.327+0000] {processor.py:157} INFO - Started process (PID=4266) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:34:33.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:34:33.331+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:34:33.356+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.356+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:34:33.527+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.527+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15543736500012528
[2025-01-09T14:34:33.528+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.527+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4266]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:34:33.528+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.528+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:34:33.529+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.528+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:34:33.529+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.529+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:34:33.529+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.529+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4266]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:34:33.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.532+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4266]: It took 0.003s to build the Airflow DAG.
[2025-01-09T14:34:33.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:34:33.549+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.549+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:34:33.576+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:34:33.576+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:34:33.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.276 seconds
[2025-01-09T14:35:04.601+0000] {processor.py:157} INFO - Started process (PID=4360) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:35:04.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:35:04.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:35:04.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.625+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:35:04.795+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.795+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15422035099982168
[2025-01-09T14:35:04.796+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.795+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4360]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:35:04.796+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.796+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:35:04.797+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.797+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:35:04.797+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.797+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:35:04.797+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.797+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4360]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:35:04.800+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.800+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4360]: It took 0.00273s to build the Airflow DAG.
[2025-01-09T14:35:04.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:35:04.816+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.816+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:35:04.842+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:04.842+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:35:04.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-09T14:35:35.205+0000] {processor.py:157} INFO - Started process (PID=4457) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:35:35.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:35:35.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:35:35.235+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.235+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:35:35.362+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.361+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11421465100011119
[2025-01-09T14:35:35.362+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.362+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4457]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:35:35.363+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.362+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:35:35.363+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.363+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:35:35.363+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.363+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:35:35.364+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.364+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4457]: It took 0.129s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:35:35.366+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.366+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4457]: It took 0.00251s to build the Airflow DAG.
[2025-01-09T14:35:35.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:35:35.380+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.380+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:35:35.403+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:35:35.403+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:35:35.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.221 seconds
[2025-01-09T14:36:06.254+0000] {processor.py:157} INFO - Started process (PID=4543) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:36:06.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:36:06.257+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:36:06.278+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.278+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:36:06.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.408+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11831305900022926
[2025-01-09T14:36:06.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.409+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4543]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:36:06.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.409+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:36:06.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.409+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:36:06.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.410+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:36:06.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.410+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4543]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:36:06.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.412+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4543]: It took 0.00237s to build the Airflow DAG.
[2025-01-09T14:36:06.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:36:06.426+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.426+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:36:06.447+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:06.447+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:36:06.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.213 seconds
[2025-01-09T14:36:36.856+0000] {processor.py:157} INFO - Started process (PID=4630) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:36:36.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:36:36.859+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:36.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:36:36.883+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:36.883+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:36:37.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.086+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18349632999979804
[2025-01-09T14:36:37.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.087+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4630]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:36:37.088+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.088+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:36:37.088+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.088+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:36:37.089+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.088+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:36:37.089+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.089+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4630]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:36:37.093+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.092+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4630]: It took 0.00343s to build the Airflow DAG.
[2025-01-09T14:36:37.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:36:37.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.110+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:36:37.141+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:36:37.140+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:36:37.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-09T14:37:07.287+0000] {processor.py:157} INFO - Started process (PID=4716) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:37:07.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:37:07.291+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:37:07.318+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.318+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:37:07.488+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.487+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15472453399979713
[2025-01-09T14:37:07.488+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.488+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4716]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:37:07.489+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.489+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:37:07.489+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.489+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:37:07.490+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.489+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:37:07.490+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.490+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4716]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:37:07.493+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.493+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4716]: It took 0.00292s to build the Airflow DAG.
[2025-01-09T14:37:07.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:37:07.509+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.509+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:37:07.544+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:07.544+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:37:07.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.291 seconds
[2025-01-09T14:37:38.553+0000] {processor.py:157} INFO - Started process (PID=4821) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:37:38.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:37:38.562+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:37:38.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.582+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:37:38.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.694+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.0981718150001143
[2025-01-09T14:37:38.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.694+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4821]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:37:38.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.695+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:37:38.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.695+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:37:38.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.695+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:37:38.696+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.696+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4821]: It took 0.114s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:37:38.698+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.698+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4821]: It took 0.00238s to build the Airflow DAG.
[2025-01-09T14:37:38.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:37:38.712+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.712+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:37:38.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:37:38.736+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:37:38.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-09T14:38:09.010+0000] {processor.py:157} INFO - Started process (PID=4907) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:38:09.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:38:09.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:38:09.046+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.045+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:38:09.223+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.223+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.161379019999913
[2025-01-09T14:38:09.223+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.223+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4907]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:38:09.224+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.224+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:38:09.224+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.224+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:38:09.225+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.225+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:38:09.225+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.225+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4907]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:38:09.228+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.228+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4907]: It took 0.00304s to build the Airflow DAG.
[2025-01-09T14:38:09.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:38:09.243+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.243+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:38:09.275+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:09.274+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:38:09.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-09T14:38:39.375+0000] {processor.py:157} INFO - Started process (PID=4994) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:38:39.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:38:39.378+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:38:39.402+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.401+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:38:39.531+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.531+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11574278900025092
[2025-01-09T14:38:39.531+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.531+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|4994]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:38:39.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.532+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:38:39.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.532+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:38:39.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.532+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:38:39.533+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.533+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|4994]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:38:39.535+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.535+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|4994]: It took 0.00254s to build the Airflow DAG.
[2025-01-09T14:38:39.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:38:39.548+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.548+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:38:39.569+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:38:39.569+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:38:39.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.214 seconds
[2025-01-09T14:39:10.616+0000] {processor.py:157} INFO - Started process (PID=5080) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:39:10.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:39:10.622+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:39:10.655+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.654+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:39:10.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.863+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1861324940000486
[2025-01-09T14:39:10.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.863+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|5080]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:39:10.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.864+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:39:10.865+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.865+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:39:10.865+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.865+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:39:10.866+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.866+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|5080]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:39:10.870+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.870+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|5080]: It took 0.00382s to build the Airflow DAG.
[2025-01-09T14:39:10.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:39:10.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.892+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:39:10.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:10.938+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:39:10.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.367 seconds
[2025-01-09T14:39:41.973+0000] {processor.py:157} INFO - Started process (PID=5167) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:39:41.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:39:41.976+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:41.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:39:41.998+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:41.998+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:39:42.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.130+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11961991099997249
[2025-01-09T14:39:42.131+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.131+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|5167]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:39:42.131+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.131+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:39:42.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.132+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:39:42.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.132+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:39:42.133+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.133+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|5167]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:39:42.135+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.135+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|5167]: It took 0.00255s to build the Airflow DAG.
[2025-01-09T14:39:42.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:39:42.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.150+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:39:42.173+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:39:42.173+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:39:42.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T14:40:12.271+0000] {processor.py:157} INFO - Started process (PID=5272) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:40:12.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:40:12.275+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:40:12.299+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.298+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:40:12.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.461+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1486499319998984
[2025-01-09T14:40:12.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.461+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|5272]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:40:12.462+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.462+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:40:12.462+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.462+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:40:12.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.463+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:40:12.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.463+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|5272]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:40:12.466+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.466+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|5272]: It took 0.00267s to build the Airflow DAG.
[2025-01-09T14:40:12.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:40:12.480+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.480+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:40:12.505+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:12.505+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:40:12.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-09T14:40:42.829+0000] {processor.py:157} INFO - Started process (PID=5358) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:40:42.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:40:42.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:42.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:40:42.858+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:42.858+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:40:43.008+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.008+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1370722020001267
[2025-01-09T14:40:43.009+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.009+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|5358]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:40:43.010+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.010+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:40:43.011+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.011+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:40:43.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.012+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:40:43.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.013+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|5358]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:40:43.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.019+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|5358]: It took 0.00681s to build the Airflow DAG.
[2025-01-09T14:40:43.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:40:43.038+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.037+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:40:43.061+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:40:43.061+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:40:43.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-09T14:41:06.992+0000] {processor.py:157} INFO - Started process (PID=5444) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:41:06.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:41:06.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:06.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:41:07.048+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.048+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:41:07.182+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.181+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11999680500002796
[2025-01-09T14:41:07.182+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.182+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|5444]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:41:07.182+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.182+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:41:07.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.183+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:41:07.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.183+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:41:07.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.183+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|5444]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:41:07.186+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.186+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|5444]: It took 0.00283s to build the Airflow DAG.
[2025-01-09T14:41:07.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:41:07.201+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.201+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:41:07.229+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:07.229+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:41:07.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-09T14:41:37.411+0000] {processor.py:157} INFO - Started process (PID=5530) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:41:37.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:41:37.415+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:41:37.439+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.439+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:41:37.587+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.587+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13458319400024266
[2025-01-09T14:41:37.588+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.588+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|5530]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:41:37.588+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.588+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:41:37.589+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.589+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:41:37.589+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.589+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:41:37.589+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.589+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|5530]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:41:37.592+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.592+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|5530]: It took 0.00255s to build the Airflow DAG.
[2025-01-09T14:41:37.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:41:37.607+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.607+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:41:37.633+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:41:37.633+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:41:37.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-09T14:42:08.166+0000] {processor.py:157} INFO - Started process (PID=5616) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:42:08.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:42:08.169+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:42:08.195+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.195+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:42:08.358+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.358+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14827777800019248
[2025-01-09T14:42:08.359+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.358+0000] {graph.py:519} INFO - Cosmos performance [26e3b27da28d|5616]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:42:08.359+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.359+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:42:08.360+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.360+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:42:08.360+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.360+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:42:08.360+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.360+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [26e3b27da28d|5616]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:42:08.364+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.364+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [26e3b27da28d|5616]: It took 0.0033s to build the Airflow DAG.
[2025-01-09T14:42:08.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:42:08.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.381+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:42:08.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:42:08.409+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:42:08.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-09T14:43:36.516+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:43:36.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:43:36.522+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:43:36.565+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.564+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:43:36.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.822+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23128261200008637
[2025-01-09T14:43:36.823+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.823+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|77]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:43:36.825+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.824+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:43:36.826+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.825+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:43:36.826+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.826+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:43:36.827+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.827+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|77]: It took 0.263s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:43:36.834+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:36.834+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|77]: It took 0.00676s to build the Airflow DAG.
[2025-01-09T14:43:36.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:43:37.082+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:37.082+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:43:37.131+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:43:37.131+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:43:37.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.673 seconds
[2025-01-09T14:44:07.411+0000] {processor.py:157} INFO - Started process (PID=164) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:44:07.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:44:07.415+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:44:07.438+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.437+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:44:07.631+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.631+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17895587500015608
[2025-01-09T14:44:07.632+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.632+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|164]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:44:07.633+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.633+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:44:07.634+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.633+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:44:07.634+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.634+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:44:07.635+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.635+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|164]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:44:07.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.640+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|164]: It took 0.00548s to build the Airflow DAG.
[2025-01-09T14:44:07.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:44:07.665+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.665+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:44:07.709+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:07.709+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:44:07.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.320 seconds
[2025-01-09T14:44:37.879+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:44:37.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:44:37.889+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:37.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:44:37.924+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:37.924+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:44:38.118+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.118+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17210266699976273
[2025-01-09T14:44:38.119+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.118+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|261]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:44:38.119+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.119+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:44:38.120+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.120+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:44:38.120+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.120+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:44:38.121+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.120+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|261]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:44:38.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.124+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|261]: It took 0.00329s to build the Airflow DAG.
[2025-01-09T14:44:38.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:44:38.146+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.145+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:44:38.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:44:38.185+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:44:38.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.359 seconds
[2025-01-09T14:45:08.344+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:45:08.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:45:08.348+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:45:08.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.377+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:45:08.555+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.554+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1571069990000069
[2025-01-09T14:45:08.555+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.555+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|344]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:45:08.556+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.555+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:45:08.556+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.556+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:45:08.556+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.556+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:45:08.557+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.557+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|344]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:45:08.561+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.560+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|344]: It took 0.00362s to build the Airflow DAG.
[2025-01-09T14:45:08.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:45:08.580+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.580+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:45:08.648+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:08.648+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:45:08.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.358 seconds
[2025-01-09T14:45:38.779+0000] {processor.py:157} INFO - Started process (PID=441) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:45:38.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:45:38.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:45:38.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.802+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:45:38.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.939+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12406038100016303
[2025-01-09T14:45:38.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.939+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|441]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:45:38.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.939+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:45:38.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.940+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:45:38.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.940+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:45:38.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.940+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|441]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:45:38.943+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.943+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|441]: It took 0.00237s to build the Airflow DAG.
[2025-01-09T14:45:38.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:45:38.955+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.955+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:45:38.977+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:45:38.977+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:45:38.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-09T14:46:09.097+0000] {processor.py:157} INFO - Started process (PID=527) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:46:09.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:46:09.100+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:46:09.121+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.121+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:46:09.268+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.268+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1338696269999673
[2025-01-09T14:46:09.268+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.268+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|527]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:46:09.269+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.269+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:46:09.269+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.269+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:46:09.270+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.269+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:46:09.270+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.270+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|527]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:46:09.272+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.272+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|527]: It took 0.00236s to build the Airflow DAG.
[2025-01-09T14:46:09.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:46:09.285+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.285+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:46:09.306+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:09.306+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:46:09.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-09T14:46:39.574+0000] {processor.py:157} INFO - Started process (PID=613) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:46:39.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:46:39.577+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:46:39.602+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.602+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:46:39.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.736+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.121487301000343
[2025-01-09T14:46:39.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.736+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|613]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:46:39.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.737+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:46:39.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.737+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:46:39.738+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.738+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:46:39.738+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.738+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|613]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:46:39.741+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.741+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|613]: It took 0.00298s to build the Airflow DAG.
[2025-01-09T14:46:39.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:46:39.754+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.754+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:46:39.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:46:39.775+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:46:39.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-09T14:47:09.907+0000] {processor.py:157} INFO - Started process (PID=700) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:47:09.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:47:09.913+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:09.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:47:09.952+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:09.952+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:47:10.174+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.174+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1995970190000662
[2025-01-09T14:47:10.175+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.175+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|700]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:47:10.176+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.176+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:47:10.177+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.176+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:47:10.177+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.177+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:47:10.178+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.178+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|700]: It took 0.226s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:47:10.181+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.181+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|700]: It took 0.0035s to build the Airflow DAG.
[2025-01-09T14:47:10.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:47:10.199+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.199+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:47:10.232+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:10.232+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:47:10.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.351 seconds
[2025-01-09T14:47:40.450+0000] {processor.py:157} INFO - Started process (PID=785) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:47:40.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:47:40.454+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:47:40.487+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.487+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:47:40.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.693+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18957713700001477
[2025-01-09T14:47:40.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.694+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|785]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:47:40.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.695+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:47:40.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.695+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:47:40.696+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.696+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:47:40.697+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.696+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|785]: It took 0.209s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:47:40.700+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.700+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|785]: It took 0.00365s to build the Airflow DAG.
[2025-01-09T14:47:40.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:47:40.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.716+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:47:40.745+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:47:40.745+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:47:40.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.315 seconds
[2025-01-09T14:48:11.141+0000] {processor.py:157} INFO - Started process (PID=890) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:48:11.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:48:11.147+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:48:11.177+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.176+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:48:11.439+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.438+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23903084699941246
[2025-01-09T14:48:11.440+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.439+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|890]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:48:11.440+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.440+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:48:11.441+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.441+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:48:11.442+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.441+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:48:11.443+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.442+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|890]: It took 0.266s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:48:11.448+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.447+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|890]: It took 0.00502s to build the Airflow DAG.
[2025-01-09T14:48:11.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:48:11.474+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.474+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:48:11.508+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:11.508+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:48:11.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.391 seconds
[2025-01-09T14:48:41.744+0000] {processor.py:157} INFO - Started process (PID=976) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:48:41.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:48:41.747+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:48:41.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.772+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:48:41.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.939+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15300626499993086
[2025-01-09T14:48:41.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.939+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|976]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:48:41.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.940+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:48:41.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.940+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:48:41.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.940+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:48:41.941+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.941+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|976]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:48:41.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.944+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|976]: It took 0.00281s to build the Airflow DAG.
[2025-01-09T14:48:41.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:48:41.957+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.957+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:48:41.981+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:48:41.980+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:48:42.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-09T14:49:12.069+0000] {processor.py:157} INFO - Started process (PID=1062) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:49:12.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:49:12.074+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:49:12.098+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.098+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:49:12.238+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.238+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12638362900088396
[2025-01-09T14:49:12.239+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.239+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1062]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:49:12.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.239+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:49:12.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.240+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:49:12.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.240+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:49:12.241+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.240+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1062]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:49:12.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.243+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1062]: It took 0.00298s to build the Airflow DAG.
[2025-01-09T14:49:12.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:49:12.256+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.256+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:49:12.282+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:12.281+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:49:12.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-09T14:49:42.460+0000] {processor.py:157} INFO - Started process (PID=1149) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:49:42.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:49:42.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:49:42.483+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.482+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:49:42.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.627+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13138786600029562
[2025-01-09T14:49:42.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.628+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1149]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:49:42.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.628+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:49:42.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.629+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:49:42.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.629+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:49:42.630+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.630+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1149]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:49:42.633+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.633+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1149]: It took 0.00312s to build the Airflow DAG.
[2025-01-09T14:49:42.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:49:42.647+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.647+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:49:42.671+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:49:42.671+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:49:42.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-09T14:50:12.834+0000] {processor.py:157} INFO - Started process (PID=1246) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:50:12.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:50:12.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:50:12.857+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.857+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:50:12.988+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.987+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11796435799988103
[2025-01-09T14:50:12.988+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.988+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1246]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:50:12.988+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.988+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:50:12.989+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.989+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:50:12.989+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.989+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:50:12.989+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.989+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1246]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:50:12.992+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:12.992+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1246]: It took 0.00282s to build the Airflow DAG.
[2025-01-09T14:50:12.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:50:13.005+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:13.005+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:50:13.031+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:13.031+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:50:13.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.220 seconds
[2025-01-09T14:50:43.105+0000] {processor.py:157} INFO - Started process (PID=1352) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:50:43.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:50:43.109+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:50:43.127+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.127+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:50:43.277+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.277+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1353763089991844
[2025-01-09T14:50:43.277+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.277+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1352]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:50:43.278+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.278+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:50:43.278+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.278+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:50:43.279+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.278+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:50:43.279+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.279+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1352]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:50:43.282+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.282+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1352]: It took 0.00285s to build the Airflow DAG.
[2025-01-09T14:50:43.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:50:43.300+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.300+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:50:43.325+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:50:43.325+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:50:43.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-09T14:51:14.239+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:51:14.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:51:14.242+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:51:14.267+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.267+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:51:14.395+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.395+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11377410600016447
[2025-01-09T14:51:14.395+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.395+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1439]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:51:14.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.396+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:51:14.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.396+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:51:14.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.396+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:51:14.397+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.397+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1439]: It took 0.13s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:51:14.399+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.399+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1439]: It took 0.00248s to build the Airflow DAG.
[2025-01-09T14:51:14.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:51:14.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.413+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:51:14.434+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:14.434+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:51:14.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-09T14:51:44.502+0000] {processor.py:157} INFO - Started process (PID=1526) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:51:44.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:51:44.506+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:51:44.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.530+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:51:44.664+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.664+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11992266800007201
[2025-01-09T14:51:44.664+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.664+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1526]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:51:44.665+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.665+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:51:44.666+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.666+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:51:44.666+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.666+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:51:44.666+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.666+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1526]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:51:44.669+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.669+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1526]: It took 0.00246s to build the Airflow DAG.
[2025-01-09T14:51:44.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:51:44.683+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.683+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:51:44.705+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:51:44.704+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:51:44.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T14:52:15.677+0000] {processor.py:157} INFO - Started process (PID=1612) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:52:15.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:52:15.680+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:15.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:52:15.708+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:15.707+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:52:16.397+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.397+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6757860889993026
[2025-01-09T14:52:16.397+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.397+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1612]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:52:16.398+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.398+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:52:16.398+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.398+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:52:16.399+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.399+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:52:16.399+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.399+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1612]: It took 0.692s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:52:16.402+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.402+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1612]: It took 0.00311s to build the Airflow DAG.
[2025-01-09T14:52:16.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:52:16.423+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.423+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:52:16.448+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:16.448+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:52:16.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.796 seconds
[2025-01-09T14:52:46.757+0000] {processor.py:157} INFO - Started process (PID=1704) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:52:46.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:52:46.760+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:46.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:52:46.783+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:46.783+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:52:47.008+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.008+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21056024700010312
[2025-01-09T14:52:47.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.018+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1704]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:52:47.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.018+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:52:47.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.019+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:52:47.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.020+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:52:47.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.020+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1704]: It took 0.237s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:52:47.024+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.024+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1704]: It took 0.00356s to build the Airflow DAG.
[2025-01-09T14:52:47.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:52:47.041+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.041+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:52:47.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:52:47.070+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:52:47.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.338 seconds
[2025-01-09T14:53:17.652+0000] {processor.py:157} INFO - Started process (PID=1810) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:53:17.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:53:17.658+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:53:17.687+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.686+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:53:17.874+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.874+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17086595499949908
[2025-01-09T14:53:17.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.874+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1810]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:53:17.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.875+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:53:17.876+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.876+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:53:17.876+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.876+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:53:17.877+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.877+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1810]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:53:17.880+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.880+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1810]: It took 0.00343s to build the Airflow DAG.
[2025-01-09T14:53:17.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:53:17.899+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.899+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:53:17.935+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:17.935+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:53:17.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.315 seconds
[2025-01-09T14:53:48.078+0000] {processor.py:157} INFO - Started process (PID=1895) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:53:48.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:53:48.081+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:53:48.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.104+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:53:48.238+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.238+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12188199000047462
[2025-01-09T14:53:48.238+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.238+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1895]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:53:48.239+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.239+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:53:48.239+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.239+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:53:48.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.239+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:53:48.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.240+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1895]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:53:48.243+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.242+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1895]: It took 0.0026s to build the Airflow DAG.
[2025-01-09T14:53:48.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:53:48.256+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.256+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:53:48.278+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:53:48.278+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:53:48.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.221 seconds
[2025-01-09T14:54:18.610+0000] {processor.py:157} INFO - Started process (PID=1983) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:54:18.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:54:18.613+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:54:18.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.640+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:54:18.778+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.778+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12486366800021642
[2025-01-09T14:54:18.778+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.778+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|1983]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:54:18.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.779+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:54:18.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.779+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:54:18.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.779+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:54:18.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.780+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|1983]: It took 0.14s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:54:18.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.782+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|1983]: It took 0.00235s to build the Airflow DAG.
[2025-01-09T14:54:18.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:54:18.795+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.795+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:54:18.816+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:18.815+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:54:18.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-09T14:54:49.016+0000] {processor.py:157} INFO - Started process (PID=2071) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:54:49.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:54:49.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:54:49.042+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.041+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:54:49.193+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.193+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1382630269999936
[2025-01-09T14:54:49.193+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.193+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2071]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:54:49.194+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.194+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:54:49.195+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.195+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:54:49.195+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.195+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:54:49.196+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.196+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2071]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:54:49.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.199+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2071]: It took 0.00376s to build the Airflow DAG.
[2025-01-09T14:54:49.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:54:49.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.216+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:54:49.241+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:54:49.240+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:54:49.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-09T14:55:19.400+0000] {processor.py:157} INFO - Started process (PID=2167) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:55:19.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:55:19.403+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:55:19.423+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.423+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:55:19.581+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.581+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.143590757000311
[2025-01-09T14:55:19.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.582+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2167]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:55:19.583+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.582+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:55:19.583+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.583+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:55:19.584+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.584+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:55:19.585+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.584+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2167]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:55:19.589+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.589+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2167]: It took 0.00449s to build the Airflow DAG.
[2025-01-09T14:55:19.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:55:19.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.606+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:55:19.631+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:19.631+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:55:19.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-09T14:55:49.690+0000] {processor.py:157} INFO - Started process (PID=2264) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:55:49.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:55:49.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:55:49.716+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.716+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:55:49.854+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.854+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12419110799964983
[2025-01-09T14:55:49.854+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.854+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2264]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:55:49.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.855+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:55:49.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.855+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:55:49.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.855+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:55:49.856+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.856+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2264]: It took 0.14s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:55:49.858+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.858+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2264]: It took 0.00226s to build the Airflow DAG.
[2025-01-09T14:55:49.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:55:49.871+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.871+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:55:49.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:55:49.892+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:55:49.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-09T14:56:19.948+0000] {processor.py:157} INFO - Started process (PID=2351) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:56:19.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:56:19.952+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:19.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:56:19.974+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:19.974+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:56:20.103+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.103+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11655615899962868
[2025-01-09T14:56:20.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.103+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2351]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:56:20.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.104+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:56:20.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.104+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:56:20.105+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.104+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:56:20.105+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.105+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2351]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:56:20.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.107+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2351]: It took 0.00217s to build the Airflow DAG.
[2025-01-09T14:56:20.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:56:20.119+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.119+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:56:20.140+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:20.139+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:56:20.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.212 seconds
[2025-01-09T14:56:50.187+0000] {processor.py:157} INFO - Started process (PID=2438) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:56:50.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:56:50.190+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:56:50.214+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.214+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:56:50.349+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.349+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12365655200028414
[2025-01-09T14:56:50.350+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.350+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2438]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:56:50.350+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.350+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:56:50.351+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.350+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:56:50.351+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.351+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:56:50.351+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.351+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2438]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:56:50.353+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.353+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2438]: It took 0.00231s to build the Airflow DAG.
[2025-01-09T14:56:50.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:56:50.367+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.366+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:56:50.388+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:56:50.388+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:56:50.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-09T14:57:20.593+0000] {processor.py:157} INFO - Started process (PID=2531) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:57:20.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:57:20.598+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:57:20.618+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.618+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:57:20.797+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.797+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1665856649997295
[2025-01-09T14:57:20.798+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.798+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2531]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:57:20.799+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.799+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:57:20.800+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.799+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:57:20.800+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.800+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:57:20.801+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.801+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2531]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:57:20.805+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.805+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2531]: It took 0.0046s to build the Airflow DAG.
[2025-01-09T14:57:20.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:57:20.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.822+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:57:20.848+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:20.848+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:57:20.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-09T14:57:51.090+0000] {processor.py:157} INFO - Started process (PID=2629) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:57:51.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:57:51.093+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:57:51.114+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.114+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:57:51.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.240+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11317944099937449
[2025-01-09T14:57:51.241+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.241+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2629]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:57:51.241+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.241+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:57:51.242+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.241+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:57:51.242+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.242+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:57:51.242+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.242+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2629]: It took 0.128s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:57:51.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.244+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2629]: It took 0.00217s to build the Airflow DAG.
[2025-01-09T14:57:51.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:57:51.257+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.257+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:57:51.277+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:57:51.277+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:57:51.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.210 seconds
[2025-01-09T14:58:21.428+0000] {processor.py:157} INFO - Started process (PID=2715) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:58:21.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:58:21.432+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:58:21.455+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.455+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:58:21.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.626+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15626087400050892
[2025-01-09T14:58:21.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.626+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2715]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:58:21.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.627+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:58:21.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.628+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:58:21.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.628+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:58:21.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.629+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2715]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:58:21.633+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.633+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2715]: It took 0.004s to build the Airflow DAG.
[2025-01-09T14:58:21.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:58:21.653+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.653+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:58:21.686+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:21.686+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:58:21.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.283 seconds
[2025-01-09T14:58:52.014+0000] {processor.py:157} INFO - Started process (PID=2801) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:58:52.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:58:52.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:58:52.040+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.040+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:58:52.162+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.162+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10694178099947749
[2025-01-09T14:58:52.163+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.162+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2801]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:58:52.163+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.163+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:58:52.163+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.163+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:58:52.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.164+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:58:52.164+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.164+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2801]: It took 0.124s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:58:52.167+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.167+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2801]: It took 0.00295s to build the Airflow DAG.
[2025-01-09T14:58:52.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:58:52.179+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.179+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:58:52.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:58:52.200+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:58:52.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.209 seconds
[2025-01-09T14:59:22.307+0000] {processor.py:157} INFO - Started process (PID=2893) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:59:22.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:59:22.312+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:59:22.339+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.339+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:59:22.507+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.507+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14980422300050122
[2025-01-09T14:59:22.508+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.508+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2893]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:59:22.509+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.508+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:59:22.509+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.509+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:59:22.509+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.509+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:59:22.510+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.510+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2893]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:59:22.513+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.513+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2893]: It took 0.00285s to build the Airflow DAG.
[2025-01-09T14:59:22.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:59:22.527+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.527+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:59:22.553+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:22.553+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:59:22.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-09T14:59:52.712+0000] {processor.py:157} INFO - Started process (PID=2992) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:59:52.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T14:59:52.715+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:59:52.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.736+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T14:59:52.857+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.857+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10618895900006464
[2025-01-09T14:59:52.857+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.857+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|2992]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T14:59:52.858+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.858+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T14:59:52.858+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.858+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T14:59:52.858+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.858+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T14:59:52.859+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.859+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|2992]: It took 0.122s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T14:59:52.861+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.861+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|2992]: It took 0.00222s to build the Airflow DAG.
[2025-01-09T14:59:52.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T14:59:52.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.873+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T14:59:52.894+0000] {logging_mixin.py:151} INFO - [2025-01-09T14:59:52.894+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T14:59:52.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.203 seconds
[2025-01-09T15:00:23.792+0000] {processor.py:157} INFO - Started process (PID=3079) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:00:23.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:00:23.795+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:00:23.821+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.821+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:00:23.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.995+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16205372500007797
[2025-01-09T15:00:23.996+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.996+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3079]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:00:23.996+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.996+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:00:23.997+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.997+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:00:23.997+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.997+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:00:23.997+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:23.997+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3079]: It took 0.176s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:00:24.000+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:24.000+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3079]: It took 0.00236s to build the Airflow DAG.
[2025-01-09T15:00:24.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:00:24.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:24.012+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:00:24.033+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:24.033+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:00:24.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-09T15:00:54.938+0000] {processor.py:157} INFO - Started process (PID=3166) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:00:54.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:00:54.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:54.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:00:54.969+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:54.969+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:00:55.110+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.110+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12678168899947195
[2025-01-09T15:00:55.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.110+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3166]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:00:55.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.111+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:00:55.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.111+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:00:55.112+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.112+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:00:55.112+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.112+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3166]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:00:55.115+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.115+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3166]: It took 0.00281s to build the Airflow DAG.
[2025-01-09T15:00:55.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:00:55.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.130+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:00:55.159+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:00:55.158+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:00:55.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T15:01:25.299+0000] {processor.py:157} INFO - Started process (PID=3274) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:01:25.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:01:25.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:01:25.329+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.329+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:01:25.495+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.495+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15072495299955335
[2025-01-09T15:01:25.496+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.495+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3274]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:01:25.496+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.496+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:01:25.496+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.496+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:01:25.497+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.497+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:01:25.497+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.497+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3274]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:01:25.500+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.499+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3274]: It took 0.00245s to build the Airflow DAG.
[2025-01-09T15:01:25.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:01:25.513+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.513+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:01:25.534+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:25.534+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:01:25.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-09T15:01:55.600+0000] {processor.py:157} INFO - Started process (PID=3361) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:01:55.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:01:55.603+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:01:55.625+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.625+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:01:55.778+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.778+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13817792700046994
[2025-01-09T15:01:55.778+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.778+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3361]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:01:55.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.779+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:01:55.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.780+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:01:55.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.780+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:01:55.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.780+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3361]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:01:55.783+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.783+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3361]: It took 0.00272s to build the Airflow DAG.
[2025-01-09T15:01:55.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:01:55.796+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.796+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:01:55.818+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:01:55.818+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:01:55.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T15:02:25.894+0000] {processor.py:157} INFO - Started process (PID=3444) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:02:25.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:02:25.897+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:25.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:02:25.917+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:25.917+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:02:26.064+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.064+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13386766599978728
[2025-01-09T15:02:26.064+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.064+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3444]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:02:26.065+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.065+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:02:26.065+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.065+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:02:26.066+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.066+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:02:26.066+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.066+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3444]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:02:26.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.069+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3444]: It took 0.00308s to build the Airflow DAG.
[2025-01-09T15:02:26.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:02:26.086+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.086+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:02:26.112+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:26.112+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:02:26.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T15:02:56.175+0000] {processor.py:157} INFO - Started process (PID=3538) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:02:56.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:02:56.178+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:02:56.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.199+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:02:56.357+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.356+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14255905600020924
[2025-01-09T15:02:56.357+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.357+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3538]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:02:56.358+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.358+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:02:56.358+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.358+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:02:56.358+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.358+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:02:56.359+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.359+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3538]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:02:56.362+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.362+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3538]: It took 0.0031s to build the Airflow DAG.
[2025-01-09T15:02:56.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:02:56.379+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.379+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:02:56.406+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:02:56.406+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:02:56.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-09T15:03:26.504+0000] {processor.py:157} INFO - Started process (PID=3635) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:03:26.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:03:26.507+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:03:26.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.532+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:03:26.674+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.674+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12931312799992156
[2025-01-09T15:03:26.674+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.674+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3635]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:03:26.675+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.675+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:03:26.675+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.675+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:03:26.676+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.676+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:03:26.676+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.676+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3635]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:03:26.678+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.678+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3635]: It took 0.00249s to build the Airflow DAG.
[2025-01-09T15:03:26.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:03:26.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.693+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:03:26.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:26.716+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:03:26.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-09T15:03:56.835+0000] {processor.py:157} INFO - Started process (PID=3721) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:03:56.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:03:56.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:56.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:03:56.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:56.862+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:03:56.998+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:56.998+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12403595900013897
[2025-01-09T15:03:56.999+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:56.998+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3721]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:03:56.999+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:56.999+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:03:56.999+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:56.999+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:03:57.000+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:57.000+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:03:57.000+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:57.000+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3721]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:03:57.003+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:57.002+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3721]: It took 0.00239s to build the Airflow DAG.
[2025-01-09T15:03:57.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:03:57.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:57.016+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:03:57.040+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:03:57.040+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:03:57.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-09T15:04:27.331+0000] {processor.py:157} INFO - Started process (PID=3807) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:04:27.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:04:27.336+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:04:27.357+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.357+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:04:27.502+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.502+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13122300099985296
[2025-01-09T15:04:27.503+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.502+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3807]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:04:27.503+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.503+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:04:27.504+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.503+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:04:27.504+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.504+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:04:27.504+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.504+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3807]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:04:27.507+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.507+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3807]: It took 0.0027s to build the Airflow DAG.
[2025-01-09T15:04:27.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:04:27.520+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.520+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:04:27.546+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:27.546+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:04:27.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-09T15:04:57.625+0000] {processor.py:157} INFO - Started process (PID=3912) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:04:57.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:04:57.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:04:57.650+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.650+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:04:57.801+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.800+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1366020870000284
[2025-01-09T15:04:57.801+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.801+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|3912]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:04:57.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.801+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:04:57.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.802+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:04:57.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.802+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:04:57.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.802+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|3912]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:04:57.805+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.805+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|3912]: It took 0.00286s to build the Airflow DAG.
[2025-01-09T15:04:57.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:04:57.820+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.820+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:04:57.845+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:04:57.845+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:04:57.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-09T15:05:27.975+0000] {processor.py:157} INFO - Started process (PID=4000) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:05:27.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:05:27.978+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:27.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:05:28.001+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.000+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:05:28.135+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.135+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12228404200050136
[2025-01-09T15:05:28.135+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.135+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4000]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:05:28.136+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.136+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:05:28.136+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.136+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:05:28.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.136+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:05:28.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.137+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4000]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:05:28.139+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.139+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4000]: It took 0.00247s to build the Airflow DAG.
[2025-01-09T15:05:28.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:05:28.152+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.152+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:05:28.174+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:28.174+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:05:28.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-09T15:05:58.287+0000] {processor.py:157} INFO - Started process (PID=4088) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:05:58.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:05:58.291+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:05:58.317+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.317+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:05:58.465+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.465+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13576949599973887
[2025-01-09T15:05:58.466+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.466+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4088]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:05:58.466+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.466+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:05:58.466+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.466+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:05:58.467+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.467+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:05:58.467+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.467+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4088]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:05:58.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.469+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4088]: It took 0.00239s to build the Airflow DAG.
[2025-01-09T15:05:58.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:05:58.483+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.482+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:05:58.504+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:05:58.504+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:05:58.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-09T15:06:28.610+0000] {processor.py:157} INFO - Started process (PID=4184) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:06:28.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:06:28.613+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:06:28.631+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.631+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:06:28.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.779+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1342634069997075
[2025-01-09T15:06:28.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.779+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4184]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:06:28.780+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.780+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:06:28.781+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.781+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:06:28.781+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.781+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:06:28.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.781+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4184]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:06:28.784+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.784+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4184]: It took 0.00288s to build the Airflow DAG.
[2025-01-09T15:06:28.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:06:28.801+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.800+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:06:28.833+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:28.833+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:06:28.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-09T15:06:59.714+0000] {processor.py:157} INFO - Started process (PID=4280) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:06:59.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:06:59.718+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:06:59.738+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.738+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:06:59.867+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.867+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1155920729997888
[2025-01-09T15:06:59.867+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.867+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4280]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:06:59.868+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.868+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:06:59.868+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.868+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:06:59.868+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.868+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:06:59.869+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.869+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4280]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:06:59.872+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.872+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4280]: It took 0.0029s to build the Airflow DAG.
[2025-01-09T15:06:59.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:06:59.885+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.885+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:06:59.908+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:06:59.908+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:06:59.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.214 seconds
[2025-01-09T15:07:30.075+0000] {processor.py:157} INFO - Started process (PID=4367) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:07:30.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:07:30.077+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:07:30.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.104+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:07:30.260+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.260+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14192541099964728
[2025-01-09T15:07:30.261+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.261+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4367]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:07:30.261+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.261+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:07:30.262+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.262+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:07:30.262+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.262+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:07:30.262+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.262+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4367]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:07:30.265+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.265+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4367]: It took 0.00286s to build the Airflow DAG.
[2025-01-09T15:07:30.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:07:30.278+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.278+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:07:30.299+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:07:30.299+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:07:30.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-09T15:08:00.429+0000] {processor.py:157} INFO - Started process (PID=4455) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:08:00.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:08:00.432+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:08:00.454+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.453+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:08:00.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.624+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15651852399969357
[2025-01-09T15:08:00.625+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.625+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4455]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:08:00.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.626+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:08:00.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.626+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:08:00.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.627+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:08:00.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.627+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4455]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:08:00.631+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.631+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4455]: It took 0.00394s to build the Airflow DAG.
[2025-01-09T15:08:00.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:08:00.649+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.649+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:08:00.673+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:00.673+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:08:00.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-09T15:08:30.933+0000] {processor.py:157} INFO - Started process (PID=4562) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:08:30.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:08:30.936+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:30.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:08:30.959+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:30.959+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:08:31.123+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.123+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14922163400024147
[2025-01-09T15:08:31.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.124+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4562]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:08:31.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.124+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:08:31.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.125+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:08:31.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.125+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:08:31.126+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.125+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4562]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:08:31.128+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.128+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4562]: It took 0.00257s to build the Airflow DAG.
[2025-01-09T15:08:31.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:08:31.142+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.142+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:08:31.165+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:08:31.165+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:08:31.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-09T15:09:01.298+0000] {processor.py:157} INFO - Started process (PID=4649) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:09:01.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:09:01.301+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:09:01.325+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.324+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:09:01.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.469+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.131254068999624
[2025-01-09T15:09:01.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.469+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4649]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:09:01.470+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.470+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:09:01.470+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.470+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:09:01.471+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.471+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:09:01.471+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.471+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4649]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:09:01.474+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.473+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4649]: It took 0.00239s to build the Airflow DAG.
[2025-01-09T15:09:01.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:09:01.487+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.487+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:09:01.510+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:01.510+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:09:01.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-09T15:09:31.565+0000] {processor.py:157} INFO - Started process (PID=4736) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:09:31.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:09:31.570+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:09:31.595+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.594+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:09:31.753+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.753+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1425423269993189
[2025-01-09T15:09:31.753+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.753+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4736]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:09:31.754+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.754+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:09:31.754+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.754+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:09:31.755+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.755+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:09:31.755+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.755+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4736]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:09:31.758+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.758+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4736]: It took 0.00293s to build the Airflow DAG.
[2025-01-09T15:09:31.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:09:31.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.773+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:09:31.795+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:09:31.795+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:09:31.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-09T15:10:02.678+0000] {processor.py:157} INFO - Started process (PID=4822) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:10:02.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:10:02.681+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:10:02.701+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.701+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:10:02.854+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.854+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14029110800038325
[2025-01-09T15:10:02.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.855+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4822]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:10:02.856+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.856+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:10:02.856+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.856+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:10:02.857+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.857+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:10:02.857+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.857+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4822]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:10:02.861+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.860+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4822]: It took 0.00321s to build the Airflow DAG.
[2025-01-09T15:10:02.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:10:02.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.875+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:10:02.896+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:02.896+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:10:02.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-09T15:10:33.040+0000] {processor.py:157} INFO - Started process (PID=4930) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:10:33.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:10:33.044+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:10:33.070+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.070+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:10:33.215+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.215+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.131468950999988
[2025-01-09T15:10:33.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.216+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|4930]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:10:33.217+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.217+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:10:33.218+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.218+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:10:33.219+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.218+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:10:33.219+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.219+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|4930]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:10:33.224+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.224+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|4930]: It took 0.00491s to build the Airflow DAG.
[2025-01-09T15:10:33.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:10:33.238+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.238+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:10:33.260+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:10:33.260+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:10:33.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-09T15:11:04.200+0000] {processor.py:157} INFO - Started process (PID=5016) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:11:04.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:11:04.203+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:11:04.227+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.227+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:11:04.362+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.362+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1226778780001041
[2025-01-09T15:11:04.363+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.363+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5016]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:11:04.363+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.363+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:11:04.364+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.363+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:11:04.364+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.364+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:11:04.364+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.364+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5016]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:11:04.367+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.367+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5016]: It took 0.00265s to build the Airflow DAG.
[2025-01-09T15:11:04.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:11:04.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.381+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:11:04.402+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:04.402+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:11:04.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T15:11:34.628+0000] {processor.py:157} INFO - Started process (PID=5102) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:11:34.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:11:34.633+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:11:34.675+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.675+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:11:34.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.832+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14270086400028958
[2025-01-09T15:11:34.833+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.832+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5102]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:11:34.833+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.833+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:11:34.834+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.833+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:11:34.834+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.834+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:11:34.834+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.834+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5102]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:11:34.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.837+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5102]: It took 0.00312s to build the Airflow DAG.
[2025-01-09T15:11:34.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:11:34.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.855+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:11:34.881+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:11:34.881+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:11:34.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.276 seconds
[2025-01-09T15:12:05.257+0000] {processor.py:157} INFO - Started process (PID=5196) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:12:05.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:12:05.261+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:12:05.285+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.285+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:12:05.467+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.466+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16582761400059098
[2025-01-09T15:12:05.467+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.467+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5196]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:12:05.468+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.468+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:12:05.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.468+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:12:05.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.469+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:12:05.470+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.470+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5196]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:12:05.474+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.474+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5196]: It took 0.00428s to build the Airflow DAG.
[2025-01-09T15:12:05.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:12:05.492+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.492+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:12:05.519+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:05.518+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:12:05.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-09T15:12:35.623+0000] {processor.py:157} INFO - Started process (PID=5295) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:12:35.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:12:35.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:12:35.653+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.653+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:12:35.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.810+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14148227099940414
[2025-01-09T15:12:35.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.810+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5295]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:12:35.811+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.811+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:12:35.811+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.811+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:12:35.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.812+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:12:35.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.812+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5295]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:12:35.816+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.815+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5295]: It took 0.00321s to build the Airflow DAG.
[2025-01-09T15:12:35.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:12:35.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.832+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:12:35.858+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:12:35.858+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:12:35.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-09T15:13:06.875+0000] {processor.py:157} INFO - Started process (PID=5381) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:13:06.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:13:06.879+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:06.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:13:06.905+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:06.905+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:13:07.043+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.043+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12443651899957331
[2025-01-09T15:13:07.043+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.043+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5381]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:13:07.044+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.044+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:13:07.044+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.044+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:13:07.044+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.044+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:13:07.045+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.045+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5381]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:13:07.047+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.047+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5381]: It took 0.0024s to build the Airflow DAG.
[2025-01-09T15:13:07.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:13:07.060+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.060+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:13:07.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:07.087+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:13:07.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-09T15:13:37.223+0000] {processor.py:157} INFO - Started process (PID=5467) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:13:37.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:13:37.228+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:13:37.260+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.260+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:13:37.425+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.425+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14934287600044627
[2025-01-09T15:13:37.426+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.426+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5467]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:13:37.426+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.426+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:13:37.427+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.427+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:13:37.428+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.427+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:13:37.428+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.428+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5467]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:13:37.431+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.431+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5467]: It took 0.00327s to build the Airflow DAG.
[2025-01-09T15:13:37.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:13:37.447+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.447+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:13:37.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:13:37.476+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:13:37.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-09T15:14:07.640+0000] {processor.py:157} INFO - Started process (PID=5562) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:14:07.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:14:07.644+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:14:07.670+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.670+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:14:07.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.838+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1528333179994661
[2025-01-09T15:14:07.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.838+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5562]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:14:07.839+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.839+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:14:07.840+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.840+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:14:07.840+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.840+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:14:07.841+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.840+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5562]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:14:07.844+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.844+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5562]: It took 0.00353s to build the Airflow DAG.
[2025-01-09T15:14:07.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:14:07.859+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.859+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:14:07.887+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:07.886+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:14:07.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-09T15:14:37.950+0000] {processor.py:157} INFO - Started process (PID=5661) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:14:37.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:14:37.953+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:37.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:14:37.979+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:37.979+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:14:38.129+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.129+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13589673099977517
[2025-01-09T15:14:38.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.130+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5661]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:14:38.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.130+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:14:38.131+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.131+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:14:38.131+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.131+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:14:38.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.132+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5661]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:14:38.134+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.134+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5661]: It took 0.00261s to build the Airflow DAG.
[2025-01-09T15:14:38.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:14:38.152+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.152+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:14:38.174+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:14:38.174+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:14:38.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-09T15:15:08.257+0000] {processor.py:157} INFO - Started process (PID=5748) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:15:08.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:15:08.261+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:15:08.287+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.286+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:15:08.450+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.449+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1489259090003543
[2025-01-09T15:15:08.450+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.450+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5748]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:15:08.451+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.450+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:15:08.451+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.451+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:15:08.452+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.451+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:15:08.452+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.452+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5748]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:15:08.455+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.455+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5748]: It took 0.00279s to build the Airflow DAG.
[2025-01-09T15:15:08.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:15:08.470+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.470+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:15:08.500+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:08.500+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:15:08.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-09T15:15:38.577+0000] {processor.py:157} INFO - Started process (PID=5834) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:15:38.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:15:38.581+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:15:38.609+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.609+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:15:38.774+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.774+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1502499580001313
[2025-01-09T15:15:38.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.774+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5834]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:15:38.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.775+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:15:38.776+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.776+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:15:38.776+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.776+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:15:38.777+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.776+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5834]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:15:38.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.779+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5834]: It took 0.00285s to build the Airflow DAG.
[2025-01-09T15:15:38.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:15:38.795+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.795+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:15:38.826+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:15:38.825+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:15:38.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-09T15:16:08.938+0000] {processor.py:157} INFO - Started process (PID=5928) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:16:08.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:16:08.942+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:08.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:16:08.970+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:08.970+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:16:09.147+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.147+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16388362599991524
[2025-01-09T15:16:09.148+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.148+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|5928]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:16:09.149+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.148+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:16:09.149+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.149+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:16:09.149+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.149+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:16:09.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.150+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|5928]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:16:09.153+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.153+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|5928]: It took 0.0033s to build the Airflow DAG.
[2025-01-09T15:16:09.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:16:09.169+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.169+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:16:09.201+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:09.201+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:16:09.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-09T15:16:39.596+0000] {processor.py:157} INFO - Started process (PID=6027) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:16:39.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:16:39.600+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:16:39.627+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.627+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:16:39.762+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.762+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12201219799953833
[2025-01-09T15:16:39.762+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.762+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6027]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:16:39.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.763+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:16:39.764+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.763+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:16:39.764+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.764+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:16:39.765+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.764+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6027]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:16:39.768+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.768+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6027]: It took 0.00311s to build the Airflow DAG.
[2025-01-09T15:16:39.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:16:39.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.782+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:16:39.805+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:16:39.804+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:16:39.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-09T15:17:09.970+0000] {processor.py:157} INFO - Started process (PID=6105) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:17:09.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:17:09.974+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:09.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:17:09.995+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:09.995+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:17:10.147+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.147+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13923653700021532
[2025-01-09T15:17:10.147+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.147+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6105]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:17:10.148+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.148+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:17:10.148+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.148+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:17:10.149+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.149+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:17:10.149+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.149+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6105]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:17:10.152+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.152+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6105]: It took 0.00336s to build the Airflow DAG.
[2025-01-09T15:17:10.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:17:10.166+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.165+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:17:10.189+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:10.189+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:17:10.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T15:17:40.547+0000] {processor.py:157} INFO - Started process (PID=6191) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:17:40.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:17:40.555+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:17:40.586+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.586+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:17:40.761+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.761+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15119675799996912
[2025-01-09T15:17:40.761+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.761+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6191]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:17:40.762+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.762+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:17:40.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.762+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:17:40.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.763+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:17:40.764+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.764+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6191]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:17:40.768+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.768+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6191]: It took 0.00443s to build the Airflow DAG.
[2025-01-09T15:17:40.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:17:40.783+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.783+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:17:40.810+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:17:40.810+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:17:40.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.292 seconds
[2025-01-09T15:18:11.422+0000] {processor.py:157} INFO - Started process (PID=6296) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:18:11.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:18:11.426+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:18:11.455+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.455+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:18:11.616+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.616+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1439272860006895
[2025-01-09T15:18:11.616+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.616+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6296]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:18:11.617+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.617+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:18:11.618+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.617+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:18:11.618+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.618+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:18:11.619+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.619+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6296]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:18:11.622+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.622+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6296]: It took 0.00312s to build the Airflow DAG.
[2025-01-09T15:18:11.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:18:11.636+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.636+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:18:11.660+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:11.660+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:18:11.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-09T15:18:41.855+0000] {processor.py:157} INFO - Started process (PID=6382) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:18:41.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:18:41.859+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:41.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:18:41.881+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:41.881+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:18:42.017+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.017+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1235520810005255
[2025-01-09T15:18:42.017+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.017+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6382]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:18:42.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.018+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:18:42.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.018+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:18:42.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.019+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:18:42.019+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.019+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6382]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:18:42.022+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.021+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6382]: It took 0.00249s to build the Airflow DAG.
[2025-01-09T15:18:42.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:18:42.036+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.036+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:18:42.064+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:18:42.064+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:18:42.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-09T15:19:12.149+0000] {processor.py:157} INFO - Started process (PID=6469) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:19:12.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:19:12.153+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:19:12.174+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.174+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:19:12.319+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.318+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13125090199991973
[2025-01-09T15:19:12.319+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.319+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6469]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:19:12.319+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.319+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:19:12.320+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.320+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:19:12.320+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.320+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:19:12.320+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.320+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6469]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:19:12.323+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.323+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6469]: It took 0.00237s to build the Airflow DAG.
[2025-01-09T15:19:12.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:19:12.336+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.335+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:19:12.357+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:12.357+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:19:12.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-09T15:19:42.502+0000] {processor.py:157} INFO - Started process (PID=6575) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:19:42.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:19:42.505+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:19:42.527+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.527+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:19:42.715+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.715+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17217723799967644
[2025-01-09T15:19:42.716+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.715+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6575]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:19:42.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.717+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:19:42.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.717+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:19:42.718+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.718+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:19:42.718+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.718+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6575]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:19:42.724+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.723+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6575]: It took 0.0052s to build the Airflow DAG.
[2025-01-09T15:19:42.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:19:42.755+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.755+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:19:42.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:19:42.802+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:19:42.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.331 seconds
[2025-01-09T15:20:13.701+0000] {processor.py:157} INFO - Started process (PID=6662) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:20:13.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:20:13.705+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:20:13.727+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.726+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:20:13.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.862+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12333361099990725
[2025-01-09T15:20:13.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.863+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6662]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:20:13.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.864+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:20:13.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.864+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:20:13.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.864+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:20:13.865+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.865+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6662]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:20:13.867+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.867+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6662]: It took 0.00239s to build the Airflow DAG.
[2025-01-09T15:20:13.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:20:13.880+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.879+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:20:13.904+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:13.903+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:20:13.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.221 seconds
[2025-01-09T15:20:44.052+0000] {processor.py:157} INFO - Started process (PID=6750) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:20:44.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:20:44.056+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:20:44.088+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.087+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:20:44.243+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.242+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13552241600064008
[2025-01-09T15:20:44.243+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.243+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6750]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:20:44.243+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.243+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:20:44.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.244+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:20:44.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.244+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:20:44.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.244+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6750]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:20:44.247+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.247+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6750]: It took 0.00251s to build the Airflow DAG.
[2025-01-09T15:20:44.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:20:44.260+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.259+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:20:44.280+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:20:44.280+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:20:44.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-09T15:21:15.278+0000] {processor.py:157} INFO - Started process (PID=6860) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:21:15.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:21:15.282+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:21:15.306+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.306+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:21:15.444+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.444+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12490440400051739
[2025-01-09T15:21:15.445+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.445+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6860]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:21:15.445+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.445+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:21:15.446+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.446+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:21:15.446+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.446+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:21:15.447+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.447+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6860]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:21:15.450+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.450+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6860]: It took 0.00354s to build the Airflow DAG.
[2025-01-09T15:21:15.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:21:15.464+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.464+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:21:15.484+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:15.484+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:21:15.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.227 seconds
[2025-01-09T15:21:45.728+0000] {processor.py:157} INFO - Started process (PID=6946) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:21:45.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:21:45.731+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:21:45.754+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.754+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:21:45.877+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.877+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10525225400033378
[2025-01-09T15:21:45.877+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.877+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|6946]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:21:45.878+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.878+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:21:45.878+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.878+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:21:45.878+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.878+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:21:45.879+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.879+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|6946]: It took 0.124s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:21:45.881+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.881+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|6946]: It took 0.00213s to build the Airflow DAG.
[2025-01-09T15:21:45.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:21:45.894+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.894+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:21:45.916+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:21:45.916+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:21:45.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.216 seconds
[2025-01-09T15:22:16.866+0000] {processor.py:157} INFO - Started process (PID=7031) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:22:16.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:22:16.870+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:16.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:22:16.890+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:16.890+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:22:17.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.016+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11312320799970621
[2025-01-09T15:22:17.017+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.017+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7031]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:22:17.017+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.017+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:22:17.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.018+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:22:17.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.018+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:22:17.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.018+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7031]: It took 0.129s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:22:17.021+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.021+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7031]: It took 0.0028s to build the Airflow DAG.
[2025-01-09T15:22:17.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:22:17.035+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.035+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:22:17.058+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:17.058+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:22:17.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.213 seconds
[2025-01-09T15:22:48.058+0000] {processor.py:157} INFO - Started process (PID=7125) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:22:48.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:22:48.062+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:22:48.084+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.084+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:22:48.233+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.233+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1358765630002381
[2025-01-09T15:22:48.233+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.233+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7125]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:22:48.234+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.234+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:22:48.234+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.234+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:22:48.235+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.234+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:22:48.235+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.235+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7125]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:22:48.237+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.237+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7125]: It took 0.00243s to build the Airflow DAG.
[2025-01-09T15:22:48.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:22:48.251+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.251+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:22:48.275+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:22:48.275+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:22:48.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T15:23:18.701+0000] {processor.py:157} INFO - Started process (PID=7222) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:23:18.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:23:18.705+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:23:18.734+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.734+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:23:18.891+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.890+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13936669599934248
[2025-01-09T15:23:18.891+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.891+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7222]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:23:18.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.891+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:23:18.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.892+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:23:18.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.892+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:23:18.893+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.893+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7222]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:23:18.895+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.895+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7222]: It took 0.00268s to build the Airflow DAG.
[2025-01-09T15:23:18.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:23:18.911+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.911+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:23:18.945+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:18.945+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:23:19.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.449 seconds
[2025-01-09T15:23:49.209+0000] {processor.py:157} INFO - Started process (PID=7309) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:23:49.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:23:49.215+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:23:49.245+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.244+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:23:49.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.407+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14901222400021652
[2025-01-09T15:23:49.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.408+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7309]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:23:49.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.408+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:23:49.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.409+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:23:49.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.409+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:23:49.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.409+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7309]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:23:49.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.413+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7309]: It took 0.00352s to build the Airflow DAG.
[2025-01-09T15:23:49.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:23:49.429+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.429+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:23:49.457+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:23:49.457+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:23:49.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-09T15:24:19.611+0000] {processor.py:157} INFO - Started process (PID=7395) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:24:19.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:24:19.614+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:24:19.632+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.632+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:24:19.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.821+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17626061899954948
[2025-01-09T15:24:19.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.822+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7395]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:24:19.823+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.823+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:24:19.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.823+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:24:19.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.824+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:24:19.825+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.825+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7395]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:24:19.830+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.829+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7395]: It took 0.00456s to build the Airflow DAG.
[2025-01-09T15:24:19.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:24:19.854+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.854+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:24:19.899+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:19.899+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:24:19.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.323 seconds
[2025-01-09T15:24:49.997+0000] {processor.py:157} INFO - Started process (PID=7500) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:24:49.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:24:50.001+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:24:50.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.023+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:24:50.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.216+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17682631499974377
[2025-01-09T15:24:50.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.216+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7500]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:24:50.217+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.217+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:24:50.217+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.217+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:24:50.218+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.217+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:24:50.218+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.218+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7500]: It took 0.195s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:24:50.220+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.220+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7500]: It took 0.00251s to build the Airflow DAG.
[2025-01-09T15:24:50.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:24:50.236+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.236+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:24:50.265+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:24:50.265+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:24:50.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.522 seconds
[2025-01-09T15:25:20.598+0000] {processor.py:157} INFO - Started process (PID=7586) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:25:20.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:25:20.601+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:25:20.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.624+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:25:20.783+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.783+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14468970600046305
[2025-01-09T15:25:20.784+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.784+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7586]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:25:20.784+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.784+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:25:20.785+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.785+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:25:20.785+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.785+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:25:20.785+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.785+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7586]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:25:20.788+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.788+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7586]: It took 0.00259s to build the Airflow DAG.
[2025-01-09T15:25:20.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:25:20.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.802+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:25:20.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:20.824+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:25:20.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-09T15:25:51.088+0000] {processor.py:157} INFO - Started process (PID=7673) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:25:51.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:25:51.091+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:25:51.114+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.114+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:25:51.284+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.284+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15603647500029183
[2025-01-09T15:25:51.285+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.285+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7673]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:25:51.285+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.285+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:25:51.286+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.286+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:25:51.286+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.286+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:25:51.286+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.286+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7673]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:25:51.289+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.289+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7673]: It took 0.00261s to build the Airflow DAG.
[2025-01-09T15:25:51.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:25:51.305+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.305+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:25:51.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:25:51.476+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:25:51.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.410 seconds
[2025-01-09T15:26:22.155+0000] {processor.py:157} INFO - Started process (PID=7767) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:26:22.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:26:22.159+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:26:22.182+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.182+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:26:22.329+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.329+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1328071430007185
[2025-01-09T15:26:22.329+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.329+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7767]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:26:22.330+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.330+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:26:22.330+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.330+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:26:22.331+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.330+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:26:22.331+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.331+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7767]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:26:22.335+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.335+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7767]: It took 0.0038s to build the Airflow DAG.
[2025-01-09T15:26:22.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:26:22.349+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.349+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:26:22.374+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:22.374+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:26:22.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.455 seconds
[2025-01-09T15:26:52.706+0000] {processor.py:157} INFO - Started process (PID=7865) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:26:52.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:26:52.709+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:26:52.730+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.730+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:26:52.850+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.850+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1076399150006182
[2025-01-09T15:26:52.850+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.850+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7865]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:26:52.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.851+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:26:52.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.851+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:26:52.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.851+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:26:52.852+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.852+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7865]: It took 0.122s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:26:52.854+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.854+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7865]: It took 0.00229s to build the Airflow DAG.
[2025-01-09T15:26:52.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:26:52.867+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.867+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:26:52.890+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:26:52.890+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:26:52.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.204 seconds
[2025-01-09T15:27:23.122+0000] {processor.py:157} INFO - Started process (PID=7950) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:27:23.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:27:23.127+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:27:23.162+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.161+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:27:23.354+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.354+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17707160899954033
[2025-01-09T15:27:23.354+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.354+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|7950]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:27:23.355+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.355+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:27:23.355+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.355+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:27:23.356+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.356+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:27:23.356+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.356+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|7950]: It took 0.195s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:27:23.360+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.360+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|7950]: It took 0.00355s to build the Airflow DAG.
[2025-01-09T15:27:23.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:27:23.380+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.380+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:27:23.572+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:23.572+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:27:23.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.474 seconds
[2025-01-09T15:27:54.498+0000] {processor.py:157} INFO - Started process (PID=8036) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:27:54.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:27:54.501+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:27:54.528+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.528+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:27:54.677+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.677+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13441489100023318
[2025-01-09T15:27:54.678+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.678+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8036]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:27:54.678+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.678+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:27:54.679+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.679+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:27:54.679+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.679+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:27:54.679+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.679+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8036]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:27:54.682+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.682+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8036]: It took 0.00243s to build the Airflow DAG.
[2025-01-09T15:27:54.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:27:54.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.695+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:27:54.721+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:27:54.720+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:27:54.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.402 seconds
[2025-01-09T15:28:24.952+0000] {processor.py:157} INFO - Started process (PID=8141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:28:24.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:28:24.955+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:24.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:28:24.979+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:24.979+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:28:25.114+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.114+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12199256800067815
[2025-01-09T15:28:25.114+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.114+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8141]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:28:25.115+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.115+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:28:25.115+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.115+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:28:25.116+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.116+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:28:25.116+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.116+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8141]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:28:25.119+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.119+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8141]: It took 0.0027s to build the Airflow DAG.
[2025-01-09T15:28:25.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:28:25.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.132+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:28:25.153+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:25.153+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:28:25.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T15:28:56.025+0000] {processor.py:157} INFO - Started process (PID=8227) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:28:56.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:28:56.028+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:28:56.053+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.053+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:28:56.184+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.184+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11838497200005804
[2025-01-09T15:28:56.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.185+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8227]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:28:56.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.185+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:28:56.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.185+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:28:56.186+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.186+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:28:56.186+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.186+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8227]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:28:56.188+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.188+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8227]: It took 0.00225s to build the Airflow DAG.
[2025-01-09T15:28:56.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:28:56.202+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.202+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:28:56.368+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:28:56.368+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:28:56.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.367 seconds
[2025-01-09T15:29:26.605+0000] {processor.py:157} INFO - Started process (PID=8313) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:29:26.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:29:26.609+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:29:26.632+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.632+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:29:26.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.772+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12406094899961317
[2025-01-09T15:29:26.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.772+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8313]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:29:26.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.773+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:29:26.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.773+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:29:26.774+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.774+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:29:26.774+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.774+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8313]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:29:26.777+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.776+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8313]: It took 0.00249s to build the Airflow DAG.
[2025-01-09T15:29:26.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:29:26.790+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.790+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:29:26.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:26.814+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:29:26.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.378 seconds
[2025-01-09T15:29:57.629+0000] {processor.py:157} INFO - Started process (PID=8417) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:29:57.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:29:57.632+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:29:57.656+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.656+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:29:57.926+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.926+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10877137300030881
[2025-01-09T15:29:57.927+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.926+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8417]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:29:57.927+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.927+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:29:57.927+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.927+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:29:57.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.928+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:29:57.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.928+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8417]: It took 0.272s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:29:57.930+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.930+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8417]: It took 0.00214s to build the Airflow DAG.
[2025-01-09T15:29:57.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:29:57.941+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.941+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:29:57.960+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:29:57.960+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:29:57.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.351 seconds
[2025-01-09T15:30:28.368+0000] {processor.py:157} INFO - Started process (PID=8503) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:30:28.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:30:28.371+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:30:28.397+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.397+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:30:28.531+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.531+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12170085300022038
[2025-01-09T15:30:28.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.531+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8503]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:30:28.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.532+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:30:28.532+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.532+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:30:28.533+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.533+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:30:28.533+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.533+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8503]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:30:28.536+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.535+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8503]: It took 0.00254s to build the Airflow DAG.
[2025-01-09T15:30:28.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:30:28.549+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.549+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:30:28.716+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:28.716+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:30:28.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.369 seconds
[2025-01-09T15:30:59.504+0000] {processor.py:157} INFO - Started process (PID=8589) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:30:59.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:30:59.508+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:30:59.533+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.533+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:30:59.687+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.687+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14139546600017638
[2025-01-09T15:30:59.688+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.688+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8589]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:30:59.688+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.688+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:30:59.689+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.689+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:30:59.689+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.689+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:30:59.689+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.689+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8589]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:30:59.692+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.692+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8589]: It took 0.00308s to build the Airflow DAG.
[2025-01-09T15:30:59.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:30:59.706+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.706+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:30:59.728+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:30:59.728+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:30:59.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T15:31:30.278+0000] {processor.py:157} INFO - Started process (PID=8694) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:31:30.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:31:30.282+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:31:30.305+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.305+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:31:30.441+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.441+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12068435799938015
[2025-01-09T15:31:30.442+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.442+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8694]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:31:30.442+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.442+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:31:30.443+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.443+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:31:30.443+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.443+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:31:30.444+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.444+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8694]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:31:30.448+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.448+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8694]: It took 0.00375s to build the Airflow DAG.
[2025-01-09T15:31:30.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:31:30.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.461+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:31:30.481+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:31:30.481+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:31:30.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-09T15:32:01.182+0000] {processor.py:157} INFO - Started process (PID=8780) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:01.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:32:01.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:01.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.209+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:32:01.349+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.349+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12524406899956375
[2025-01-09T15:32:01.349+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.349+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8780]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:32:01.350+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.350+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:32:01.350+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.350+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:32:01.351+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.351+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:32:01.351+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.351+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8780]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:32:01.355+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.355+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8780]: It took 0.00341s to build the Airflow DAG.
[2025-01-09T15:32:01.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:01.369+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.369+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:32:01.390+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:01.390+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:32:01.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-09T15:32:31.610+0000] {processor.py:157} INFO - Started process (PID=8867) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:31.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:32:31.613+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:31.632+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.632+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:32:31.762+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.762+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11832917399988219
[2025-01-09T15:32:31.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.763+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8867]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:32:31.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.763+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:32:31.764+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.764+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:32:31.764+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.764+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:32:31.765+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.764+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8867]: It took 0.132s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:32:31.767+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.767+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8867]: It took 0.00253s to build the Airflow DAG.
[2025-01-09T15:32:31.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:31.781+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.781+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:32:31.805+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:31.805+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:32:31.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-09T15:32:38.273+0000] {processor.py:157} INFO - Started process (PID=8889) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:38.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:32:38.277+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:38.312+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.312+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:32:38.478+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.477+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1445501719999811
[2025-01-09T15:32:38.478+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.478+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8889]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:32:38.479+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.479+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:32:38.479+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.479+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:32:38.479+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.479+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:32:38.480+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.480+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8889]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:32:38.484+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.483+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8889]: It took 0.00377s to build the Airflow DAG.
[2025-01-09T15:32:38.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:38.501+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.501+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:32:38.533+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:38.533+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:32:38.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-09T15:32:39.614+0000] {processor.py:157} INFO - Started process (PID=8890) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:39.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:32:39.618+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:39.657+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.657+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:32:39.817+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.816+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14538611200077867
[2025-01-09T15:32:39.817+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.817+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8890]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:32:39.818+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.817+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:32:39.818+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.818+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:32:39.818+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.818+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:32:39.819+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.818+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8890]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:32:39.821+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.821+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8890]: It took 0.00257s to build the Airflow DAG.
[2025-01-09T15:32:39.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:32:39.836+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.836+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:32:39.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:32:39.862+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:32:39.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-09T15:33:09.949+0000] {processor.py:157} INFO - Started process (PID=8976) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:33:09.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:33:09.953+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:09.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:33:09.975+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:09.975+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:33:10.116+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.116+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12752027900023677
[2025-01-09T15:33:10.117+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.117+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|8976]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:33:10.117+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.117+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:33:10.118+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.117+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:33:10.118+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.118+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:33:10.118+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.118+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|8976]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:33:10.121+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.121+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|8976]: It took 0.00245s to build the Airflow DAG.
[2025-01-09T15:33:10.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:33:10.134+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.134+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:33:10.157+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:10.157+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:33:10.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-09T15:33:40.261+0000] {processor.py:157} INFO - Started process (PID=9062) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:33:40.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:33:40.265+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:33:40.288+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.288+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:33:40.417+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.417+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11602085499998793
[2025-01-09T15:33:40.417+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.417+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9062]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:33:40.418+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.418+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:33:40.418+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.418+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:33:40.419+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.419+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:33:40.419+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.419+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9062]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:33:40.423+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.422+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9062]: It took 0.00354s to build the Airflow DAG.
[2025-01-09T15:33:40.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:33:40.437+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.437+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:33:40.462+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:33:40.462+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:33:40.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T15:34:10.681+0000] {processor.py:157} INFO - Started process (PID=9148) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:34:10.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:34:10.684+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:34:10.707+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.707+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:34:10.849+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.849+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12861862199952157
[2025-01-09T15:34:10.849+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.849+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9148]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:34:10.850+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.850+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:34:10.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.850+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:34:10.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.851+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:34:10.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.851+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9148]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:34:10.854+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.854+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9148]: It took 0.00277s to build the Airflow DAG.
[2025-01-09T15:34:10.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:34:10.869+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.869+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:34:10.891+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:10.891+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:34:10.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-09T15:34:41.625+0000] {processor.py:157} INFO - Started process (PID=9253) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:34:41.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:34:41.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:34:41.653+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.653+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:34:41.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.782+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11500401699959184
[2025-01-09T15:34:41.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.782+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9253]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:34:41.783+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.783+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:34:41.783+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.783+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:34:41.784+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.784+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:34:41.784+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.784+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9253]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:34:41.788+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.788+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9253]: It took 0.00372s to build the Airflow DAG.
[2025-01-09T15:34:41.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:34:41.801+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.801+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:34:41.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:34:41.822+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:34:41.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-09T15:35:12.559+0000] {processor.py:157} INFO - Started process (PID=9339) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:35:12.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:35:12.562+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:35:12.585+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.584+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:35:12.706+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.705+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10757241400006023
[2025-01-09T15:35:12.706+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.706+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9339]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:35:12.707+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.707+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:35:12.707+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.707+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:35:12.708+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.707+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:35:12.708+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.708+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9339]: It took 0.123s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:35:12.710+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.710+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9339]: It took 0.00244s to build the Airflow DAG.
[2025-01-09T15:35:12.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:35:12.725+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.724+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:35:12.752+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:12.752+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:35:12.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.219 seconds
[2025-01-09T15:35:43.450+0000] {processor.py:157} INFO - Started process (PID=9425) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:35:43.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:35:43.455+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:35:43.491+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.490+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:35:43.686+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.685+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17684634099987306
[2025-01-09T15:35:43.686+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.686+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9425]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:35:43.687+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.687+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:35:43.688+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.688+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:35:43.688+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.688+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:35:43.689+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.689+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9425]: It took 0.199s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:35:43.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.693+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9425]: It took 0.00417s to build the Airflow DAG.
[2025-01-09T15:35:43.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:35:43.712+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.712+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:35:43.743+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:35:43.743+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:35:43.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.320 seconds
[2025-01-09T15:36:14.078+0000] {processor.py:157} INFO - Started process (PID=9530) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:36:14.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:36:14.082+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:36:14.108+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.108+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:36:14.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.244+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12239861299985932
[2025-01-09T15:36:14.244+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.244+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9530]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:36:14.245+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.245+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:36:14.245+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.245+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:36:14.245+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.245+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:36:14.246+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.246+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9530]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:36:14.248+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.248+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9530]: It took 0.0023s to build the Airflow DAG.
[2025-01-09T15:36:14.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:36:14.261+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.261+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:36:14.283+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:14.282+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:36:14.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-09T15:36:44.692+0000] {processor.py:157} INFO - Started process (PID=9616) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:36:44.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:36:44.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:36:44.721+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.721+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:36:44.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.873+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13800960600019607
[2025-01-09T15:36:44.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.873+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9616]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:36:44.874+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.874+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:36:44.874+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.874+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:36:44.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.875+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:36:44.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.875+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9616]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:36:44.878+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.878+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9616]: It took 0.00299s to build the Airflow DAG.
[2025-01-09T15:36:44.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:36:44.891+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.891+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:36:44.912+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:36:44.912+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:36:44.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-09T15:37:15.229+0000] {processor.py:157} INFO - Started process (PID=9702) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:37:15.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:37:15.232+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:37:15.259+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.259+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:37:15.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.408+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1346528860003673
[2025-01-09T15:37:15.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.408+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9702]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:37:15.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.409+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:37:15.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.409+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:37:15.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.409+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:37:15.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.410+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9702]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:37:15.412+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.412+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9702]: It took 0.00232s to build the Airflow DAG.
[2025-01-09T15:37:15.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:37:15.425+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.425+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:37:15.447+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:15.446+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:37:15.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-09T15:37:46.226+0000] {processor.py:157} INFO - Started process (PID=9796) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:37:46.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:37:46.230+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:37:46.252+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.252+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:37:46.403+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.403+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13722073799999635
[2025-01-09T15:37:46.403+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.403+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9796]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:37:46.404+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.404+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:37:46.405+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.405+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:37:46.405+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.405+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:37:46.406+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.406+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9796]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:37:46.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.410+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9796]: It took 0.00405s to build the Airflow DAG.
[2025-01-09T15:37:46.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:37:46.437+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.436+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:37:46.462+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:37:46.462+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:37:46.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-09T15:38:16.944+0000] {processor.py:157} INFO - Started process (PID=9893) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:38:16.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:38:16.949+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:16.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:38:16.980+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:16.980+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:38:17.110+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.110+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11703971899987664
[2025-01-09T15:38:17.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.111+0000] {graph.py:519} INFO - Cosmos performance [1f3e07701460|9893]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:38:17.112+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.112+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:38:17.112+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.112+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:38:17.113+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.113+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:38:17.113+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.113+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1f3e07701460|9893]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:38:17.117+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.117+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1f3e07701460|9893]: It took 0.00344s to build the Airflow DAG.
[2025-01-09T15:38:17.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:38:17.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.130+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:38:17.152+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:38:17.152+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:38:17.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.231 seconds
[2025-01-09T15:39:36.338+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:39:36.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:39:36.344+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:39:36.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.381+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:39:36.604+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.604+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20017831599943747
[2025-01-09T15:39:36.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.605+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:39:36.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.606+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:39:36.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.606+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:39:36.607+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.607+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:39:36.608+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.607+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|70]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:39:36.612+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.612+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|70]: It took 0.00474s to build the Airflow DAG.
[2025-01-09T15:39:36.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:39:36.758+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.758+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:39:36.800+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:39:36.800+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:39:36.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.499 seconds
[2025-01-09T15:40:06.930+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:40:06.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:40:06.933+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:06.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:40:06.958+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:06.958+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:40:07.092+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.092+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1208561630000986
[2025-01-09T15:40:07.093+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.092+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|159]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:40:07.093+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.093+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:40:07.093+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.093+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:40:07.094+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.094+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:40:07.094+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.094+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|159]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:40:07.096+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.096+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|159]: It took 0.00218s to build the Airflow DAG.
[2025-01-09T15:40:07.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:40:07.109+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.108+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:40:07.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:07.130+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:40:07.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.221 seconds
[2025-01-09T15:40:37.261+0000] {processor.py:157} INFO - Started process (PID=254) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:40:37.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:40:37.265+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:40:37.289+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.289+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:40:37.447+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.447+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14404037199983577
[2025-01-09T15:40:37.447+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.447+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|254]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:40:37.448+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.448+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:40:37.448+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.448+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:40:37.449+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.449+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:40:37.449+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.449+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|254]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:40:37.453+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.452+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|254]: It took 0.00334s to build the Airflow DAG.
[2025-01-09T15:40:37.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:40:37.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.469+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:40:37.512+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:40:37.511+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:40:37.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-09T15:41:07.626+0000] {processor.py:157} INFO - Started process (PID=352) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:41:07.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:41:07.630+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:41:07.654+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.654+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:41:07.811+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.811+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1437461350005833
[2025-01-09T15:41:07.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.812+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|352]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:41:07.813+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.812+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:41:07.813+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.813+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:41:07.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.814+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:41:07.814+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.814+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|352]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:41:07.817+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.817+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|352]: It took 0.0029s to build the Airflow DAG.
[2025-01-09T15:41:07.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:41:07.831+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.831+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:41:07.852+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:07.852+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:41:07.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-09T15:41:37.953+0000] {processor.py:157} INFO - Started process (PID=438) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:41:37.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:41:37.957+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:37.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:41:37.980+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:37.979+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:41:38.123+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.123+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13014975700025389
[2025-01-09T15:41:38.123+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.123+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|438]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:41:38.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.124+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:41:38.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.124+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:41:38.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.125+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:41:38.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.125+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|438]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:41:38.127+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.127+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|438]: It took 0.0024s to build the Airflow DAG.
[2025-01-09T15:41:38.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:41:38.140+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.140+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:41:38.162+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:41:38.162+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:41:38.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-09T15:42:08.231+0000] {processor.py:157} INFO - Started process (PID=525) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:42:08.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:42:08.235+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:42:08.266+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.266+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:42:08.926+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.926+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6467304190000505
[2025-01-09T15:42:08.927+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.927+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|525]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:42:08.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.928+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:42:08.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.928+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:42:08.929+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.928+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:42:08.929+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.929+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|525]: It took 0.663s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:42:08.932+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.932+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|525]: It took 0.00287s to build the Airflow DAG.
[2025-01-09T15:42:08.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:42:08.946+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.946+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:42:08.968+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:08.968+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:42:08.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.764 seconds
[2025-01-09T15:42:39.862+0000] {processor.py:157} INFO - Started process (PID=611) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:42:39.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:42:39.865+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:39.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:42:39.890+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:39.889+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:42:40.078+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.078+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17190335000032064
[2025-01-09T15:42:40.079+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.079+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|611]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:42:40.080+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.080+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:42:40.080+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.080+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:42:40.081+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.080+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:42:40.081+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.081+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|611]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:42:40.085+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.085+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|611]: It took 0.00374s to build the Airflow DAG.
[2025-01-09T15:42:40.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:42:40.102+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.101+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:42:40.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:42:40.130+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:42:40.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-09T15:43:10.223+0000] {processor.py:157} INFO - Started process (PID=705) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:43:10.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:43:10.226+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:43:10.249+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.249+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:43:10.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.409+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14453782700002193
[2025-01-09T15:43:10.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.409+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|705]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:43:10.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.410+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:43:10.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.410+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:43:10.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.411+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:43:10.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.411+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|705]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:43:10.414+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.414+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|705]: It took 0.00289s to build the Airflow DAG.
[2025-01-09T15:43:10.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:43:10.429+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.429+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:43:10.458+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:10.458+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:43:10.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-09T15:43:40.531+0000] {processor.py:157} INFO - Started process (PID=803) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:43:40.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:43:40.533+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:43:40.556+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.556+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:43:40.701+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.701+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.131897989999743
[2025-01-09T15:43:40.701+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.701+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|803]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:43:40.702+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.702+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:43:40.702+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.702+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:43:40.702+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.702+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:43:40.703+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.703+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|803]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:43:40.706+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.705+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|803]: It took 0.00276s to build the Airflow DAG.
[2025-01-09T15:43:40.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:43:40.721+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.721+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:43:40.745+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:43:40.745+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:43:40.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-09T15:44:10.941+0000] {processor.py:157} INFO - Started process (PID=891) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:44:10.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:44:10.943+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:10.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:44:10.963+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:10.963+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:44:11.118+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.118+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14128861900007905
[2025-01-09T15:44:11.118+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.118+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|891]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:44:11.119+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.119+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:44:11.119+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.119+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:44:11.120+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.119+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:44:11.120+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.120+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|891]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:44:11.122+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.122+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|891]: It took 0.00233s to build the Airflow DAG.
[2025-01-09T15:44:11.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:44:11.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.137+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:44:11.160+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:11.160+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:44:11.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T15:44:41.293+0000] {processor.py:157} INFO - Started process (PID=979) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:44:41.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:44:41.296+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:44:41.317+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.317+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:44:41.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.463+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13225225800033513
[2025-01-09T15:44:41.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.463+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|979]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:44:41.464+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.464+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:44:41.464+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.464+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:44:41.465+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.465+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:44:41.465+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.465+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|979]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:44:41.467+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.467+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|979]: It took 0.00244s to build the Airflow DAG.
[2025-01-09T15:44:41.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:44:41.481+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.481+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:44:41.505+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:44:41.505+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:44:41.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-09T15:45:11.748+0000] {processor.py:157} INFO - Started process (PID=1075) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:45:11.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:45:11.752+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:45:11.776+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.776+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:45:11.937+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.937+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1450588890002109
[2025-01-09T15:45:11.938+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.938+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1075]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:45:11.938+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.938+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:45:11.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.939+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:45:11.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.939+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:45:11.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.940+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1075]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:45:11.943+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.943+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1075]: It took 0.00283s to build the Airflow DAG.
[2025-01-09T15:45:11.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:45:11.960+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.960+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:45:11.986+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:11.986+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:45:12.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-09T15:45:42.194+0000] {processor.py:157} INFO - Started process (PID=1173) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:45:42.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:45:42.197+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:45:42.219+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.218+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:45:42.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.380+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1480416200001855
[2025-01-09T15:45:42.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.381+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1173]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:45:42.382+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.382+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:45:42.383+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.383+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:45:42.383+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.383+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:45:42.384+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.383+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1173]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:45:42.388+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.387+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1173]: It took 0.00409s to build the Airflow DAG.
[2025-01-09T15:45:42.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:45:42.403+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.403+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:45:42.425+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:45:42.425+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:45:42.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-09T15:46:12.573+0000] {processor.py:157} INFO - Started process (PID=1259) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:46:12.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:46:12.576+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:46:12.597+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.597+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:46:12.759+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.759+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14777056099956098
[2025-01-09T15:46:12.760+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.759+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1259]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:46:12.760+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.760+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:46:12.760+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.760+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:46:12.761+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.761+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:46:12.761+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.761+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1259]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:46:12.764+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.764+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1259]: It took 0.00308s to build the Airflow DAG.
[2025-01-09T15:46:12.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:46:12.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.779+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:46:12.804+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:12.804+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:46:12.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-09T15:46:42.968+0000] {processor.py:157} INFO - Started process (PID=1347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:46:42.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:46:42.971+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:42.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:46:42.990+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:42.990+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:46:43.122+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.122+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11657022799954575
[2025-01-09T15:46:43.123+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.123+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1347]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:46:43.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.123+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:46:43.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.124+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:46:43.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.124+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:46:43.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.125+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1347]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:46:43.129+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.129+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1347]: It took 0.00397s to build the Airflow DAG.
[2025-01-09T15:46:43.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:46:43.144+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.144+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:46:43.168+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:46:43.168+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:46:43.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-09T15:47:14.113+0000] {processor.py:157} INFO - Started process (PID=1441) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:47:14.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:47:14.118+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:47:14.153+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.153+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:47:14.378+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.378+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20086582499970973
[2025-01-09T15:47:14.379+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.379+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1441]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:47:14.379+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.379+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:47:14.380+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.380+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:47:14.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.381+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:47:14.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.381+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1441]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:47:14.385+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.385+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1441]: It took 0.00367s to build the Airflow DAG.
[2025-01-09T15:47:14.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:47:14.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.411+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:47:14.453+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:14.453+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:47:14.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.373 seconds
[2025-01-09T15:47:44.856+0000] {processor.py:157} INFO - Started process (PID=1528) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:47:44.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:47:44.876+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:44.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:47:44.939+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:44.939+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:47:45.332+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.331+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3643132859997422
[2025-01-09T15:47:45.333+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.332+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1528]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:47:45.334+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.334+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:47:45.335+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.335+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:47:45.336+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.336+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:47:45.338+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.337+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1528]: It took 0.399s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:47:45.345+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.345+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1528]: It took 0.00747s to build the Airflow DAG.
[2025-01-09T15:47:45.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:47:45.390+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.389+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:47:45.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:47:45.461+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:47:45.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.653 seconds
[2025-01-09T15:48:15.862+0000] {processor.py:157} INFO - Started process (PID=1625) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:48:15.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:48:15.866+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:15.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:48:15.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:15.892+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:48:16.038+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.038+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13117056200007937
[2025-01-09T15:48:16.038+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.038+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1625]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:48:16.039+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.039+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:48:16.039+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.039+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:48:16.040+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.040+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:48:16.040+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.040+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1625]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:48:16.044+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.044+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1625]: It took 0.00368s to build the Airflow DAG.
[2025-01-09T15:48:16.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:48:16.059+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.059+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:48:16.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:16.083+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:48:16.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-09T15:48:46.236+0000] {processor.py:157} INFO - Started process (PID=1713) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:48:46.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:48:46.239+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:48:46.266+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.266+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:48:46.403+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.403+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12505085100019642
[2025-01-09T15:48:46.403+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.403+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1713]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:48:46.404+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.404+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:48:46.404+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.404+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:48:46.404+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.404+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:48:46.405+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.405+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1713]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:48:46.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.407+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1713]: It took 0.00224s to build the Airflow DAG.
[2025-01-09T15:48:46.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:48:46.420+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.420+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:48:46.442+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:48:46.442+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:48:46.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-09T15:49:16.559+0000] {processor.py:157} INFO - Started process (PID=1800) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:49:16.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:49:16.563+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:49:16.602+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.602+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:49:16.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.735+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11752033399989159
[2025-01-09T15:49:16.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.735+0000] {graph.py:519} INFO - Cosmos performance [3e0da1a36509|1800]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:49:16.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.736+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:49:16.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.736+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:49:16.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.736+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:49:16.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.737+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3e0da1a36509|1800]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:49:16.739+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.739+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3e0da1a36509|1800]: It took 0.00236s to build the Airflow DAG.
[2025-01-09T15:49:16.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:49:16.753+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.752+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:49:16.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:49:16.775+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:49:16.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-09T15:50:32.696+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:50:32.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:50:32.700+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:50:32.733+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.733+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:50:32.942+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.942+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18956520500069018
[2025-01-09T15:50:32.943+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.943+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:50:32.943+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.943+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:50:32.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.944+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:50:32.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.944+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:50:32.945+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.945+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|70]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:50:32.949+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:32.949+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|70]: It took 0.0043s to build the Airflow DAG.
[2025-01-09T15:50:32.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:50:33.153+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:33.153+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:50:33.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:50:33.209+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:50:33.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.565 seconds
[2025-01-09T15:51:03.601+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:51:03.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:51:03.607+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:51:03.644+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.644+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:51:03.888+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.887+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22050700499949016
[2025-01-09T15:51:03.888+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.888+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|156]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:51:03.889+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.889+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:51:03.889+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.889+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:51:03.890+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.890+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:51:03.890+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.890+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|156]: It took 0.247s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:51:03.895+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.894+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|156]: It took 0.00419s to build the Airflow DAG.
[2025-01-09T15:51:03.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:51:03.927+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.926+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:51:03.972+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:03.972+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:51:03.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.398 seconds
[2025-01-09T15:51:34.200+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:51:34.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:51:34.204+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:51:34.237+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.237+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:51:34.406+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.406+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1544536639994476
[2025-01-09T15:51:34.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.407+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|249]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:51:34.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.408+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:51:34.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.408+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:51:34.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.409+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:51:34.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.410+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|249]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:51:34.415+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.414+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|249]: It took 0.00448s to build the Airflow DAG.
[2025-01-09T15:51:34.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:51:34.452+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.452+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:51:34.490+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:51:34.490+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:51:34.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.317 seconds
[2025-01-09T15:52:04.997+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:52:04.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:52:05.002+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:52:05.031+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.031+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:52:05.198+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.198+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1491984650001541
[2025-01-09T15:52:05.198+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.198+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|344]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:52:05.199+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.199+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:52:05.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.199+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:52:05.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.200+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:52:05.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.200+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|344]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:52:05.204+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.204+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|344]: It took 0.00333s to build the Airflow DAG.
[2025-01-09T15:52:05.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:52:05.221+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.221+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:52:05.249+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:05.249+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:52:05.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-09T15:52:35.639+0000] {processor.py:157} INFO - Started process (PID=441) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:52:35.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:52:35.643+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:52:35.670+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.670+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:52:35.836+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.836+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14905901899965102
[2025-01-09T15:52:35.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.837+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|441]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:52:35.837+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.837+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:52:35.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.838+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:52:35.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.838+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:52:35.839+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.839+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|441]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:52:35.842+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.842+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|441]: It took 0.00353s to build the Airflow DAG.
[2025-01-09T15:52:35.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:52:35.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.863+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:52:35.898+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:52:35.898+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:52:35.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-09T15:53:06.022+0000] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:53:06.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:53:06.025+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:53:06.047+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.047+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:53:06.205+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.205+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1337512499994773
[2025-01-09T15:53:06.205+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.205+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|528]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:53:06.206+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.206+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:53:06.206+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.206+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:53:06.207+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.207+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:53:06.208+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.207+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|528]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:53:06.212+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.211+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|528]: It took 0.00397s to build the Airflow DAG.
[2025-01-09T15:53:06.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:53:06.227+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.227+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:53:06.252+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:06.252+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:53:06.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-09T15:53:36.314+0000] {processor.py:157} INFO - Started process (PID=615) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:53:36.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:53:36.317+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:53:36.337+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.337+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:53:36.484+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.483+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1331846700004462
[2025-01-09T15:53:36.484+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.484+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|615]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:53:36.484+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.484+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:53:36.485+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.485+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:53:36.485+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.485+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:53:36.486+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.485+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|615]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:53:36.488+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.488+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|615]: It took 0.00262s to build the Airflow DAG.
[2025-01-09T15:53:36.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:53:36.501+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.501+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:53:36.524+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:53:36.524+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:53:36.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-09T15:54:06.636+0000] {processor.py:157} INFO - Started process (PID=703) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:54:06.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:54:06.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:54:06.664+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.664+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:54:06.831+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.831+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1519440720003331
[2025-01-09T15:54:06.831+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.831+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|703]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:54:06.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.832+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:54:06.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.832+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:54:06.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.832+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:54:06.833+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.833+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|703]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:54:06.835+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.835+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|703]: It took 0.00269s to build the Airflow DAG.
[2025-01-09T15:54:06.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:54:06.849+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.849+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:54:06.874+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:06.874+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:54:06.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-09T15:54:37.106+0000] {processor.py:157} INFO - Started process (PID=799) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:54:37.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:54:37.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:54:37.134+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.134+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:54:37.287+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.286+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1370469690000391
[2025-01-09T15:54:37.287+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.287+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|799]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:54:37.288+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.288+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:54:37.288+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.288+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:54:37.289+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.289+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:54:37.289+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.289+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|799]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:54:37.293+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.293+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|799]: It took 0.00355s to build the Airflow DAG.
[2025-01-09T15:54:37.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:54:37.310+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.310+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:54:37.336+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:54:37.336+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:54:37.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-09T15:55:07.510+0000] {processor.py:157} INFO - Started process (PID=897) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:55:07.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:55:07.515+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:55:07.537+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.537+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:55:07.701+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.701+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14969479699902877
[2025-01-09T15:55:07.702+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.702+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|897]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:55:07.702+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.702+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:55:07.703+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.703+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:55:07.703+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.703+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:55:07.704+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.703+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|897]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:55:07.707+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.706+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|897]: It took 0.00293s to build the Airflow DAG.
[2025-01-09T15:55:07.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:55:07.724+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.723+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:55:07.757+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:07.757+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:55:07.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-09T15:55:37.807+0000] {processor.py:157} INFO - Started process (PID=984) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:55:37.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:55:37.811+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:55:37.832+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.832+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:55:37.953+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.953+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10774219300037657
[2025-01-09T15:55:37.953+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.953+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|984]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:55:37.954+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.954+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:55:37.954+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.954+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:55:37.954+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.954+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:55:37.955+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.955+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|984]: It took 0.122s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:55:37.957+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.957+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|984]: It took 0.0023s to build the Airflow DAG.
[2025-01-09T15:55:37.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:55:37.970+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.970+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:55:37.991+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:55:37.991+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:55:38.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.213 seconds
[2025-01-09T15:56:08.056+0000] {processor.py:157} INFO - Started process (PID=1070) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:56:08.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:56:08.059+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:56:08.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.083+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:56:08.208+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.208+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11165468599938322
[2025-01-09T15:56:08.208+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.208+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1070]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:56:08.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.209+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:56:08.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.209+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:56:08.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.209+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:56:08.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.210+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1070]: It took 0.127s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:56:08.213+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.213+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1070]: It took 0.00327s to build the Airflow DAG.
[2025-01-09T15:56:08.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:56:08.227+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.226+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:56:08.249+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:08.249+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:56:08.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-09T15:56:38.329+0000] {processor.py:157} INFO - Started process (PID=1165) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:56:38.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:56:38.332+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:56:38.357+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.357+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:56:38.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.475+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10567126199930499
[2025-01-09T15:56:38.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.476+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1165]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:56:38.477+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.476+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:56:38.477+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.477+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:56:38.477+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.477+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:56:38.478+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.477+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1165]: It took 0.12s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:56:38.480+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.480+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1165]: It took 0.00268s to build the Airflow DAG.
[2025-01-09T15:56:38.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:56:38.493+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.493+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:56:38.515+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:56:38.514+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:56:38.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.206 seconds
[2025-01-09T15:57:08.591+0000] {processor.py:157} INFO - Started process (PID=1259) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:57:08.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:57:08.595+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:57:08.617+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.617+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:57:08.771+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.771+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13934885799972108
[2025-01-09T15:57:08.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.771+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1259]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:57:08.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.772+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:57:08.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.772+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:57:08.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.773+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:57:08.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.773+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1259]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:57:08.777+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.777+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1259]: It took 0.00361s to build the Airflow DAG.
[2025-01-09T15:57:08.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:57:08.793+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.793+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:57:08.817+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:08.817+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:57:08.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-09T15:57:38.936+0000] {processor.py:157} INFO - Started process (PID=1357) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:57:38.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:57:38.940+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:38.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:57:38.966+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:38.966+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:57:39.105+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.105+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12407587699999567
[2025-01-09T15:57:39.106+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.106+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1357]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:57:39.106+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.106+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:57:39.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.107+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:57:39.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.107+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:57:39.108+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.108+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1357]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:57:39.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.111+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1357]: It took 0.00352s to build the Airflow DAG.
[2025-01-09T15:57:39.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:57:39.128+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.128+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:57:39.155+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:57:39.155+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:57:39.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-09T15:58:09.209+0000] {processor.py:157} INFO - Started process (PID=1444) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:58:09.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:58:09.212+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:58:09.236+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.236+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:58:09.367+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.367+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1179541639994568
[2025-01-09T15:58:09.368+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.367+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1444]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:58:09.368+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.368+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:58:09.368+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.368+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:58:09.369+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.369+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:58:09.369+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.369+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1444]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:58:09.371+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.371+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1444]: It took 0.00228s to build the Airflow DAG.
[2025-01-09T15:58:09.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:58:09.385+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.384+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:58:09.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:09.407+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:58:09.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.220 seconds
[2025-01-09T15:58:39.495+0000] {processor.py:157} INFO - Started process (PID=1531) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:58:39.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:58:39.498+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:58:39.520+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.520+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:58:39.661+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.661+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.128421203000471
[2025-01-09T15:58:39.662+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.662+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1531]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:58:39.662+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.662+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:58:39.663+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.663+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:58:39.663+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.663+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:58:39.664+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.664+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1531]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:58:39.667+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.667+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1531]: It took 0.00311s to build the Airflow DAG.
[2025-01-09T15:58:39.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:58:39.680+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.680+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:58:39.702+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:58:39.702+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:58:39.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-09T15:59:09.808+0000] {processor.py:157} INFO - Started process (PID=1617) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:59:09.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:59:09.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:09.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:59:09.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:09.838+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:59:10.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.022+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17043946599915216
[2025-01-09T15:59:10.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.023+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1617]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:59:10.024+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.024+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:59:10.025+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.025+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:59:10.025+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.025+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:59:10.026+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.026+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1617]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:59:10.030+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.030+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1617]: It took 0.00411s to build the Airflow DAG.
[2025-01-09T15:59:10.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:59:10.044+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.044+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:59:10.073+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:10.073+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:59:10.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-09T15:59:40.121+0000] {processor.py:157} INFO - Started process (PID=1713) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:59:40.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T15:59:40.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:59:40.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.150+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T15:59:40.331+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.331+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1666520609996951
[2025-01-09T15:59:40.332+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.332+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1713]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T15:59:40.333+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.333+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T15:59:40.333+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.333+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T15:59:40.334+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.334+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T15:59:40.334+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.334+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1713]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T15:59:40.339+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.338+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1713]: It took 0.00427s to build the Airflow DAG.
[2025-01-09T15:59:40.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T15:59:40.354+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.354+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T15:59:40.383+0000] {logging_mixin.py:151} INFO - [2025-01-09T15:59:40.383+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T15:59:40.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.283 seconds
[2025-01-09T16:00:10.554+0000] {processor.py:157} INFO - Started process (PID=1807) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:00:10.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:00:10.558+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:00:10.577+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.576+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:00:10.727+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.727+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13644652299990412
[2025-01-09T16:00:10.727+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.727+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1807]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:00:10.728+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.728+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:00:10.729+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.728+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:00:10.729+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.729+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:00:10.729+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.729+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1807]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:00:10.733+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.733+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1807]: It took 0.00397s to build the Airflow DAG.
[2025-01-09T16:00:10.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:00:10.749+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.749+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:00:10.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:10.775+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:00:10.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T16:00:40.943+0000] {processor.py:157} INFO - Started process (PID=1895) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:00:40.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:00:40.947+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:40.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:00:40.971+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:40.971+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:00:41.110+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.110+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12626036799883877
[2025-01-09T16:00:41.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.111+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1895]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:00:41.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.111+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:00:41.112+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.112+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:00:41.112+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.112+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:00:41.113+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.113+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1895]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:00:41.116+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.116+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1895]: It took 0.00314s to build the Airflow DAG.
[2025-01-09T16:00:41.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:00:41.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.130+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:00:41.154+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:00:41.153+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:00:41.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-09T16:01:11.226+0000] {processor.py:157} INFO - Started process (PID=1982) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:01:11.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:01:11.229+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:01:11.254+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.254+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:01:11.395+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.394+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12738561799960735
[2025-01-09T16:01:11.395+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.395+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|1982]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:01:11.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.395+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:01:11.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.396+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:01:11.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.396+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:01:11.397+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.397+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|1982]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:01:11.400+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.400+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|1982]: It took 0.00321s to build the Airflow DAG.
[2025-01-09T16:01:11.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:01:11.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.413+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:01:11.435+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:11.435+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:01:11.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-09T16:01:41.546+0000] {processor.py:157} INFO - Started process (PID=2070) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:01:41.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:01:41.549+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:01:41.573+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.572+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:01:41.724+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.724+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1386986750003416
[2025-01-09T16:01:41.725+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.725+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|2070]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:01:41.725+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.725+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:01:41.726+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.726+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:01:41.726+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.726+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:01:41.726+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.726+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|2070]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:01:41.729+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.729+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|2070]: It took 0.00234s to build the Airflow DAG.
[2025-01-09T16:01:41.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:01:41.742+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.742+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:01:41.774+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:01:41.774+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:01:41.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-09T16:02:11.877+0000] {processor.py:157} INFO - Started process (PID=2163) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:02:11.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:02:11.881+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:11.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:02:11.912+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:11.911+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:02:12.082+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.082+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15308271299909393
[2025-01-09T16:02:12.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.083+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|2163]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:02:12.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.083+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:02:12.084+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.084+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:02:12.084+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.084+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:02:12.084+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.084+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|2163]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:02:12.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.087+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|2163]: It took 0.00285s to build the Airflow DAG.
[2025-01-09T16:02:12.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:02:12.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.104+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:02:12.133+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:12.132+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:02:12.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-09T16:02:42.190+0000] {processor.py:157} INFO - Started process (PID=2260) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:02:42.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:02:42.194+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:02:42.220+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.220+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:02:42.406+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.406+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16905611000038334
[2025-01-09T16:02:42.407+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.406+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|2260]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:02:42.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.407+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:02:42.408+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.408+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:02:42.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.409+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:02:42.409+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.409+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|2260]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:02:42.414+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.414+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|2260]: It took 0.00493s to build the Airflow DAG.
[2025-01-09T16:02:42.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:02:42.433+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.433+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:02:42.465+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:02:42.465+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:02:42.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-09T16:03:12.561+0000] {processor.py:157} INFO - Started process (PID=2347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:03:12.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:03:12.564+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:03:12.591+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.591+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:03:12.734+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.734+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12999696099905123
[2025-01-09T16:03:12.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.734+0000] {graph.py:519} INFO - Cosmos performance [1e7441cb5915|2347]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:03:12.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.735+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:03:12.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.735+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:03:12.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.736+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:03:12.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.736+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [1e7441cb5915|2347]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:03:12.739+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.739+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [1e7441cb5915|2347]: It took 0.00275s to build the Airflow DAG.
[2025-01-09T16:03:12.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:03:12.751+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.751+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:03:12.771+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:03:12.771+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:03:12.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-09T16:04:38.094+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:04:38.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:04:38.098+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:04:38.129+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.129+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:04:38.303+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.303+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15766565400008403
[2025-01-09T16:04:38.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.304+0000] {graph.py:519} INFO - Cosmos performance [339a7339052e|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:04:38.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.304+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:04:38.305+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.305+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:04:38.306+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.305+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:04:38.306+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.306+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [339a7339052e|70]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:04:38.311+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.311+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [339a7339052e|70]: It took 0.00482s to build the Airflow DAG.
[2025-01-09T16:04:38.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:04:38.432+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.432+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:04:38.466+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:04:38.466+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:04:38.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.405 seconds
[2025-01-09T16:05:08.540+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:05:08.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:05:08.546+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:05:08.575+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.575+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:05:08.734+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.734+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14411867799935862
[2025-01-09T16:05:08.734+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.734+0000] {graph.py:519} INFO - Cosmos performance [339a7339052e|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:05:08.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.735+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:05:08.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.735+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:05:08.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.736+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:05:08.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.736+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [339a7339052e|157]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:05:08.740+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.740+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [339a7339052e|157]: It took 0.00355s to build the Airflow DAG.
[2025-01-09T16:05:08.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:05:08.756+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.756+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:05:08.785+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:08.785+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:05:08.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-09T16:05:38.999+0000] {processor.py:157} INFO - Started process (PID=245) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:05:39.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:05:39.004+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:05:39.032+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.032+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:05:39.213+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.212+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1628980750010669
[2025-01-09T16:05:39.213+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.213+0000] {graph.py:519} INFO - Cosmos performance [339a7339052e|245]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:05:39.214+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.214+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:05:39.215+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.215+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:05:39.215+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.215+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:05:39.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.216+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [339a7339052e|245]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:05:39.220+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.220+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [339a7339052e|245]: It took 0.00406s to build the Airflow DAG.
[2025-01-09T16:05:39.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:05:39.237+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.237+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:05:39.266+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:05:39.266+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:05:39.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.294 seconds
[2025-01-09T16:06:09.395+0000] {processor.py:157} INFO - Started process (PID=338) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:06:09.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:06:09.399+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:06:09.421+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.421+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:06:09.574+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.573+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13783329800025967
[2025-01-09T16:06:09.574+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.574+0000] {graph.py:519} INFO - Cosmos performance [339a7339052e|338]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:06:09.575+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.575+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:06:09.575+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.575+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:06:09.576+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.575+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:06:09.576+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.576+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [339a7339052e|338]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:06:09.579+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.579+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [339a7339052e|338]: It took 0.00319s to build the Airflow DAG.
[2025-01-09T16:06:09.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:06:09.595+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.595+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:06:09.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:09.624+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:06:09.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-09T16:06:39.743+0000] {processor.py:157} INFO - Started process (PID=436) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:06:39.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:06:39.747+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:06:39.768+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.768+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:06:39.919+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.919+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1381418950004445
[2025-01-09T16:06:39.919+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.919+0000] {graph.py:519} INFO - Cosmos performance [339a7339052e|436]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:06:39.920+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.920+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:06:39.921+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.921+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:06:39.921+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.921+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:06:39.922+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.921+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [339a7339052e|436]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:06:39.925+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.925+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [339a7339052e|436]: It took 0.00381s to build the Airflow DAG.
[2025-01-09T16:06:39.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:06:39.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.943+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:06:39.979+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:06:39.979+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:06:40.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-09T16:07:10.100+0000] {processor.py:157} INFO - Started process (PID=523) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:07:10.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:07:10.103+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:07:10.129+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.128+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:07:10.256+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.256+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11375775600026827
[2025-01-09T16:07:10.257+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.257+0000] {graph.py:519} INFO - Cosmos performance [339a7339052e|523]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:07:10.257+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.257+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:07:10.257+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.257+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:07:10.258+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.258+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:07:10.258+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.258+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [339a7339052e|523]: It took 0.13s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:07:10.260+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.260+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [339a7339052e|523]: It took 0.00234s to build the Airflow DAG.
[2025-01-09T16:07:10.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:07:10.273+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.273+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:07:10.295+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:10.295+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:07:10.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-09T16:07:40.691+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:07:40.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:07:40.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:07:40.727+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.727+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:07:40.887+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.887+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14029344499977014
[2025-01-09T16:07:40.888+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.888+0000] {graph.py:519} INFO - Cosmos performance [339a7339052e|606]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:07:40.888+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.888+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:07:40.889+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.889+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:07:40.889+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.889+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:07:40.890+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.889+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [339a7339052e|606]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:07:40.893+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.893+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [339a7339052e|606]: It took 0.00312s to build the Airflow DAG.
[2025-01-09T16:07:40.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:07:40.908+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.908+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:07:40.933+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:07:40.932+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:07:40.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-09T16:08:52.951+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:08:52.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:08:52.955+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:52.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:08:52.984+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:52.984+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:08:53.155+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.154+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15431911899941042
[2025-01-09T16:08:53.155+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.155+0000] {graph.py:519} INFO - Cosmos performance [d7b679f22b57|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:08:53.156+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.156+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:08:53.157+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.156+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:08:53.157+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.157+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:08:53.158+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.158+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7b679f22b57|70]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:08:53.162+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.162+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7b679f22b57|70]: It took 0.00457s to build the Airflow DAG.
[2025-01-09T16:08:53.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:08:53.276+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.276+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:08:53.303+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:08:53.303+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:08:53.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.378 seconds
[2025-01-09T16:09:23.475+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:09:23.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:09:23.479+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:09:23.500+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.500+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:09:23.643+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.642+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13075918999857095
[2025-01-09T16:09:23.643+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.643+0000] {graph.py:519} INFO - Cosmos performance [d7b679f22b57|158]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:09:23.644+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.644+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:09:23.644+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.644+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:09:23.644+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.644+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:09:23.645+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.645+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7b679f22b57|158]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:09:23.647+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.647+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7b679f22b57|158]: It took 0.00265s to build the Airflow DAG.
[2025-01-09T16:09:23.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:09:23.662+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.662+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:09:23.689+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:09:23.688+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:09:23.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-09T16:10:31.241+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:10:31.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:10:31.246+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:10:31.277+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.277+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:10:31.458+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.458+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16487754800073162
[2025-01-09T16:10:31.458+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.458+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:10:31.459+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.459+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:10:31.460+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.460+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:10:31.460+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.460+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:10:31.461+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.460+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|70]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:10:31.465+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.465+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|70]: It took 0.00424s to build the Airflow DAG.
[2025-01-09T16:10:31.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:10:31.593+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.593+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:10:31.622+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:10:31.622+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:10:31.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.408 seconds
[2025-01-09T16:11:01.794+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:11:01.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:11:01.798+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:11:01.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.822+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:11:01.943+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.943+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10830109500057006
[2025-01-09T16:11:01.943+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.943+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|158]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:11:01.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.943+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:11:01.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.944+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:11:01.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.944+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:11:01.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.944+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|158]: It took 0.123s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:11:01.946+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.946+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|158]: It took 0.00215s to build the Airflow DAG.
[2025-01-09T16:11:01.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:11:01.960+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.960+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:11:01.982+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:01.982+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:11:02.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.216 seconds
[2025-01-09T16:11:32.228+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:11:32.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:11:32.232+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:11:32.259+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.259+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:11:32.400+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.400+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12553127799947106
[2025-01-09T16:11:32.400+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.400+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|249]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:11:32.401+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.401+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:11:32.401+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.401+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:11:32.402+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.402+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:11:32.402+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.402+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|249]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:11:32.405+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.405+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|249]: It took 0.00268s to build the Airflow DAG.
[2025-01-09T16:11:32.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:11:32.419+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.418+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:11:32.445+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:11:32.445+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:11:32.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T16:12:03.107+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:12:03.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:12:03.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:12:03.133+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.133+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:12:03.301+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.301+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15343531500002427
[2025-01-09T16:12:03.302+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.302+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|347]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:12:03.303+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.303+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:12:03.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.303+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:12:03.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.304+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:12:03.305+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.305+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|347]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:12:03.309+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.308+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|347]: It took 0.00379s to build the Airflow DAG.
[2025-01-09T16:12:03.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:12:03.330+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.330+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:12:03.363+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:03.362+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:12:03.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-09T16:12:33.688+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:12:33.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:12:33.691+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:12:33.713+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.713+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:12:33.861+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.861+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1345739570006117
[2025-01-09T16:12:33.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.861+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|433]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:12:33.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.862+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:12:33.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.862+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:12:33.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.863+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:12:33.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.863+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|433]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:12:33.866+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.866+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|433]: It took 0.00271s to build the Airflow DAG.
[2025-01-09T16:12:33.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:12:33.880+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.880+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:12:33.906+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:12:33.906+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:12:33.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-09T16:13:04.276+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:13:04.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:13:04.279+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:13:04.300+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.300+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:13:04.450+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.450+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13536906999979692
[2025-01-09T16:13:04.450+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.450+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|519]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:13:04.451+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.451+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:13:04.451+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.451+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:13:04.452+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.452+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:13:04.452+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.452+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|519]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:13:04.455+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.455+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|519]: It took 0.00285s to build the Airflow DAG.
[2025-01-09T16:13:04.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:13:04.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.469+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:13:04.490+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:04.490+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:13:04.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-09T16:13:34.679+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:13:34.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:13:34.685+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:13:34.723+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.723+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:13:34.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.873+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12815906499963603
[2025-01-09T16:13:34.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.873+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|606]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:13:34.874+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.874+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:13:34.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.874+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:13:34.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.875+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:13:34.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.875+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|606]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:13:34.878+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.878+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|606]: It took 0.00293s to build the Airflow DAG.
[2025-01-09T16:13:34.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:13:34.896+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.896+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:13:34.921+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:13:34.921+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:13:34.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-09T16:14:05.006+0000] {processor.py:157} INFO - Started process (PID=701) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:14:05.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:14:05.010+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:14:05.042+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.042+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:14:05.212+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.212+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15502162700067856
[2025-01-09T16:14:05.213+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.213+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|701]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:14:05.213+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.213+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:14:05.214+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.214+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:14:05.214+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.214+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:14:05.215+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.215+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|701]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:14:05.217+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.217+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|701]: It took 0.00269s to build the Airflow DAG.
[2025-01-09T16:14:05.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:14:05.232+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.232+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:14:05.259+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:05.259+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:14:05.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.276 seconds
[2025-01-09T16:14:35.350+0000] {processor.py:157} INFO - Started process (PID=818) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:14:35.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:14:35.354+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:14:35.382+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.382+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:14:35.552+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.552+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15333013399867923
[2025-01-09T16:14:35.553+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.553+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|818]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:14:35.554+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.553+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:14:35.554+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.554+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:14:35.555+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.554+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:14:35.555+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.555+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|818]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:14:35.559+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.559+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|818]: It took 0.00447s to build the Airflow DAG.
[2025-01-09T16:14:35.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:14:35.568+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.568+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:14:35.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:14:35.605+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:14:35.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-09T16:15:06.383+0000] {processor.py:157} INFO - Started process (PID=904) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:15:06.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:15:06.386+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:15:06.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.411+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:15:06.565+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.564+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14026130699858186
[2025-01-09T16:15:06.565+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.565+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|904]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:15:06.566+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.565+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:15:06.566+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.566+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:15:06.566+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.566+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:15:06.567+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.566+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|904]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:15:06.570+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.569+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|904]: It took 0.00289s to build the Airflow DAG.
[2025-01-09T16:15:06.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:15:06.583+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.583+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:15:06.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:06.605+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:15:06.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-09T16:15:36.700+0000] {processor.py:157} INFO - Started process (PID=990) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:15:36.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:15:36.705+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:15:36.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.737+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:15:36.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.944+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1870754819992726
[2025-01-09T16:15:36.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.944+0000] {graph.py:519} INFO - Cosmos performance [7d336a2b4f58|990]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:15:36.945+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.945+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:15:36.946+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.945+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:15:36.946+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.946+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:15:36.946+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.946+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [7d336a2b4f58|990]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:15:36.950+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.949+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [7d336a2b4f58|990]: It took 0.00322s to build the Airflow DAG.
[2025-01-09T16:15:36.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:15:36.967+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:36.966+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:15:37.005+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:15:37.004+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:15:37.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-09T16:16:39.090+0000] {processor.py:157} INFO - Started process (PID=69) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:16:39.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:16:39.095+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:16:39.131+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.131+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:16:39.314+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.314+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16674841599888168
[2025-01-09T16:16:39.315+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.314+0000] {graph.py:519} INFO - Cosmos performance [87f6f16b2137|69]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:16:39.316+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.315+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:16:39.316+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.316+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:16:39.316+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.316+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:16:39.317+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.317+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [87f6f16b2137|69]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:16:39.321+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.321+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [87f6f16b2137|69]: It took 0.00428s to build the Airflow DAG.
[2025-01-09T16:16:39.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:16:39.450+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.450+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:16:39.481+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:16:39.480+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:16:39.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.417 seconds
[2025-01-09T16:17:09.645+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:17:09.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:17:09.648+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:17:09.670+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.670+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:17:09.811+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.811+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.128307262000817
[2025-01-09T16:17:09.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.812+0000] {graph.py:519} INFO - Cosmos performance [87f6f16b2137|155]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:17:09.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.812+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:17:09.812+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.812+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:17:09.813+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.813+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:17:09.813+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.813+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [87f6f16b2137|155]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:17:09.815+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.815+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [87f6f16b2137|155]: It took 0.00228s to build the Airflow DAG.
[2025-01-09T16:17:09.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:17:09.830+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:17:09.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:09.862+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:17:09.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-09T16:17:40.039+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:17:40.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:17:40.042+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:17:40.068+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.067+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:17:40.225+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.225+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14403089200095565
[2025-01-09T16:17:40.226+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.226+0000] {graph.py:519} INFO - Cosmos performance [87f6f16b2137|241]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:17:40.227+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.227+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:17:40.227+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.227+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:17:40.228+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.228+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:17:40.228+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.228+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [87f6f16b2137|241]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:17:40.232+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.232+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [87f6f16b2137|241]: It took 0.00381s to build the Airflow DAG.
[2025-01-09T16:17:40.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:17:40.248+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.248+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:17:40.275+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:17:40.275+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:17:40.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-09T16:18:10.804+0000] {processor.py:157} INFO - Started process (PID=327) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:18:10.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:18:10.816+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:10.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:18:10.846+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:10.846+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:18:11.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.012+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14909461000024749
[2025-01-09T16:18:11.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.013+0000] {graph.py:519} INFO - Cosmos performance [87f6f16b2137|327]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:18:11.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.013+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:18:11.014+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.014+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:18:11.014+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.014+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:18:11.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.015+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [87f6f16b2137|327]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:18:11.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.018+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [87f6f16b2137|327]: It took 0.0032s to build the Airflow DAG.
[2025-01-09T16:18:11.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:18:11.034+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.034+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:18:11.063+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:11.063+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:18:11.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-09T16:18:41.303+0000] {processor.py:157} INFO - Started process (PID=413) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:18:41.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:18:41.307+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:18:41.330+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.330+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:18:41.505+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.505+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15948240900070232
[2025-01-09T16:18:41.506+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.506+0000] {graph.py:519} INFO - Cosmos performance [87f6f16b2137|413]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:18:41.506+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.506+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:18:41.507+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.507+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:18:41.507+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.507+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:18:41.508+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.507+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [87f6f16b2137|413]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:18:41.511+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.511+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [87f6f16b2137|413]: It took 0.00368s to build the Airflow DAG.
[2025-01-09T16:18:41.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:18:41.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.530+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:18:41.566+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:18:41.566+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:18:41.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-09T16:19:11.833+0000] {processor.py:157} INFO - Started process (PID=500) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:19:11.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:19:11.838+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:11.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:19:11.901+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:11.900+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:19:12.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.136+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19649866200052202
[2025-01-09T16:19:12.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.137+0000] {graph.py:519} INFO - Cosmos performance [87f6f16b2137|500]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:19:12.138+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.138+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:19:12.139+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.139+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:19:12.139+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.139+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:19:12.140+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.140+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [87f6f16b2137|500]: It took 0.24s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:19:12.144+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.144+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [87f6f16b2137|500]: It took 0.00405s to build the Airflow DAG.
[2025-01-09T16:19:12.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:19:12.167+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.167+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:19:12.211+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:19:12.210+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:19:12.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.408 seconds
[2025-01-09T16:20:37.896+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:20:37.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:20:37.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:37.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:20:37.934+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:37.934+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:20:38.141+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.141+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19109947500146518
[2025-01-09T16:20:38.142+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.142+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:20:38.143+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.143+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:20:38.144+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.143+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:20:38.144+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.144+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:20:38.145+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.145+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|70]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:20:38.151+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.151+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|70]: It took 0.00614s to build the Airflow DAG.
[2025-01-09T16:20:38.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:20:38.375+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.374+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:20:38.423+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:20:38.422+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:20:38.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.557 seconds
[2025-01-09T16:21:09.211+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:21:09.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:21:09.215+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:21:09.240+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.239+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:21:09.380+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.380+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1237079549991904
[2025-01-09T16:21:09.380+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.380+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:21:09.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.381+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:21:09.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.381+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:21:09.381+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.381+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:21:09.382+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.382+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|157]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:21:09.384+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.384+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|157]: It took 0.00245s to build the Airflow DAG.
[2025-01-09T16:21:09.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:21:09.398+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.398+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:21:09.432+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:09.432+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:21:09.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T16:21:39.940+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:21:39.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:21:39.946+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:39.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:21:39.982+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:39.982+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:21:40.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.208+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20428456999979971
[2025-01-09T16:21:40.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.209+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|251]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:21:40.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.210+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:21:40.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.210+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:21:40.211+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.211+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:21:40.211+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.211+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|251]: It took 0.229s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:21:40.214+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.214+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|251]: It took 0.00309s to build the Airflow DAG.
[2025-01-09T16:21:40.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:21:40.229+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.229+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:21:40.257+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:21:40.256+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:21:40.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.339 seconds
[2025-01-09T16:22:10.426+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:22:10.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:22:10.430+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:22:10.459+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.459+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:22:10.689+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.689+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.209581054001319
[2025-01-09T16:22:10.690+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.690+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|344]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:22:10.691+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.691+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:22:10.692+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.692+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:22:10.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.692+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:22:10.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.693+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|344]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:22:10.698+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.698+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|344]: It took 0.00507s to build the Airflow DAG.
[2025-01-09T16:22:10.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:22:10.727+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.726+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:22:10.818+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:10.817+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:22:10.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.450 seconds
[2025-01-09T16:22:41.717+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:22:41.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:22:41.721+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:22:41.748+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.747+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:22:41.894+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.894+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12925320500107773
[2025-01-09T16:22:41.894+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.894+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|431]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:22:41.895+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.895+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:22:41.895+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.895+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:22:41.896+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.896+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:22:41.896+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.896+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|431]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:22:41.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.900+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|431]: It took 0.00366s to build the Airflow DAG.
[2025-01-09T16:22:41.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:22:41.916+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.916+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:22:41.945+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:22:41.945+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:22:41.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-09T16:23:12.100+0000] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:23:12.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:23:12.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:23:12.130+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.130+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:23:12.302+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.302+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15385710499867855
[2025-01-09T16:23:12.302+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.302+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|528]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:23:12.303+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.303+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:23:12.303+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.303+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:23:12.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.304+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:23:12.304+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.304+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|528]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:23:12.308+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.308+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|528]: It took 0.00355s to build the Airflow DAG.
[2025-01-09T16:23:12.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:23:12.325+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.325+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:23:12.354+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:12.353+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:23:12.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-09T16:23:42.570+0000] {processor.py:157} INFO - Started process (PID=615) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:23:42.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:23:42.573+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:23:42.592+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.592+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:23:42.733+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.732+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12705842099967413
[2025-01-09T16:23:42.733+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.733+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|615]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:23:42.734+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.734+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:23:42.734+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.734+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:23:42.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.734+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:23:42.735+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.735+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|615]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:23:42.738+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.738+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|615]: It took 0.00263s to build the Airflow DAG.
[2025-01-09T16:23:42.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:23:42.753+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.753+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:23:42.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:23:42.778+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:23:42.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-09T16:24:12.867+0000] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:24:12.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:24:12.870+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:12.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:24:12.887+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:12.887+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:24:13.022+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.022+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12322497100103647
[2025-01-09T16:24:13.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.023+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|702]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:24:13.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.023+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:24:13.024+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.024+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:24:13.024+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.024+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:24:13.025+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.025+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|702]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:24:13.027+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.027+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|702]: It took 0.00259s to build the Airflow DAG.
[2025-01-09T16:24:13.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:24:13.041+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.041+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:24:13.065+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:13.065+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:24:13.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.219 seconds
[2025-01-09T16:24:43.144+0000] {processor.py:157} INFO - Started process (PID=787) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:24:43.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:24:43.146+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:24:43.167+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.167+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:24:43.342+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.342+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16104794300008507
[2025-01-09T16:24:43.343+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.343+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|787]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:24:43.343+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.343+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:24:43.344+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.344+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:24:43.344+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.344+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:24:43.345+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.344+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|787]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:24:43.348+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.347+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|787]: It took 0.00301s to build the Airflow DAG.
[2025-01-09T16:24:43.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:24:43.362+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.362+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:24:43.391+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:24:43.391+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:24:43.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-09T16:25:13.498+0000] {processor.py:157} INFO - Started process (PID=873) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:25:13.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:25:13.502+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:25:13.525+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.525+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:25:13.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.694+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15412779500002216
[2025-01-09T16:25:13.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.694+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|873]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:25:13.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.695+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:25:13.696+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.696+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:25:13.696+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.696+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:25:13.697+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.697+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|873]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:25:13.701+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.701+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|873]: It took 0.00395s to build the Airflow DAG.
[2025-01-09T16:25:13.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:25:13.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.716+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:25:13.743+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:13.743+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:25:13.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-09T16:25:43.855+0000] {processor.py:157} INFO - Started process (PID=968) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:25:43.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:25:43.859+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:43.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:25:43.885+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:43.884+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:25:44.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.087+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18361090200050967
[2025-01-09T16:25:44.088+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.088+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|968]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:25:44.090+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.089+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:25:44.091+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.090+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:25:44.091+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.091+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:25:44.092+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.092+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|968]: It took 0.208s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:25:44.096+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.096+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|968]: It took 0.00438s to build the Airflow DAG.
[2025-01-09T16:25:44.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:25:44.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.132+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:25:44.211+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:25:44.210+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:25:44.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.392 seconds
[2025-01-09T16:26:14.409+0000] {processor.py:157} INFO - Started process (PID=1067) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:26:14.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:26:14.415+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:26:14.442+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.442+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:26:14.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.625+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16785107299983792
[2025-01-09T16:26:14.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.626+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1067]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:26:14.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.627+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:26:14.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.628+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:26:14.629+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.629+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:26:14.630+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.630+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1067]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:26:14.635+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.635+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1067]: It took 0.00478s to build the Airflow DAG.
[2025-01-09T16:26:14.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:26:14.656+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.655+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:26:14.723+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:14.723+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:26:14.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.341 seconds
[2025-01-09T16:26:44.954+0000] {processor.py:157} INFO - Started process (PID=1150) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:26:44.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:26:44.958+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:44.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:26:44.982+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:44.981+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:26:45.131+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.131+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13598049500069465
[2025-01-09T16:26:45.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.131+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1150]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:26:45.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.132+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:26:45.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.132+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:26:45.133+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.133+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:26:45.133+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.133+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1150]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:26:45.136+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.136+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1150]: It took 0.00271s to build the Airflow DAG.
[2025-01-09T16:26:45.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:26:45.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.150+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:26:45.173+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:26:45.172+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:26:45.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-09T16:27:15.733+0000] {processor.py:157} INFO - Started process (PID=1242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:27:15.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:27:15.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:27:15.755+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.755+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:27:15.899+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.899+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1316314110008534
[2025-01-09T16:27:15.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.900+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1242]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:27:15.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.900+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:27:15.901+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.901+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:27:15.901+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.901+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:27:15.902+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.902+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1242]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:27:15.905+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.905+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1242]: It took 0.00376s to build the Airflow DAG.
[2025-01-09T16:27:15.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:27:15.923+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.923+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:27:15.951+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:15.950+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:27:15.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-09T16:27:46.036+0000] {processor.py:157} INFO - Started process (PID=1328) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:27:46.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:27:46.039+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:27:46.059+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.059+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:27:46.222+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.221+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14894479699978547
[2025-01-09T16:27:46.223+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.223+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1328]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:27:46.224+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.224+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:27:46.225+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.225+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:27:46.225+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.225+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:27:46.226+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.226+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1328]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:27:46.230+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.230+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1328]: It took 0.00403s to build the Airflow DAG.
[2025-01-09T16:27:46.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:27:46.251+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.251+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:27:46.294+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:27:46.294+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:27:46.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.291 seconds
[2025-01-09T16:28:16.558+0000] {processor.py:157} INFO - Started process (PID=1423) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:28:16.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:28:16.563+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:28:16.586+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.585+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:28:16.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.736+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13560099300048023
[2025-01-09T16:28:16.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.736+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1423]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:28:16.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.737+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:28:16.737+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.737+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:28:16.738+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.738+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:28:16.738+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.738+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1423]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:28:16.741+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.741+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1423]: It took 0.00279s to build the Airflow DAG.
[2025-01-09T16:28:16.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:28:16.761+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.760+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:28:16.790+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:16.789+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:28:16.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-09T16:28:46.924+0000] {processor.py:157} INFO - Started process (PID=1521) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:28:46.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:28:46.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:46.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:28:46.952+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:46.952+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:28:47.105+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.105+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13902263800082437
[2025-01-09T16:28:47.106+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.105+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1521]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:28:47.106+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.106+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:28:47.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.107+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:28:47.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.107+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:28:47.108+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.108+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1521]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:28:47.111+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.111+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1521]: It took 0.00351s to build the Airflow DAG.
[2025-01-09T16:28:47.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:28:47.127+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.127+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:28:47.153+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:28:47.152+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:28:47.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-09T16:29:17.460+0000] {processor.py:157} INFO - Started process (PID=1605) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:29:17.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:29:17.463+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:29:17.483+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.483+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:29:17.639+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.639+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14390633800030628
[2025-01-09T16:29:17.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.640+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1605]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:29:17.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.640+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:29:17.641+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.641+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:29:17.642+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.641+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:29:17.642+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.642+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1605]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:29:17.646+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.646+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1605]: It took 0.00433s to build the Airflow DAG.
[2025-01-09T16:29:17.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:29:17.664+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.664+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:29:17.687+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:17.687+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:29:17.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-09T16:29:48.025+0000] {processor.py:157} INFO - Started process (PID=1691) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:29:48.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:29:48.028+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:29:48.053+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.053+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:29:48.220+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.220+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15095978300087154
[2025-01-09T16:29:48.221+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.220+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1691]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:29:48.222+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.221+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:29:48.222+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.222+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:29:48.223+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.223+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:29:48.223+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.223+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1691]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:29:48.228+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.228+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1691]: It took 0.0049s to build the Airflow DAG.
[2025-01-09T16:29:48.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:29:48.250+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.249+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:29:48.274+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:29:48.273+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:29:48.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-09T16:30:18.432+0000] {processor.py:157} INFO - Started process (PID=1779) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:30:18.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:30:18.435+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:30:18.459+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.459+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:30:18.622+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.622+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1493860720001976
[2025-01-09T16:30:18.623+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.622+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1779]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:30:18.623+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.623+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:30:18.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.624+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:30:18.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.624+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:30:18.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.624+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1779]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:30:18.628+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.627+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1779]: It took 0.0031s to build the Airflow DAG.
[2025-01-09T16:30:18.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:30:18.645+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.645+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:30:18.670+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:18.670+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:30:18.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-09T16:30:48.796+0000] {processor.py:157} INFO - Started process (PID=1886) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:30:48.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:30:48.799+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:30:48.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.824+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:30:48.981+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.981+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1415204979984992
[2025-01-09T16:30:48.982+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.982+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1886]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:30:48.983+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.983+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:30:48.984+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.984+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:30:48.984+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.984+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:30:48.985+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.985+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1886]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:30:48.989+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:48.989+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1886]: It took 0.00392s to build the Airflow DAG.
[2025-01-09T16:30:48.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:30:49.007+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:49.007+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:30:49.037+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:30:49.037+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:30:49.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.266 seconds
[2025-01-09T16:31:19.111+0000] {processor.py:157} INFO - Started process (PID=1974) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:31:19.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:31:19.114+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:31:19.141+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.140+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:31:19.285+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.284+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13024946400037152
[2025-01-09T16:31:19.285+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.285+0000] {graph.py:519} INFO - Cosmos performance [82c87609d76c|1974]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:31:19.286+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.286+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:31:19.287+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.287+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:31:19.288+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.288+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:31:19.289+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.288+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [82c87609d76c|1974]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:31:19.294+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.294+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [82c87609d76c|1974]: It took 0.00517s to build the Airflow DAG.
[2025-01-09T16:31:19.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:31:19.311+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.311+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:31:19.340+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:31:19.340+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:31:19.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-09T16:43:16.341+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:43:16.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:43:16.348+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:16.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:43:16.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:16.396+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:43:17.102+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.101+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.6777093780001451
[2025-01-09T16:43:17.104+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.103+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|79]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:43:17.106+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.106+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:43:17.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.107+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:43:17.108+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.108+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:43:17.109+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.109+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|79]: It took 0.713s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:43:17.121+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.116+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|79]: It took 0.00776s to build the Airflow DAG.
[2025-01-09T16:43:17.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:43:17.475+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.474+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:43:17.576+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:17.575+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:43:17.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.322 seconds
[2025-01-09T16:43:47.989+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:43:47.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:43:47.994+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:47.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:43:48.025+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.025+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:43:48.182+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.182+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14390730500053905
[2025-01-09T16:43:48.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.183+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|158]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:43:48.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.183+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:43:48.184+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.184+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:43:48.186+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.186+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:43:48.187+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.187+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|158]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:43:48.190+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.190+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|158]: It took 0.00384s to build the Airflow DAG.
[2025-01-09T16:43:48.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:43:48.206+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.206+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:43:48.249+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:43:48.249+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:43:48.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-09T16:44:18.525+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:44:18.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:44:18.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:44:18.557+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.557+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:44:18.728+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.727+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15459625699986645
[2025-01-09T16:44:18.728+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.728+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|244]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:44:18.729+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.729+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:44:18.729+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.729+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:44:18.730+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.729+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:44:18.730+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.730+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|244]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:44:18.733+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.733+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|244]: It took 0.00321s to build the Airflow DAG.
[2025-01-09T16:44:18.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:44:18.750+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.750+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:44:18.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:18.781+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:44:18.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-09T16:44:49.118+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:44:49.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:44:49.123+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:44:49.148+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.148+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:44:49.334+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.333+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17003101000045717
[2025-01-09T16:44:49.335+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.334+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|349]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:44:49.336+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.336+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:44:49.337+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.337+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:44:49.337+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.337+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:44:49.338+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.338+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|349]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:44:49.344+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.344+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|349]: It took 0.00624s to build the Airflow DAG.
[2025-01-09T16:44:49.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:44:49.361+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.361+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:44:49.390+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:44:49.390+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:44:49.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-09T16:45:19.739+0000] {processor.py:157} INFO - Started process (PID=435) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:45:19.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:45:19.742+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:45:19.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.763+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:45:19.927+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.927+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1505745989998104
[2025-01-09T16:45:19.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.928+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|435]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:45:19.928+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.928+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:45:19.929+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.929+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:45:19.929+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.929+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:45:19.930+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.929+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|435]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:45:19.933+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.933+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|435]: It took 0.00371s to build the Airflow DAG.
[2025-01-09T16:45:19.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:45:19.948+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.948+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:45:19.986+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:19.985+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:45:20.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-09T16:45:50.504+0000] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:45:50.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:45:50.507+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:45:50.530+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.530+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:45:50.690+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.690+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14600937099930889
[2025-01-09T16:45:50.691+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.691+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|528]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:45:50.692+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.692+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:45:50.692+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.692+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:45:50.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.693+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:45:50.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.693+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|528]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:45:50.697+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.697+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|528]: It took 0.00382s to build the Airflow DAG.
[2025-01-09T16:45:50.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:45:50.714+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.714+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:45:50.741+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:45:50.741+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:45:50.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-09T16:46:20.928+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:46:20.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:46:20.931+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:20.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:46:20.956+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:20.956+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:46:21.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.124+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1538689009994414
[2025-01-09T16:46:21.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.125+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|616]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:46:21.125+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.125+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:46:21.126+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.126+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:46:21.126+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.126+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:46:21.127+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.127+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|616]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:46:21.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.131+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|616]: It took 0.00439s to build the Airflow DAG.
[2025-01-09T16:46:21.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:46:21.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.150+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:46:21.178+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:21.178+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:46:21.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-09T16:46:51.321+0000] {processor.py:157} INFO - Started process (PID=704) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:46:51.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:46:51.324+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:46:51.351+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.351+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:46:51.523+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.523+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15820701899974665
[2025-01-09T16:46:51.523+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.523+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|704]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:46:51.524+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.524+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:46:51.524+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.524+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:46:51.524+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.524+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:46:51.525+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.525+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|704]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:46:51.528+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.528+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|704]: It took 0.00305s to build the Airflow DAG.
[2025-01-09T16:46:51.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:46:51.541+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.541+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:46:51.565+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:46:51.565+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:46:51.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-09T16:47:21.671+0000] {processor.py:157} INFO - Started process (PID=790) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:47:21.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:47:21.674+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:47:21.692+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.692+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:47:21.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.861+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15643692200137593
[2025-01-09T16:47:21.862+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.862+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|790]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:47:21.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.863+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:47:21.863+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.863+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:47:21.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.864+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:47:21.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.864+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|790]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:47:21.867+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.867+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|790]: It took 0.00279s to build the Airflow DAG.
[2025-01-09T16:47:21.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:47:21.882+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.881+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:47:21.905+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:21.905+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:47:21.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-09T16:47:52.053+0000] {processor.py:157} INFO - Started process (PID=878) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:47:52.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:47:52.056+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:47:52.082+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.082+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:47:52.264+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.264+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16482993400131818
[2025-01-09T16:47:52.265+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.265+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|878]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:47:52.266+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.265+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:47:52.266+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.266+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:47:52.266+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.266+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:47:52.267+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.267+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|878]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:47:52.270+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.270+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|878]: It took 0.00308s to build the Airflow DAG.
[2025-01-09T16:47:52.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:47:52.286+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.286+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:47:52.310+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:47:52.310+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:47:52.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-09T16:48:22.471+0000] {processor.py:157} INFO - Started process (PID=965) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:48:22.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:48:22.475+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:48:22.506+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.506+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:48:22.704+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.704+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18238123700029973
[2025-01-09T16:48:22.704+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.704+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|965]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:48:22.705+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.705+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:48:22.706+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.706+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:48:22.706+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.706+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:48:22.706+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.706+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|965]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:48:22.710+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.710+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|965]: It took 0.00378s to build the Airflow DAG.
[2025-01-09T16:48:22.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:48:22.730+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.730+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:48:22.762+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:22.761+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:48:22.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-09T16:48:53.211+0000] {processor.py:157} INFO - Started process (PID=1063) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:48:53.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:48:53.216+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:48:53.245+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.245+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:48:53.433+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.433+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1649720299992623
[2025-01-09T16:48:53.434+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.434+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1063]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:48:53.434+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.434+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:48:53.435+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.435+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:48:53.435+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.435+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:48:53.436+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.436+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1063]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:48:53.439+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.439+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1063]: It took 0.00331s to build the Airflow DAG.
[2025-01-09T16:48:53.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:48:53.457+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.457+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:48:53.486+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:48:53.486+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:48:53.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-09T16:49:23.564+0000] {processor.py:157} INFO - Started process (PID=1150) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:49:23.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:49:23.567+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:49:23.589+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.589+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:49:23.731+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.731+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12841393799863
[2025-01-09T16:49:23.731+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.731+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1150]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:49:23.732+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.732+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:49:23.732+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.732+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:49:23.733+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.733+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:49:23.733+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.733+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1150]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:49:23.736+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.736+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1150]: It took 0.00336s to build the Airflow DAG.
[2025-01-09T16:49:23.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:49:23.750+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.750+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:49:23.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:23.775+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:49:23.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-09T16:49:54.083+0000] {processor.py:157} INFO - Started process (PID=1235) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:49:54.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:49:54.087+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:49:54.108+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.108+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:49:54.267+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.266+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14512849899983848
[2025-01-09T16:49:54.267+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.267+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1235]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:49:54.268+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.267+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:49:54.268+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.268+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:49:54.268+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.268+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:49:54.268+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.268+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1235]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:49:54.271+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.271+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1235]: It took 0.00289s to build the Airflow DAG.
[2025-01-09T16:49:54.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:49:54.286+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.286+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:49:54.315+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:49:54.314+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:49:54.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-09T16:50:24.913+0000] {processor.py:157} INFO - Started process (PID=1321) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:50:24.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:50:24.916+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:24.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:50:24.942+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:24.942+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:50:25.095+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.095+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13805671899899608
[2025-01-09T16:50:25.096+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.096+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1321]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:50:25.096+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.096+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:50:25.097+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.097+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:50:25.097+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.097+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:50:25.097+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.097+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1321]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:50:25.100+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.100+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1321]: It took 0.00265s to build the Airflow DAG.
[2025-01-09T16:50:25.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:50:25.115+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.114+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:50:25.137+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:25.137+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:50:25.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-09T16:50:55.750+0000] {processor.py:157} INFO - Started process (PID=1412) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:50:55.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:50:55.753+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:50:55.774+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.774+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:50:55.910+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.910+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12212174200067238
[2025-01-09T16:50:55.910+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.910+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1412]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:50:55.911+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.911+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:50:55.911+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.911+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:50:55.911+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.911+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:50:55.912+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.911+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1412]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:50:55.914+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.914+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1412]: It took 0.0024s to build the Airflow DAG.
[2025-01-09T16:50:55.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:50:55.927+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.927+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:50:55.950+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:50:55.950+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:50:55.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.223 seconds
[2025-01-09T16:51:26.099+0000] {processor.py:157} INFO - Started process (PID=1506) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:51:26.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:51:26.102+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:51:26.127+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.127+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:51:26.352+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.351+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20932128299864416
[2025-01-09T16:51:26.352+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.352+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1506]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:51:26.353+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.353+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:51:26.353+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.353+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:51:26.354+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.354+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:51:26.354+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.354+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1506]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:51:26.357+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.357+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1506]: It took 0.00303s to build the Airflow DAG.
[2025-01-09T16:51:26.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:51:26.373+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.373+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:51:26.404+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:26.403+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:51:26.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.333 seconds
[2025-01-09T16:51:56.505+0000] {processor.py:157} INFO - Started process (PID=1603) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:51:56.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:51:56.509+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:51:56.537+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.537+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:51:56.693+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.693+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14310134900006233
[2025-01-09T16:51:56.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.694+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1603]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:51:56.694+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.694+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:51:56.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.694+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:51:56.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.695+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:51:56.695+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.695+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1603]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:51:56.697+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.697+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1603]: It took 0.00222s to build the Airflow DAG.
[2025-01-09T16:51:56.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:51:56.710+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.710+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:51:56.734+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:51:56.734+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:51:56.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-09T16:52:26.849+0000] {processor.py:157} INFO - Started process (PID=1690) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:52:26.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:52:26.852+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:26.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:52:26.872+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:26.872+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:52:27.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.013+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12711379299980763
[2025-01-09T16:52:27.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.013+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1690]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:52:27.014+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.014+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:52:27.014+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.014+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:52:27.014+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.014+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:52:27.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.015+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1690]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:52:27.018+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.018+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1690]: It took 0.00293s to build the Airflow DAG.
[2025-01-09T16:52:27.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:52:27.033+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.032+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:52:27.057+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:27.057+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:52:27.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-09T16:52:57.617+0000] {processor.py:157} INFO - Started process (PID=1775) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:52:57.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:52:57.621+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:52:57.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.640+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:52:57.804+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.804+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14989089599839645
[2025-01-09T16:52:57.805+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.805+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1775]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:52:57.805+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.805+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:52:57.806+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.805+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:52:57.806+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.806+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:52:57.806+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.806+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1775]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:52:57.809+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.809+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1775]: It took 0.0029s to build the Airflow DAG.
[2025-01-09T16:52:57.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:52:57.823+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.823+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:52:57.846+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:52:57.846+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:52:57.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-09T16:53:28.314+0000] {processor.py:157} INFO - Started process (PID=1861) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:53:28.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:53:28.317+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:53:28.346+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.346+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:53:28.509+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.509+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14099092799915525
[2025-01-09T16:53:28.510+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.510+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1861]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:53:28.510+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.510+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:53:28.511+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.511+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:53:28.512+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.511+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:53:28.512+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.512+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1861]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:53:28.517+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.516+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1861]: It took 0.00441s to build the Airflow DAG.
[2025-01-09T16:53:28.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:53:28.531+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.531+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:53:28.558+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:28.558+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:53:28.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-09T16:53:58.632+0000] {processor.py:157} INFO - Started process (PID=1955) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:53:58.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:53:58.635+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:53:58.657+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.656+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:53:58.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.824+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15255569999862928
[2025-01-09T16:53:58.825+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.824+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|1955]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:53:58.825+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.825+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:53:58.825+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.825+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:53:58.826+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.826+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:53:58.826+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.826+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|1955]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:53:58.829+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.829+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|1955]: It took 0.00316s to build the Airflow DAG.
[2025-01-09T16:53:58.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:53:58.845+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.845+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:53:58.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:53:58.872+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:53:58.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-09T16:54:29.020+0000] {processor.py:157} INFO - Started process (PID=2052) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:54:29.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:54:29.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:54:29.055+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.055+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:54:29.208+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.208+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1373191210004734
[2025-01-09T16:54:29.208+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.208+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2052]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:54:29.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.209+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:54:29.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.209+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:54:29.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.210+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:54:29.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.210+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2052]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:54:29.213+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.213+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2052]: It took 0.00294s to build the Airflow DAG.
[2025-01-09T16:54:29.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:54:29.229+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.229+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:54:29.256+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:29.255+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:54:29.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-09T16:54:59.879+0000] {processor.py:157} INFO - Started process (PID=2138) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:54:59.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:54:59.883+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:59.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:54:59.910+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:54:59.910+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:55:00.099+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.099+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17516870300096343
[2025-01-09T16:55:00.099+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.099+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2138]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:55:00.100+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.100+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:55:00.101+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.101+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:55:00.102+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.101+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:55:00.102+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.102+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2138]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:55:00.107+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.107+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2138]: It took 0.00515s to build the Airflow DAG.
[2025-01-09T16:55:00.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:55:00.124+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.124+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:55:00.150+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:00.149+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:55:00.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-09T16:55:30.293+0000] {processor.py:157} INFO - Started process (PID=2226) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:55:30.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:55:30.298+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:55:30.330+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.330+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:55:30.474+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.474+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12589994100017066
[2025-01-09T16:55:30.475+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.475+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2226]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:55:30.475+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.475+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:55:30.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.476+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:55:30.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.476+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:55:30.477+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.476+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2226]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:55:30.479+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.479+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2226]: It took 0.00293s to build the Airflow DAG.
[2025-01-09T16:55:30.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:55:30.494+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.494+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:55:30.516+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:55:30.516+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:55:30.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-09T16:56:01.416+0000] {processor.py:157} INFO - Started process (PID=2312) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:56:01.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:56:01.419+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:56:01.440+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.440+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:56:01.604+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.603+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14816807199895266
[2025-01-09T16:56:01.604+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.604+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2312]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:56:01.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.605+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:56:01.605+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.605+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:56:01.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.606+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:56:01.606+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.606+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2312]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:56:01.610+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.610+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2312]: It took 0.00392s to build the Airflow DAG.
[2025-01-09T16:56:01.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:56:01.625+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.625+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:56:01.661+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:01.661+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:56:01.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.272 seconds
[2025-01-09T16:56:31.817+0000] {processor.py:157} INFO - Started process (PID=2398) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:56:31.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:56:31.821+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:31.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:56:31.844+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:31.843+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:56:32.013+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.013+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15471459600121307
[2025-01-09T16:56:32.014+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.014+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2398]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:56:32.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.014+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:56:32.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.015+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:56:32.015+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.015+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:56:32.016+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.016+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2398]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:56:32.020+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.020+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2398]: It took 0.00396s to build the Airflow DAG.
[2025-01-09T16:56:32.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:56:32.035+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.035+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:56:32.058+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:56:32.058+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:56:32.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.266 seconds
[2025-01-09T16:57:02.205+0000] {processor.py:157} INFO - Started process (PID=2484) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:57:02.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:57:02.209+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:57:02.233+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.233+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:57:02.422+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.422+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17533100100081356
[2025-01-09T16:57:02.423+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.422+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2484]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:57:02.423+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.423+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:57:02.424+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.424+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:57:02.425+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.424+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:57:02.425+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.425+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2484]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:57:02.429+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.429+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2484]: It took 0.00415s to build the Airflow DAG.
[2025-01-09T16:57:02.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:57:02.446+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.446+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:57:02.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:02.475+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:57:02.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.294 seconds
[2025-01-09T16:57:32.609+0000] {processor.py:157} INFO - Started process (PID=2578) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:57:32.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:57:32.613+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:57:32.640+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.640+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:57:32.849+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.849+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19200599400028295
[2025-01-09T16:57:32.850+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.849+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2578]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:57:32.850+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.850+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:57:32.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.851+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:57:32.851+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.851+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:57:32.852+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.852+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2578]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:57:32.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.855+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2578]: It took 0.00331s to build the Airflow DAG.
[2025-01-09T16:57:32.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:57:32.873+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.873+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:57:32.905+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:57:32.905+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:57:32.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.323 seconds
[2025-01-09T16:58:02.980+0000] {processor.py:157} INFO - Started process (PID=2675) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:58:02.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:58:02.983+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:02.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:58:03.008+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.008+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:58:03.201+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.201+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17907457500041346
[2025-01-09T16:58:03.202+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.202+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2675]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:58:03.203+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.203+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:58:03.203+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.203+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:58:03.204+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.204+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:58:03.205+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.205+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2675]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:58:03.210+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.210+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2675]: It took 0.00503s to build the Airflow DAG.
[2025-01-09T16:58:03.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:58:03.228+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.228+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:58:03.264+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:03.264+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:58:03.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.312 seconds
[2025-01-09T16:58:33.379+0000] {processor.py:157} INFO - Started process (PID=2761) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:58:33.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:58:33.382+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:58:33.404+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.404+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:58:33.555+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.555+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13739917900056753
[2025-01-09T16:58:33.555+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.555+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2761]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:58:33.556+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.556+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:58:33.556+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.556+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:58:33.556+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.556+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:58:33.557+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.557+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2761]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:58:33.559+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.559+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2761]: It took 0.00268s to build the Airflow DAG.
[2025-01-09T16:58:33.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:58:33.573+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.573+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:58:33.599+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:58:33.599+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:58:33.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-09T16:59:03.872+0000] {processor.py:157} INFO - Started process (PID=2847) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:59:03.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:59:03.875+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:03.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:59:03.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:03.900+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:59:04.058+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.058+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14418856300108018
[2025-01-09T16:59:04.059+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.058+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2847]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:59:04.059+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.059+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:59:04.060+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.060+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:59:04.061+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.060+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:59:04.061+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.061+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2847]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:59:04.065+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.065+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2847]: It took 0.00388s to build the Airflow DAG.
[2025-01-09T16:59:04.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:59:04.080+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.079+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:59:04.103+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:04.103+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:59:04.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-09T16:59:34.392+0000] {processor.py:157} INFO - Started process (PID=2934) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:59:34.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T16:59:34.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:59:34.419+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.419+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T16:59:34.580+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.579+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14582845499899122
[2025-01-09T16:59:34.580+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.580+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|2934]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T16:59:34.581+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.581+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T16:59:34.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.582+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T16:59:34.582+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.582+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T16:59:34.583+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.582+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|2934]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T16:59:34.586+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.586+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|2934]: It took 0.0039s to build the Airflow DAG.
[2025-01-09T16:59:34.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T16:59:34.603+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.602+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T16:59:34.626+0000] {logging_mixin.py:151} INFO - [2025-01-09T16:59:34.626+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T16:59:34.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-09T17:00:04.779+0000] {processor.py:157} INFO - Started process (PID=3020) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:00:04.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:00:04.782+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:00:04.804+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.804+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:00:04.980+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.980+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16295109299971955
[2025-01-09T17:00:04.981+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.981+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3020]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:00:04.981+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.981+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:00:04.982+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.982+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:00:04.982+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.982+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:00:04.983+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.983+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3020]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:00:04.986+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:04.986+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3020]: It took 0.00317s to build the Airflow DAG.
[2025-01-09T17:00:04.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:00:05.004+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:05.004+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:00:05.027+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:05.027+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:00:05.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-09T17:00:35.117+0000] {processor.py:157} INFO - Started process (PID=3126) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:00:35.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:00:35.120+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:00:35.147+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.147+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:00:35.292+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.291+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13078314399899682
[2025-01-09T17:00:35.292+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.292+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3126]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:00:35.293+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.293+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:00:35.293+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.293+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:00:35.293+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.293+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:00:35.294+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.294+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3126]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:00:35.296+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.296+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3126]: It took 0.00274s to build the Airflow DAG.
[2025-01-09T17:00:35.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:00:35.313+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.313+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:00:35.342+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:00:35.342+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:00:35.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T17:01:05.562+0000] {processor.py:157} INFO - Started process (PID=3211) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:01:05.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:01:05.568+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:01:05.595+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.595+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:01:05.744+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.744+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13430540599983942
[2025-01-09T17:01:05.744+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.744+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3211]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:01:05.745+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.745+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:01:05.745+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.745+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:01:05.745+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.745+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:01:05.746+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.746+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3211]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:01:05.749+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.749+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3211]: It took 0.0029s to build the Airflow DAG.
[2025-01-09T17:01:05.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:01:05.763+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.763+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:01:05.787+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:05.786+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:01:05.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-09T17:01:35.852+0000] {processor.py:157} INFO - Started process (PID=3297) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:01:35.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:01:35.855+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:35.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:01:35.879+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:35.879+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:01:36.029+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.029+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13611358200068935
[2025-01-09T17:01:36.029+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.029+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3297]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:01:36.030+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.030+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:01:36.030+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.030+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:01:36.030+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.030+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:01:36.031+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.031+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3297]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:01:36.034+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.033+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3297]: It took 0.00292s to build the Airflow DAG.
[2025-01-09T17:01:36.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:01:36.047+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.047+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:01:36.075+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:01:36.074+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:01:36.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-09T17:02:06.157+0000] {processor.py:157} INFO - Started process (PID=3383) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:02:06.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:02:06.160+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:02:06.196+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.196+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:02:06.367+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.367+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15541751099954126
[2025-01-09T17:02:06.368+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.368+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3383]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:02:06.368+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.368+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:02:06.369+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.369+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:02:06.369+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.369+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:02:06.370+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.370+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3383]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:02:06.373+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.373+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3383]: It took 0.00336s to build the Airflow DAG.
[2025-01-09T17:02:06.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:02:06.387+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.387+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:02:06.410+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:06.409+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:02:06.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-09T17:02:36.766+0000] {processor.py:157} INFO - Started process (PID=3476) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:02:36.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:02:36.769+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:02:36.791+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.791+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:02:36.963+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.962+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15749974000027578
[2025-01-09T17:02:36.963+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.963+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3476]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:02:36.964+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.964+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:02:36.964+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.964+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:02:36.964+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.964+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:02:36.965+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.965+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3476]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:02:36.968+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.968+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3476]: It took 0.00313s to build the Airflow DAG.
[2025-01-09T17:02:36.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:02:36.983+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:36.983+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:02:37.007+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:02:37.007+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:02:37.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.266 seconds
[2025-01-09T17:03:07.079+0000] {processor.py:157} INFO - Started process (PID=3574) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:03:07.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:03:07.083+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:03:07.106+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.106+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:03:07.273+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.273+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15238889799911703
[2025-01-09T17:03:07.274+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.274+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3574]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:03:07.275+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.274+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:03:07.275+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.275+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:03:07.275+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.275+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:03:07.276+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.276+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3574]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:03:07.280+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.279+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3574]: It took 0.00355s to build the Airflow DAG.
[2025-01-09T17:03:07.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:03:07.295+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.295+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:03:07.332+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:07.332+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:03:07.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-09T17:03:37.421+0000] {processor.py:157} INFO - Started process (PID=3660) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:03:37.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:03:37.426+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:03:37.451+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.450+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:03:37.596+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.596+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1319691780008725
[2025-01-09T17:03:37.597+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.596+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3660]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:03:37.597+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.597+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:03:37.597+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.597+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:03:37.598+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.598+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:03:37.598+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.598+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3660]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:03:37.601+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.601+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3660]: It took 0.00269s to build the Airflow DAG.
[2025-01-09T17:03:37.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:03:37.615+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.614+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:03:37.637+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:03:37.637+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:03:37.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-09T17:04:08.128+0000] {processor.py:157} INFO - Started process (PID=3746) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:04:08.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:04:08.132+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:04:08.161+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.160+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:04:08.325+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.325+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1450042560009024
[2025-01-09T17:04:08.326+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.326+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3746]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:04:08.327+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.326+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:04:08.327+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.327+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:04:08.328+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.328+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:04:08.328+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.328+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3746]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:04:08.332+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.331+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3746]: It took 0.00329s to build the Airflow DAG.
[2025-01-09T17:04:08.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:04:08.347+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.347+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:04:08.375+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:08.374+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:04:08.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-09T17:04:38.824+0000] {processor.py:157} INFO - Started process (PID=3832) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:04:38.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:04:38.830+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:38.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:04:38.860+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:38.860+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:04:39.021+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.021+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14518727799986664
[2025-01-09T17:04:39.021+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.021+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3832]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:04:39.022+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.022+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:04:39.022+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.022+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:04:39.022+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.022+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:04:39.023+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.023+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3832]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:04:39.026+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.026+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3832]: It took 0.00303s to build the Airflow DAG.
[2025-01-09T17:04:39.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:04:39.041+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.041+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:04:39.063+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:04:39.063+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:04:39.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-09T17:05:09.199+0000] {processor.py:157} INFO - Started process (PID=3926) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:05:09.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:05:09.203+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:05:09.227+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.227+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:05:09.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.411+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17045593400143844
[2025-01-09T17:05:09.411+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.411+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|3926]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:05:09.412+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.412+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:05:09.412+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.412+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:05:09.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.413+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:05:09.413+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.413+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|3926]: It took 0.187s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:05:09.417+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.417+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|3926]: It took 0.00339s to build the Airflow DAG.
[2025-01-09T17:05:09.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:05:09.432+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.432+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:05:09.455+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:09.455+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:05:09.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-09T17:05:39.594+0000] {processor.py:157} INFO - Started process (PID=4023) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:05:39.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:05:39.597+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:05:39.619+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.618+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:05:39.774+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.774+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14198480499908328
[2025-01-09T17:05:39.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.775+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|4023]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:05:39.775+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.775+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:05:39.776+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.776+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:05:39.776+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.776+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:05:39.776+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.776+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|4023]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:05:39.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.779+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|4023]: It took 0.0026s to build the Airflow DAG.
[2025-01-09T17:05:39.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:05:39.795+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.795+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:05:39.827+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:05:39.827+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:05:39.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-09T17:06:10.248+0000] {processor.py:157} INFO - Started process (PID=4110) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:06:10.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:06:10.251+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:06:10.276+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.275+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:06:10.469+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.469+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17990130799989856
[2025-01-09T17:06:10.470+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.470+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|4110]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:06:10.471+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.471+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:06:10.472+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.472+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:06:10.473+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.473+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:06:10.473+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.473+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|4110]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:06:10.476+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.476+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|4110]: It took 0.00314s to build the Airflow DAG.
[2025-01-09T17:06:10.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:06:10.492+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.492+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:06:10.519+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:10.519+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:06:10.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-09T17:06:40.663+0000] {processor.py:157} INFO - Started process (PID=4198) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:06:40.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:06:40.666+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:06:40.688+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.688+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:06:40.822+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.822+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12045367599966994
[2025-01-09T17:06:40.823+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.822+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|4198]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:06:40.823+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.823+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:06:40.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.824+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:06:40.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.824+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:06:40.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.824+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|4198]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:06:40.827+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.827+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|4198]: It took 0.0024s to build the Airflow DAG.
[2025-01-09T17:06:40.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:06:40.841+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.840+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:06:40.864+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:06:40.863+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:06:40.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.227 seconds
[2025-01-09T17:07:11.562+0000] {processor.py:157} INFO - Started process (PID=4280) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:07:11.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:07:11.565+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:07:11.590+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.589+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:07:11.770+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.770+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1651522020001721
[2025-01-09T17:07:11.771+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.771+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|4280]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:07:11.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.772+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:07:11.772+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.772+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:07:11.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.773+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:07:11.773+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.773+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|4280]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:07:11.779+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.779+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|4280]: It took 0.00552s to build the Airflow DAG.
[2025-01-09T17:07:11.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:07:11.803+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.803+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:07:11.831+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:11.830+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:07:11.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-09T17:07:42.136+0000] {processor.py:157} INFO - Started process (PID=4385) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:07:42.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:07:42.140+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:07:42.170+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.169+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:07:42.370+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.370+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18017338299978292
[2025-01-09T17:07:42.370+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.370+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|4385]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:07:42.371+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.371+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:07:42.372+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.372+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:07:42.372+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.372+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:07:42.373+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.373+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|4385]: It took 0.204s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:07:42.377+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.376+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|4385]: It took 0.00393s to build the Airflow DAG.
[2025-01-09T17:07:42.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:07:42.396+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.395+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:07:42.427+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:07:42.427+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:07:42.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-09T17:08:12.593+0000] {processor.py:157} INFO - Started process (PID=4473) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:08:12.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:08:12.597+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:08:12.624+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.624+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:08:12.799+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.799+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15670088099977875
[2025-01-09T17:08:12.800+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.800+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|4473]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:08:12.801+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.801+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:08:12.801+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.801+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:08:12.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.801+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:08:12.802+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.802+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|4473]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:08:12.806+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.806+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|4473]: It took 0.00377s to build the Airflow DAG.
[2025-01-09T17:08:12.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:08:12.824+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.823+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:08:12.856+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:12.856+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:08:12.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-09T17:08:43.008+0000] {processor.py:157} INFO - Started process (PID=4561) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:08:43.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:08:43.012+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:08:43.036+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.036+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:08:43.181+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.181+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1305581689994142
[2025-01-09T17:08:43.181+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.181+0000] {graph.py:519} INFO - Cosmos performance [d7f5077f2bca|4561]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:08:43.182+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.182+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:08:43.182+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.182+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:08:43.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.183+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:08:43.183+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.183+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7f5077f2bca|4561]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:08:43.186+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.185+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7f5077f2bca|4561]: It took 0.00255s to build the Airflow DAG.
[2025-01-09T17:08:43.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:08:43.200+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.200+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:08:43.223+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:08:43.223+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-09T17:08:43.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-09T17:55:17.594+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:55:17.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:55:17.596+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:55:17.623+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.623+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:55:17.632+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.632+0000] {graph.py:508} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation
[2025-01-09T17:55:17.633+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.633+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-09T17:55:17.642+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.642+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /opt/airflow/dbt/dbt_stock_project/target/partial_parse.msgpack
[2025-01-09T17:55:17.680+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.680+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-09T17:55:17.681+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.681+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-09T17:55:17.682+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:17.681+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpyx9r54a2 --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-09T17:55:28.022+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.021+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12629195699992124
[2025-01-09T17:55:28.026+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.026+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-09T17:55:28.036+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.036+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:55:28.037+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.037+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:55:28.037+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.037+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|80]: It took 10.4s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-09T17:55:28.042+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.042+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|80]: It took 0.0045s to build the Airflow DAG.
[2025-01-09T17:55:28.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:55:28.135+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.135+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:PolygonAPI_to_BigQuery
[2025-01-09T17:55:28.149+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.149+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:PolygonAPI_to_BigQuery
[2025-01-09T17:55:28.163+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.163+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:PolygonAPI_to_BigQuery
[2025-01-09T17:55:28.176+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.176+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:55:28.185+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.185+0000] {dag.py:2929} INFO - Creating ORM DAG for PolygonAPI_to_BigQuery
[2025-01-09T17:55:28.196+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:28.196+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T17:55:28.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 10.628 seconds
[2025-01-09T17:55:58.468+0000] {processor.py:157} INFO - Started process (PID=163) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:55:58.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T17:55:58.470+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:55:58.495+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.494+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T17:55:58.677+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.677+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17172616899915738
[2025-01-09T17:55:58.678+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.678+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|163]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T17:55:58.679+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.679+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T17:55:58.679+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.679+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T17:55:58.680+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.680+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T17:55:58.680+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.680+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|163]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T17:55:58.684+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.684+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|163]: It took 0.00384s to build the Airflow DAG.
[2025-01-09T17:55:58.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T17:55:58.717+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.717+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T17:55:58.751+0000] {logging_mixin.py:151} INFO - [2025-01-09T17:55:58.750+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T17:55:58.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.317 seconds
[2025-01-09T18:44:25.628+0000] {processor.py:157} INFO - Started process (PID=177) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T18:44:25.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T18:44:25.632+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T18:44:25.672+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.671+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T18:44:25.889+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.889+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20336796199990204
[2025-01-09T18:44:25.890+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.890+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|177]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T18:44:25.891+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.891+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T18:44:25.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.892+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T18:44:25.892+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.892+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T18:44:25.893+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.893+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|177]: It took 0.222s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T18:44:25.900+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.900+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|177]: It took 0.00745s to build the Airflow DAG.
[2025-01-09T18:44:25.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T18:44:25.929+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.928+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T18:44:25.964+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:25.963+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T18:44:25.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.369 seconds
[2025-01-09T18:44:56.768+0000] {processor.py:157} INFO - Started process (PID=216) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T18:44:56.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-09T18:44:56.770+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T18:44:56.799+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.799+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-09T18:44:56.918+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.918+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11111522999999579
[2025-01-09T18:44:56.919+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.918+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|216]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-09T18:44:56.919+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.919+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-09T18:44:56.920+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.920+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-09T18:44:56.920+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.920+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-09T18:44:56.921+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.921+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|216]: It took 0.122s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-09T18:44:56.924+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.924+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|216]: It took 0.00297s to build the Airflow DAG.
[2025-01-09T18:44:56.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-09T18:44:56.944+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.944+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-09T18:44:56.965+0000] {logging_mixin.py:151} INFO - [2025-01-09T18:44:56.965+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-08T00:00:00+00:00, run_after=2025-01-09T00:00:00+00:00
[2025-01-09T18:44:56.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.221 seconds
