[2025-01-10T12:45:02.274+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:45:02.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:45:02.277+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:45:02.309+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.309+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:45:02.528+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.528+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20565099200000247
[2025-01-10T12:45:02.529+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.529+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|72]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:45:02.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.529+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:45:02.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.530+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:45:02.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.530+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:45:02.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.531+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|72]: It took 0.223s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:45:02.535+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.535+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|72]: It took 0.00418s to build the Airflow DAG.
[2025-01-10T12:45:02.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:45:02.561+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.560+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:45:02.591+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:02.591+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:45:02.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.348 seconds
[2025-01-10T12:45:33.382+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:45:33.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:45:33.385+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:45:33.418+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.418+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:45:33.612+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.611+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1793068519999963
[2025-01-10T12:45:33.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.612+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|111]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:45:33.614+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.613+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:45:33.614+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.614+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:45:33.615+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.615+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:45:33.616+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.616+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|111]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:45:33.621+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.620+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|111]: It took 0.00472s to build the Airflow DAG.
[2025-01-10T12:45:33.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:45:33.645+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.645+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:45:33.673+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:45:33.673+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:45:33.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.324 seconds
[2025-01-10T12:46:04.718+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:46:04.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:46:04.720+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:46:04.743+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.743+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:46:04.977+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.977+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22271529300000736
[2025-01-10T12:46:04.978+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.978+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|158]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:46:04.979+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.979+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:46:04.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.980+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:46:04.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.980+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:46:04.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.981+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|158]: It took 0.239s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:46:04.986+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:04.985+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|158]: It took 0.00442s to build the Airflow DAG.
[2025-01-10T12:46:04.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:46:05.018+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:05.017+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:46:05.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:05.064+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:46:05.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.383 seconds
[2025-01-10T12:46:36.008+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:46:36.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:46:36.009+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:46:36.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.034+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:46:36.151+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.151+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10951021999999
[2025-01-10T12:46:36.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.151+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|208]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:46:36.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.152+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:46:36.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.152+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:46:36.153+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.153+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:46:36.153+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.153+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|208]: It took 0.119s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:46:36.155+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.155+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|208]: It took 0.00237s to build the Airflow DAG.
[2025-01-10T12:46:36.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:46:36.171+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.171+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:46:36.190+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:46:36.190+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:46:36.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.214 seconds
[2025-01-10T12:47:07.283+0000] {processor.py:157} INFO - Started process (PID=247) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:47:07.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:47:07.285+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:47:07.305+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.305+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:47:07.421+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.420+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10736068299999602
[2025-01-10T12:47:07.421+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.421+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|247]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:47:07.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.422+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:47:07.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.422+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:47:07.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.422+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:47:07.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.423+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|247]: It took 0.118s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:47:07.425+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.425+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|247]: It took 0.00242s to build the Airflow DAG.
[2025-01-10T12:47:07.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:47:07.440+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.440+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:47:07.458+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:07.457+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:47:07.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.199 seconds
[2025-01-10T12:47:38.493+0000] {processor.py:157} INFO - Started process (PID=286) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:47:38.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:47:38.497+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:47:38.519+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.518+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:47:38.639+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.639+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11208167300000582
[2025-01-10T12:47:38.639+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.639+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|286]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:47:38.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.640+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:47:38.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.640+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:47:38.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.640+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:47:38.641+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.641+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|286]: It took 0.122s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:47:38.643+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.643+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|286]: It took 0.00247s to build the Airflow DAG.
[2025-01-10T12:47:38.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:47:38.660+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.659+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:47:38.680+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:47:38.679+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:47:38.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.213 seconds
[2025-01-10T12:48:09.073+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:48:09.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:48:09.075+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:48:09.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.100+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:48:09.227+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.227+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11862806300001694
[2025-01-10T12:48:09.228+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.228+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|344]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:48:09.228+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.228+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:48:09.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.229+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:48:09.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.229+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:48:09.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.229+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|344]: It took 0.129s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:48:09.232+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.232+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|344]: It took 0.00226s to build the Airflow DAG.
[2025-01-10T12:48:09.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:48:09.247+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.247+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:48:09.267+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:09.267+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:48:09.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.227 seconds
[2025-01-10T12:48:39.699+0000] {processor.py:157} INFO - Started process (PID=384) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:48:39.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:48:39.701+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:48:39.724+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.724+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:48:39.841+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.841+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10970358599999486
[2025-01-10T12:48:39.841+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.841+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|384]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:48:39.842+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.842+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:48:39.842+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.842+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:48:39.843+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.843+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:48:39.843+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.843+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|384]: It took 0.12s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:48:39.845+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.845+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|384]: It took 0.00237s to build the Airflow DAG.
[2025-01-10T12:48:39.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:48:39.860+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.860+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:48:39.881+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:48:39.881+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:48:39.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.211 seconds
[2025-01-10T12:49:10.287+0000] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:49:10.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:49:10.289+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:49:10.317+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.316+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:49:10.448+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.448+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1216219840000008
[2025-01-10T12:49:10.449+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.448+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|423]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:49:10.450+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.449+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:49:10.450+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.450+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:49:10.451+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.451+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:49:10.451+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.451+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|423]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:49:10.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.454+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|423]: It took 0.00329s to build the Airflow DAG.
[2025-01-10T12:49:10.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:49:10.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.475+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:49:10.499+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:10.499+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:49:10.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-10T12:49:40.941+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:49:40.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:49:40.943+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:40.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:49:40.968+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:40.967+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:49:41.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.114+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13747032200001286
[2025-01-10T12:49:41.115+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.115+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|469]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:49:41.116+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.115+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:49:41.116+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.116+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:49:41.117+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.117+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:49:41.117+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.117+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|469]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:49:41.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.121+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|469]: It took 0.00373s to build the Airflow DAG.
[2025-01-10T12:49:41.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:49:41.142+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.141+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:49:41.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:49:41.173+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:49:41.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-10T12:50:11.588+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:50:11.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T12:50:11.591+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:50:11.626+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.626+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T12:50:11.902+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.902+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.25918445299998893
[2025-01-10T12:50:11.903+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.903+0000] {graph.py:519} INFO - Cosmos performance [e07bdf378f1a|509]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T12:50:11.905+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.904+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T12:50:11.906+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.905+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T12:50:11.906+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.906+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T12:50:11.907+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.907+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e07bdf378f1a|509]: It took 0.281s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T12:50:11.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.911+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e07bdf378f1a|509]: It took 0.00386s to build the Airflow DAG.
[2025-01-10T12:50:11.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T12:50:11.938+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.937+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T12:50:11.978+0000] {logging_mixin.py:151} INFO - [2025-01-10T12:50:11.978+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T12:50:12.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.426 seconds
[2025-01-10T13:02:48.294+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:02:48.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:02:48.304+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:02:48.357+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.357+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:02:48.711+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.710+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3229155179999452
[2025-01-10T13:02:48.712+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.711+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|77]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:02:48.713+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.713+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:02:48.714+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.713+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:02:48.714+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.714+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:02:48.715+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.715+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|77]: It took 0.359s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:02:48.723+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.722+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|77]: It took 0.0071s to build the Airflow DAG.
[2025-01-10T13:02:48.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:02:48.930+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.930+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:02:48.984+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:02:48.984+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-09T00:00:00+00:00, run_after=2025-01-10T00:00:00+00:00
[2025-01-10T13:02:49.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.740 seconds
[2025-01-10T13:03:19.137+0000] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:03:19.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:03:19.141+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:03:19.168+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.168+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:03:19.337+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.337+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15511037700002817
[2025-01-10T13:03:19.337+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.337+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|165]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:03:19.338+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.338+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:03:19.338+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.338+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:03:19.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.339+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:03:19.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.339+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|165]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:03:19.342+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.342+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|165]: It took 0.00328s to build the Airflow DAG.
[2025-01-10T13:03:19.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:03:19.356+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.356+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:03:19.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:19.379+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:03:19.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-10T13:03:50.237+0000] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:03:50.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:03:50.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:03:50.265+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.265+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:03:50.433+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.432+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14974775499990756
[2025-01-10T13:03:50.433+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.433+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|259]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:03:50.434+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.434+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:03:50.434+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.434+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:03:50.435+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.434+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:03:50.435+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.435+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|259]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:03:50.438+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.438+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|259]: It took 0.00317s to build the Airflow DAG.
[2025-01-10T13:03:50.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:03:50.468+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.468+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:03:50.540+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:03:50.539+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:03:50.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.341 seconds
[2025-01-10T13:04:20.721+0000] {processor.py:157} INFO - Started process (PID=356) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:04:20.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:04:20.725+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:04:20.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.748+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:04:20.909+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.909+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14774973099997624
[2025-01-10T13:04:20.910+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.910+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|356]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:04:20.910+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.910+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:04:20.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.911+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:04:20.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.911+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:04:20.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.911+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|356]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:04:20.915+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.914+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|356]: It took 0.0032s to build the Airflow DAG.
[2025-01-10T13:04:20.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:04:20.929+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.929+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:04:20.954+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:20.954+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:04:20.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-10T13:04:51.012+0000] {processor.py:157} INFO - Started process (PID=444) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:04:51.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:04:51.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:04:51.048+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.048+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:04:51.175+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.175+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10860257899980752
[2025-01-10T13:04:51.176+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.176+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|444]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:04:51.176+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.176+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:04:51.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.176+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:04:51.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.177+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:04:51.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.177+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|444]: It took 0.129s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:04:51.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.180+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|444]: It took 0.00253s to build the Airflow DAG.
[2025-01-10T13:04:51.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:04:51.194+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.194+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:04:51.218+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:04:51.218+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:04:51.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-10T13:05:21.297+0000] {processor.py:157} INFO - Started process (PID=529) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:05:21.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:05:21.300+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:05:21.329+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.329+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:05:21.478+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.478+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13477771500015479
[2025-01-10T13:05:21.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.478+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|529]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:05:21.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.479+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:05:21.480+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.479+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:05:21.480+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.480+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:05:21.480+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.480+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|529]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:05:21.483+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.483+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|529]: It took 0.0029s to build the Airflow DAG.
[2025-01-10T13:05:21.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:05:21.505+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.505+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:05:21.536+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:21.535+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:05:21.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-10T13:05:51.712+0000] {processor.py:157} INFO - Started process (PID=615) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:05:51.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:05:51.716+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:05:51.741+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.741+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:05:51.902+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.902+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.148039714999868
[2025-01-10T13:05:51.903+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.903+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|615]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:05:51.903+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.903+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:05:51.904+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.904+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:05:51.904+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.904+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:05:51.904+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.904+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|615]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:05:51.908+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.908+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|615]: It took 0.00337s to build the Airflow DAG.
[2025-01-10T13:05:51.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:05:51.921+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.921+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:05:51.947+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:05:51.946+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:05:51.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-10T13:06:22.041+0000] {processor.py:157} INFO - Started process (PID=703) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:06:22.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:06:22.046+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:06:22.068+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.068+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:06:22.218+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.218+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1366350670000429
[2025-01-10T13:06:22.219+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.219+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|703]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:06:22.219+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.219+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:06:22.220+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.220+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:06:22.220+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.220+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:06:22.221+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.220+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|703]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:06:22.223+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.223+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|703]: It took 0.00295s to build the Airflow DAG.
[2025-01-10T13:06:22.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:06:22.237+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.237+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:06:22.264+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:22.263+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:06:22.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-10T13:06:52.480+0000] {processor.py:157} INFO - Started process (PID=790) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:06:52.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:06:52.483+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:06:52.522+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.521+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:06:52.687+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.687+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14957507100007206
[2025-01-10T13:06:52.688+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.687+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|790]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:06:52.688+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.688+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:06:52.689+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.688+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:06:52.689+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.689+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:06:52.689+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.689+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|790]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:06:52.692+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.692+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|790]: It took 0.00293s to build the Airflow DAG.
[2025-01-10T13:06:52.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:06:52.707+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.707+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:06:52.730+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:06:52.730+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:06:52.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-10T13:07:22.795+0000] {processor.py:157} INFO - Started process (PID=884) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:07:22.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:07:22.798+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:22.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:07:22.822+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:22.822+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:07:23.008+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.007+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16382245699992382
[2025-01-10T13:07:23.008+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.008+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|884]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:07:23.009+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.009+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:07:23.009+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.009+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:07:23.010+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.010+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:07:23.010+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.010+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|884]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:07:23.013+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.013+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|884]: It took 0.00318s to build the Airflow DAG.
[2025-01-10T13:07:23.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:07:23.031+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.031+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:07:23.063+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:23.063+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:07:23.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-10T13:07:53.246+0000] {processor.py:157} INFO - Started process (PID=982) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:07:53.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:07:53.251+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:07:53.280+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.280+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:07:53.453+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.452+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15634366400013278
[2025-01-10T13:07:53.453+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.453+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|982]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:07:53.454+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.454+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:07:53.454+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.454+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:07:53.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.454+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:07:53.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.455+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|982]: It took 0.175s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:07:53.458+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.458+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|982]: It took 0.00331s to build the Airflow DAG.
[2025-01-10T13:07:53.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:07:53.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.475+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:07:53.505+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:07:53.504+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:07:53.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-10T13:08:23.633+0000] {processor.py:157} INFO - Started process (PID=1076) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:08:23.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:08:23.636+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:08:23.657+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.657+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:08:23.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.814+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14255398800014518
[2025-01-10T13:08:23.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.814+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1076]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:08:23.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.815+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:08:23.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.815+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:08:23.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.816+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:08:23.817+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.817+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1076]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:08:23.821+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.821+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1076]: It took 0.00387s to build the Airflow DAG.
[2025-01-10T13:08:23.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:08:23.837+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.837+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:08:23.861+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:23.861+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:08:23.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-10T13:08:54.032+0000] {processor.py:157} INFO - Started process (PID=1164) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:08:54.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:08:54.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:08:54.060+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.060+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:08:54.212+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.211+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13740150299986453
[2025-01-10T13:08:54.212+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.212+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1164]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:08:54.213+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.213+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:08:54.213+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.213+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:08:54.213+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.213+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:08:54.214+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.213+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1164]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:08:54.216+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.216+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1164]: It took 0.00262s to build the Airflow DAG.
[2025-01-10T13:08:54.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:08:54.230+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.230+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:08:54.253+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:08:54.252+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:08:54.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-10T13:09:24.342+0000] {processor.py:157} INFO - Started process (PID=1252) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:09:24.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:09:24.347+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:09:24.378+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.378+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:09:24.534+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.534+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1417771090000315
[2025-01-10T13:09:24.534+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.534+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1252]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:09:24.535+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.535+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:09:24.535+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.535+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:09:24.536+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.536+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:09:24.536+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.536+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1252]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:09:24.539+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.539+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1252]: It took 0.00297s to build the Airflow DAG.
[2025-01-10T13:09:24.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:09:24.554+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.554+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:09:24.578+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:24.578+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:09:24.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-10T13:09:55.388+0000] {processor.py:157} INFO - Started process (PID=1345) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:09:55.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:09:55.391+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:09:55.419+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.419+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:09:55.605+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.605+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1697075379997841
[2025-01-10T13:09:55.606+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.606+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1345]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:09:55.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.606+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:09:55.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.607+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:09:55.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.607+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:09:55.608+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.608+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1345]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:09:55.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.612+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1345]: It took 0.00478s to build the Airflow DAG.
[2025-01-10T13:09:55.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:09:55.632+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.631+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:09:55.662+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:09:55.662+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:09:55.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.304 seconds
[2025-01-10T13:10:25.776+0000] {processor.py:157} INFO - Started process (PID=1443) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:10:25.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:10:25.794+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:10:25.825+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.825+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:10:25.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.981+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14198682700020981
[2025-01-10T13:10:25.982+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.982+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1443]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:10:25.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.982+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:10:25.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.983+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:10:25.984+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.984+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:10:25.984+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.984+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1443]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:10:25.988+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:25.988+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1443]: It took 0.00375s to build the Airflow DAG.
[2025-01-10T13:10:25.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:10:26.004+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:26.004+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:10:26.033+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:26.032+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:10:26.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-10T13:10:56.136+0000] {processor.py:157} INFO - Started process (PID=1529) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:10:56.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:10:56.140+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:10:56.171+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.171+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:10:56.315+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.314+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12916125900005682
[2025-01-10T13:10:56.315+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.315+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1529]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:10:56.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.315+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:10:56.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.316+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:10:56.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.316+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:10:56.317+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.316+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1529]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:10:56.319+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.319+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1529]: It took 0.00266s to build the Airflow DAG.
[2025-01-10T13:10:56.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:10:56.334+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.334+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:10:56.360+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:10:56.360+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:10:56.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-10T13:11:26.987+0000] {processor.py:157} INFO - Started process (PID=1615) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:11:26.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:11:26.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:26.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:11:27.012+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.012+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:11:27.175+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.175+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14282440900001347
[2025-01-10T13:11:27.176+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.175+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1615]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:11:27.176+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.176+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:11:27.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.176+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:11:27.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.177+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:11:27.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.177+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1615]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:11:27.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.180+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1615]: It took 0.00291s to build the Airflow DAG.
[2025-01-10T13:11:27.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:11:27.194+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.194+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:11:27.216+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:27.216+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:11:27.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-10T13:11:57.715+0000] {processor.py:157} INFO - Started process (PID=1701) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:11:57.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:11:57.718+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:11:57.740+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.740+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:11:57.910+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.910+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15729387199985467
[2025-01-10T13:11:57.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.911+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1701]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:11:57.912+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.911+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:11:57.912+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.912+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:11:57.913+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.912+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:11:57.913+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.913+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1701]: It took 0.173s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:11:57.917+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.916+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1701]: It took 0.00347s to build the Airflow DAG.
[2025-01-10T13:11:57.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:11:57.931+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.931+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:11:57.954+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:11:57.954+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:11:57.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-10T13:12:28.028+0000] {processor.py:157} INFO - Started process (PID=1787) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:12:28.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:12:28.032+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:12:28.053+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.053+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:12:28.194+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.194+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12689251599999807
[2025-01-10T13:12:28.194+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.194+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1787]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:12:28.195+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.195+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:12:28.195+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.195+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:12:28.196+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.196+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:12:28.196+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.196+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1787]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:12:28.199+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.199+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1787]: It took 0.00309s to build the Airflow DAG.
[2025-01-10T13:12:28.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:12:28.214+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.214+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:12:28.239+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:28.239+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:12:28.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-10T13:12:58.433+0000] {processor.py:157} INFO - Started process (PID=1892) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:12:58.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:12:58.436+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:12:58.461+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.461+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:12:58.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.640+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16267732799997248
[2025-01-10T13:12:58.641+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.641+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1892]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:12:58.642+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.642+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:12:58.642+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.642+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:12:58.643+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.642+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:12:58.643+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.643+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1892]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:12:58.646+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.646+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1892]: It took 0.00301s to build the Airflow DAG.
[2025-01-10T13:12:58.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:12:58.664+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.664+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:12:58.695+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:12:58.695+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:12:58.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-10T13:13:28.810+0000] {processor.py:157} INFO - Started process (PID=1978) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:13:28.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:13:28.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:13:28.836+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.836+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:13:28.979+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.979+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12880334800001947
[2025-01-10T13:13:28.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.979+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|1978]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:13:28.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.980+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:13:28.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.980+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:13:28.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.981+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:13:28.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.981+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|1978]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:13:28.985+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.984+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|1978]: It took 0.00331s to build the Airflow DAG.
[2025-01-10T13:13:28.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:13:28.998+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:28.998+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:13:29.020+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:29.020+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:13:29.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.231 seconds
[2025-01-10T13:13:59.508+0000] {processor.py:157} INFO - Started process (PID=2064) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:13:59.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:13:59.513+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:13:59.542+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.542+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:13:59.696+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.696+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13816947100008292
[2025-01-10T13:13:59.697+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.697+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2064]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:13:59.698+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.697+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:13:59.698+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.698+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:13:59.698+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.698+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:13:59.699+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.699+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2064]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:13:59.702+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.702+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2064]: It took 0.0034s to build the Airflow DAG.
[2025-01-10T13:13:59.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:13:59.717+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.717+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:13:59.742+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:13:59.741+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:13:59.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-10T13:14:30.128+0000] {processor.py:157} INFO - Started process (PID=2150) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:14:30.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:14:30.131+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:14:30.155+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.155+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:14:30.298+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.298+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12966006500005278
[2025-01-10T13:14:30.298+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.298+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2150]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:14:30.299+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.299+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:14:30.299+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.299+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:14:30.299+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.299+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:14:30.300+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.300+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2150]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:14:30.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.302+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2150]: It took 0.00259s to build the Airflow DAG.
[2025-01-10T13:14:30.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:14:30.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.316+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:14:30.338+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:14:30.338+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:14:30.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-10T13:15:00.614+0000] {processor.py:157} INFO - Started process (PID=2236) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:15:00.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:15:00.618+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:15:00.657+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.657+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:15:00.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.816+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1424260039998444
[2025-01-10T13:15:00.817+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.817+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2236]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:15:00.818+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.818+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:15:00.818+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.818+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:15:00.819+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.819+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:15:00.820+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.819+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2236]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:15:00.823+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.823+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2236]: It took 0.0038s to build the Airflow DAG.
[2025-01-10T13:15:00.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:15:00.839+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.839+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:15:00.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:00.868+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:15:00.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-10T13:15:30.940+0000] {processor.py:157} INFO - Started process (PID=2342) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:15:30.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:15:30.943+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:30.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:15:30.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:30.969+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:15:31.151+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.151+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16650404999995772
[2025-01-10T13:15:31.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.152+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2342]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:15:31.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.152+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:15:31.153+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.153+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:15:31.153+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.153+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:15:31.154+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.154+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2342]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:15:31.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.157+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2342]: It took 0.00326s to build the Airflow DAG.
[2025-01-10T13:15:31.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:15:31.173+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.172+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:15:31.199+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:15:31.199+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:15:31.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.283 seconds
[2025-01-10T13:16:01.338+0000] {processor.py:157} INFO - Started process (PID=2429) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:16:01.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:16:01.343+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:16:01.369+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.369+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:16:01.527+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.527+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14599754500000017
[2025-01-10T13:16:01.528+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.528+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2429]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:16:01.528+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.528+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:16:01.529+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.529+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:16:01.529+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.529+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:16:01.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.529+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2429]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:16:01.533+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.533+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2429]: It took 0.00334s to build the Airflow DAG.
[2025-01-10T13:16:01.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:16:01.550+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.550+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:16:01.573+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:01.573+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:16:01.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-10T13:16:32.554+0000] {processor.py:157} INFO - Started process (PID=2516) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:16:32.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:16:32.557+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:16:32.584+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.584+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:16:32.730+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.730+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1323766739999428
[2025-01-10T13:16:32.731+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.730+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2516]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:16:32.731+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.731+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:16:32.731+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.731+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:16:32.732+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.732+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:16:32.732+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.732+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2516]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:16:32.735+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.734+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2516]: It took 0.00251s to build the Airflow DAG.
[2025-01-10T13:16:32.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:16:32.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.748+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:16:32.774+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:16:32.774+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:16:32.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-10T13:17:02.841+0000] {processor.py:157} INFO - Started process (PID=2603) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:17:02.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:17:02.845+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:02.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:17:02.870+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:02.870+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:17:03.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.034+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14935345200001393
[2025-01-10T13:17:03.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.034+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2603]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:17:03.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.035+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:17:03.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.035+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:17:03.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.035+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:17:03.036+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.036+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2603]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:17:03.038+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.038+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2603]: It took 0.00261s to build the Airflow DAG.
[2025-01-10T13:17:03.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:17:03.052+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.052+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:17:03.080+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:03.080+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:17:03.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-10T13:17:33.285+0000] {processor.py:157} INFO - Started process (PID=2695) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:17:33.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:17:33.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:17:33.309+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.309+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:17:33.477+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.477+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15374503499992898
[2025-01-10T13:17:33.478+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.478+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2695]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:17:33.478+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.478+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:17:33.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.479+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:17:33.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.479+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:17:33.480+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.480+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2695]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:17:33.483+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.482+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2695]: It took 0.00285s to build the Airflow DAG.
[2025-01-10T13:17:33.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:17:33.500+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.500+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:17:33.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:17:33.526+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:17:33.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-10T13:18:03.775+0000] {processor.py:157} INFO - Started process (PID=2793) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:18:03.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:18:03.778+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:18:03.801+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.801+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:18:03.966+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.966+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15114447499991002
[2025-01-10T13:18:03.967+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.966+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2793]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:18:03.968+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.968+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:18:03.968+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.968+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:18:03.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.969+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:18:03.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.969+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2793]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:18:03.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.973+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2793]: It took 0.00388s to build the Airflow DAG.
[2025-01-10T13:18:03.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:18:03.989+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:03.989+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:18:04.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:04.016+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:18:04.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.266 seconds
[2025-01-10T13:18:34.175+0000] {processor.py:157} INFO - Started process (PID=2881) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:18:34.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:18:34.178+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:18:34.202+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.202+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:18:34.353+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.353+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13706552600001487
[2025-01-10T13:18:34.353+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.353+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2881]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:18:34.354+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.354+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:18:34.354+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.354+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:18:34.355+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.355+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:18:34.355+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.355+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2881]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:18:34.358+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.358+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2881]: It took 0.00287s to build the Airflow DAG.
[2025-01-10T13:18:34.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:18:34.373+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.373+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:18:34.400+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:18:34.399+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:18:34.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-10T13:19:04.785+0000] {processor.py:157} INFO - Started process (PID=2969) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:19:04.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:19:04.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:19:04.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.813+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:19:04.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.981+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14729540899998028
[2025-01-10T13:19:04.982+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.982+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|2969]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:19:04.982+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.982+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:19:04.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.983+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:19:04.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.983+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:19:04.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.983+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|2969]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:19:04.987+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:04.986+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|2969]: It took 0.00315s to build the Airflow DAG.
[2025-01-10T13:19:04.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:19:05.004+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:05.004+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:19:05.031+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:05.031+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:19:05.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-10T13:19:35.401+0000] {processor.py:157} INFO - Started process (PID=3056) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:19:35.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:19:35.404+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:19:35.438+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.438+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:19:35.567+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.566+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11150467600009506
[2025-01-10T13:19:35.567+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.567+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3056]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:19:35.567+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.567+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:19:35.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.568+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:19:35.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.568+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:19:35.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.568+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3056]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:19:35.571+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.570+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3056]: It took 0.00233s to build the Airflow DAG.
[2025-01-10T13:19:35.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:19:35.584+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.584+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:19:35.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:19:35.606+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:19:35.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-10T13:20:05.685+0000] {processor.py:157} INFO - Started process (PID=3141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:20:05.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:20:05.689+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:20:05.713+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.713+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:20:05.850+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.850+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1233961700004329
[2025-01-10T13:20:05.851+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.851+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3141]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:20:05.852+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.852+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:20:05.852+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.852+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:20:05.853+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.853+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:20:05.853+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.853+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3141]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:20:05.857+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.857+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3141]: It took 0.00367s to build the Airflow DAG.
[2025-01-10T13:20:05.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:20:05.874+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.874+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:20:05.900+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:05.900+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:20:05.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-10T13:20:36.017+0000] {processor.py:157} INFO - Started process (PID=3235) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:20:36.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:20:36.021+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:20:36.048+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.048+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:20:36.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.341+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.27594882599987614
[2025-01-10T13:20:36.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.341+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3235]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:20:36.342+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.342+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:20:36.342+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.342+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:20:36.343+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.343+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:20:36.343+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.343+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3235]: It took 0.296s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:20:36.347+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.347+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3235]: It took 0.00392s to build the Airflow DAG.
[2025-01-10T13:20:36.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:20:36.365+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.364+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:20:36.392+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:20:36.392+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:20:36.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.398 seconds
[2025-01-10T13:21:06.989+0000] {processor.py:157} INFO - Started process (PID=3333) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:21:06.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:21:06.995+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:06.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:21:07.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.035+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:21:07.225+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.224+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1698409239998
[2025-01-10T13:21:07.225+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.225+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3333]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:21:07.226+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.226+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:21:07.226+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.226+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:21:07.227+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.227+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:21:07.228+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.228+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3333]: It took 0.193s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:21:07.232+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.232+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3333]: It took 0.00428s to build the Airflow DAG.
[2025-01-10T13:21:07.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:21:07.257+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.257+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:21:07.295+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:07.294+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:21:07.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-10T13:21:37.506+0000] {processor.py:157} INFO - Started process (PID=3419) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:21:37.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:21:37.510+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:21:37.534+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.533+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:21:37.677+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.677+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12990477399989686
[2025-01-10T13:21:37.678+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.678+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3419]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:21:37.678+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.678+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:21:37.679+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.679+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:21:37.679+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.679+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:21:37.680+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.680+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3419]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:21:37.682+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.682+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3419]: It took 0.00269s to build the Airflow DAG.
[2025-01-10T13:21:37.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:21:37.696+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.696+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:21:37.719+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:21:37.719+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:21:37.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-10T13:22:07.799+0000] {processor.py:157} INFO - Started process (PID=3506) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:22:07.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:22:07.803+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:22:07.829+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.829+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:22:07.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.969+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12611484299986842
[2025-01-10T13:22:07.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.969+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3506]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:22:07.970+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.970+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:22:07.970+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.970+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:22:07.971+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.970+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:22:07.971+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.971+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3506]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:22:07.974+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.973+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3506]: It took 0.00261s to build the Airflow DAG.
[2025-01-10T13:22:07.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:22:07.989+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:07.989+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:22:08.017+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:08.017+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:22:08.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T13:22:38.084+0000] {processor.py:157} INFO - Started process (PID=3594) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:22:38.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:22:38.087+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:22:38.115+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.114+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:22:38.247+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.247+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11921197399988159
[2025-01-10T13:22:38.248+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.248+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3594]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:22:38.248+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.248+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:22:38.249+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.249+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:22:38.249+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.249+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:22:38.249+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.249+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3594]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:22:38.252+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.251+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3594]: It took 0.0023s to build the Airflow DAG.
[2025-01-10T13:22:38.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:22:38.265+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.265+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:22:38.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:22:38.288+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:22:38.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-10T13:23:08.901+0000] {processor.py:157} INFO - Started process (PID=3687) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:23:08.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:23:08.907+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:08.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:23:08.933+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:08.933+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:23:09.120+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.120+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17134452400023292
[2025-01-10T13:23:09.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.121+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3687]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:23:09.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.121+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:23:09.122+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.121+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:23:09.122+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.122+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:23:09.123+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.122+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3687]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:23:09.126+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.126+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3687]: It took 0.00341s to build the Airflow DAG.
[2025-01-10T13:23:09.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:23:09.147+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.146+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:23:09.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:09.174+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:23:09.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.306 seconds
[2025-01-10T13:23:39.267+0000] {processor.py:157} INFO - Started process (PID=3784) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:23:39.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:23:39.271+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:23:39.294+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.294+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:23:39.474+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.473+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16155371800005014
[2025-01-10T13:23:39.474+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.474+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3784]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:23:39.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.475+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:23:39.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.475+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:23:39.476+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.476+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:23:39.476+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.476+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3784]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:23:39.480+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.480+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3784]: It took 0.00355s to build the Airflow DAG.
[2025-01-10T13:23:39.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:23:39.497+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.497+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:23:39.527+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:23:39.527+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:23:39.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.287 seconds
[2025-01-10T13:24:09.729+0000] {processor.py:157} INFO - Started process (PID=3870) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:24:09.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:24:09.733+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:24:09.759+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.759+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:24:09.938+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.938+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16445454399990922
[2025-01-10T13:24:09.939+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.938+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3870]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:24:09.939+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.939+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:24:09.940+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.940+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:24:09.941+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.940+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:24:09.941+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.941+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3870]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:24:09.945+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.945+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3870]: It took 0.00438s to build the Airflow DAG.
[2025-01-10T13:24:09.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:24:09.962+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.962+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:24:09.988+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:09.988+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:24:10.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.283 seconds
[2025-01-10T13:24:40.079+0000] {processor.py:157} INFO - Started process (PID=3955) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:24:40.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:24:40.083+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:24:40.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.110+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:24:40.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.301+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17455721600026664
[2025-01-10T13:24:40.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.302+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|3955]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:24:40.303+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.303+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:24:40.304+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.304+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:24:40.304+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.304+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:24:40.305+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.305+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|3955]: It took 0.195s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:24:40.310+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.309+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|3955]: It took 0.00464s to build the Airflow DAG.
[2025-01-10T13:24:40.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:24:40.343+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.343+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:24:40.395+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:24:40.395+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:24:40.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.347 seconds
[2025-01-10T13:25:10.510+0000] {processor.py:157} INFO - Started process (PID=4035) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:25:10.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:25:10.514+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:25:10.540+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.540+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:25:10.718+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.718+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16212731599989638
[2025-01-10T13:25:10.719+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.719+0000] {graph.py:519} INFO - Cosmos performance [837882bfe7a8|4035]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:25:10.720+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.719+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:25:10.720+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.720+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:25:10.720+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.720+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:25:10.721+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.721+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [837882bfe7a8|4035]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:25:10.724+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.724+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [837882bfe7a8|4035]: It took 0.00293s to build the Airflow DAG.
[2025-01-10T13:25:10.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:25:10.741+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.740+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:25:10.773+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:25:10.773+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:25:10.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.291 seconds
[2025-01-10T13:26:34.328+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:26:34.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:26:34.333+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:26:34.371+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.371+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:26:34.602+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.601+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21361507900019205
[2025-01-10T13:26:34.602+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.602+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:26:34.604+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.603+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:26:34.605+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.604+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:26:34.605+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.605+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:26:34.606+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.606+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|70]: It took 0.235s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:26:34.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.612+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|70]: It took 0.00638s to build the Airflow DAG.
[2025-01-10T13:26:34.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:26:34.783+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.783+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:26:34.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:26:34.815+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:26:34.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.524 seconds
[2025-01-10T13:27:04.981+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:27:04.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:27:04.985+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:04.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:27:05.009+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.009+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:27:05.144+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.144+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12157815099999425
[2025-01-10T13:27:05.145+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.145+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|158]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:27:05.145+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.145+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:27:05.146+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.145+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:27:05.146+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.146+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:27:05.146+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.146+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|158]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:27:05.149+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.149+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|158]: It took 0.00277s to build the Airflow DAG.
[2025-01-10T13:27:05.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:27:05.163+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.162+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:27:05.186+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:05.186+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:27:05.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-10T13:27:35.273+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:27:35.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:27:35.276+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:27:35.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.302+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:27:35.453+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.453+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13559780200012028
[2025-01-10T13:27:35.454+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.454+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|244]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:27:35.454+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.454+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:27:35.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.455+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:27:35.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.455+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:27:35.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.455+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|244]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:27:35.459+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.458+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|244]: It took 0.00308s to build the Airflow DAG.
[2025-01-10T13:27:35.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:27:35.478+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.478+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:27:35.508+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:27:35.508+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:27:35.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-10T13:28:05.704+0000] {processor.py:157} INFO - Started process (PID=336) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:28:05.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:28:05.709+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:28:05.734+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.734+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:28:05.908+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.907+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1589842260000296
[2025-01-10T13:28:05.908+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.908+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|336]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:28:05.909+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.909+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:28:05.910+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.909+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:28:05.910+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.910+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:28:05.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.911+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|336]: It took 0.177s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:28:05.916+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.915+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|336]: It took 0.00468s to build the Airflow DAG.
[2025-01-10T13:28:05.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:28:05.934+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.933+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:28:05.963+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:05.963+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:28:05.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-10T13:28:36.418+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:28:36.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:28:36.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:28:36.449+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.449+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:28:36.612+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.611+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1465681710001263
[2025-01-10T13:28:36.612+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.612+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|433]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:28:36.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.613+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:28:36.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.613+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:28:36.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.613+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:28:36.614+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.614+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|433]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:28:36.616+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.616+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|433]: It took 0.00266s to build the Airflow DAG.
[2025-01-10T13:28:36.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:28:36.629+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.629+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:28:36.652+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:28:36.652+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:28:36.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-10T13:29:06.902+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:29:06.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:29:06.906+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:06.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:29:06.928+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:06.928+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:29:07.067+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.067+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12461218199996438
[2025-01-10T13:29:07.067+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.067+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|519]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:29:07.068+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.068+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:29:07.068+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.068+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:29:07.069+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.069+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:29:07.069+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.069+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|519]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:29:07.073+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.073+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|519]: It took 0.00326s to build the Airflow DAG.
[2025-01-10T13:29:07.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:29:07.087+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.087+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:29:07.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:07.110+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:29:07.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-10T13:29:37.206+0000] {processor.py:157} INFO - Started process (PID=605) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:29:37.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:29:37.209+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:29:37.230+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.230+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:29:37.377+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.377+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13374475299997357
[2025-01-10T13:29:37.378+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.378+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|605]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:29:37.378+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.378+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:29:37.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.379+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:29:37.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.379+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:29:37.380+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.380+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|605]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:29:37.383+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.383+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|605]: It took 0.00316s to build the Airflow DAG.
[2025-01-10T13:29:37.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:29:37.399+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.398+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:29:37.424+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:29:37.423+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:29:37.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T13:30:07.523+0000] {processor.py:157} INFO - Started process (PID=692) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:30:07.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:30:07.527+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:30:07.550+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.550+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:30:07.701+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.701+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13815729299994928
[2025-01-10T13:30:07.702+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.702+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|692]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:30:07.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.703+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:30:07.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.703+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:30:07.704+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.703+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:30:07.704+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.704+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|692]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:30:07.708+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.708+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|692]: It took 0.00384s to build the Airflow DAG.
[2025-01-10T13:30:07.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:30:07.722+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.722+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:30:07.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:07.747+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:30:07.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-10T13:30:38.030+0000] {processor.py:157} INFO - Started process (PID=797) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:30:38.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:30:38.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:30:38.057+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.057+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:30:38.223+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.223+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15172686200003227
[2025-01-10T13:30:38.224+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.224+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|797]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:30:38.224+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.224+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:30:38.225+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.225+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:30:38.225+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.225+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:30:38.226+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.226+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|797]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:30:38.230+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.230+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|797]: It took 0.00425s to build the Airflow DAG.
[2025-01-10T13:30:38.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:30:38.248+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.247+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:30:38.276+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:30:38.276+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:30:38.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-10T13:31:08.472+0000] {processor.py:157} INFO - Started process (PID=884) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:31:08.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:31:08.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:31:08.494+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.494+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:31:08.638+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.638+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1315034479998758
[2025-01-10T13:31:08.639+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.639+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|884]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:31:08.639+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.639+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:31:08.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.639+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:31:08.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.640+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:31:08.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.640+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|884]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:31:08.643+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.643+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|884]: It took 0.00283s to build the Airflow DAG.
[2025-01-10T13:31:08.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:31:08.657+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.657+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:31:08.679+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:08.679+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:31:08.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-10T13:31:38.752+0000] {processor.py:157} INFO - Started process (PID=971) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:31:38.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:31:38.756+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:31:38.781+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.781+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:31:38.933+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.933+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1394315339998684
[2025-01-10T13:31:38.934+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.934+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|971]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:31:38.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.934+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:31:38.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.935+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:31:38.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.935+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:31:38.936+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.936+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|971]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:31:38.939+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.939+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|971]: It took 0.00295s to build the Airflow DAG.
[2025-01-10T13:31:38.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:31:38.952+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.952+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:31:38.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:31:38.976+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:31:38.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T13:32:09.138+0000] {processor.py:157} INFO - Started process (PID=1059) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:32:09.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:32:09.142+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:32:09.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.165+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:32:09.293+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.293+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11461415299982036
[2025-01-10T13:32:09.293+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.293+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|1059]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:32:09.294+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.294+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:32:09.294+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.294+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:32:09.294+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.294+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:32:09.295+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.295+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|1059]: It took 0.13s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:32:09.297+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.297+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|1059]: It took 0.00243s to build the Airflow DAG.
[2025-01-10T13:32:09.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:32:09.311+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.311+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:32:09.333+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:09.333+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:32:09.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-10T13:32:40.279+0000] {processor.py:157} INFO - Started process (PID=1153) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:32:40.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:32:40.283+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:32:40.310+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.310+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:32:40.486+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.486+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16013132800026142
[2025-01-10T13:32:40.486+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.486+0000] {graph.py:519} INFO - Cosmos performance [32331c52e80e|1153]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:32:40.487+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.487+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:32:40.487+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.487+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:32:40.488+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.488+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:32:40.489+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.489+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [32331c52e80e|1153]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:32:40.493+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.492+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [32331c52e80e|1153]: It took 0.00381s to build the Airflow DAG.
[2025-01-10T13:32:40.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:32:40.511+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.511+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:32:40.540+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:32:40.540+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:32:40.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-10T13:33:56.604+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:33:56.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:33:56.609+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:33:56.643+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.642+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:33:56.829+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.828+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17132815100012522
[2025-01-10T13:33:56.829+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.829+0000] {graph.py:519} INFO - Cosmos performance [e9a48fe12ca1|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:33:56.830+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.830+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:33:56.830+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.830+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:33:56.831+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.831+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:33:56.832+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.831+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e9a48fe12ca1|70]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:33:56.836+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.836+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e9a48fe12ca1|70]: It took 0.00448s to build the Airflow DAG.
[2025-01-10T13:33:56.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:33:56.961+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.961+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:33:56.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:33:56.989+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:33:57.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.417 seconds
[2025-01-10T13:34:27.187+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:34:27.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:34:27.190+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:34:27.228+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.227+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:34:27.499+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.498+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2361386960001255
[2025-01-10T13:34:27.499+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.499+0000] {graph.py:519} INFO - Cosmos performance [e9a48fe12ca1|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:34:27.500+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.500+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:34:27.501+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.500+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:34:27.501+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.501+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:34:27.501+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.501+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e9a48fe12ca1|157]: It took 0.274s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:34:27.505+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.505+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e9a48fe12ca1|157]: It took 0.0035s to build the Airflow DAG.
[2025-01-10T13:34:27.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:34:27.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.525+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:34:27.561+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:27.561+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:34:27.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.403 seconds
[2025-01-10T13:34:57.661+0000] {processor.py:157} INFO - Started process (PID=245) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:34:57.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:34:57.665+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:34:57.689+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.689+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:34:57.832+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.832+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12809706399957577
[2025-01-10T13:34:57.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.833+0000] {graph.py:519} INFO - Cosmos performance [e9a48fe12ca1|245]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:34:57.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.833+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:34:57.834+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.833+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:34:57.834+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.834+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:34:57.834+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.834+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e9a48fe12ca1|245]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:34:57.837+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.837+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e9a48fe12ca1|245]: It took 0.0026s to build the Airflow DAG.
[2025-01-10T13:34:57.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:34:57.851+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.851+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:34:57.879+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:34:57.879+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:34:57.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-10T13:35:28.198+0000] {processor.py:157} INFO - Started process (PID=337) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:35:28.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:35:28.204+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:35:28.230+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.230+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:35:28.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.410+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16338534099986646
[2025-01-10T13:35:28.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.410+0000] {graph.py:519} INFO - Cosmos performance [e9a48fe12ca1|337]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:35:28.411+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.411+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:35:28.412+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.411+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:35:28.412+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.412+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:35:28.413+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.412+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [e9a48fe12ca1|337]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:35:28.417+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.417+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [e9a48fe12ca1|337]: It took 0.0043s to build the Airflow DAG.
[2025-01-10T13:35:28.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:35:28.440+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.440+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:35:28.472+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:35:28.472+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:35:28.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-10T13:36:32.770+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:36:32.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:36:32.774+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:32.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:36:32.810+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:32.810+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:36:33.010+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.010+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1821123519998764
[2025-01-10T13:36:33.010+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.010+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:36:33.011+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.011+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:36:33.012+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.011+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:36:33.012+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.012+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:36:33.012+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.012+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|70]: It took 0.203s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:36:33.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.016+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|70]: It took 0.00385s to build the Airflow DAG.
[2025-01-10T13:36:33.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:36:33.141+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.141+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:36:33.170+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:36:33.170+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:36:33.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.436 seconds
[2025-01-10T13:37:03.373+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:37:03.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:37:03.376+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:37:03.400+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.400+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:37:03.543+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.543+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12900711800011777
[2025-01-10T13:37:03.543+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.543+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:37:03.544+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.544+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:37:03.544+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.544+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:37:03.545+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.545+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:37:03.545+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.545+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|157]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:37:03.548+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.547+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|157]: It took 0.00253s to build the Airflow DAG.
[2025-01-10T13:37:03.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:37:03.561+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.561+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:37:03.585+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:03.585+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:37:03.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-10T13:37:34.118+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:37:34.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:37:34.122+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:37:34.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.152+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:37:34.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.339+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16994834399974934
[2025-01-10T13:37:34.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.339+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|250]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:37:34.340+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.340+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:37:34.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.341+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:37:34.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.341+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:37:34.342+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.342+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|250]: It took 0.19s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:37:34.345+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.345+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|250]: It took 0.00348s to build the Airflow DAG.
[2025-01-10T13:37:34.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:37:34.363+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.363+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:37:34.393+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:37:34.393+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:37:34.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-10T13:38:04.655+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:38:04.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:38:04.659+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:38:04.685+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.684+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:38:04.860+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.859+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1598875679997036
[2025-01-10T13:38:04.860+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.860+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|347]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:38:04.861+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.861+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:38:04.861+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.861+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:38:04.862+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.862+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:38:04.862+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.862+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|347]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:38:04.866+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.866+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|347]: It took 0.00366s to build the Airflow DAG.
[2025-01-10T13:38:04.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:38:04.882+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.882+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:38:04.908+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:04.908+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:38:04.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-10T13:38:35.560+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:38:35.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:38:35.564+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:38:35.585+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.585+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:38:35.733+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.733+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13384165399975245
[2025-01-10T13:38:35.733+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.733+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|433]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:38:35.734+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.734+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:38:35.734+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.734+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:38:35.734+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.734+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:38:35.735+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.734+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|433]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:38:35.737+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.737+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|433]: It took 0.00249s to build the Airflow DAG.
[2025-01-10T13:38:35.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:38:35.750+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.750+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:38:35.773+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:38:35.773+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:38:35.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-10T13:39:06.091+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:39:06.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:39:06.094+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:39:06.118+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.118+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:39:06.257+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.257+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12520244500001354
[2025-01-10T13:39:06.258+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.258+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|519]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:39:06.258+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.258+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:39:06.259+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.259+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:39:06.259+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.259+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:39:06.260+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.259+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|519]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:39:06.262+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.262+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|519]: It took 0.00291s to build the Airflow DAG.
[2025-01-10T13:39:06.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:39:06.277+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.277+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:39:06.298+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:06.298+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:39:06.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-10T13:39:36.407+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:39:36.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:39:36.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:39:36.429+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.429+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:39:36.565+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.565+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12288317100001223
[2025-01-10T13:39:36.565+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.565+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|606]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:39:36.566+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.566+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:39:36.566+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.566+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:39:36.566+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.566+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:39:36.567+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.567+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|606]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:39:36.570+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.570+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|606]: It took 0.00311s to build the Airflow DAG.
[2025-01-10T13:39:36.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:39:36.584+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.583+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:39:36.610+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:39:36.610+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:39:36.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.227 seconds
[2025-01-10T13:40:06.679+0000] {processor.py:157} INFO - Started process (PID=710) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:40:06.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:40:06.683+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:40:06.705+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.704+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:40:06.886+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.885+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16578982299961353
[2025-01-10T13:40:06.886+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.886+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|710]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:40:06.887+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.887+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:40:06.887+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.887+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:40:06.888+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.888+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:40:06.888+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.888+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|710]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:40:06.892+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.892+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|710]: It took 0.0038s to build the Airflow DAG.
[2025-01-10T13:40:06.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:40:06.908+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.908+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:40:06.936+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:06.936+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:40:06.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-10T13:40:37.217+0000] {processor.py:157} INFO - Started process (PID=796) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:40:37.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:40:37.221+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:40:37.242+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.242+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:40:37.386+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.386+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13069163199998002
[2025-01-10T13:40:37.386+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.386+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|796]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:40:37.387+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.387+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:40:37.387+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.387+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:40:37.388+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.388+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:40:37.388+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.388+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|796]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:40:37.391+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.391+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|796]: It took 0.00316s to build the Airflow DAG.
[2025-01-10T13:40:37.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:40:37.406+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.406+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:40:37.430+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:40:37.430+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:40:37.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-10T13:41:07.543+0000] {processor.py:157} INFO - Started process (PID=882) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:41:07.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:41:07.548+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:41:07.577+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.576+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:41:07.762+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.762+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1660042240000621
[2025-01-10T13:41:07.762+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.762+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|882]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:41:07.763+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.763+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:41:07.763+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.763+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:41:07.763+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.763+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:41:07.764+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.764+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|882]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:41:07.767+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.767+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|882]: It took 0.00316s to build the Airflow DAG.
[2025-01-10T13:41:07.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:41:07.782+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.781+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:41:07.806+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:07.806+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:41:07.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-10T13:41:37.948+0000] {processor.py:157} INFO - Started process (PID=968) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:41:37.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:41:37.951+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:37.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:41:37.972+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:37.972+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:41:38.108+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.108+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12254254800018316
[2025-01-10T13:41:38.108+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.108+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|968]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:41:38.109+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.109+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:41:38.109+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.109+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:41:38.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.110+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:41:38.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.110+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|968]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:41:38.113+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.113+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|968]: It took 0.00297s to build the Airflow DAG.
[2025-01-10T13:41:38.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:41:38.128+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.127+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:41:38.151+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:41:38.151+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:41:38.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-10T13:42:08.242+0000] {processor.py:157} INFO - Started process (PID=1061) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:42:08.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:42:08.246+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:42:08.273+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.272+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:42:08.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.466+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17609898199998497
[2025-01-10T13:42:08.467+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.467+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1061]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:42:08.468+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.468+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:42:08.468+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.468+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:42:08.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.469+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:42:08.470+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.470+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1061]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:42:08.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.475+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1061]: It took 0.00496s to build the Airflow DAG.
[2025-01-10T13:42:08.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:42:08.492+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.492+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:42:08.519+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:08.518+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:42:08.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-10T13:42:39.002+0000] {processor.py:157} INFO - Started process (PID=1166) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:42:39.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:42:39.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:42:39.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.035+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:42:39.223+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.222+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17044075800004066
[2025-01-10T13:42:39.227+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.226+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1166]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:42:39.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.228+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:42:39.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.229+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:42:39.230+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.230+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:42:39.231+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.231+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1166]: It took 0.196s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:42:39.237+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.237+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1166]: It took 0.00551s to build the Airflow DAG.
[2025-01-10T13:42:39.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:42:39.256+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.256+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:42:39.286+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:42:39.286+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:42:39.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.311 seconds
[2025-01-10T13:43:09.394+0000] {processor.py:157} INFO - Started process (PID=1252) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:43:09.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:43:09.398+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:43:09.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.423+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:43:09.571+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.571+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13520342799984064
[2025-01-10T13:43:09.572+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.572+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1252]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:43:09.573+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.572+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:43:09.573+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.573+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:43:09.573+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.573+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:43:09.574+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.574+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1252]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:43:09.577+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.577+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1252]: It took 0.00333s to build the Airflow DAG.
[2025-01-10T13:43:09.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:43:09.590+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.590+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:43:09.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:09.613+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:43:09.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T13:43:39.842+0000] {processor.py:157} INFO - Started process (PID=1338) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:43:39.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:43:39.846+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:39.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:43:39.869+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:39.869+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:43:40.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.015+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13283289599985437
[2025-01-10T13:43:40.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.016+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1338]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:43:40.017+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.016+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:43:40.017+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.017+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:43:40.017+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.017+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:43:40.018+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.017+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1338]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:43:40.021+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.020+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1338]: It took 0.00296s to build the Airflow DAG.
[2025-01-10T13:43:40.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:43:40.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.034+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:43:40.058+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:43:40.058+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:43:40.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-10T13:44:10.203+0000] {processor.py:157} INFO - Started process (PID=1424) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:44:10.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:44:10.207+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:44:10.228+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.228+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:44:10.387+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.387+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14572309599998334
[2025-01-10T13:44:10.388+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.388+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1424]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:44:10.388+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.388+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:44:10.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.389+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:44:10.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.389+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:44:10.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.389+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1424]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:44:10.392+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.392+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1424]: It took 0.00257s to build the Airflow DAG.
[2025-01-10T13:44:10.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:44:10.406+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.405+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:44:10.428+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:10.428+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:44:10.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T13:44:40.599+0000] {processor.py:157} INFO - Started process (PID=1511) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:44:40.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:44:40.602+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:44:40.626+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.626+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:44:40.772+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.772+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13194422300011865
[2025-01-10T13:44:40.772+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.772+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1511]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:44:40.773+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.773+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:44:40.773+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.773+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:44:40.773+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.773+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:44:40.774+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.774+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1511]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:44:40.776+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.776+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1511]: It took 0.00242s to build the Airflow DAG.
[2025-01-10T13:44:40.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:44:40.790+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.790+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:44:40.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:44:40.814+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:44:40.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-10T13:45:10.900+0000] {processor.py:157} INFO - Started process (PID=1616) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:45:10.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:45:10.904+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:10.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:45:10.926+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:10.926+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:45:11.112+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.112+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.170355594999819
[2025-01-10T13:45:11.113+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.112+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1616]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:45:11.113+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.113+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:45:11.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.113+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:45:11.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.114+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:45:11.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.114+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1616]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:45:11.118+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.117+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1616]: It took 0.00313s to build the Airflow DAG.
[2025-01-10T13:45:11.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:45:11.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.136+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:45:11.168+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:11.168+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:45:11.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-10T13:45:41.293+0000] {processor.py:157} INFO - Started process (PID=1701) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:45:41.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:45:41.296+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:45:41.319+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.319+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:45:41.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.469+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1359032280001884
[2025-01-10T13:45:41.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.469+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1701]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:45:41.470+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.470+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:45:41.470+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.470+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:45:41.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.470+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:45:41.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.471+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1701]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:45:41.474+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.474+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1701]: It took 0.00317s to build the Airflow DAG.
[2025-01-10T13:45:41.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:45:41.489+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.489+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:45:41.517+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:45:41.517+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:45:41.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-10T13:46:11.644+0000] {processor.py:157} INFO - Started process (PID=1788) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:46:11.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:46:11.648+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:46:11.670+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.670+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:46:11.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.832+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14588839599991843
[2025-01-10T13:46:11.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.833+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1788]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:46:11.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.833+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:46:11.834+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.834+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:46:11.834+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.834+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:46:11.834+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.834+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1788]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:46:11.837+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.837+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1788]: It took 0.00261s to build the Airflow DAG.
[2025-01-10T13:46:11.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:46:11.851+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.851+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:46:11.875+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:11.875+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:46:11.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-10T13:46:41.977+0000] {processor.py:157} INFO - Started process (PID=1874) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:46:41.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:46:41.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:41.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:46:42.003+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.003+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:46:42.139+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.139+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12259958599997844
[2025-01-10T13:46:42.139+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.139+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1874]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:46:42.140+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.140+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:46:42.140+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.140+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:46:42.141+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.141+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:46:42.141+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.141+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1874]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:46:42.143+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.143+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1874]: It took 0.00238s to build the Airflow DAG.
[2025-01-10T13:46:42.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:46:42.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.157+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:46:42.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:46:42.179+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:46:42.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-10T13:47:12.322+0000] {processor.py:157} INFO - Started process (PID=1961) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:47:12.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:47:12.325+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:47:12.346+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.346+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:47:12.512+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.512+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15298934600014036
[2025-01-10T13:47:12.513+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.513+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|1961]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:47:12.513+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.513+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:47:12.514+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.514+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:47:12.514+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.514+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:47:12.515+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.515+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|1961]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:47:12.519+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.518+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|1961]: It took 0.00365s to build the Airflow DAG.
[2025-01-10T13:47:12.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:47:12.536+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.536+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:47:12.560+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:12.559+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:47:12.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-10T13:47:42.725+0000] {processor.py:157} INFO - Started process (PID=2073) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:47:42.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:47:42.729+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:47:42.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.754+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:47:42.922+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.922+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15402503399991474
[2025-01-10T13:47:42.923+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.922+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2073]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:47:42.923+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.923+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:47:42.924+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.924+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:47:42.924+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.924+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:47:42.925+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.925+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2073]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:47:42.927+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.927+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2073]: It took 0.00278s to build the Airflow DAG.
[2025-01-10T13:47:42.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:47:42.943+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.943+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:47:42.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:47:42.975+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:47:43.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-10T13:48:13.108+0000] {processor.py:157} INFO - Started process (PID=2160) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:48:13.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:48:13.112+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:48:13.138+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.137+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:48:13.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.287+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13527636700018775
[2025-01-10T13:48:13.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.288+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2160]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:48:13.289+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.289+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:48:13.289+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.289+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:48:13.290+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.290+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:48:13.290+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.290+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2160]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:48:13.293+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.293+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2160]: It took 0.00288s to build the Airflow DAG.
[2025-01-10T13:48:13.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:48:13.309+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.309+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:48:13.332+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:13.331+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:48:13.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T13:48:43.399+0000] {processor.py:157} INFO - Started process (PID=2248) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:48:43.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:48:43.403+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:48:43.429+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.429+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:48:43.573+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.573+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13058819400021093
[2025-01-10T13:48:43.574+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.574+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2248]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:48:43.574+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.574+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:48:43.575+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.575+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:48:43.575+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.575+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:48:43.575+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.575+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2248]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:48:43.578+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.578+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2248]: It took 0.00241s to build the Airflow DAG.
[2025-01-10T13:48:43.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:48:43.592+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.592+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:48:43.616+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:48:43.616+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:48:43.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T13:49:13.757+0000] {processor.py:157} INFO - Started process (PID=2336) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:49:13.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:49:13.760+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:49:13.785+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.784+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:49:13.913+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.913+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.115441663999718
[2025-01-10T13:49:13.914+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.914+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2336]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:49:13.914+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.914+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:49:13.915+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.915+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:49:13.915+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.915+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:49:13.915+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.915+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2336]: It took 0.131s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:49:13.918+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.918+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2336]: It took 0.00247s to build the Airflow DAG.
[2025-01-10T13:49:13.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:49:13.933+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.933+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:49:13.955+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:13.955+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:49:13.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.219 seconds
[2025-01-10T13:49:44.899+0000] {processor.py:157} INFO - Started process (PID=2422) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:49:44.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:49:44.903+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:44.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:49:44.933+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:44.932+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:49:45.119+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.118+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1673389060001682
[2025-01-10T13:49:45.119+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.119+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2422]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:49:45.120+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.120+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:49:45.120+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.120+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:49:45.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.121+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:49:45.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.121+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2422]: It took 0.189s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:49:45.126+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.126+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2422]: It took 0.00483s to build the Airflow DAG.
[2025-01-10T13:49:45.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:49:45.151+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.151+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:49:45.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:49:45.179+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:49:45.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.306 seconds
[2025-01-10T13:50:15.272+0000] {processor.py:157} INFO - Started process (PID=2527) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:50:15.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:50:15.276+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:50:15.300+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.299+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:50:15.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.468+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1530384640000193
[2025-01-10T13:50:15.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.469+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2527]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:50:15.470+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.470+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:50:15.470+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.470+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:50:15.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.471+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:50:15.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.471+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2527]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:50:15.474+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.474+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2527]: It took 0.00307s to build the Airflow DAG.
[2025-01-10T13:50:15.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:50:15.492+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.492+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:50:15.520+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:15.520+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:50:15.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-10T13:50:45.736+0000] {processor.py:157} INFO - Started process (PID=2613) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:50:45.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:50:45.739+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:50:45.762+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.761+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:50:45.910+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.910+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13525235199995223
[2025-01-10T13:50:45.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.911+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2613]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:50:45.911+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.911+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:50:45.912+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.912+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:50:45.912+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.912+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:50:45.913+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.913+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2613]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:50:45.917+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.917+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2613]: It took 0.0041s to build the Airflow DAG.
[2025-01-10T13:50:45.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:50:45.931+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.931+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:50:45.954+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:50:45.954+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:50:45.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-10T13:51:16.319+0000] {processor.py:157} INFO - Started process (PID=2699) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:51:16.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:51:16.322+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:51:16.344+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.344+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:51:16.494+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.494+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1366185140000198
[2025-01-10T13:51:16.495+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.495+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2699]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:51:16.495+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.495+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:51:16.496+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.496+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:51:16.496+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.496+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:51:16.496+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.496+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2699]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:51:16.499+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.499+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2699]: It took 0.00291s to build the Airflow DAG.
[2025-01-10T13:51:16.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:51:16.515+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.515+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:51:16.541+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:16.540+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:51:16.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-10T13:51:46.679+0000] {processor.py:157} INFO - Started process (PID=2787) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:51:46.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:51:46.682+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:51:46.709+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.709+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:51:46.832+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.831+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10937165599989385
[2025-01-10T13:51:46.832+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.832+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2787]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:51:46.832+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.832+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:51:46.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.833+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:51:46.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.833+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:51:46.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.833+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2787]: It took 0.124s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:51:46.835+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.835+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2787]: It took 0.00218s to build the Airflow DAG.
[2025-01-10T13:51:46.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:51:46.848+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.848+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:51:46.870+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:51:46.869+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:51:46.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-10T13:52:17.001+0000] {processor.py:157} INFO - Started process (PID=2881) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:52:17.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:52:17.004+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:52:17.026+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.026+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:52:17.167+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.167+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12719372199990175
[2025-01-10T13:52:17.167+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.167+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2881]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:52:17.168+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.168+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:52:17.169+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.168+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:52:17.169+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.169+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:52:17.170+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.169+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2881]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:52:17.173+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.173+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2881]: It took 0.00346s to build the Airflow DAG.
[2025-01-10T13:52:17.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:52:17.192+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.192+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:52:17.217+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:17.217+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:52:17.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-10T13:52:47.370+0000] {processor.py:157} INFO - Started process (PID=2976) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:52:47.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:52:47.374+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:52:47.402+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.401+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:52:47.557+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.557+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14203290099976584
[2025-01-10T13:52:47.557+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.557+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|2976]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:52:47.558+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.558+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:52:47.558+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.558+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:52:47.559+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.559+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:52:47.559+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.559+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|2976]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:52:47.562+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.562+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|2976]: It took 0.00269s to build the Airflow DAG.
[2025-01-10T13:52:47.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:52:47.579+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.579+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:52:47.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:52:47.607+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:52:47.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-10T13:53:17.700+0000] {processor.py:157} INFO - Started process (PID=3064) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:53:17.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T13:53:17.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:53:17.727+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.727+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T13:53:17.867+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.867+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12728404300014518
[2025-01-10T13:53:17.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.868+0000] {graph.py:519} INFO - Cosmos performance [f2bf1f6c1110|3064]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T13:53:17.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.868+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T13:53:17.869+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.869+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T13:53:17.869+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.869+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T13:53:17.869+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.869+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [f2bf1f6c1110|3064]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T13:53:17.872+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.872+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [f2bf1f6c1110|3064]: It took 0.00262s to build the Airflow DAG.
[2025-01-10T13:53:17.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T13:53:17.885+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.884+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T13:53:17.906+0000] {logging_mixin.py:151} INFO - [2025-01-10T13:53:17.906+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T13:53:17.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.227 seconds
[2025-01-10T14:31:04.790+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:31:04.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:31:04.794+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:04.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:31:04.831+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:04.831+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:31:05.025+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.025+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17759713000032207
[2025-01-10T14:31:05.026+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.026+0000] {graph.py:519} INFO - Cosmos performance [d7e25bffb24b|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:31:05.027+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.026+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:31:05.027+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.027+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:31:05.028+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.027+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:31:05.028+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.028+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7e25bffb24b|70]: It took 0.197s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:31:05.033+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.032+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7e25bffb24b|70]: It took 0.00447s to build the Airflow DAG.
[2025-01-10T14:31:05.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:31:05.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.173+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:31:05.205+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:05.204+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:31:05.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.450 seconds
[2025-01-10T14:31:35.362+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:31:35.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:31:35.366+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:31:35.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.389+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:31:35.542+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.542+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1393524739996792
[2025-01-10T14:31:35.543+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.542+0000] {graph.py:519} INFO - Cosmos performance [d7e25bffb24b|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:31:35.543+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.543+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:31:35.544+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.544+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:31:35.544+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.544+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:31:35.545+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.544+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7e25bffb24b|157]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:31:35.548+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.547+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7e25bffb24b|157]: It took 0.00302s to build the Airflow DAG.
[2025-01-10T14:31:35.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:31:35.563+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.562+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:31:35.589+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:31:35.589+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:31:35.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-10T14:32:05.832+0000] {processor.py:157} INFO - Started process (PID=245) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:32:05.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:32:05.836+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:05.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:32:05.872+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:05.872+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:32:06.812+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.811+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.9215179239999998
[2025-01-10T14:32:06.812+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.812+0000] {graph.py:519} INFO - Cosmos performance [d7e25bffb24b|245]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:32:06.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.813+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:32:06.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.814+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:32:06.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.814+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:32:06.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.815+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7e25bffb24b|245]: It took 0.943s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:32:06.820+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.820+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7e25bffb24b|245]: It took 0.00503s to build the Airflow DAG.
[2025-01-10T14:32:06.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:32:06.844+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.844+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:32:06.885+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:06.885+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:32:06.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.085 seconds
[2025-01-10T14:32:37.612+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:32:37.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:32:37.616+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:32:37.645+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.645+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:32:37.794+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.794+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13331826299963723
[2025-01-10T14:32:37.795+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.795+0000] {graph.py:519} INFO - Cosmos performance [d7e25bffb24b|344]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:32:37.796+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.796+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:32:37.796+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.796+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:32:37.797+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.796+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:32:37.797+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.797+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7e25bffb24b|344]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:32:37.801+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.801+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7e25bffb24b|344]: It took 0.00354s to build the Airflow DAG.
[2025-01-10T14:32:37.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:32:37.819+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.819+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:32:37.846+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:32:37.846+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:32:37.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-10T14:33:07.971+0000] {processor.py:157} INFO - Started process (PID=443) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:33:07.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:33:07.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:07.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:33:07.999+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:07.999+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:33:08.132+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.132+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12017937600012374
[2025-01-10T14:33:08.133+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.133+0000] {graph.py:519} INFO - Cosmos performance [d7e25bffb24b|443]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:33:08.133+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.133+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:33:08.134+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.134+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:33:08.134+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.134+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:33:08.134+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.134+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7e25bffb24b|443]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:33:08.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.137+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7e25bffb24b|443]: It took 0.00251s to build the Airflow DAG.
[2025-01-10T14:33:08.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:33:08.150+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.150+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:33:08.173+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:08.172+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:33:08.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-10T14:33:38.407+0000] {processor.py:157} INFO - Started process (PID=527) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:33:38.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:33:38.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:33:38.434+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.434+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:33:38.602+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.602+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1550018079997244
[2025-01-10T14:33:38.603+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.603+0000] {graph.py:519} INFO - Cosmos performance [d7e25bffb24b|527]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:33:38.604+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.603+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:33:38.604+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.604+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:33:38.605+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.605+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:33:38.605+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.605+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [d7e25bffb24b|527]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:33:38.609+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.609+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [d7e25bffb24b|527]: It took 0.00357s to build the Airflow DAG.
[2025-01-10T14:33:38.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:33:38.626+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.625+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:33:38.651+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:33:38.651+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:33:38.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-10T14:35:07.708+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:35:07.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:35:07.713+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:35:07.745+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.745+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:35:07.927+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.927+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16550981499949557
[2025-01-10T14:35:07.927+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.927+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:35:07.928+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.928+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:35:07.929+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.928+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:35:07.929+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.929+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:35:07.930+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.929+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|70]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:35:07.934+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:07.934+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|70]: It took 0.00414s to build the Airflow DAG.
[2025-01-10T14:35:07.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:35:08.067+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:08.067+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:35:08.097+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:08.097+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:35:08.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.418 seconds
[2025-01-10T14:35:38.986+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:35:38.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:35:38.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:38.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:35:39.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.014+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:35:39.160+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.160+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1272836890002509
[2025-01-10T14:35:39.160+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.160+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:35:39.161+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.161+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:35:39.161+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.161+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:35:39.161+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.161+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:35:39.162+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.162+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|157]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:35:39.164+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.164+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|157]: It took 0.00234s to build the Airflow DAG.
[2025-01-10T14:35:39.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:35:39.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.179+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:35:39.203+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:35:39.203+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:35:39.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T14:36:09.407+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:36:09.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:36:09.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:36:09.432+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.432+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:36:09.611+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.611+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16483550800057856
[2025-01-10T14:36:09.612+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.612+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|251]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:36:09.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.612+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:36:09.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.613+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:36:09.614+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.614+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:36:09.614+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.614+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|251]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:36:09.618+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.618+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|251]: It took 0.00356s to build the Airflow DAG.
[2025-01-10T14:36:09.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:36:09.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.634+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:36:09.663+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:09.663+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:36:09.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-10T14:36:39.976+0000] {processor.py:157} INFO - Started process (PID=348) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:36:39.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:36:39.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:39.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:36:40.002+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.002+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:36:40.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.183+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16581542399944738
[2025-01-10T14:36:40.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.184+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|348]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:36:40.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.185+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:36:40.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.185+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:36:40.186+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.186+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:36:40.186+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.186+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|348]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:36:40.189+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.189+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|348]: It took 0.00297s to build the Airflow DAG.
[2025-01-10T14:36:40.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:36:40.207+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.207+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:36:40.240+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:36:40.239+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:36:40.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-10T14:37:10.623+0000] {processor.py:157} INFO - Started process (PID=434) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:37:10.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:37:10.626+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:37:10.650+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.650+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:37:10.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.813+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14803871899948717
[2025-01-10T14:37:10.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.814+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|434]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:37:10.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.814+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:37:10.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.815+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:37:10.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.815+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:37:10.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.816+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|434]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:37:10.819+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.818+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|434]: It took 0.00299s to build the Airflow DAG.
[2025-01-10T14:37:10.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:37:10.833+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.833+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:37:10.860+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:10.859+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:37:10.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-10T14:37:41.020+0000] {processor.py:157} INFO - Started process (PID=522) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:37:41.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:37:41.024+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:37:41.050+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.050+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:37:41.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.179+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11561673799951677
[2025-01-10T14:37:41.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.180+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|522]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:37:41.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.180+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:37:41.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.181+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:37:41.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.181+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:37:41.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.181+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|522]: It took 0.132s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:37:41.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.184+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|522]: It took 0.00254s to build the Airflow DAG.
[2025-01-10T14:37:41.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:37:41.197+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.197+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:37:41.219+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:37:41.219+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:37:41.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-10T14:38:11.354+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:38:11.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:38:11.357+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:38:11.386+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.385+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:38:11.553+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.553+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15282080199995107
[2025-01-10T14:38:11.554+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.554+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|606]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:38:11.554+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.554+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:38:11.555+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.555+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:38:11.555+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.555+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:38:11.555+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.555+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|606]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:38:11.558+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.558+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|606]: It took 0.00267s to build the Airflow DAG.
[2025-01-10T14:38:11.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:38:11.576+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.575+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:38:11.601+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:11.601+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:38:11.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-10T14:38:41.668+0000] {processor.py:157} INFO - Started process (PID=694) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:38:41.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:38:41.672+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:38:41.692+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.692+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:38:41.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.867+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16223161300058564
[2025-01-10T14:38:41.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.868+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|694]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:38:41.869+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.869+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:38:41.869+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.869+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:38:41.870+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.870+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:38:41.870+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.870+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|694]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:38:41.874+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.874+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|694]: It took 0.00355s to build the Airflow DAG.
[2025-01-10T14:38:41.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:38:41.894+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.893+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:38:41.926+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:38:41.926+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:38:41.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-10T14:39:12.024+0000] {processor.py:157} INFO - Started process (PID=800) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:39:12.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:39:12.027+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:39:12.050+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.050+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:39:12.220+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.220+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15378799599966442
[2025-01-10T14:39:12.221+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.221+0000] {graph.py:519} INFO - Cosmos performance [13ac899a2ced|800]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:39:12.222+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.222+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:39:12.222+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.222+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:39:12.223+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.223+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:39:12.224+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.224+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [13ac899a2ced|800]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:39:12.227+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.227+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [13ac899a2ced|800]: It took 0.00365s to build the Airflow DAG.
[2025-01-10T14:39:12.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:39:12.245+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.245+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:39:12.278+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:39:12.277+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:39:12.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-10T14:40:32.097+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:40:32.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:40:32.104+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:40:32.150+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.150+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:40:32.363+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.363+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18954503899931296
[2025-01-10T14:40:32.364+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.363+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:40:32.365+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.365+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:40:32.366+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.365+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:40:32.366+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.366+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:40:32.367+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.366+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|70]: It took 0.217s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:40:32.372+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.371+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|70]: It took 0.00472s to build the Airflow DAG.
[2025-01-10T14:40:32.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:40:32.505+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.504+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:40:32.548+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:40:32.547+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:40:32.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.490 seconds
[2025-01-10T14:41:02.831+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:41:02.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:41:02.835+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:41:02.860+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.859+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:41:02.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.975+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10209852300067723
[2025-01-10T14:41:02.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.975+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|156]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:41:02.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.976+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:41:02.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.976+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:41:02.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.976+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:41:02.977+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.977+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|156]: It took 0.117s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:41:02.979+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.979+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|156]: It took 0.00241s to build the Airflow DAG.
[2025-01-10T14:41:02.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:41:02.992+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:02.992+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:41:03.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:03.015+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:41:03.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.206 seconds
[2025-01-10T14:41:33.258+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:41:33.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:41:33.262+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:41:33.286+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.285+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:41:33.437+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.437+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13557578600011766
[2025-01-10T14:41:33.437+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.437+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|251]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:41:33.438+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.438+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:41:33.438+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.438+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:41:33.438+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.438+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:41:33.439+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.439+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|251]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:41:33.442+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.442+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|251]: It took 0.00296s to build the Airflow DAG.
[2025-01-10T14:41:33.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:41:33.457+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.456+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:41:33.498+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:41:33.497+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:41:33.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-10T14:42:03.710+0000] {processor.py:157} INFO - Started process (PID=350) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:42:03.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:42:03.713+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:42:03.741+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.741+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:42:03.878+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.878+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12397762399996282
[2025-01-10T14:42:03.879+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.879+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|350]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:42:03.879+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.879+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:42:03.880+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.880+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:42:03.880+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.880+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:42:03.880+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.880+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|350]: It took 0.14s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:42:03.883+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.883+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|350]: It took 0.00245s to build the Airflow DAG.
[2025-01-10T14:42:03.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:42:03.898+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.898+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:42:03.920+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:03.920+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:42:03.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-10T14:42:34.064+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:42:34.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:42:34.067+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:42:34.087+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.087+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:42:34.233+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.233+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13288480099981825
[2025-01-10T14:42:34.234+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.234+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|439]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:42:34.235+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.235+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:42:34.235+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.235+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:42:34.236+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.236+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:42:34.236+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.236+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|439]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:42:34.239+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.239+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|439]: It took 0.00327s to build the Airflow DAG.
[2025-01-10T14:42:34.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:42:34.253+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.253+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:42:34.275+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:42:34.275+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:42:34.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-10T14:43:04.378+0000] {processor.py:157} INFO - Started process (PID=527) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:43:04.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:43:04.381+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:43:04.407+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.407+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:43:04.529+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.529+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10936527800004114
[2025-01-10T14:43:04.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.529+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|527]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:43:04.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.530+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:43:04.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.530+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:43:04.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.531+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:43:04.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.531+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|527]: It took 0.124s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:43:04.533+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.533+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|527]: It took 0.00231s to build the Airflow DAG.
[2025-01-10T14:43:04.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:43:04.546+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.546+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:43:04.566+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:04.566+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:43:04.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.209 seconds
[2025-01-10T14:43:35.532+0000] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:43:35.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:43:35.536+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:43:35.563+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.563+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:43:35.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.746+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1658412920005503
[2025-01-10T14:43:35.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.747+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|632]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:43:35.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.748+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:43:35.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.748+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:43:35.749+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.748+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:43:35.749+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.749+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|632]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:43:35.752+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.752+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|632]: It took 0.00334s to build the Airflow DAG.
[2025-01-10T14:43:35.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:43:35.769+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.769+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:43:35.804+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:43:35.804+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:43:35.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-10T14:44:05.992+0000] {processor.py:157} INFO - Started process (PID=720) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:44:05.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:44:05.997+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:05.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:44:06.028+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.028+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:44:06.226+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.226+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17822390399942378
[2025-01-10T14:44:06.227+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.226+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|720]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:44:06.227+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.227+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:44:06.228+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.228+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:44:06.228+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.228+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:44:06.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.229+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|720]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:44:06.233+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.232+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|720]: It took 0.00377s to build the Airflow DAG.
[2025-01-10T14:44:06.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:44:06.253+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.253+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:44:06.286+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:06.286+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:44:06.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.326 seconds
[2025-01-10T14:44:36.953+0000] {processor.py:157} INFO - Started process (PID=804) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:44:36.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:44:36.956+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:36.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:44:36.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:36.976+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:44:37.129+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.129+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1403828140000769
[2025-01-10T14:44:37.130+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.130+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|804]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:44:37.130+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.130+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:44:37.131+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.130+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:44:37.131+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.131+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:44:37.131+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.131+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|804]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:44:37.134+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.134+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|804]: It took 0.00252s to build the Airflow DAG.
[2025-01-10T14:44:37.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:44:37.148+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.147+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:44:37.169+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:44:37.169+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:44:37.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-10T14:45:07.260+0000] {processor.py:157} INFO - Started process (PID=898) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:45:07.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:45:07.263+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:45:07.290+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.290+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:45:07.439+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.438+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13360143699992477
[2025-01-10T14:45:07.439+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.439+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|898]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:45:07.440+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.440+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:45:07.440+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.440+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:45:07.441+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.441+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:45:07.441+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.441+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|898]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:45:07.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.445+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|898]: It took 0.00337s to build the Airflow DAG.
[2025-01-10T14:45:07.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:45:07.462+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.462+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:45:07.490+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:07.490+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:45:07.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-10T14:45:37.632+0000] {processor.py:157} INFO - Started process (PID=995) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:45:37.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:45:37.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:45:37.661+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.661+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:45:37.811+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.810+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1362215010003638
[2025-01-10T14:45:37.811+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.811+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|995]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:45:37.812+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.811+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:45:37.812+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.812+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:45:37.812+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.812+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:45:37.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.813+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|995]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:45:37.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.815+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|995]: It took 0.00274s to build the Airflow DAG.
[2025-01-10T14:45:37.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:45:37.830+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:45:37.854+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:45:37.854+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:45:37.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-10T14:46:07.912+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:46:07.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:46:07.915+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:07.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:46:07.944+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:07.944+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:46:08.077+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.077+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11989468899992062
[2025-01-10T14:46:08.077+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.077+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1082]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:46:08.078+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.078+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:46:08.078+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.078+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:46:08.078+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.078+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:46:08.079+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.079+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1082]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:46:08.081+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.081+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1082]: It took 0.00238s to build the Airflow DAG.
[2025-01-10T14:46:08.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:46:08.094+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.093+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:46:08.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:08.114+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:46:08.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.223 seconds
[2025-01-10T14:46:39.084+0000] {processor.py:157} INFO - Started process (PID=1168) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:46:39.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:46:39.088+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:46:39.111+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.111+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:46:39.251+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.251+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12688555200020346
[2025-01-10T14:46:39.251+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.251+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1168]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:46:39.252+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.252+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:46:39.252+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.252+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:46:39.252+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.252+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:46:39.253+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.253+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1168]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:46:39.255+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.255+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1168]: It took 0.00249s to build the Airflow DAG.
[2025-01-10T14:46:39.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:46:39.272+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.272+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:46:39.298+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:46:39.297+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:46:39.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-10T14:47:09.392+0000] {processor.py:157} INFO - Started process (PID=1275) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:47:09.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:47:09.395+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:47:09.419+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.419+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:47:09.585+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.585+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15180701999997837
[2025-01-10T14:47:09.586+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.586+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1275]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:47:09.587+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.587+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:47:09.587+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.587+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:47:09.587+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.587+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:47:09.588+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.588+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1275]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:47:09.592+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.592+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1275]: It took 0.0038s to build the Airflow DAG.
[2025-01-10T14:47:09.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:47:09.609+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.609+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:47:09.637+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:09.637+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:47:09.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-10T14:47:39.743+0000] {processor.py:157} INFO - Started process (PID=1363) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:47:39.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:47:39.746+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:47:39.769+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.769+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:47:39.948+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.948+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16411404199971003
[2025-01-10T14:47:39.949+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.949+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1363]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:47:39.950+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.950+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:47:39.950+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.950+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:47:39.951+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.951+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:47:39.951+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.951+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1363]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:47:39.956+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.955+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1363]: It took 0.00419s to build the Airflow DAG.
[2025-01-10T14:47:39.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:47:39.972+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:39.972+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:47:40.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:47:40.006+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:47:40.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-10T14:48:10.381+0000] {processor.py:157} INFO - Started process (PID=1447) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:48:10.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:48:10.384+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:48:10.409+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.409+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:48:10.544+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.544+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12156142299954809
[2025-01-10T14:48:10.544+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.544+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1447]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:48:10.545+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.545+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:48:10.545+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.545+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:48:10.546+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.546+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:48:10.546+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.546+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1447]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:48:10.549+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.549+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1447]: It took 0.00269s to build the Airflow DAG.
[2025-01-10T14:48:10.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:48:10.561+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.561+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:48:10.587+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:10.587+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:48:10.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.227 seconds
[2025-01-10T14:48:41.170+0000] {processor.py:157} INFO - Started process (PID=1540) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:48:41.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:48:41.173+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:48:41.197+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.196+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:48:41.374+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.374+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16163708699968993
[2025-01-10T14:48:41.375+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.374+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1540]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:48:41.376+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.375+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:48:41.376+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.376+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:48:41.377+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.377+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:48:41.377+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.377+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1540]: It took 0.181s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:48:41.381+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.381+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1540]: It took 0.00399s to build the Airflow DAG.
[2025-01-10T14:48:41.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:48:41.404+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.403+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:48:41.430+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:48:41.429+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:48:41.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-10T14:49:11.578+0000] {processor.py:157} INFO - Started process (PID=1640) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:49:11.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:49:11.582+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:49:11.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.607+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:49:11.742+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.742+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12194260900014342
[2025-01-10T14:49:11.743+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.743+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1640]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:49:11.743+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.743+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:49:11.744+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.744+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:49:11.744+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.744+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:49:11.744+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.744+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1640]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:49:11.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.747+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1640]: It took 0.00254s to build the Airflow DAG.
[2025-01-10T14:49:11.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:49:11.760+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.760+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:49:11.782+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:11.782+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:49:11.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-10T14:49:41.932+0000] {processor.py:157} INFO - Started process (PID=1726) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:49:41.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:49:41.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:41.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:49:41.957+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:41.957+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:49:42.090+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.089+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1194888149993858
[2025-01-10T14:49:42.090+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.090+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1726]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:49:42.090+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.090+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:49:42.091+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.091+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:49:42.091+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.091+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:49:42.092+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.091+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1726]: It took 0.134s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:49:42.094+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.094+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1726]: It took 0.0024s to build the Airflow DAG.
[2025-01-10T14:49:42.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:49:42.107+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.107+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:49:42.130+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:49:42.130+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:49:42.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.220 seconds
[2025-01-10T14:50:12.489+0000] {processor.py:157} INFO - Started process (PID=1817) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:50:12.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:50:12.493+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:50:12.519+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.519+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:50:12.670+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.669+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13586996800040652
[2025-01-10T14:50:12.670+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.670+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1817]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:50:12.671+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.671+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:50:12.671+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.671+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:50:12.671+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.671+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:50:12.672+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.672+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1817]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:50:12.675+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.675+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1817]: It took 0.0034s to build the Airflow DAG.
[2025-01-10T14:50:12.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:50:12.690+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.690+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:50:12.714+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:12.714+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:50:12.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T14:50:42.784+0000] {processor.py:157} INFO - Started process (PID=1903) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:50:42.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:50:42.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:50:42.819+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.819+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:50:42.985+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.985+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1489943589995164
[2025-01-10T14:50:42.986+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.986+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1903]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:50:42.986+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.986+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:50:42.987+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.987+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:50:42.987+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.987+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:50:42.988+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.988+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1903]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:50:42.991+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:42.991+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1903]: It took 0.00317s to build the Airflow DAG.
[2025-01-10T14:50:42.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:50:43.008+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:43.007+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:50:43.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:50:43.033+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:50:43.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-10T14:51:13.167+0000] {processor.py:157} INFO - Started process (PID=1996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:51:13.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:51:13.172+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:51:13.199+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.198+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:51:13.356+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.356+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14218176400027005
[2025-01-10T14:51:13.357+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.357+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|1996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:51:13.357+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.357+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:51:13.358+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.358+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:51:13.358+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.358+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:51:13.358+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.358+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|1996]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:51:13.362+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.361+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|1996]: It took 0.00319s to build the Airflow DAG.
[2025-01-10T14:51:13.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:51:13.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.379+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:51:13.411+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:13.411+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:51:13.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-10T14:51:43.581+0000] {processor.py:157} INFO - Started process (PID=2096) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:51:43.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:51:43.584+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:51:43.606+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.606+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:51:43.753+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.753+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13345202099935705
[2025-01-10T14:51:43.753+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.753+0000] {graph.py:519} INFO - Cosmos performance [ce78032e3533|2096]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:51:43.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.754+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:51:43.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.754+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:51:43.755+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.754+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:51:43.755+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.755+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [ce78032e3533|2096]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:51:43.759+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.758+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [ce78032e3533|2096]: It took 0.00353s to build the Airflow DAG.
[2025-01-10T14:51:43.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:51:43.774+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.774+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:51:43.799+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:51:43.799+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:51:43.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-10T14:52:57.783+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:52:57.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:52:57.787+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:57.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:52:57.823+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:57.823+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:52:58.012+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.012+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17154825599936885
[2025-01-10T14:52:58.012+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.012+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:52:58.013+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.013+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:52:58.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.014+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:52:58.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.014+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:52:58.015+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.015+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|70]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:52:58.019+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.019+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|70]: It took 0.00401s to build the Airflow DAG.
[2025-01-10T14:52:58.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:52:58.142+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.141+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:52:58.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:52:58.174+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:52:58.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.419 seconds
[2025-01-10T14:53:28.303+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:53:28.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:53:28.306+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:53:28.328+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.328+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:53:28.464+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.464+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11954762799996388
[2025-01-10T14:53:28.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.465+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:53:28.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.465+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:53:28.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.465+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:53:28.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.466+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:53:28.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.466+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|157]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:53:28.468+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.468+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|157]: It took 0.00234s to build the Airflow DAG.
[2025-01-10T14:53:28.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:53:28.481+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.481+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:53:28.504+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:28.503+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:53:28.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.223 seconds
[2025-01-10T14:53:58.900+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:53:58.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:53:58.904+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:58.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:53:58.933+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:58.933+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:53:59.108+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.108+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15809510800045246
[2025-01-10T14:53:59.109+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.109+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|261]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:53:59.109+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.109+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:53:59.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.110+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:53:59.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.110+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:53:59.111+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.110+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|261]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:53:59.113+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.113+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|261]: It took 0.00287s to build the Airflow DAG.
[2025-01-10T14:53:59.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:53:59.130+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.130+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:53:59.155+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:53:59.155+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:53:59.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-10T14:54:29.293+0000] {processor.py:157} INFO - Started process (PID=348) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:54:29.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:54:29.296+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:54:29.322+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.322+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:54:29.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.465+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12947662499936996
[2025-01-10T14:54:29.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.465+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|348]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:54:29.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.466+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:54:29.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.466+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:54:29.467+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.467+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:54:29.467+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.467+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|348]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:54:29.470+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.470+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|348]: It took 0.0029s to build the Airflow DAG.
[2025-01-10T14:54:29.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:54:29.483+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.483+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:54:29.506+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:29.506+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:54:29.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-10T14:54:59.883+0000] {processor.py:157} INFO - Started process (PID=434) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:54:59.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:54:59.886+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:59.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:54:59.906+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:54:59.906+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:55:00.063+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.062+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14275578999968275
[2025-01-10T14:55:00.063+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.063+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|434]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:55:00.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.064+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:55:00.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.064+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:55:00.065+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.065+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:55:00.065+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.065+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|434]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:55:00.070+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.069+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|434]: It took 0.00428s to build the Airflow DAG.
[2025-01-10T14:55:00.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:55:00.084+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.084+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:55:00.108+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:00.108+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:55:00.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T14:55:30.173+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:55:30.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:55:30.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:55:30.198+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.198+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:55:30.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.339+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12750111900004413
[2025-01-10T14:55:30.340+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.340+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|520]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:55:30.340+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.340+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:55:30.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.341+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:55:30.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.341+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:55:30.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.341+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|520]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:55:30.345+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.344+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|520]: It took 0.00317s to build the Airflow DAG.
[2025-01-10T14:55:30.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:55:30.359+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.359+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:55:30.384+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:55:30.384+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:55:30.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-10T14:56:00.564+0000] {processor.py:157} INFO - Started process (PID=621) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:56:00.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:56:00.570+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:56:00.602+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.602+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:56:00.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.786+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16299782799978857
[2025-01-10T14:56:00.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.786+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|621]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:56:00.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.787+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:56:00.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.788+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:56:00.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.789+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:56:00.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.789+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|621]: It took 0.188s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:56:00.793+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.793+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|621]: It took 0.00396s to build the Airflow DAG.
[2025-01-10T14:56:00.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:56:00.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.816+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:56:00.885+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:00.884+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:56:00.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-10T14:56:31.269+0000] {processor.py:157} INFO - Started process (PID=719) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:56:31.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:56:31.273+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:56:31.299+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.299+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:56:31.492+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.492+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1771319740000763
[2025-01-10T14:56:31.492+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.492+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|719]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:56:31.493+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.493+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:56:31.493+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.493+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:56:31.494+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.494+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:56:31.495+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.494+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|719]: It took 0.195s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:56:31.498+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.498+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|719]: It took 0.00349s to build the Airflow DAG.
[2025-01-10T14:56:31.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:56:31.513+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.513+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:56:31.541+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:56:31.541+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:56:31.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.296 seconds
[2025-01-10T14:57:01.726+0000] {processor.py:157} INFO - Started process (PID=806) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:57:01.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:57:01.730+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:57:01.755+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.755+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:57:01.972+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.972+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2011672170001475
[2025-01-10T14:57:01.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.973+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|806]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:57:01.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.973+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:57:01.974+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.974+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:57:01.974+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.974+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:57:01.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.975+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|806]: It took 0.22s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:57:01.979+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.978+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|806]: It took 0.00363s to build the Airflow DAG.
[2025-01-10T14:57:01.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:57:01.996+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:01.995+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:57:02.023+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:02.022+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:57:02.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.323 seconds
[2025-01-10T14:57:32.093+0000] {processor.py:157} INFO - Started process (PID=892) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:57:32.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:57:32.097+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:57:32.117+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.117+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:57:32.262+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.262+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13176835299964296
[2025-01-10T14:57:32.263+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.263+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|892]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:57:32.263+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.263+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:57:32.264+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.264+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:57:32.264+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.264+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:57:32.264+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.264+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|892]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:57:32.267+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.267+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|892]: It took 0.00248s to build the Airflow DAG.
[2025-01-10T14:57:32.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:57:32.280+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.280+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:57:32.301+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:57:32.301+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:57:32.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-10T14:58:02.426+0000] {processor.py:157} INFO - Started process (PID=979) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:58:02.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:58:02.429+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:58:02.452+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.452+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:58:02.632+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.632+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1662749650004116
[2025-01-10T14:58:02.633+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.633+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|979]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:58:02.633+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.633+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:58:02.634+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.634+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:58:02.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.634+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:58:02.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.635+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|979]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:58:02.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.639+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|979]: It took 0.00437s to build the Airflow DAG.
[2025-01-10T14:58:02.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:58:02.654+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.654+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:58:02.683+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:02.682+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:58:02.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-10T14:58:32.765+0000] {processor.py:157} INFO - Started process (PID=1072) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:58:32.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T14:58:32.770+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:58:32.801+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.801+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T14:58:32.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.969+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1507601479997902
[2025-01-10T14:58:32.970+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.970+0000] {graph.py:519} INFO - Cosmos performance [dc5a7b2a7766|1072]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T14:58:32.971+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.970+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T14:58:32.971+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.971+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T14:58:32.971+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.971+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T14:58:32.972+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.972+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [dc5a7b2a7766|1072]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T14:58:32.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.975+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [dc5a7b2a7766|1072]: It took 0.00326s to build the Airflow DAG.
[2025-01-10T14:58:32.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T14:58:32.991+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:32.991+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T14:58:33.015+0000] {logging_mixin.py:151} INFO - [2025-01-10T14:58:33.014+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T14:58:33.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-10T15:35:05.624+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:35:05.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:35:05.629+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:35:05.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:35:05.669+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:35:05.659+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:35:05.670+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:35:05.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.115 seconds
[2025-01-10T15:35:36.437+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:35:36.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:35:36.441+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:35:36.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:35:36.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:35:36.465+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:35:36.472+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:35:36.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.066 seconds
[2025-01-10T15:36:06.788+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:36:06.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:36:06.797+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:36:06.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:36:06.828+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:36:06.823+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:36:06.829+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:36:06.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.072 seconds
[2025-01-10T15:44:37.411+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:44:37.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:44:37.415+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:44:37.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:44:37.446+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:44:37.439+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:44:37.447+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:44:37.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.062 seconds
[2025-01-10T15:45:07.617+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:45:07.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:45:07.620+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:45:07.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:45:07.654+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:45:07.648+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:45:07.654+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:45:07.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.058 seconds
[2025-01-10T15:45:38.302+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:45:38.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:45:38.306+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:45:38.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:45:38.337+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:45:38.330+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:45:38.337+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:45:38.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.074 seconds
[2025-01-10T15:46:53.587+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:46:53.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:46:53.593+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:46:53.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:46:53.642+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:46:53.636+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:46:53.644+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:46:53.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.099 seconds
[2025-01-10T15:47:24.194+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:47:24.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:47:24.197+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:47:24.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:47:24.222+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:47:24.216+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:47:24.223+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:47:24.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.056 seconds
[2025-01-10T15:47:54.401+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:47:54.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:47:54.405+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:47:54.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:47:54.431+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:47:54.426+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:47:54.431+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:47:54.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.060 seconds
[2025-01-10T15:48:24.743+0000] {processor.py:157} INFO - Started process (PID=348) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:48:24.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:48:24.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:48:24.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:48:24.771+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:48:24.766+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:48:24.772+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:48:24.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.055 seconds
[2025-01-10T15:48:55.337+0000] {processor.py:157} INFO - Started process (PID=434) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:48:55.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:48:55.341+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:48:55.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:48:55.366+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:48:55.359+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:48:55.366+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:48:55.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.058 seconds
[2025-01-10T15:49:25.683+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:49:25.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:49:25.687+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:49:25.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:49:25.711+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:49:25.705+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:49:25.711+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:49:25.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.055 seconds
[2025-01-10T15:49:55.842+0000] {processor.py:157} INFO - Started process (PID=614) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:49:55.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:49:55.848+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:49:55.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:49:55.874+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:49:55.868+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:49:55.874+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:49:55.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.056 seconds
[2025-01-10T15:50:26.045+0000] {processor.py:157} INFO - Started process (PID=711) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:50:26.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:50:26.049+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:50:26.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:50:26.073+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:50:26.068+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:50:26.074+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:50:26.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.059 seconds
[2025-01-10T15:50:56.164+0000] {processor.py:157} INFO - Started process (PID=796) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:50:56.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:50:56.168+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:50:56.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:50:56.192+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:50:56.187+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:50:56.193+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:50:56.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.056 seconds
[2025-01-10T15:51:26.404+0000] {processor.py:157} INFO - Started process (PID=890) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:51:26.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:51:26.407+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:51:26.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:51:26.436+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:51:26.431+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:51:26.437+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:51:26.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.055 seconds
[2025-01-10T15:51:56.750+0000] {processor.py:157} INFO - Started process (PID=976) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:51:56.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:51:56.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:51:56.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:51:56.785+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:51:56.779+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:51:56.786+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:51:56.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.070 seconds
[2025-01-10T15:52:27.010+0000] {processor.py:157} INFO - Started process (PID=1070) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:52:27.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:52:27.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:52:27.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:52:27.041+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:52:27.036+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:52:27.042+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:52:27.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.054 seconds
[2025-01-10T15:52:57.135+0000] {processor.py:157} INFO - Started process (PID=1168) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:52:57.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:52:57.139+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:52:57.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:52:57.164+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:52:57.159+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:52:57.165+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:52:57.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.053 seconds
[2025-01-10T15:53:27.447+0000] {processor.py:157} INFO - Started process (PID=1254) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:53:27.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:53:27.450+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:53:27.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:53:27.476+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:53:27.469+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 214, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/config.py", line 249, in validate_project
    raise CosmosValueError(f"Could not find {name} at {path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-10T15:53:27.476+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:53:27.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.051 seconds
[2025-01-10T15:54:52.723+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:54:52.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:54:52.727+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:54:52.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.754+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:54:52.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.972+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2018170920000557
[2025-01-10T15:54:52.974+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.973+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|70]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:54:52.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.975+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:54:52.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.976+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:54:52.977+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.977+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:54:52.978+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.977+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|70]: It took 0.223s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:54:52.986+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:52.985+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|70]: It took 0.00796s to build the Airflow DAG.
[2025-01-10T15:54:52.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:54:53.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:53.137+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:54:53.167+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:54:53.167+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:54:53.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.477 seconds
[2025-01-10T15:55:23.653+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:55:23.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:55:23.656+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:55:23.675+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.675+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:55:23.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.813+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12463244700120413
[2025-01-10T15:55:23.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.814+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:55:23.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.814+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:55:23.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.815+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:55:23.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.815+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:55:23.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.815+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|157]: It took 0.14s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:55:23.818+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.818+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|157]: It took 0.00242s to build the Airflow DAG.
[2025-01-10T15:55:23.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:55:23.831+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:55:23.852+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:23.852+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:55:23.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.220 seconds
[2025-01-10T15:55:54.001+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:55:54.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:55:54.004+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:55:54.025+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.025+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:55:54.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.179+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13882627299972228
[2025-01-10T15:55:54.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.180+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|262]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:55:54.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.180+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:55:54.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.181+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:55:54.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.181+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:55:54.182+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.182+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|262]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:55:54.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.185+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|262]: It took 0.00319s to build the Airflow DAG.
[2025-01-10T15:55:54.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:55:54.201+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.200+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:55:54.226+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:55:54.226+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:55:54.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-10T15:56:24.356+0000] {processor.py:157} INFO - Started process (PID=348) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:56:24.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:56:24.360+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:56:24.385+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.385+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:56:24.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.530+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13153894000060973
[2025-01-10T15:56:24.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.530+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|348]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:56:24.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.531+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:56:24.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.531+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:56:24.532+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.531+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:56:24.532+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.532+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|348]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:56:24.534+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.534+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|348]: It took 0.00237s to build the Airflow DAG.
[2025-01-10T15:56:24.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:56:24.547+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.547+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:56:24.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:24.568+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:56:24.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-10T15:56:54.755+0000] {processor.py:157} INFO - Started process (PID=435) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:56:54.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:56:54.758+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:56:54.783+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.782+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:56:54.934+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.934+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13795430299978761
[2025-01-10T15:56:54.934+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.934+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|435]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:56:54.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.935+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:56:54.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.935+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:56:54.936+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.936+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:56:54.936+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.936+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|435]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:56:54.939+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.939+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|435]: It took 0.00298s to build the Airflow DAG.
[2025-01-10T15:56:54.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:56:54.953+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.953+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:56:54.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:56:54.976+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:56:54.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-10T15:57:25.107+0000] {processor.py:157} INFO - Started process (PID=533) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:57:25.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:57:25.111+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:57:25.139+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.138+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:57:25.270+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.270+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11785100900124235
[2025-01-10T15:57:25.270+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.270+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|533]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:57:25.271+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.271+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:57:25.271+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.271+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:57:25.271+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.271+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:57:25.272+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.272+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|533]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:57:25.274+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.274+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|533]: It took 0.00226s to build the Airflow DAG.
[2025-01-10T15:57:25.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:57:25.286+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.286+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:57:25.307+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:25.307+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:57:25.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-10T15:57:55.580+0000] {processor.py:157} INFO - Started process (PID=626) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:57:55.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:57:55.584+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:57:55.606+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.605+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:57:55.745+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.745+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12672516200109385
[2025-01-10T15:57:55.746+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.745+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|626]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:57:55.746+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.746+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:57:55.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.747+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:57:55.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.747+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:57:55.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.747+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|626]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:57:55.750+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.750+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|626]: It took 0.00266s to build the Airflow DAG.
[2025-01-10T15:57:55.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:57:55.764+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.764+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:57:55.787+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:57:55.787+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:57:55.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-10T15:58:25.934+0000] {processor.py:157} INFO - Started process (PID=717) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:58:25.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:58:25.939+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:25.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:58:25.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:25.973+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:58:26.136+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.136+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14476077099971008
[2025-01-10T15:58:26.136+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.136+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|717]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:58:26.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.137+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:58:26.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.137+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:58:26.138+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.138+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:58:26.138+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.138+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|717]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:58:26.142+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.142+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|717]: It took 0.00355s to build the Airflow DAG.
[2025-01-10T15:58:26.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:58:26.159+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.158+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:58:26.190+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:26.190+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:58:26.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-10T15:58:56.456+0000] {processor.py:157} INFO - Started process (PID=821) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:58:56.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:58:56.462+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:58:56.522+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.522+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:58:56.705+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.705+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1670968329999596
[2025-01-10T15:58:56.705+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.705+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|821]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:58:56.706+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.706+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:58:56.707+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.707+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:58:56.707+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.707+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:58:56.708+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.707+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|821]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:58:56.712+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.712+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|821]: It took 0.00474s to build the Airflow DAG.
[2025-01-10T15:58:56.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:58:56.728+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.728+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:58:56.768+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:58:56.768+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:58:56.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.375 seconds
[2025-01-10T15:59:27.886+0000] {processor.py:157} INFO - Started process (PID=888) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:59:27.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:59:27.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:27.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:59:28.129+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.129+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:59:28.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.787+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3925385399998049
[2025-01-10T15:59:28.802+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.802+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|888]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T15:59:28.810+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.810+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T15:59:28.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.812+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T15:59:28.817+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.816+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T15:59:28.818+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.817+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|888]: It took 0.689s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T15:59:28.849+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.849+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|888]: It took 0.0316s to build the Airflow DAG.
[2025-01-10T15:59:28.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:59:28.930+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.929+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T15:59:28.997+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:28.995+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T15:59:29.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.437 seconds
[2025-01-10T15:59:59.552+0000] {processor.py:157} INFO - Started process (PID=973) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:59:59.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T15:59:59.560+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:59.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T15:59:59.604+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:59.604+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T15:59:59.997+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:59.997+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3566441439998016
[2025-01-10T15:59:59.999+0000] {logging_mixin.py:151} INFO - [2025-01-10T15:59:59.998+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|973]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:00:00.005+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:00.005+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:00:00.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:00.007+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:00:00.009+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:00.008+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:00:00.011+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:00.011+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|973]: It took 0.408s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:00:00.031+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:00.031+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|973]: It took 0.0202s to build the Airflow DAG.
[2025-01-10T16:00:00.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:00:00.107+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:00.106+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:00:00.192+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:00.191+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:00:00.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.697 seconds
[2025-01-10T16:00:30.356+0000] {processor.py:157} INFO - Started process (PID=1060) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:00:30.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:00:30.361+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:00:30.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.389+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:00:30.597+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.597+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19150995599920861
[2025-01-10T16:00:30.598+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.598+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1060]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:00:30.599+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.599+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:00:30.599+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.599+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:00:30.600+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.600+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:00:30.601+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.600+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1060]: It took 0.211s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:00:30.605+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.604+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1060]: It took 0.00409s to build the Airflow DAG.
[2025-01-10T16:00:30.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:00:30.624+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.624+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:00:30.653+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:00:30.652+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:00:30.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-10T16:01:01.599+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:01:01.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:01:01.602+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:01:01.629+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.628+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:01:01.806+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.806+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16337253100027738
[2025-01-10T16:01:01.807+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.807+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1147]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:01:01.809+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.808+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:01:01.809+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.809+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:01:01.810+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.810+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:01:01.811+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.810+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1147]: It took 0.182s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:01:01.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.816+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1147]: It took 0.0054s to build the Airflow DAG.
[2025-01-10T16:01:01.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:01:01.844+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.844+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:01:01.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:01.868+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:01:01.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.290 seconds
[2025-01-10T16:01:32.040+0000] {processor.py:157} INFO - Started process (PID=1233) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:01:32.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:01:32.043+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:01:32.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.064+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:01:32.200+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.200+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12207312299869955
[2025-01-10T16:01:32.200+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.200+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1233]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:01:32.201+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.201+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:01:32.201+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.201+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:01:32.202+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.202+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:01:32.202+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.202+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1233]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:01:32.205+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.205+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1233]: It took 0.0029s to build the Airflow DAG.
[2025-01-10T16:01:32.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:01:32.220+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.220+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:01:32.244+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:01:32.244+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:01:32.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-10T16:02:02.332+0000] {processor.py:157} INFO - Started process (PID=1320) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:02:02.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:02:02.336+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:02:02.362+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.362+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:02:02.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.525+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1499923219998891
[2025-01-10T16:02:02.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.526+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1320]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:02:02.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.526+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:02:02.527+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.527+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:02:02.527+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.527+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:02:02.528+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.528+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1320]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:02:02.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.530+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1320]: It took 0.00273s to build the Airflow DAG.
[2025-01-10T16:02:02.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:02:02.547+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.546+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:02:02.572+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:02.572+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:02:02.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-10T16:02:32.965+0000] {processor.py:157} INFO - Started process (PID=1412) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:02:32.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:02:32.968+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:32.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:02:32.992+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:32.992+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:02:33.155+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.155+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14906792100009625
[2025-01-10T16:02:33.156+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.156+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1412]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:02:33.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.156+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:02:33.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.157+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:02:33.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.157+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:02:33.158+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.158+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1412]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:02:33.162+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.162+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1412]: It took 0.00391s to build the Airflow DAG.
[2025-01-10T16:02:33.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:02:33.178+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.178+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:02:33.206+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:02:33.206+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:02:33.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-10T16:03:03.365+0000] {processor.py:157} INFO - Started process (PID=1512) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:03:03.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:03:03.369+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:03:03.398+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.398+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:03:03.559+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.559+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1428956260006089
[2025-01-10T16:03:03.560+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.560+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1512]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:03:03.561+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.560+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:03:03.561+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.561+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:03:03.561+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.561+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:03:03.562+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.562+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1512]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:03:03.564+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.564+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1512]: It took 0.00268s to build the Airflow DAG.
[2025-01-10T16:03:03.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:03:03.579+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.579+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:03:03.601+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:03.601+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:03:03.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-10T16:03:34.583+0000] {processor.py:157} INFO - Started process (PID=1598) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:03:34.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:03:34.588+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:03:34.612+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.612+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:03:34.784+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.784+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15664478100006818
[2025-01-10T16:03:34.785+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.784+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1598]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:03:34.785+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.785+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:03:34.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.785+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:03:34.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.786+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:03:34.787+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.787+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1598]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:03:34.791+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.790+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1598]: It took 0.00399s to build the Airflow DAG.
[2025-01-10T16:03:34.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:03:34.810+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.810+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:03:34.838+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:03:34.838+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:03:34.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-10T16:04:04.958+0000] {processor.py:157} INFO - Started process (PID=1686) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:04:04.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:04:04.962+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:04.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:04:04.991+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:04.991+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:04:05.135+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.135+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12734739600091416
[2025-01-10T16:04:05.136+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.136+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1686]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:04:05.136+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.136+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:04:05.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.137+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:04:05.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.137+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:04:05.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.137+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1686]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:04:05.140+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.140+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1686]: It took 0.0026s to build the Airflow DAG.
[2025-01-10T16:04:05.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:04:05.156+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.155+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:04:05.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:05.179+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:04:05.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-10T16:04:35.330+0000] {processor.py:157} INFO - Started process (PID=1772) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:04:35.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:04:35.333+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:04:35.355+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.355+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:04:35.478+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.477+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.10920812999938789
[2025-01-10T16:04:35.478+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.478+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1772]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:04:35.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.478+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:04:35.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.479+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:04:35.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.479+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:04:35.480+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.479+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1772]: It took 0.125s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:04:35.482+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.482+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1772]: It took 0.00251s to build the Airflow DAG.
[2025-01-10T16:04:35.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:04:35.495+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.495+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:04:35.517+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:04:35.517+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:04:35.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.208 seconds
[2025-01-10T16:05:05.687+0000] {processor.py:157} INFO - Started process (PID=1877) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:05:05.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:05:05.691+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:05:05.711+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.711+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:05:05.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.867+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1436577029999171
[2025-01-10T16:05:05.868+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.868+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1877]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:05:05.869+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.869+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:05:05.870+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.869+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:05:05.870+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.870+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:05:05.871+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.871+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1877]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:05:05.875+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.874+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1877]: It took 0.00394s to build the Airflow DAG.
[2025-01-10T16:05:05.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:05:05.893+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.892+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:05:05.923+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:05.922+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:05:05.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-10T16:05:35.981+0000] {processor.py:157} INFO - Started process (PID=1965) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:05:35.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:05:35.984+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:35.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:05:36.004+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.004+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:05:36.156+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.155+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13839396700132056
[2025-01-10T16:05:36.156+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.156+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|1965]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:05:36.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.157+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:05:36.158+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.158+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:05:36.158+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.158+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:05:36.159+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.159+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|1965]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:05:36.162+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.162+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|1965]: It took 0.00335s to build the Airflow DAG.
[2025-01-10T16:05:36.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:05:36.176+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.176+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:05:36.200+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:05:36.200+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:05:36.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T16:06:06.408+0000] {processor.py:157} INFO - Started process (PID=2053) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:06:06.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:06:06.412+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:06:06.437+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.437+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:06:06.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.568+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11663703399972292
[2025-01-10T16:06:06.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.568+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2053]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:06:06.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.569+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:06:06.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.569+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:06:06.570+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.570+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:06:06.570+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.570+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2053]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:06:06.574+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.573+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2053]: It took 0.00313s to build the Airflow DAG.
[2025-01-10T16:06:06.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:06:06.587+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.587+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:06:06.610+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:06.609+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:06:06.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.223 seconds
[2025-01-10T16:06:36.923+0000] {processor.py:157} INFO - Started process (PID=2140) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:06:36.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:06:36.927+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:36.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:06:36.954+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:36.954+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:06:37.099+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.099+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13131967399931455
[2025-01-10T16:06:37.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.100+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2140]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:06:37.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.101+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:06:37.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.101+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:06:37.102+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.102+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:06:37.102+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.102+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2140]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:06:37.106+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.106+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2140]: It took 0.00412s to build the Airflow DAG.
[2025-01-10T16:06:37.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:06:37.122+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.121+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:06:37.151+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:06:37.150+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:06:37.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-10T16:07:07.319+0000] {processor.py:157} INFO - Started process (PID=2239) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:07:07.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:07:07.323+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:07:07.345+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.345+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:07:07.502+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.501+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14300121999986004
[2025-01-10T16:07:07.502+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.502+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2239]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:07:07.503+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.503+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:07:07.503+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.503+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:07:07.504+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.504+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:07:07.504+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.504+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2239]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:07:07.507+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.507+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2239]: It took 0.00301s to build the Airflow DAG.
[2025-01-10T16:07:07.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:07:07.524+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.524+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:07:07.553+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:07.553+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:07:07.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-10T16:07:37.871+0000] {processor.py:157} INFO - Started process (PID=2325) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:07:37.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:07:37.875+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:37.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:07:37.897+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:37.897+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:07:38.052+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.052+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13880134800092492
[2025-01-10T16:07:38.052+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.052+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2325]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:07:38.053+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.053+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:07:38.053+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.053+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:07:38.054+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.053+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:07:38.054+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.054+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2325]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:07:38.056+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.056+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2325]: It took 0.00246s to build the Airflow DAG.
[2025-01-10T16:07:38.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:07:38.070+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.070+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:07:38.093+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:07:38.093+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:07:38.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-10T16:08:08.336+0000] {processor.py:157} INFO - Started process (PID=2411) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:08:08.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:08:08.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:08:08.362+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.362+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:08:08.520+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.519+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14352439499998582
[2025-01-10T16:08:08.520+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.520+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2411]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:08:08.521+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.521+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:08:08.521+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.521+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:08:08.521+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.521+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:08:08.522+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.522+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2411]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:08:08.525+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.524+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2411]: It took 0.00276s to build the Airflow DAG.
[2025-01-10T16:08:08.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:08:08.541+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.541+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:08:08.565+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:08.565+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:08:08.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-10T16:08:38.798+0000] {processor.py:157} INFO - Started process (PID=2516) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:08:38.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:08:38.802+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:38.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:08:38.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:38.825+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:08:38.998+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:38.998+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15769346200067957
[2025-01-10T16:08:38.999+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:38.999+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2516]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:08:38.999+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:38.999+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:08:39.000+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:39.000+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:08:39.000+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:39.000+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:08:39.001+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:39.001+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2516]: It took 0.175s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:08:39.004+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:39.004+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2516]: It took 0.00308s to build the Airflow DAG.
[2025-01-10T16:08:39.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:08:39.027+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:39.026+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:08:39.053+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:08:39.052+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:08:39.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.280 seconds
[2025-01-10T16:09:09.274+0000] {processor.py:157} INFO - Started process (PID=2603) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:09:09.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:09:09.277+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:09:09.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.302+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:09:09.444+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.444+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12836343399976613
[2025-01-10T16:09:09.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.445+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2603]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:09:09.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.445+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:09:09.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.445+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:09:09.446+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.446+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:09:09.446+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.446+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2603]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:09:09.449+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.449+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2603]: It took 0.00285s to build the Airflow DAG.
[2025-01-10T16:09:09.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:09:09.464+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.464+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:09:09.487+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:09.487+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:09:09.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-10T16:09:39.636+0000] {processor.py:157} INFO - Started process (PID=2689) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:09:39.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:09:39.639+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:09:39.659+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.659+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:09:39.795+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.795+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12300093799967726
[2025-01-10T16:09:39.796+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.796+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2689]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:09:39.796+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.796+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:09:39.797+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.797+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:09:39.797+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.797+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:09:39.797+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.797+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2689]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:09:39.800+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.800+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2689]: It took 0.00251s to build the Airflow DAG.
[2025-01-10T16:09:39.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:09:39.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.813+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:09:39.844+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:09:39.844+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:09:39.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-10T16:10:10.129+0000] {processor.py:157} INFO - Started process (PID=2794) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:10:10.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:10:10.133+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:10:10.155+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.154+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:10:10.301+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.301+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13358449599945743
[2025-01-10T16:10:10.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.302+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2794]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:10:10.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.302+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:10:10.303+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.303+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:10:10.303+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.303+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:10:10.303+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.303+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2794]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:10:10.306+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.306+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2794]: It took 0.00296s to build the Airflow DAG.
[2025-01-10T16:10:10.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:10:10.323+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.322+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:10:10.349+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:10.349+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:10:10.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-10T16:10:40.601+0000] {processor.py:157} INFO - Started process (PID=2880) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:10:40.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:10:40.604+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:10:40.627+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.627+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:10:40.771+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.770+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12707644200054347
[2025-01-10T16:10:40.771+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.771+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2880]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:10:40.772+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.771+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:10:40.772+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.772+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:10:40.772+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.772+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:10:40.772+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.772+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2880]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:10:40.775+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.775+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2880]: It took 0.00279s to build the Airflow DAG.
[2025-01-10T16:10:40.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:10:40.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.789+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:10:40.812+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:10:40.812+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:10:40.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-10T16:11:11.010+0000] {processor.py:157} INFO - Started process (PID=2966) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:11:11.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:11:11.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:11:11.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.034+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:11:11.172+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.172+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12385190399982093
[2025-01-10T16:11:11.172+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.172+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|2966]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:11:11.173+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.173+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:11:11.173+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.173+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:11:11.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.174+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:11:11.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.174+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|2966]: It took 0.14s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:11:11.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.177+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|2966]: It took 0.00296s to build the Airflow DAG.
[2025-01-10T16:11:11.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:11:11.191+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.191+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:11:11.215+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:11.214+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:11:11.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-10T16:11:41.559+0000] {processor.py:157} INFO - Started process (PID=3071) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:11:41.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:11:41.563+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:11:41.586+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.586+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:11:41.751+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.751+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15093123300175648
[2025-01-10T16:11:41.751+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.751+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3071]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:11:41.752+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.752+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:11:41.752+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.752+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:11:41.753+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.753+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:11:41.753+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.753+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3071]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:11:41.756+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.756+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3071]: It took 0.00288s to build the Airflow DAG.
[2025-01-10T16:11:41.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:11:41.772+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.772+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:11:41.799+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:11:41.799+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:11:41.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-10T16:12:12.001+0000] {processor.py:157} INFO - Started process (PID=3157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:12:12.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:12:12.005+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:12:12.029+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.029+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:12:12.175+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.175+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1321691369994369
[2025-01-10T16:12:12.176+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.176+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:12:12.176+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.176+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:12:12.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.177+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:12:12.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.177+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:12:12.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.177+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3157]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:12:12.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.180+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3157]: It took 0.00283s to build the Airflow DAG.
[2025-01-10T16:12:12.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:12:12.194+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.194+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:12:12.218+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:12.218+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:12:12.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T16:12:42.529+0000] {processor.py:157} INFO - Started process (PID=3243) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:12:42.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:12:42.532+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:12:42.555+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.555+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:12:42.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.702+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13428978199954145
[2025-01-10T16:12:42.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.703+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3243]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:12:42.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.703+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:12:42.704+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.704+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:12:42.704+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.704+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:12:42.704+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.704+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3243]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:12:42.707+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.707+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3243]: It took 0.00237s to build the Airflow DAG.
[2025-01-10T16:12:42.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:12:42.721+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.721+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:12:42.743+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:12:42.743+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:12:42.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-10T16:13:13.000+0000] {processor.py:157} INFO - Started process (PID=3337) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:13:13.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:13:13.003+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:13:13.023+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.023+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:13:13.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.181+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14455072300006577
[2025-01-10T16:13:13.182+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.182+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3337]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:13:13.182+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.182+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:13:13.183+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.183+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:13:13.183+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.183+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:13:13.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.183+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3337]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:13:13.186+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.186+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3337]: It took 0.00259s to build the Airflow DAG.
[2025-01-10T16:13:13.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:13:13.203+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.203+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:13:13.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:13.228+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:13:13.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-10T16:13:43.511+0000] {processor.py:157} INFO - Started process (PID=3434) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:13:43.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:13:43.514+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:13:43.537+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.537+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:13:43.691+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.691+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13906587699966622
[2025-01-10T16:13:43.691+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.691+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3434]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:13:43.692+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.692+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:13:43.692+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.692+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:13:43.693+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.693+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:13:43.693+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.693+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3434]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:13:43.697+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.697+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3434]: It took 0.00343s to build the Airflow DAG.
[2025-01-10T16:13:43.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:13:43.711+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.711+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:13:43.735+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:13:43.735+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:13:43.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-10T16:14:14.125+0000] {processor.py:157} INFO - Started process (PID=3520) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:14:14.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:14:14.129+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:14:14.154+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.154+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:14:14.322+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.322+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15265575100056594
[2025-01-10T16:14:14.323+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.323+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3520]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:14:14.324+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.324+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:14:14.324+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.324+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:14:14.325+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.325+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:14:14.325+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.325+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3520]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:14:14.329+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.329+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3520]: It took 0.00362s to build the Airflow DAG.
[2025-01-10T16:14:14.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:14:14.348+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.348+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:14:14.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:14.379+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:14:14.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-10T16:14:44.687+0000] {processor.py:157} INFO - Started process (PID=3607) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:14:44.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:14:44.690+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:14:44.710+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.710+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:14:44.873+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.873+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14963733700096782
[2025-01-10T16:14:44.874+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.874+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3607]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:14:44.874+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.874+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:14:44.875+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.875+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:14:44.875+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.875+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:14:44.876+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.876+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3607]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:14:44.879+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.879+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3607]: It took 0.00344s to build the Airflow DAG.
[2025-01-10T16:14:44.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:14:44.897+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.896+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:14:44.921+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:14:44.920+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:14:44.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-10T16:15:14.987+0000] {processor.py:157} INFO - Started process (PID=3694) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:15:14.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:15:14.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:14.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:15:15.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.014+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:15:15.170+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.170+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14252877800026909
[2025-01-10T16:15:15.170+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.170+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3694]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:15:15.171+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.171+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:15:15.171+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.171+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:15:15.172+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.171+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:15:15.172+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.172+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3694]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:15:15.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.174+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3694]: It took 0.00243s to build the Airflow DAG.
[2025-01-10T16:15:15.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:15:15.188+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.187+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:15:15.212+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:15.212+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:15:15.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-10T16:15:45.603+0000] {processor.py:157} INFO - Started process (PID=3798) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:15:45.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:15:45.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:15:45.630+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.630+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:15:45.799+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.799+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.154114879998815
[2025-01-10T16:15:45.800+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.800+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3798]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:15:45.801+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.800+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:15:45.801+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.801+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:15:45.801+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.801+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:15:45.802+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.802+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3798]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:15:45.805+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.805+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3798]: It took 0.00329s to build the Airflow DAG.
[2025-01-10T16:15:45.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:15:45.824+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.823+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:15:45.858+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:15:45.858+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:15:45.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.286 seconds
[2025-01-10T16:16:15.957+0000] {processor.py:157} INFO - Started process (PID=3885) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:16:15.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:16:15.961+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:15.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:16:15.985+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:15.985+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:16:16.154+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.154+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15393848799976695
[2025-01-10T16:16:16.155+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.155+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3885]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:16:16.156+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.156+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:16:16.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.156+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:16:16.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.157+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:16:16.157+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.157+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3885]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:16:16.161+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.161+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3885]: It took 0.00332s to build the Airflow DAG.
[2025-01-10T16:16:16.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:16:16.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.179+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:16:16.211+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:16.211+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:16:16.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-10T16:16:46.382+0000] {processor.py:157} INFO - Started process (PID=3971) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:16:46.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:16:46.386+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:16:46.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.409+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:16:46.563+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.563+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13782825699854584
[2025-01-10T16:16:46.563+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.563+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|3971]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:16:46.564+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.564+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:16:46.564+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.564+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:16:46.565+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.565+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:16:46.565+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.565+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|3971]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:16:46.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.568+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|3971]: It took 0.0029s to build the Airflow DAG.
[2025-01-10T16:16:46.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:16:46.584+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.584+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:16:46.609+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:16:46.609+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:16:46.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-10T16:17:16.883+0000] {processor.py:157} INFO - Started process (PID=4056) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:17:16.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:17:16.887+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:16.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:17:16.918+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:16.917+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:17:17.081+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.081+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14089929500005383
[2025-01-10T16:17:17.082+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.082+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4056]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:17:17.082+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.082+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:17:17.083+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.083+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:17:17.083+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.083+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:17:17.084+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.084+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4056]: It took 0.167s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:17:17.087+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.087+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4056]: It took 0.00288s to build the Airflow DAG.
[2025-01-10T16:17:17.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:17:17.106+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.106+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:17:17.135+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:17.134+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:17:17.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-10T16:17:47.263+0000] {processor.py:157} INFO - Started process (PID=4152) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:17:47.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:17:47.266+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:17:47.290+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.289+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:17:47.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.422+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11872015400149394
[2025-01-10T16:17:47.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.422+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4152]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:17:47.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.423+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:17:47.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.423+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:17:47.424+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.424+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:17:47.424+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.424+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4152]: It took 0.135s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:17:47.427+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.427+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4152]: It took 0.00298s to build the Airflow DAG.
[2025-01-10T16:17:47.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:17:47.440+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.440+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:17:47.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:17:47.465+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:17:47.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T16:18:18.104+0000] {processor.py:157} INFO - Started process (PID=4247) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:18:18.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:18:18.108+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:18.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:18:18.138+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:18.138+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:18:23.671+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.671+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 5.515689770998506
[2025-01-10T16:18:23.672+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.672+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4247]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:18:23.672+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.672+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:18:23.673+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.673+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:18:23.673+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.673+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:18:23.674+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.674+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4247]: It took 5.54s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:18:23.678+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.678+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4247]: It took 0.00391s to build the Airflow DAG.
[2025-01-10T16:18:23.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:18:23.691+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.691+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:18:23.712+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:23.712+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:18:23.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 5.631 seconds
[2025-01-10T16:18:54.337+0000] {processor.py:157} INFO - Started process (PID=4379) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:18:54.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:18:54.340+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:18:54.361+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.361+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:18:54.524+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.524+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1491510809992178
[2025-01-10T16:18:54.525+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.525+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4379]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:18:54.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.525+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:18:54.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.526+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:18:54.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.526+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:18:54.527+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.527+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4379]: It took 0.166s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:18:54.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.530+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4379]: It took 0.00335s to build the Airflow DAG.
[2025-01-10T16:18:54.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:18:54.545+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.545+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:18:54.567+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:18:54.567+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:18:54.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-10T16:19:25.191+0000] {processor.py:157} INFO - Started process (PID=4465) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:19:25.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:19:25.194+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:19:25.220+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.220+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:19:25.365+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.364+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13096312400011811
[2025-01-10T16:19:25.365+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.365+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4465]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:19:25.366+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.365+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:19:25.366+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.366+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:19:25.366+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.366+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:19:25.367+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.367+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4465]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:19:25.370+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.370+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4465]: It took 0.00288s to build the Airflow DAG.
[2025-01-10T16:19:25.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:19:25.384+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.384+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:19:25.407+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:25.407+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:19:25.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-10T16:19:55.550+0000] {processor.py:157} INFO - Started process (PID=4551) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:19:55.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:19:55.553+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:19:55.579+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.579+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:19:55.732+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.732+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14046091300042463
[2025-01-10T16:19:55.733+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.733+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4551]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:19:55.734+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.734+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:19:55.734+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.734+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:19:55.735+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.735+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:19:55.735+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.735+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4551]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:19:55.739+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.739+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4551]: It took 0.00397s to build the Airflow DAG.
[2025-01-10T16:19:55.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:19:55.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.753+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:19:55.775+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:19:55.775+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:19:55.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-10T16:20:26.578+0000] {processor.py:157} INFO - Started process (PID=4656) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:20:26.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:20:26.581+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:20:26.602+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.602+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:20:26.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.747+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13100073100031295
[2025-01-10T16:20:26.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.747+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4656]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:20:26.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.748+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:20:26.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.748+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:20:26.749+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.749+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:20:26.749+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.749+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4656]: It took 0.147s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:20:26.753+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.753+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4656]: It took 0.00403s to build the Airflow DAG.
[2025-01-10T16:20:26.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:20:26.768+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.767+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:20:26.790+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:26.790+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:20:26.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-10T16:20:56.911+0000] {processor.py:157} INFO - Started process (PID=4742) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:20:56.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:20:56.917+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:56.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:20:56.943+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:56.943+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:20:57.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.114+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15514313399944513
[2025-01-10T16:20:57.115+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.115+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4742]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:20:57.115+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.115+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:20:57.116+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.116+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:20:57.116+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.116+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:20:57.117+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.117+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4742]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:20:57.119+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.119+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4742]: It took 0.00281s to build the Airflow DAG.
[2025-01-10T16:20:57.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:20:57.135+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.135+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:20:57.161+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:20:57.160+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:20:57.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.274 seconds
[2025-01-10T16:21:27.311+0000] {processor.py:157} INFO - Started process (PID=4830) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:21:27.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:21:27.314+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:21:27.338+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.338+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:21:27.464+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.464+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11226945999987947
[2025-01-10T16:21:27.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.464+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4830]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:21:27.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.465+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:21:27.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.465+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:21:27.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.466+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:21:27.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.466+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4830]: It took 0.128s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:21:27.468+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.468+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4830]: It took 0.0024s to build the Airflow DAG.
[2025-01-10T16:21:27.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:21:27.482+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.482+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:21:27.503+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:27.503+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:21:27.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.214 seconds
[2025-01-10T16:21:57.884+0000] {processor.py:157} INFO - Started process (PID=4933) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:21:57.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:21:57.888+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:57.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:21:57.913+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:57.913+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:21:58.059+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.059+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1315112250013044
[2025-01-10T16:21:58.060+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.060+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|4933]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:21:58.060+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.060+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:21:58.061+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.060+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:21:58.061+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.061+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:21:58.062+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.061+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|4933]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:21:58.065+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.064+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|4933]: It took 0.00301s to build the Airflow DAG.
[2025-01-10T16:21:58.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:21:58.084+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.084+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:21:58.117+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:21:58.117+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:21:58.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-10T16:22:28.466+0000] {processor.py:157} INFO - Started process (PID=5019) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:22:28.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:22:28.470+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:22:28.492+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.492+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:22:28.642+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.642+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1349054479996994
[2025-01-10T16:22:28.643+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.643+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5019]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:22:28.643+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.643+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:22:28.644+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.644+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:22:28.644+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.644+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:22:28.645+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.645+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5019]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:22:28.648+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.648+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5019]: It took 0.00334s to build the Airflow DAG.
[2025-01-10T16:22:28.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:22:28.663+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.663+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:22:28.685+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:28.685+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:22:28.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-10T16:22:59.439+0000] {processor.py:157} INFO - Started process (PID=5105) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:22:59.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:22:59.443+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:22:59.467+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.467+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:22:59.621+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.620+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14161524499832012
[2025-01-10T16:22:59.622+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.622+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5105]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:22:59.622+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.622+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:22:59.623+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.623+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:22:59.623+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.623+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:22:59.624+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.624+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5105]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:22:59.627+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.627+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5105]: It took 0.00324s to build the Airflow DAG.
[2025-01-10T16:22:59.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:22:59.640+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.640+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:22:59.661+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:22:59.661+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:22:59.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T16:23:29.773+0000] {processor.py:157} INFO - Started process (PID=5209) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:23:29.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:23:29.777+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:23:29.800+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.800+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:23:29.959+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.958+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14369459499903314
[2025-01-10T16:23:29.959+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.959+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5209]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:23:29.960+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.960+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:23:29.960+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.960+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:23:29.961+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.961+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:23:29.961+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.961+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5209]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:23:29.966+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.966+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5209]: It took 0.00451s to build the Airflow DAG.
[2025-01-10T16:23:29.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:23:29.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:29.981+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:23:30.005+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:23:30.005+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:23:30.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-10T16:24:00.097+0000] {processor.py:157} INFO - Started process (PID=5295) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:24:00.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:24:00.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:24:00.123+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.122+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:24:00.295+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.295+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1589918800000305
[2025-01-10T16:24:00.295+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.295+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5295]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:24:00.296+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.296+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:24:00.297+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.297+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:24:00.297+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.297+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:24:00.298+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.298+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5295]: It took 0.175s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:24:00.301+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.301+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5295]: It took 0.00341s to build the Airflow DAG.
[2025-01-10T16:24:00.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:24:00.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.315+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:24:00.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:00.338+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:24:00.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-10T16:24:30.445+0000] {processor.py:157} INFO - Started process (PID=5383) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:24:30.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:24:30.448+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:24:30.474+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.474+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:24:30.609+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.609+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12140073900081916
[2025-01-10T16:24:30.609+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.609+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5383]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:24:30.610+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.610+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:24:30.610+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.610+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:24:30.610+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.610+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:24:30.611+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.611+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5383]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:24:30.613+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.613+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5383]: It took 0.00221s to build the Airflow DAG.
[2025-01-10T16:24:30.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:24:30.625+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.625+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:24:30.647+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:24:30.647+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:24:30.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-10T16:25:00.932+0000] {processor.py:157} INFO - Started process (PID=5486) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:25:00.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:25:00.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:00.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:25:00.957+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:00.957+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:25:01.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.110+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1384856109998509
[2025-01-10T16:25:01.111+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.111+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5486]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:25:01.111+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.111+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:25:01.112+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.112+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:25:01.112+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.112+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:25:01.113+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.112+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5486]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:25:01.116+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.116+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5486]: It took 0.00346s to build the Airflow DAG.
[2025-01-10T16:25:01.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:25:01.140+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.140+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:25:01.177+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:01.177+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:25:01.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-10T16:25:31.915+0000] {processor.py:157} INFO - Started process (PID=5572) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:25:31.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:25:31.919+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:31.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:25:31.944+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:31.944+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:25:32.099+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.099+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13769575399965106
[2025-01-10T16:25:32.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.100+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5572]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:25:32.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.100+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:25:32.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.101+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:25:32.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.101+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:25:32.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.101+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5572]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:25:32.104+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.104+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5572]: It took 0.00245s to build the Airflow DAG.
[2025-01-10T16:25:32.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:25:32.120+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.120+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:25:32.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:25:32.151+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:25:32.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.264 seconds
[2025-01-10T16:26:02.259+0000] {processor.py:157} INFO - Started process (PID=5658) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:26:02.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:26:02.264+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:26:02.292+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.292+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:26:02.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.475+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16613966000113578
[2025-01-10T16:26:02.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.475+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5658]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:26:02.476+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.476+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:26:02.477+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.477+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:26:02.477+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.477+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:26:02.478+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.478+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5658]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:26:02.482+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.482+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5658]: It took 0.00448s to build the Airflow DAG.
[2025-01-10T16:26:02.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:26:02.500+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.500+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:26:02.527+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:02.527+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:26:02.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.294 seconds
[2025-01-10T16:26:32.708+0000] {processor.py:157} INFO - Started process (PID=5752) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:26:32.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:26:32.711+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:26:32.731+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.731+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:26:32.900+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.900+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1534271250002348
[2025-01-10T16:26:32.901+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.901+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5752]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:26:32.901+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.901+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:26:32.902+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.901+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:26:32.902+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.902+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:26:32.902+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.902+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5752]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:26:32.906+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.905+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5752]: It took 0.003s to build the Airflow DAG.
[2025-01-10T16:26:32.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:26:32.921+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.921+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:26:32.945+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:26:32.945+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:26:32.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-10T16:27:03.189+0000] {processor.py:157} INFO - Started process (PID=5849) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:27:03.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:27:03.192+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:27:03.214+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.213+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:27:03.353+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.353+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1256133349997981
[2025-01-10T16:27:03.353+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.353+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5849]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:27:03.354+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.354+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:27:03.354+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.354+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:27:03.355+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.355+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:27:03.355+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.355+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5849]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:27:03.358+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.358+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5849]: It took 0.00308s to build the Airflow DAG.
[2025-01-10T16:27:03.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:27:03.373+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.373+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:27:03.397+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:03.397+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:27:03.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.231 seconds
[2025-01-10T16:27:33.525+0000] {processor.py:157} INFO - Started process (PID=5937) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:27:33.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:27:33.528+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:27:33.550+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.549+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:27:33.681+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.681+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11776070900123159
[2025-01-10T16:27:33.681+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.681+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|5937]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:27:33.682+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.682+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:27:33.682+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.682+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:27:33.683+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.683+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:27:33.683+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.683+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|5937]: It took 0.134s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:27:33.686+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.686+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|5937]: It took 0.00286s to build the Airflow DAG.
[2025-01-10T16:27:33.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:27:33.700+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.700+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:27:33.723+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:27:33.723+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:27:33.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.221 seconds
[2025-01-10T16:28:03.793+0000] {processor.py:157} INFO - Started process (PID=6021) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:28:03.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:28:03.796+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:03.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:28:03.824+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:03.824+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:28:04.012+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.012+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17214887800037104
[2025-01-10T16:28:04.013+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.013+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6021]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:28:04.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.014+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:28:04.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.014+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:28:04.015+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.015+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:28:04.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.016+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6021]: It took 0.192s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:28:04.019+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.019+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6021]: It took 0.00341s to build the Airflow DAG.
[2025-01-10T16:28:04.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:28:04.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.034+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:28:04.065+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:04.065+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:28:04.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.297 seconds
[2025-01-10T16:28:34.124+0000] {processor.py:157} INFO - Started process (PID=6126) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:28:34.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:28:34.128+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:28:34.153+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.153+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:28:34.310+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.309+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14140486500036786
[2025-01-10T16:28:34.310+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.310+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6126]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:28:34.311+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.310+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:28:34.311+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.311+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:28:34.312+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.311+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:28:34.312+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.312+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6126]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:28:34.315+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.315+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6126]: It took 0.00295s to build the Airflow DAG.
[2025-01-10T16:28:34.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:28:34.332+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.331+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:28:34.356+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:28:34.356+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:28:34.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-10T16:29:04.843+0000] {processor.py:157} INFO - Started process (PID=6210) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:29:04.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:29:04.846+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:04.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:29:04.865+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:04.865+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:29:05.042+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.042+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1622041149985307
[2025-01-10T16:29:05.042+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.042+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6210]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:29:05.043+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.043+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:29:05.043+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.043+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:29:05.044+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.043+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:29:05.044+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.044+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6210]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:29:05.047+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.047+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6210]: It took 0.00299s to build the Airflow DAG.
[2025-01-10T16:29:05.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:29:05.063+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.063+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:29:05.089+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:05.089+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:29:05.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-10T16:29:35.252+0000] {processor.py:157} INFO - Started process (PID=6298) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:29:35.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:29:35.256+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:29:35.283+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.283+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:29:35.406+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.406+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1100231079999503
[2025-01-10T16:29:35.407+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.407+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6298]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:29:35.407+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.407+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:29:35.408+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.407+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:29:35.408+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.408+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:29:35.408+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.408+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6298]: It took 0.125s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:29:35.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.410+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6298]: It took 0.00224s to build the Airflow DAG.
[2025-01-10T16:29:35.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:29:35.424+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.423+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:29:35.447+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:29:35.447+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:29:35.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-10T16:30:06.358+0000] {processor.py:157} INFO - Started process (PID=6392) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:30:06.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:30:06.362+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:30:06.384+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.384+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:30:06.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.529+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1306762610001897
[2025-01-10T16:30:06.530+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.530+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6392]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:30:06.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.531+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:30:06.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.531+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:30:06.532+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.532+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:30:06.532+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.532+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6392]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:30:06.535+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.534+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6392]: It took 0.0025s to build the Airflow DAG.
[2025-01-10T16:30:06.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:30:06.549+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.549+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:30:06.575+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:06.574+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:30:06.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-10T16:30:36.664+0000] {processor.py:157} INFO - Started process (PID=6491) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:30:36.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:30:36.667+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:30:36.688+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.688+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:30:36.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.813+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11196172099880641
[2025-01-10T16:30:36.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.814+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6491]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:30:36.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.814+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:30:36.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.814+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:30:36.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.815+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:30:36.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.815+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6491]: It took 0.127s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:30:36.817+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.817+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6491]: It took 0.00231s to build the Airflow DAG.
[2025-01-10T16:30:36.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:30:36.830+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:30:36.851+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:30:36.851+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:30:36.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-10T16:31:06.937+0000] {processor.py:157} INFO - Started process (PID=6577) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:31:06.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:31:06.940+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:06.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:31:06.965+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:06.965+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:31:07.099+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.099+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12075657799869077
[2025-01-10T16:31:07.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.099+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6577]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:31:07.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.100+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:31:07.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.100+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:31:07.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.101+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:31:07.101+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.101+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6577]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:31:07.103+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.103+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6577]: It took 0.00226s to build the Airflow DAG.
[2025-01-10T16:31:07.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:31:07.118+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.117+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:31:07.140+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:07.140+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:31:07.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.225 seconds
[2025-01-10T16:31:38.054+0000] {processor.py:157} INFO - Started process (PID=6671) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:31:38.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T16:31:38.057+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:31:38.079+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.079+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T16:31:38.206+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.206+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11317364999922574
[2025-01-10T16:31:38.206+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.206+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6671]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T16:31:38.207+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.207+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T16:31:38.207+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.207+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T16:31:38.208+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.207+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T16:31:38.208+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.208+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6671]: It took 0.129s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T16:31:38.211+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.211+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6671]: It took 0.00276s to build the Airflow DAG.
[2025-01-10T16:31:38.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T16:31:38.224+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.224+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T16:31:38.246+0000] {logging_mixin.py:151} INFO - [2025-01-10T16:31:38.246+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T16:31:38.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.221 seconds
[2025-01-10T18:42:22.736+0000] {processor.py:157} INFO - Started process (PID=6745) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:42:22.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:42:22.743+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:22.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:42:22.800+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:22.799+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:42:23.128+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.128+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.30090340899914736
[2025-01-10T18:42:23.129+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.129+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6745]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:42:23.130+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.130+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:42:23.131+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.131+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:42:23.132+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.132+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:42:23.133+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.133+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6745]: It took 0.334s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:42:23.138+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.137+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6745]: It took 0.00471s to build the Airflow DAG.
[2025-01-10T18:42:23.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:42:23.162+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.162+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:42:23.206+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:23.206+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:42:23.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.509 seconds
[2025-01-10T18:42:53.312+0000] {processor.py:157} INFO - Started process (PID=6832) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:42:53.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:42:53.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:42:53.343+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.342+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:42:53.541+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.541+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18152492700028233
[2025-01-10T18:42:53.542+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.541+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6832]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:42:53.542+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.542+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:42:53.543+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.543+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:42:53.543+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.543+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:42:53.544+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.544+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6832]: It took 0.202s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:42:53.548+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.548+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6832]: It took 0.00376s to build the Airflow DAG.
[2025-01-10T18:42:53.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:42:53.571+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.571+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:42:53.611+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:42:53.610+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:42:53.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.329 seconds
[2025-01-10T18:43:23.722+0000] {processor.py:157} INFO - Started process (PID=6919) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:43:23.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:43:23.727+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:43:23.756+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.756+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:43:23.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.983+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2078462320005201
[2025-01-10T18:43:23.984+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.983+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|6919]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:43:23.984+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.984+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:43:23.985+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.985+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:43:23.985+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.985+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:43:23.986+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.986+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|6919]: It took 0.23s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:43:23.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:23.990+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|6919]: It took 0.00414s to build the Airflow DAG.
[2025-01-10T18:43:23.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:43:24.010+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:24.010+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:43:24.044+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:24.044+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:43:24.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.351 seconds
[2025-01-10T18:43:54.673+0000] {processor.py:157} INFO - Started process (PID=7007) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:43:54.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:43:54.679+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:43:54.714+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.714+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:43:54.935+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.935+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20218439400014176
[2025-01-10T18:43:54.936+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.936+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7007]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:43:54.937+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.937+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:43:54.938+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.937+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:43:54.938+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.938+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:43:54.939+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.939+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7007]: It took 0.225s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:43:54.943+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.943+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7007]: It took 0.00413s to build the Airflow DAG.
[2025-01-10T18:43:54.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:43:54.963+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.963+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:43:54.996+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:43:54.995+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:43:55.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.353 seconds
[2025-01-10T18:44:26.015+0000] {processor.py:157} INFO - Started process (PID=7095) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:44:26.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:44:26.020+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:44:26.053+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.052+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:44:26.294+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.293+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22109288899991952
[2025-01-10T18:44:26.295+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.294+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7095]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:44:26.296+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.295+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:44:26.296+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.296+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:44:26.297+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.297+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:44:26.298+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.297+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7095]: It took 0.245s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:44:26.304+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.303+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7095]: It took 0.00569s to build the Airflow DAG.
[2025-01-10T18:44:26.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:44:26.332+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.332+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:44:26.367+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:26.367+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:44:26.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.385 seconds
[2025-01-10T18:44:56.572+0000] {processor.py:157} INFO - Started process (PID=7190) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:44:56.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:44:56.577+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:44:56.608+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.608+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:44:56.819+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.819+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1900613859997975
[2025-01-10T18:44:56.819+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.819+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7190]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:44:56.820+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.820+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:44:56.821+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.821+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:44:56.821+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.821+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:44:56.822+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.822+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7190]: It took 0.214s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:44:56.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.826+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7190]: It took 0.00395s to build the Airflow DAG.
[2025-01-10T18:44:56.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:44:56.846+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.846+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:44:56.880+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:44:56.880+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:44:56.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.337 seconds
[2025-01-10T18:45:27.045+0000] {processor.py:157} INFO - Started process (PID=7285) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:45:27.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:45:27.050+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:45:27.079+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.079+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:45:27.286+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.285+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18904154299889342
[2025-01-10T18:45:27.286+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.286+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7285]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:45:27.287+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.287+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:45:27.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.288+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:45:27.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.288+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:45:27.289+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.289+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7285]: It took 0.21s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:45:27.293+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.293+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7285]: It took 0.00419s to build the Airflow DAG.
[2025-01-10T18:45:27.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:45:27.314+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.314+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:45:27.349+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:27.349+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:45:27.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.334 seconds
[2025-01-10T18:45:57.522+0000] {processor.py:157} INFO - Started process (PID=7373) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:45:57.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:45:57.528+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:45:57.560+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.559+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:45:57.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.753+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17467741099972045
[2025-01-10T18:45:57.754+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.754+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7373]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:45:57.755+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.755+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:45:57.756+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.756+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:45:57.756+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.756+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:45:57.757+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.757+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7373]: It took 0.198s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:45:57.761+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.761+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7373]: It took 0.00435s to build the Airflow DAG.
[2025-01-10T18:45:57.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:45:57.783+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.783+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:45:57.822+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:45:57.822+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:45:57.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.329 seconds
[2025-01-10T18:46:27.935+0000] {processor.py:157} INFO - Started process (PID=7459) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:46:27.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:46:27.941+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:27.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:46:27.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:27.974+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:46:28.178+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.177+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18343287000061537
[2025-01-10T18:46:28.178+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.178+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7459]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:46:28.179+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.179+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:46:28.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.179+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:46:28.180+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.180+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:46:28.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.181+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7459]: It took 0.206s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:46:28.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.185+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7459]: It took 0.00433s to build the Airflow DAG.
[2025-01-10T18:46:28.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:46:28.207+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.207+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:46:28.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:28.241+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:46:28.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.532 seconds
[2025-01-10T18:46:58.598+0000] {processor.py:157} INFO - Started process (PID=7543) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:46:58.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:46:58.603+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:46:58.632+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.632+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:46:58.852+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.852+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20021432700013975
[2025-01-10T18:46:58.853+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.853+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7543]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:46:58.854+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.853+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:46:58.854+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.854+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:46:58.855+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.855+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:46:58.856+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.855+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7543]: It took 0.224s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:46:58.861+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.860+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7543]: It took 0.00499s to build the Airflow DAG.
[2025-01-10T18:46:58.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:46:58.886+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.885+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:46:58.921+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:46:58.921+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:46:58.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.352 seconds
[2025-01-10T18:47:29.184+0000] {processor.py:157} INFO - Started process (PID=7629) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:47:29.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:47:29.189+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:47:29.221+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.221+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:47:29.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.455+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2163389819997974
[2025-01-10T18:47:29.456+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.456+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7629]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:47:29.457+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.457+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:47:29.458+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.457+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:47:29.458+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.458+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:47:29.459+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.459+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7629]: It took 0.239s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:47:29.463+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.463+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7629]: It took 0.00405s to build the Airflow DAG.
[2025-01-10T18:47:29.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:47:29.486+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.486+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:47:29.522+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:29.522+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:47:29.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.368 seconds
[2025-01-10T18:47:59.604+0000] {processor.py:157} INFO - Started process (PID=7715) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:47:59.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:47:59.608+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:47:59.634+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.633+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:47:59.776+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.776+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12834764000035648
[2025-01-10T18:47:59.777+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.777+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7715]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:47:59.777+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.777+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:47:59.778+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.778+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:47:59.778+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.778+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:47:59.778+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.778+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7715]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:47:59.781+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.781+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7715]: It took 0.00278s to build the Airflow DAG.
[2025-01-10T18:47:59.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:47:59.796+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.795+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:47:59.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:47:59.825+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:48:00.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.430 seconds
[2025-01-10T18:48:30.780+0000] {processor.py:157} INFO - Started process (PID=7809) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:48:30.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:48:30.784+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:48:30.809+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.808+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:48:30.961+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.961+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13811175699993328
[2025-01-10T18:48:30.961+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.961+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7809]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:48:30.962+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.962+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:48:30.962+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.962+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:48:30.963+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.962+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:48:30.963+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.963+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7809]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:48:30.966+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.966+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7809]: It took 0.00327s to build the Airflow DAG.
[2025-01-10T18:48:30.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:48:30.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:30.983+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:48:31.006+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:48:31.006+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:48:31.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-10T18:49:01.062+0000] {processor.py:157} INFO - Started process (PID=7909) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:49:01.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:49:01.066+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:49:01.088+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.088+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:49:01.239+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.239+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1374382419999165
[2025-01-10T18:49:01.239+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.239+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7909]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:49:01.240+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.240+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:49:01.240+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.240+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:49:01.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.240+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:49:01.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.241+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7909]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:49:01.243+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.243+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7909]: It took 0.00256s to build the Airflow DAG.
[2025-01-10T18:49:01.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:49:01.257+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.257+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:49:01.279+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:01.279+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:49:01.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-10T18:49:31.376+0000] {processor.py:157} INFO - Started process (PID=7996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:49:31.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:49:31.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:49:31.401+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.401+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:49:31.566+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.566+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15088632600054552
[2025-01-10T18:49:31.566+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.566+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|7996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:49:31.567+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.567+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:49:31.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.568+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:49:31.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.568+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:49:31.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.569+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|7996]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:49:31.573+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.573+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|7996]: It took 0.00385s to build the Airflow DAG.
[2025-01-10T18:49:31.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:49:31.591+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.590+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:49:31.622+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:49:31.622+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:49:31.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.272 seconds
[2025-01-10T18:50:01.730+0000] {processor.py:157} INFO - Started process (PID=8082) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:50:01.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:50:01.734+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:50:01.757+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.757+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:50:01.924+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.923+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15096029599953908
[2025-01-10T18:50:01.924+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.924+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8082]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:50:01.925+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.925+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:50:01.925+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.925+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:50:01.925+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.925+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:50:01.926+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.926+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8082]: It took 0.169s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:50:01.929+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.929+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8082]: It took 0.00345s to build the Airflow DAG.
[2025-01-10T18:50:01.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:50:01.945+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.945+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:50:01.971+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:01.970+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:50:01.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-10T18:50:32.149+0000] {processor.py:157} INFO - Started process (PID=8188) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:50:32.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:50:32.153+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:50:32.175+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.174+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:50:32.299+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.298+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11072033399977954
[2025-01-10T18:50:32.299+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.299+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8188]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:50:32.300+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.299+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:50:32.300+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.300+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:50:32.300+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.300+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:50:32.301+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.300+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8188]: It took 0.126s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:50:32.303+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.303+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8188]: It took 0.00276s to build the Airflow DAG.
[2025-01-10T18:50:32.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:50:32.318+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.318+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:50:32.491+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:50:32.491+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:50:32.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.363 seconds
[2025-01-10T18:51:02.974+0000] {processor.py:157} INFO - Started process (PID=8271) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:51:02.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:51:02.978+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:02.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:51:02.998+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:02.998+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:51:03.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.164+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15118125900153245
[2025-01-10T18:51:03.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.165+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8271]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:51:03.166+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.166+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:51:03.167+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.167+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:51:03.167+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.167+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:51:03.168+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.168+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8271]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:51:03.172+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.172+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8271]: It took 0.00368s to build the Airflow DAG.
[2025-01-10T18:51:03.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:51:03.188+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.188+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:51:03.210+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:03.210+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:51:03.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-10T18:51:33.271+0000] {processor.py:157} INFO - Started process (PID=8357) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:51:33.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:51:33.274+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:51:33.293+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.293+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:51:33.467+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.466+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15879101700011233
[2025-01-10T18:51:33.467+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.467+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8357]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:51:33.468+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.468+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:51:33.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.468+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:51:33.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.469+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:51:33.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.469+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8357]: It took 0.176s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:51:33.472+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.472+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8357]: It took 0.00267s to build the Airflow DAG.
[2025-01-10T18:51:33.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:51:33.489+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.488+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:51:33.673+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:51:33.673+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:51:33.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.425 seconds
[2025-01-10T18:52:04.181+0000] {processor.py:157} INFO - Started process (PID=8461) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:52:04.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:52:04.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:52:04.211+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.211+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:52:04.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.379+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15387198899952637
[2025-01-10T18:52:04.380+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.380+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8461]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:52:04.381+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.381+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:52:04.381+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.381+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:52:04.382+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.382+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:52:04.383+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.382+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8461]: It took 0.172s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:52:04.387+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.387+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8461]: It took 0.00464s to build the Airflow DAG.
[2025-01-10T18:52:04.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:52:04.411+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.411+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:52:04.448+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:04.448+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:52:04.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-10T18:52:34.917+0000] {processor.py:157} INFO - Started process (PID=8547) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:52:34.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:52:34.923+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:34.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:52:34.951+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:34.951+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:52:35.118+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.118+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15187584300110757
[2025-01-10T18:52:35.119+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.119+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8547]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:52:35.120+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.119+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:52:35.120+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.120+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:52:35.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.120+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:52:35.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.121+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8547]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:52:35.126+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.126+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8547]: It took 0.00463s to build the Airflow DAG.
[2025-01-10T18:52:35.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:52:35.143+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.143+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:52:35.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:52:35.174+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:52:35.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.282 seconds
[2025-01-10T18:53:05.416+0000] {processor.py:157} INFO - Started process (PID=8633) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:53:05.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:53:05.420+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:53:05.448+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.448+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:53:05.630+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.630+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16581601699908788
[2025-01-10T18:53:05.630+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.630+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8633]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:53:05.631+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.631+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:53:05.632+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.631+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:53:05.632+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.632+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:53:05.633+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.632+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8633]: It took 0.185s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:53:05.637+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.636+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8633]: It took 0.00411s to build the Airflow DAG.
[2025-01-10T18:53:05.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:53:05.656+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.656+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:53:05.864+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:05.864+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:53:05.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.471 seconds
[2025-01-10T18:53:36.225+0000] {processor.py:157} INFO - Started process (PID=8725) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:53:36.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:53:36.229+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:53:36.254+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.253+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:53:36.408+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.408+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1403330890007055
[2025-01-10T18:53:36.408+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.408+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8725]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:53:36.409+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.409+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:53:36.409+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.409+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:53:36.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.410+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:53:36.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.410+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8725]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:53:36.413+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.412+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8725]: It took 0.00266s to build the Airflow DAG.
[2025-01-10T18:53:36.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:53:36.429+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.429+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:53:36.453+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:53:36.452+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:53:36.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-10T18:54:06.586+0000] {processor.py:157} INFO - Started process (PID=8823) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:54:06.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:54:06.589+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:54:06.612+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.612+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:54:06.764+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.763+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13786041399907845
[2025-01-10T18:54:06.764+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.764+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8823]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:54:06.765+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.765+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:54:06.765+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.765+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:54:06.766+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.766+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:54:06.766+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.766+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8823]: It took 0.155s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:54:06.770+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.770+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8823]: It took 0.00398s to build the Airflow DAG.
[2025-01-10T18:54:06.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:54:06.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.789+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:54:06.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:06.975+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:54:06.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.414 seconds
[2025-01-10T18:54:37.321+0000] {processor.py:157} INFO - Started process (PID=8910) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:54:37.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:54:37.325+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:54:37.350+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.350+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:54:37.482+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.481+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11653071199907572
[2025-01-10T18:54:37.482+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.482+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|8910]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:54:37.483+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.483+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:54:37.483+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.483+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:54:37.483+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.483+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:54:37.484+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.484+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|8910]: It took 0.134s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:54:37.487+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.487+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|8910]: It took 0.003s to build the Airflow DAG.
[2025-01-10T18:54:37.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:54:37.502+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.502+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:54:37.533+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:54:37.533+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:54:37.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.414 seconds
[2025-01-10T18:55:08.462+0000] {processor.py:157} INFO - Started process (PID=9003) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:55:08.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:55:08.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:55:08.488+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.488+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:55:08.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.635+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.132647377999092
[2025-01-10T18:55:08.636+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.636+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9003]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:55:08.636+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.636+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:55:08.637+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.637+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:55:08.637+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.637+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:55:08.637+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.637+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9003]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:55:08.641+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.641+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9003]: It took 0.00341s to build the Airflow DAG.
[2025-01-10T18:55:08.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:55:08.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.815+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:55:08.838+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:08.838+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:55:08.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.399 seconds
[2025-01-10T18:55:39.139+0000] {processor.py:157} INFO - Started process (PID=9101) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:55:39.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:55:39.142+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:55:39.169+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.168+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:55:39.303+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.303+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12103394500081777
[2025-01-10T18:55:39.304+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.304+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9101]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:55:39.304+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.304+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:55:39.305+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.305+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:55:39.305+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.305+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:55:39.305+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.305+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9101]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:55:39.308+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.308+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9101]: It took 0.00303s to build the Airflow DAG.
[2025-01-10T18:55:39.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:55:39.325+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.324+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:55:39.510+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:55:39.510+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:55:39.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.394 seconds
[2025-01-10T18:56:09.603+0000] {processor.py:157} INFO - Started process (PID=9187) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:56:09.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:56:09.607+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:56:09.630+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.630+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:56:09.805+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.805+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15409264900154085
[2025-01-10T18:56:09.805+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.805+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9187]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:56:09.806+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.806+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:56:09.806+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.806+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:56:09.807+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.807+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:56:09.807+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.807+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9187]: It took 0.178s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:56:09.810+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.810+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9187]: It took 0.00285s to build the Airflow DAG.
[2025-01-10T18:56:09.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:56:09.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.826+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:56:09.855+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:09.855+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:56:10.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.484 seconds
[2025-01-10T18:56:40.500+0000] {processor.py:157} INFO - Started process (PID=9271) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:56:40.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:56:40.503+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:56:40.524+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.524+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:56:40.650+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.650+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11180654099916865
[2025-01-10T18:56:40.650+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.650+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9271]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:56:40.651+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.651+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:56:40.651+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.651+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:56:40.652+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.652+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:56:40.652+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.652+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9271]: It took 0.128s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:56:40.655+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.655+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9271]: It took 0.00276s to build the Airflow DAG.
[2025-01-10T18:56:40.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:56:40.817+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.817+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:56:40.843+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:56:40.843+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:56:40.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.376 seconds
[2025-01-10T18:57:10.939+0000] {processor.py:157} INFO - Started process (PID=9376) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:57:10.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:57:10.942+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:10.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:57:10.965+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:10.964+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:57:11.110+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.110+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13194320299953688
[2025-01-10T18:57:11.111+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.111+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9376]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:57:11.111+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.111+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:57:11.112+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.112+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:57:11.112+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.112+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:57:11.113+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.113+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9376]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:57:11.115+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.115+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9376]: It took 0.00255s to build the Airflow DAG.
[2025-01-10T18:57:11.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:57:11.129+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.129+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:57:11.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:11.151+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:57:11.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-10T18:57:42.079+0000] {processor.py:157} INFO - Started process (PID=9462) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:57:42.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:57:42.083+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:57:42.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.114+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:57:42.256+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.255+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12799649800035695
[2025-01-10T18:57:42.256+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.256+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9462]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:57:42.257+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.257+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:57:42.257+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.257+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:57:42.258+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.258+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:57:42.258+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.258+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9462]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:57:42.261+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.261+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9462]: It took 0.00273s to build the Airflow DAG.
[2025-01-10T18:57:42.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:57:42.277+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.276+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:57:42.301+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:57:42.301+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:57:42.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-10T18:58:12.489+0000] {processor.py:157} INFO - Started process (PID=9548) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:58:12.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:58:12.493+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:58:12.513+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.513+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:58:12.744+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.743+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2168823070005601
[2025-01-10T18:58:12.745+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.744+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9548]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:58:12.746+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.745+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:58:12.746+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.746+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:58:12.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.747+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:58:12.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.748+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9548]: It took 0.234s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:58:12.752+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.752+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9548]: It took 0.00443s to build the Airflow DAG.
[2025-01-10T18:58:12.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:58:12.773+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.773+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:58:12.799+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:12.799+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:58:12.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.328 seconds
[2025-01-10T18:58:43.447+0000] {processor.py:157} INFO - Started process (PID=9653) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:58:43.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:58:43.451+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:58:43.476+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.475+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:58:43.632+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.632+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1423891820013523
[2025-01-10T18:58:43.633+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.633+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9653]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:58:43.633+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.633+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:58:43.634+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.634+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:58:43.634+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.634+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:58:43.634+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.634+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9653]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:58:43.638+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.638+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9653]: It took 0.00362s to build the Airflow DAG.
[2025-01-10T18:58:43.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:58:43.654+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.654+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:58:43.676+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:58:43.676+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:58:43.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-10T18:59:14.071+0000] {processor.py:157} INFO - Started process (PID=9739) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:59:14.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:59:14.074+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:59:14.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.100+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:59:14.242+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.241+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12860143299985793
[2025-01-10T18:59:14.242+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.242+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9739]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:59:14.243+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.243+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:59:14.243+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.243+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:59:14.243+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.243+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:59:14.244+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.244+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9739]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:59:14.247+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.246+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9739]: It took 0.00267s to build the Airflow DAG.
[2025-01-10T18:59:14.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:59:14.261+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.261+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:59:14.285+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:14.285+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:59:14.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-10T18:59:44.824+0000] {processor.py:157} INFO - Started process (PID=9825) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:59:44.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T18:59:44.827+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:44.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:59:44.848+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:44.848+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T18:59:45.005+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.005+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1428987130002497
[2025-01-10T18:59:45.005+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.005+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9825]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T18:59:45.006+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.006+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T18:59:45.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.006+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T18:59:45.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.007+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T18:59:45.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.007+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9825]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T18:59:45.011+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.011+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9825]: It took 0.00384s to build the Airflow DAG.
[2025-01-10T18:59:45.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T18:59:45.027+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.026+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T18:59:45.048+0000] {logging_mixin.py:151} INFO - [2025-01-10T18:59:45.048+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T18:59:45.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-10T19:00:15.561+0000] {processor.py:157} INFO - Started process (PID=9930) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:00:15.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:00:15.564+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:00:15.586+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.585+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:00:15.746+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.746+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14671993999945698
[2025-01-10T19:00:15.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.746+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|9930]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:00:15.747+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.747+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:00:15.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.748+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:00:15.748+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.748+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:00:15.749+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.748+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|9930]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:00:15.751+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.751+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|9930]: It took 0.00279s to build the Airflow DAG.
[2025-01-10T19:00:15.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:00:15.766+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.766+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:00:15.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:15.788+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:00:15.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-10T19:00:46.446+0000] {processor.py:157} INFO - Started process (PID=10016) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:00:46.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:00:46.449+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:00:46.472+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.472+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:00:46.654+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.654+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16869078399940918
[2025-01-10T19:00:46.654+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.654+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10016]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:00:46.655+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.655+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:00:46.655+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.655+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:00:46.656+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.656+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:00:46.656+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.656+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10016]: It took 0.184s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:00:46.659+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.659+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10016]: It took 0.00287s to build the Airflow DAG.
[2025-01-10T19:00:46.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:00:46.673+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.672+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:00:46.696+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:00:46.696+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:00:46.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-10T19:01:16.810+0000] {processor.py:157} INFO - Started process (PID=10104) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:01:16.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:01:16.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:01:16.837+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.836+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:01:16.972+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.972+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12068124799952784
[2025-01-10T19:01:16.972+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.972+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10104]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:01:16.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.973+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:01:16.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.973+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:01:16.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.973+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:01:16.974+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.974+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10104]: It took 0.137s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:01:16.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.976+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10104]: It took 0.00264s to build the Airflow DAG.
[2025-01-10T19:01:16.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:01:16.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:16.990+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:01:17.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:17.014+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:01:17.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-10T19:01:47.968+0000] {processor.py:157} INFO - Started process (PID=10198) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:01:47.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:01:47.971+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:47.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:01:48.006+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.006+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:01:48.182+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.182+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14972159300123167
[2025-01-10T19:01:48.183+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.183+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10198]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:01:48.183+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.183+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:01:48.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.184+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:01:48.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.184+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:01:48.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.185+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10198]: It took 0.179s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:01:48.188+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.188+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10198]: It took 0.00358s to build the Airflow DAG.
[2025-01-10T19:01:48.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:01:48.205+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.204+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:01:48.232+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:01:48.232+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:01:48.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.288 seconds
[2025-01-10T19:02:18.895+0000] {processor.py:157} INFO - Started process (PID=10295) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:02:18.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:02:18.899+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:18.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:02:18.919+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:18.919+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:02:19.063+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.062+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1299102969987871
[2025-01-10T19:02:19.063+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.063+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10295]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:02:19.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.064+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:02:19.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.064+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:02:19.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.064+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:02:19.065+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.065+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10295]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:02:19.068+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.067+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10295]: It took 0.00295s to build the Airflow DAG.
[2025-01-10T19:02:19.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:02:19.082+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.082+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:02:19.105+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:19.105+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:02:19.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-10T19:02:49.573+0000] {processor.py:157} INFO - Started process (PID=10381) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:02:49.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:02:49.578+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:02:49.606+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.606+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:02:49.784+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.784+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.16443362499921932
[2025-01-10T19:02:49.785+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.784+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10381]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:02:49.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.786+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:02:49.787+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.787+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:02:49.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.787+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:02:49.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.788+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10381]: It took 0.183s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:02:49.794+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.794+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10381]: It took 0.00543s to build the Airflow DAG.
[2025-01-10T19:02:49.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:02:49.839+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.839+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:02:49.866+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:02:49.866+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:02:49.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-10T19:03:20.369+0000] {processor.py:157} INFO - Started process (PID=10475) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:03:20.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:03:20.375+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:03:20.407+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.407+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:03:20.591+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.591+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.169832581999799
[2025-01-10T19:03:20.592+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.592+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10475]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:03:20.592+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.592+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:03:20.593+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.593+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:03:20.593+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.593+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:03:20.593+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.593+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10475]: It took 0.186s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:03:20.597+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.596+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10475]: It took 0.00314s to build the Airflow DAG.
[2025-01-10T19:03:20.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:03:20.614+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.614+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:03:20.644+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:20.644+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:03:20.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.301 seconds
[2025-01-10T19:03:51.219+0000] {processor.py:157} INFO - Started process (PID=10572) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:03:51.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:03:51.223+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:03:51.245+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.244+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:03:51.404+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.403+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1457266770012211
[2025-01-10T19:03:51.404+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.404+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10572]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:03:51.405+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.405+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:03:51.406+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.405+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:03:51.406+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.406+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:03:51.407+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.407+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10572]: It took 0.162s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:03:51.411+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.410+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10572]: It took 0.00364s to build the Airflow DAG.
[2025-01-10T19:03:51.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:03:51.428+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.427+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:03:51.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:03:51.464+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:03:51.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-10T19:04:22.060+0000] {processor.py:157} INFO - Started process (PID=10658) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:04:22.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:04:22.065+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:04:22.086+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.086+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:04:22.242+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.241+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1387013809999189
[2025-01-10T19:04:22.242+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.242+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10658]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:04:22.243+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.243+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:04:22.243+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.243+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:04:22.243+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.243+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:04:22.244+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.244+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10658]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:04:22.248+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.248+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10658]: It took 0.00365s to build the Airflow DAG.
[2025-01-10T19:04:22.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:04:22.264+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.263+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:04:22.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:22.287+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:04:22.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-10T19:04:52.840+0000] {processor.py:157} INFO - Started process (PID=10751) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:04:52.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:04:52.845+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:52.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:04:52.867+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:52.866+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:04:53.029+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.029+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14898354599972663
[2025-01-10T19:04:53.029+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.029+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10751]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:04:53.030+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.030+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:04:53.031+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.030+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:04:53.031+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.031+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:04:53.032+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.032+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10751]: It took 0.165s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:04:53.036+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.036+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10751]: It took 0.00433s to build the Airflow DAG.
[2025-01-10T19:04:53.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:04:53.053+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.052+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:04:53.078+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:04:53.078+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:04:53.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-10T19:05:23.523+0000] {processor.py:157} INFO - Started process (PID=10849) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:05:23.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:05:23.526+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:05:23.553+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.553+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:05:23.701+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.700+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13366492400018615
[2025-01-10T19:05:23.701+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.701+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10849]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:05:23.702+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.702+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:05:23.702+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.702+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:05:23.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.702+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:05:23.703+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.703+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10849]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:05:23.706+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.706+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10849]: It took 0.00329s to build the Airflow DAG.
[2025-01-10T19:05:23.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:05:23.720+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.720+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:05:23.743+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:23.743+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:05:23.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-10T19:05:54.254+0000] {processor.py:157} INFO - Started process (PID=10935) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:05:54.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:05:54.258+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:05:54.289+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.288+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:05:54.449+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.449+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14550048700039042
[2025-01-10T19:05:54.450+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.450+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|10935]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:05:54.451+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.450+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:05:54.451+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.451+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:05:54.452+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.451+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:05:54.452+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.452+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|10935]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:05:54.456+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.456+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|10935]: It took 0.00373s to build the Airflow DAG.
[2025-01-10T19:05:54.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:05:54.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.471+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:05:54.494+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:05:54.494+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:05:54.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-10T19:06:24.963+0000] {processor.py:157} INFO - Started process (PID=11021) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:06:24.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:06:24.966+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:24.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:06:24.991+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:24.990+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:06:25.141+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.141+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13622892400053388
[2025-01-10T19:06:25.141+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.141+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11021]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:06:25.142+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.142+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:06:25.143+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.143+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:06:25.143+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.143+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:06:25.144+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.143+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11021]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:06:25.147+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.147+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11021]: It took 0.0036s to build the Airflow DAG.
[2025-01-10T19:06:25.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:06:25.162+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.161+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:06:25.187+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:25.187+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:06:25.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T19:06:55.787+0000] {processor.py:157} INFO - Started process (PID=11126) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:06:55.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:06:55.791+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:06:55.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.816+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:06:55.966+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.966+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13569845300116867
[2025-01-10T19:06:55.966+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.966+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11126]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:06:55.967+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.967+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:06:55.968+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.968+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:06:55.968+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.968+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:06:55.969+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.969+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11126]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:06:55.972+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.972+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11126]: It took 0.00322s to build the Airflow DAG.
[2025-01-10T19:06:55.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:06:55.989+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:55.989+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:06:56.013+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:06:56.013+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:06:56.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-10T19:07:26.110+0000] {processor.py:157} INFO - Started process (PID=11214) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:07:26.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:07:26.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:07:26.137+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.136+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:07:26.266+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.266+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11594834399875253
[2025-01-10T19:07:26.267+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.267+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11214]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:07:26.267+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.267+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:07:26.268+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.268+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:07:26.268+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.268+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:07:26.268+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.268+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11214]: It took 0.132s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:07:26.271+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.271+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11214]: It took 0.00267s to build the Airflow DAG.
[2025-01-10T19:07:26.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:07:26.285+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.285+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:07:26.306+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:26.306+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:07:26.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.216 seconds
[2025-01-10T19:07:57.107+0000] {processor.py:157} INFO - Started process (PID=11298) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:07:57.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:07:57.116+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:07:57.156+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.156+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:07:57.327+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.326+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14691314999981842
[2025-01-10T19:07:57.327+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.327+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11298]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:07:57.328+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.328+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:07:57.328+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.328+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:07:57.329+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.329+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:07:57.329+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.329+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11298]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:07:57.333+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.333+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11298]: It took 0.00409s to build the Airflow DAG.
[2025-01-10T19:07:57.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:07:57.350+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.350+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:07:57.376+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:07:57.376+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:07:57.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.295 seconds
[2025-01-10T19:08:28.256+0000] {processor.py:157} INFO - Started process (PID=11403) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:08:28.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:08:28.260+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:08:28.281+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.281+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:08:28.425+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.425+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13031066700023075
[2025-01-10T19:08:28.425+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.425+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11403]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:08:28.426+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.426+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:08:28.426+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.426+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:08:28.427+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.426+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:08:28.427+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.427+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11403]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:08:28.430+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.430+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11403]: It took 0.0031s to build the Airflow DAG.
[2025-01-10T19:08:28.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:08:28.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.445+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:08:28.472+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:28.472+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:08:28.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T19:08:58.981+0000] {processor.py:157} INFO - Started process (PID=11489) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:08:58.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:08:58.984+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:58.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:08:59.005+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.005+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:08:59.164+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.163+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1448684660008439
[2025-01-10T19:08:59.164+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.164+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11489]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:08:59.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.164+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:08:59.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.165+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:08:59.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.165+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:08:59.166+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.166+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11489]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:08:59.169+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.169+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11489]: It took 0.003s to build the Airflow DAG.
[2025-01-10T19:08:59.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:08:59.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.184+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:08:59.208+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:08:59.208+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:08:59.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-10T19:09:29.538+0000] {processor.py:157} INFO - Started process (PID=11575) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:09:29.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:09:29.543+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:09:29.567+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.567+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:09:29.739+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.739+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15694363900001918
[2025-01-10T19:09:29.739+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.739+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11575]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:09:29.740+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.740+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:09:29.740+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.740+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:09:29.741+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.741+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:09:29.741+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.741+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11575]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:09:29.744+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.744+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11575]: It took 0.00304s to build the Airflow DAG.
[2025-01-10T19:09:29.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:09:29.759+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.759+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:09:29.782+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:29.781+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:09:29.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-10T19:09:59.929+0000] {processor.py:157} INFO - Started process (PID=11670) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:09:59.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:09:59.937+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:59.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:09:59.973+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:09:59.973+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:10:00.220+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.219+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22087409699997806
[2025-01-10T19:10:00.221+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.220+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11670]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:10:00.222+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.222+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:10:00.223+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.222+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:10:00.223+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.223+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:10:00.224+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.224+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11670]: It took 0.251s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:10:00.231+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.230+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11670]: It took 0.00647s to build the Airflow DAG.
[2025-01-10T19:10:00.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:10:00.258+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.257+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:10:00.302+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:00.302+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:10:00.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.421 seconds
[2025-01-10T19:10:30.639+0000] {processor.py:157} INFO - Started process (PID=11767) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:10:30.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:10:30.645+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:10:30.673+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.672+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:10:30.894+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.894+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20352156999979343
[2025-01-10T19:10:30.895+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.895+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11767]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:10:30.896+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.896+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:10:30.897+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.897+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:10:30.898+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.898+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:10:30.898+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.898+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11767]: It took 0.226s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:10:30.903+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.903+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11767]: It took 0.00481s to build the Airflow DAG.
[2025-01-10T19:10:30.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:10:30.923+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.923+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:10:30.956+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:10:30.956+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:10:30.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.349 seconds
[2025-01-10T19:11:01.367+0000] {processor.py:157} INFO - Started process (PID=11853) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:11:01.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:11:01.371+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:11:01.398+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.398+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:11:01.587+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.587+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.17277979200116533
[2025-01-10T19:11:01.587+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.587+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11853]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:11:01.588+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.588+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:11:01.589+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.588+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:11:01.589+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.589+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:11:01.589+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.589+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11853]: It took 0.191s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:11:01.593+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.593+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11853]: It took 0.00359s to build the Airflow DAG.
[2025-01-10T19:11:01.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:11:01.611+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.610+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:11:01.641+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:01.641+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:11:01.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.302 seconds
[2025-01-10T19:11:31.770+0000] {processor.py:157} INFO - Started process (PID=11941) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:11:31.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:11:31.775+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:11:31.803+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.803+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:11:31.943+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.943+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12468334400000458
[2025-01-10T19:11:31.943+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.943+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|11941]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:11:31.944+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.944+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:11:31.945+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.944+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:11:31.945+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.945+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:11:31.945+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.945+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|11941]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:11:31.948+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.948+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|11941]: It took 0.00276s to build the Airflow DAG.
[2025-01-10T19:11:31.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:11:31.965+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.965+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:11:31.992+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:11:31.992+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:11:32.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.248 seconds
[2025-01-10T19:12:02.850+0000] {processor.py:157} INFO - Started process (PID=12027) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:12:02.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:12:02.853+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:02.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:12:02.877+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:02.876+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:12:03.033+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.033+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14330259099915565
[2025-01-10T19:12:03.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.033+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12027]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:12:03.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.034+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:12:03.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.034+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:12:03.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.035+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:12:03.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.035+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12027]: It took 0.159s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:12:03.039+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.039+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12027]: It took 0.00394s to build the Airflow DAG.
[2025-01-10T19:12:03.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:12:03.054+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.054+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:12:03.091+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:03.091+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:12:03.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-10T19:12:33.532+0000] {processor.py:157} INFO - Started process (PID=12121) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:12:33.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:12:33.535+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:12:33.563+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.563+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:12:33.721+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.721+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14304875000016182
[2025-01-10T19:12:33.721+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.721+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12121]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:12:33.722+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.722+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:12:33.722+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.722+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:12:33.723+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.723+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:12:33.723+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.723+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12121]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:12:33.728+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.727+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12121]: It took 0.00431s to build the Airflow DAG.
[2025-01-10T19:12:33.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:12:33.742+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.742+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:12:33.766+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:12:33.766+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:12:33.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-10T19:13:04.295+0000] {processor.py:157} INFO - Started process (PID=12218) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:13:04.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:13:04.299+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:13:04.325+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.324+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:13:04.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.471+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13311962800071342
[2025-01-10T19:13:04.471+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.471+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12218]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:13:04.472+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.472+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:13:04.472+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.472+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:13:04.472+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.472+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:13:04.473+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.473+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12218]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:13:04.475+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.475+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12218]: It took 0.00256s to build the Airflow DAG.
[2025-01-10T19:13:04.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:13:04.490+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.490+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:13:04.512+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:04.512+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:13:04.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-10T19:13:34.953+0000] {processor.py:157} INFO - Started process (PID=12304) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:13:34.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:13:34.956+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:34.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:13:34.981+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:34.981+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:13:35.129+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.129+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13423766100095236
[2025-01-10T19:13:35.129+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.129+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12304]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:13:35.130+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.130+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:13:35.130+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.130+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:13:35.131+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.130+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:13:35.131+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.131+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12304]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:13:35.134+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.134+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12304]: It took 0.00324s to build the Airflow DAG.
[2025-01-10T19:13:35.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:13:35.149+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.149+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:13:35.171+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:13:35.171+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:13:35.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-10T19:14:05.594+0000] {processor.py:157} INFO - Started process (PID=12398) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:14:05.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:14:05.597+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:14:05.621+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.620+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:14:05.775+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.774+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14039058500020474
[2025-01-10T19:14:05.775+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.775+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12398]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:14:05.776+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.776+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:14:05.776+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.776+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:14:05.777+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.777+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:14:05.777+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.777+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12398]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:14:05.780+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.780+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12398]: It took 0.00307s to build the Airflow DAG.
[2025-01-10T19:14:05.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:14:05.796+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.796+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:14:05.822+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:05.822+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:14:05.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-10T19:14:36.189+0000] {processor.py:157} INFO - Started process (PID=12495) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:14:36.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:14:36.192+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:14:36.216+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.216+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:14:36.369+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.369+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13982073700026376
[2025-01-10T19:14:36.370+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.370+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12495]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:14:36.371+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.370+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:14:36.371+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.371+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:14:36.372+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.372+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:14:36.372+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.372+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12495]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:14:36.375+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.375+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12495]: It took 0.0026s to build the Airflow DAG.
[2025-01-10T19:14:36.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:14:36.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.389+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:14:36.413+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:14:36.413+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:14:36.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-10T19:15:06.945+0000] {processor.py:157} INFO - Started process (PID=12581) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:15:06.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:15:06.948+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:06.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:15:06.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:06.975+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:15:07.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.120+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1329944510016503
[2025-01-10T19:15:07.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.121+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12581]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:15:07.121+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.121+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:15:07.122+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.122+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:15:07.122+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.122+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:15:07.123+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.122+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12581]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:15:07.126+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.126+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12581]: It took 0.00333s to build the Airflow DAG.
[2025-01-10T19:15:07.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:15:07.141+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.140+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:15:07.162+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:07.162+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:15:07.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-10T19:15:37.670+0000] {processor.py:157} INFO - Started process (PID=12667) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:15:37.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:15:37.674+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:15:37.698+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.698+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:15:37.870+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.870+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15599927500079502
[2025-01-10T19:15:37.871+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.871+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12667]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:15:37.871+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.871+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:15:37.872+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.872+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:15:37.872+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.872+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:15:37.872+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.872+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12667]: It took 0.174s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:15:37.876+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.876+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12667]: It took 0.00358s to build the Airflow DAG.
[2025-01-10T19:15:37.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:15:37.890+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.890+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:15:37.915+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:15:37.915+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:15:37.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-10T19:16:08.000+0000] {processor.py:157} INFO - Started process (PID=12774) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:16:08.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:16:08.003+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:16:08.026+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.026+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:16:08.163+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.163+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12306413400074234
[2025-01-10T19:16:08.163+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.163+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12774]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:16:08.164+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.164+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:16:08.164+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.164+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:16:08.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.165+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:16:08.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.165+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12774]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:16:08.168+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.168+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12774]: It took 0.00283s to build the Airflow DAG.
[2025-01-10T19:16:08.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:16:08.181+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.181+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:16:08.204+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:08.203+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:16:08.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.226 seconds
[2025-01-10T19:16:38.376+0000] {processor.py:157} INFO - Started process (PID=12862) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:16:38.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:16:38.379+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:16:38.402+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.402+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:16:38.550+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.550+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13388959300027636
[2025-01-10T19:16:38.550+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.550+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12862]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:16:38.551+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.551+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:16:38.551+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.551+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:16:38.552+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.552+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:16:38.552+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.552+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12862]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:16:38.555+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.555+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12862]: It took 0.00285s to build the Airflow DAG.
[2025-01-10T19:16:38.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:16:38.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.569+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:16:38.592+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:16:38.592+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:16:38.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-10T19:17:08.804+0000] {processor.py:157} INFO - Started process (PID=12945) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:17:08.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:17:08.808+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:17:08.831+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.831+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:17:08.974+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.973+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1279545710003731
[2025-01-10T19:17:08.974+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.974+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|12945]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:17:08.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.974+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:17:08.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.975+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:17:08.975+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.975+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:17:08.976+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.976+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|12945]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:17:08.978+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.978+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|12945]: It took 0.00276s to build the Airflow DAG.
[2025-01-10T19:17:08.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:17:08.992+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:08.992+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:17:09.018+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:09.018+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:17:09.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-10T19:17:39.594+0000] {processor.py:157} INFO - Started process (PID=13050) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:17:39.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:17:39.598+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:17:39.623+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.623+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:17:39.781+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.781+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1423183719998633
[2025-01-10T19:17:39.782+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.782+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13050]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:17:39.782+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.782+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:17:39.783+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.783+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:17:39.783+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.783+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:17:39.783+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.783+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13050]: It took 0.16s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:17:39.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.786+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13050]: It took 0.0029s to build the Airflow DAG.
[2025-01-10T19:17:39.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:17:39.801+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.801+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:17:39.823+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:17:39.823+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:17:39.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-10T19:18:10.262+0000] {processor.py:157} INFO - Started process (PID=13136) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:18:10.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:18:10.265+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:18:10.293+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.293+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:18:10.444+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.444+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1373198430010234
[2025-01-10T19:18:10.444+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.444+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13136]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:18:10.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.445+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:18:10.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.445+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:18:10.445+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.445+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:18:10.446+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.446+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13136]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:18:10.448+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.448+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13136]: It took 0.00276s to build the Airflow DAG.
[2025-01-10T19:18:10.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:18:10.462+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.462+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:18:10.485+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:10.484+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:18:10.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-10T19:18:40.994+0000] {processor.py:157} INFO - Started process (PID=13222) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:18:40.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:18:40.999+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:40.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:18:41.018+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.018+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:18:41.164+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.164+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13375904799977434
[2025-01-10T19:18:41.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.165+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13222]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:18:41.165+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.165+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:18:41.166+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.166+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:18:41.166+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.166+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:18:41.167+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.166+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13222]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:18:41.170+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.170+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13222]: It took 0.00347s to build the Airflow DAG.
[2025-01-10T19:18:41.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:18:41.186+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.186+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:18:41.209+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:18:41.209+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:18:41.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-10T19:19:11.601+0000] {processor.py:157} INFO - Started process (PID=13327) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:19:11.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:19:11.606+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:19:11.633+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.633+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:19:11.784+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.784+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1338607060006325
[2025-01-10T19:19:11.784+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.784+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13327]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:19:11.785+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.785+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:19:11.785+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.785+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:19:11.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.786+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:19:11.786+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.786+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13327]: It took 0.153s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:19:11.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.789+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13327]: It took 0.00294s to build the Airflow DAG.
[2025-01-10T19:19:11.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:19:11.805+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.805+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:19:11.829+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:11.829+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:19:11.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-10T19:19:42.313+0000] {processor.py:157} INFO - Started process (PID=13413) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:19:42.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:19:42.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:19:42.339+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.339+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:19:42.489+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.488+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13692003300093347
[2025-01-10T19:19:42.489+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.489+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13413]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:19:42.490+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.490+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:19:42.490+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.490+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:19:42.490+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.490+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:19:42.491+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.491+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13413]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:19:42.494+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.494+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13413]: It took 0.00307s to build the Airflow DAG.
[2025-01-10T19:19:42.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:19:42.507+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.507+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:19:42.531+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:19:42.530+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:19:42.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-10T19:20:13.029+0000] {processor.py:157} INFO - Started process (PID=13499) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:20:13.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:20:13.033+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:20:13.054+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.054+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:20:13.201+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.201+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1332873399987875
[2025-01-10T19:20:13.201+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.201+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13499]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:20:13.202+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.202+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:20:13.202+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.202+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:20:13.203+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.202+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:20:13.203+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.203+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13499]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:20:13.206+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.206+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13499]: It took 0.00342s to build the Airflow DAG.
[2025-01-10T19:20:13.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:20:13.220+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.220+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:20:13.245+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:13.245+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:20:13.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-10T19:20:43.660+0000] {processor.py:157} INFO - Started process (PID=13604) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:20:43.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:20:43.663+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:20:43.691+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.690+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:20:43.838+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.837+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13346468999952776
[2025-01-10T19:20:43.838+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.838+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13604]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:20:43.839+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.839+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:20:43.839+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.839+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:20:43.839+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.839+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:20:43.840+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.840+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13604]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:20:43.843+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.843+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13604]: It took 0.00308s to build the Airflow DAG.
[2025-01-10T19:20:43.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:20:43.858+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.858+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:20:43.882+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:20:43.882+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:20:43.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-10T19:21:14.272+0000] {processor.py:157} INFO - Started process (PID=13690) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:21:14.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:21:14.275+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:21:14.298+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.298+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:21:14.429+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.429+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1181662580002012
[2025-01-10T19:21:14.430+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.430+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13690]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:21:14.430+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.430+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:21:14.431+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.431+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:21:14.431+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.431+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:21:14.431+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.431+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13690]: It took 0.133s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:21:14.434+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.434+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13690]: It took 0.00246s to build the Airflow DAG.
[2025-01-10T19:21:14.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:21:14.447+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.446+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:21:14.469+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:14.469+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:21:14.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-10T19:21:44.849+0000] {processor.py:157} INFO - Started process (PID=13776) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:21:44.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:21:44.854+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:44.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:21:44.879+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:44.879+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:21:45.046+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.046+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15106256100079918
[2025-01-10T19:21:45.046+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.046+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13776]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:21:45.047+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.047+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:21:45.048+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.048+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:21:45.048+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.048+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:21:45.049+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.049+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13776]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:21:45.053+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.052+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13776]: It took 0.0038s to build the Airflow DAG.
[2025-01-10T19:21:45.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:21:45.069+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.068+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:21:45.095+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:21:45.095+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:21:45.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-10T19:22:15.541+0000] {processor.py:157} INFO - Started process (PID=13881) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:22:15.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:22:15.545+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:22:15.570+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.570+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:22:15.711+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.711+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12698881100004655
[2025-01-10T19:22:15.712+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.712+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13881]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:22:15.712+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.712+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:22:15.713+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.713+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:22:15.713+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.713+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:22:15.713+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.713+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13881]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:22:15.717+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.717+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13881]: It took 0.00328s to build the Airflow DAG.
[2025-01-10T19:22:15.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:22:15.731+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.730+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:22:15.755+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:15.755+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:22:15.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-10T19:22:46.260+0000] {processor.py:157} INFO - Started process (PID=13967) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:22:46.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:22:46.264+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:22:46.288+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.287+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:22:46.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.422+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12130448399875604
[2025-01-10T19:22:46.422+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.422+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|13967]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:22:46.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.423+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:22:46.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.423+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:22:46.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.423+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:22:46.424+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.424+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|13967]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:22:46.426+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.426+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|13967]: It took 0.00244s to build the Airflow DAG.
[2025-01-10T19:22:46.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:22:46.440+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.439+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:22:46.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:22:46.465+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:22:46.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.227 seconds
[2025-01-10T19:23:16.812+0000] {processor.py:157} INFO - Started process (PID=14053) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:23:16.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:23:16.815+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:16.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:23:16.841+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:16.841+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:23:17.002+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.001+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14670435800144332
[2025-01-10T19:23:17.002+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.002+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14053]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:23:17.003+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.003+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:23:17.003+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.003+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:23:17.003+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.003+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:23:17.004+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.004+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14053]: It took 0.163s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:23:17.008+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.007+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14053]: It took 0.0037s to build the Airflow DAG.
[2025-01-10T19:23:17.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:23:17.022+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.022+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:23:17.046+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:17.046+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:23:17.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-10T19:23:47.484+0000] {processor.py:157} INFO - Started process (PID=14158) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:23:47.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:23:47.488+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:23:47.508+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.508+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:23:47.650+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.649+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12672366299921123
[2025-01-10T19:23:47.650+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.650+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14158]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:23:47.651+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.651+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:23:47.651+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.651+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:23:47.652+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.652+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:23:47.652+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.652+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14158]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:23:47.656+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.656+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14158]: It took 0.00332s to build the Airflow DAG.
[2025-01-10T19:23:47.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:23:47.670+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.670+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:23:47.695+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:23:47.695+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:23:47.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-10T19:24:18.055+0000] {processor.py:157} INFO - Started process (PID=14244) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:24:18.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:24:18.058+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:24:18.085+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.085+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:24:18.231+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.231+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1318574710003304
[2025-01-10T19:24:18.231+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.231+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14244]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:24:18.232+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.232+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:24:18.232+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.232+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:24:18.233+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.232+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:24:18.233+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.233+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14244]: It took 0.148s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:24:18.236+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.236+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14244]: It took 0.00352s to build the Airflow DAG.
[2025-01-10T19:24:18.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:24:18.250+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.250+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:24:18.272+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:18.271+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:24:18.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-10T19:24:48.601+0000] {processor.py:157} INFO - Started process (PID=14330) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:24:48.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:24:48.605+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:24:48.629+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.629+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:24:48.773+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.773+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13075440100146807
[2025-01-10T19:24:48.774+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.774+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14330]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:24:48.774+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.774+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:24:48.775+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.775+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:24:48.775+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.775+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:24:48.776+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.776+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14330]: It took 0.146s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:24:48.779+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.779+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14330]: It took 0.00308s to build the Airflow DAG.
[2025-01-10T19:24:48.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:24:48.795+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.794+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:24:48.820+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:24:48.820+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:24:48.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-10T19:25:19.249+0000] {processor.py:157} INFO - Started process (PID=14435) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:25:19.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:25:19.254+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:25:19.276+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.275+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:25:19.441+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.441+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15147962199989706
[2025-01-10T19:25:19.442+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.442+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14435]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:25:19.442+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.442+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:25:19.443+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.443+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:25:19.443+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.443+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:25:19.444+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.443+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14435]: It took 0.168s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:25:19.447+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.447+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14435]: It took 0.00353s to build the Airflow DAG.
[2025-01-10T19:25:19.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:25:19.466+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.466+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:25:19.498+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:19.498+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:25:19.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-10T19:25:49.935+0000] {processor.py:157} INFO - Started process (PID=14521) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:25:49.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:25:49.939+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:49.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:25:49.964+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:49.963+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:25:50.102+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.102+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12553069199930178
[2025-01-10T19:25:50.102+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.102+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14521]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:25:50.103+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.103+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:25:50.103+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.103+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:25:50.104+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.104+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:25:50.104+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.104+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14521]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:25:50.107+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.107+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14521]: It took 0.00288s to build the Airflow DAG.
[2025-01-10T19:25:50.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:25:50.122+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.121+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:25:50.146+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:25:50.145+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:25:50.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.231 seconds
[2025-01-10T19:26:20.619+0000] {processor.py:157} INFO - Started process (PID=14607) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:26:20.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:26:20.623+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:26:20.649+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.649+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:26:20.806+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.805+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14012054800150509
[2025-01-10T19:26:20.806+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.806+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14607]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:26:20.807+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.807+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:26:20.807+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.807+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:26:20.807+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.807+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:26:20.808+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.808+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14607]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:26:20.811+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.811+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14607]: It took 0.00371s to build the Airflow DAG.
[2025-01-10T19:26:20.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:26:20.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.826+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:26:20.848+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:20.848+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:26:20.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.251 seconds
[2025-01-10T19:26:51.169+0000] {processor.py:157} INFO - Started process (PID=14712) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:26:51.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:26:51.172+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:26:51.194+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.193+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:26:51.347+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.347+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1405509729993355
[2025-01-10T19:26:51.348+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.348+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14712]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:26:51.349+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.349+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:26:51.349+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.349+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:26:51.350+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.350+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:26:51.350+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.350+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14712]: It took 0.157s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:26:51.354+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.353+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14712]: It took 0.00348s to build the Airflow DAG.
[2025-01-10T19:26:51.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:26:51.368+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.368+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:26:51.394+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:26:51.394+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:26:51.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-10T19:27:21.787+0000] {processor.py:157} INFO - Started process (PID=14798) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:27:21.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:27:21.791+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:27:21.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.813+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:27:21.951+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.951+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1257246639997902
[2025-01-10T19:27:21.952+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.952+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14798]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:27:21.952+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.952+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:27:21.953+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.953+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:27:21.953+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.953+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:27:21.954+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.954+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14798]: It took 0.141s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:27:21.957+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.957+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14798]: It took 0.00277s to build the Airflow DAG.
[2025-01-10T19:27:21.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:27:21.970+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.970+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:27:21.994+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:21.994+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:27:22.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-10T19:27:52.507+0000] {processor.py:157} INFO - Started process (PID=14884) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:27:52.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:27:52.510+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:27:52.534+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.533+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:27:52.685+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.685+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13837005800087354
[2025-01-10T19:27:52.686+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.685+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14884]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:27:52.686+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.686+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:27:52.686+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.686+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:27:52.687+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.687+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:27:52.687+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.687+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14884]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:27:52.691+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.690+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14884]: It took 0.00344s to build the Airflow DAG.
[2025-01-10T19:27:52.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:27:52.706+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.706+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:27:52.729+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:27:52.728+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:27:52.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-10T19:28:23.205+0000] {processor.py:157} INFO - Started process (PID=14989) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:28:23.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:28:23.208+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:28:23.234+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.234+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:28:23.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.389+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14203581199762993
[2025-01-10T19:28:23.389+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.389+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|14989]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:28:23.390+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.390+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:28:23.390+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.390+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:28:23.391+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.391+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:28:23.391+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.391+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|14989]: It took 0.158s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:28:23.395+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.395+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|14989]: It took 0.00362s to build the Airflow DAG.
[2025-01-10T19:28:23.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:28:23.410+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.410+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:28:23.433+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:23.433+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:28:23.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-10T19:28:53.840+0000] {processor.py:157} INFO - Started process (PID=15075) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:28:53.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:28:53.844+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:53.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:28:53.866+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:53.865+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:28:54.006+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.006+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12712631999966106
[2025-01-10T19:28:54.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.006+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15075]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:28:54.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.007+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:28:54.007+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.007+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:28:54.008+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.008+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:28:54.008+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.008+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15075]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:28:54.011+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.011+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15075]: It took 0.00268s to build the Airflow DAG.
[2025-01-10T19:28:54.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:28:54.024+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.024+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:28:54.047+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:28:54.047+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:28:54.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-10T19:29:24.608+0000] {processor.py:157} INFO - Started process (PID=15161) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:29:24.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:29:24.611+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:29:24.637+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.637+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:29:24.787+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.786+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13652919399828534
[2025-01-10T19:29:24.787+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.787+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15161]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:29:24.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.788+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:29:24.788+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.788+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:29:24.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.789+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:29:24.789+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.789+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15161]: It took 0.152s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:29:24.792+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.792+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15161]: It took 0.00295s to build the Airflow DAG.
[2025-01-10T19:29:24.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:29:24.805+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.805+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:29:24.827+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:24.827+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:29:24.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-10T19:29:55.241+0000] {processor.py:157} INFO - Started process (PID=15266) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:29:55.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:29:55.245+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:29:55.270+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.270+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:29:55.431+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.430+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1476459719997365
[2025-01-10T19:29:55.431+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.431+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15266]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:29:55.432+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.432+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:29:55.432+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.432+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:29:55.433+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.433+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:29:55.434+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.433+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15266]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:29:55.438+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.437+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15266]: It took 0.004s to build the Airflow DAG.
[2025-01-10T19:29:55.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:29:55.455+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.455+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:29:55.479+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:29:55.479+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:29:55.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-10T19:30:25.893+0000] {processor.py:157} INFO - Started process (PID=15352) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:30:25.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:30:25.897+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:25.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:30:25.923+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:25.923+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:30:26.071+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.071+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1353121280008054
[2025-01-10T19:30:26.071+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.071+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15352]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:30:26.072+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.072+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:30:26.072+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.072+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:30:26.073+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.073+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:30:26.073+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.073+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15352]: It took 0.151s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:30:26.077+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.076+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15352]: It took 0.00328s to build the Airflow DAG.
[2025-01-10T19:30:26.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:30:26.093+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.092+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:30:26.115+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:26.114+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:30:26.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-10T19:30:56.671+0000] {processor.py:157} INFO - Started process (PID=15438) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:30:56.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:30:56.675+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:30:56.695+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.695+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:30:56.824+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.824+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.11643415199796436
[2025-01-10T19:30:56.825+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.825+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15438]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:30:56.825+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.825+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:30:56.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.826+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:30:56.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.826+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:30:56.827+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.827+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15438]: It took 0.132s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:30:56.830+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.830+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15438]: It took 0.00303s to build the Airflow DAG.
[2025-01-10T19:30:56.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:30:56.843+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.843+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:30:56.866+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:30:56.865+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:30:56.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.214 seconds
[2025-01-10T19:31:27.215+0000] {processor.py:157} INFO - Started process (PID=15532) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:31:27.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:31:27.218+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:31:27.239+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.239+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:31:27.415+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.415+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1620381680004357
[2025-01-10T19:31:27.416+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.416+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15532]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:31:27.417+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.417+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:31:27.418+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.418+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:31:27.419+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.419+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:31:27.420+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.419+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15532]: It took 0.18s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:31:27.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.423+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15532]: It took 0.00383s to build the Airflow DAG.
[2025-01-10T19:31:27.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:31:27.438+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.437+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:31:27.461+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:27.461+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:31:27.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-10T19:31:58.073+0000] {processor.py:157} INFO - Started process (PID=15629) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:31:58.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:31:58.076+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:31:58.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.100+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:31:58.240+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.240+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12709116100086248
[2025-01-10T19:31:58.240+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.240+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15629]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:31:58.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.241+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:31:58.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.241+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:31:58.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.241+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:31:58.242+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.242+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15629]: It took 0.142s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:31:58.244+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.244+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15629]: It took 0.00267s to build the Airflow DAG.
[2025-01-10T19:31:58.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:31:58.259+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.259+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:31:58.282+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:31:58.281+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:31:58.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-10T19:32:28.810+0000] {processor.py:157} INFO - Started process (PID=15715) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:32:28.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:32:28.813+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:32:28.837+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.837+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:32:28.978+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.978+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1281621720008843
[2025-01-10T19:32:28.979+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.979+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15715]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:32:28.979+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.979+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:32:28.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.979+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:32:28.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.980+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:32:28.980+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.980+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15715]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:32:28.983+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.983+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15715]: It took 0.00255s to build the Airflow DAG.
[2025-01-10T19:32:28.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:32:28.997+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:28.997+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:32:29.020+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:29.020+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:32:29.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.231 seconds
[2025-01-10T19:32:59.315+0000] {processor.py:157} INFO - Started process (PID=15820) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:32:59.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:32:59.319+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:32:59.344+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.343+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:32:59.517+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.516+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15757230600138428
[2025-01-10T19:32:59.517+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.517+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15820]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:32:59.518+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.517+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:32:59.518+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.518+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:32:59.518+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.518+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:32:59.519+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.519+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15820]: It took 0.175s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:32:59.522+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.522+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15820]: It took 0.00353s to build the Airflow DAG.
[2025-01-10T19:32:59.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:32:59.540+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.540+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:32:59.565+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:32:59.565+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:32:59.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-10T19:33:30.032+0000] {processor.py:157} INFO - Started process (PID=15906) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:33:30.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:33:30.035+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:33:30.056+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.055+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:33:30.196+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.196+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.127826809999533
[2025-01-10T19:33:30.197+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.196+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15906]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:33:30.197+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.197+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:33:30.198+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.197+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:33:30.198+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.198+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:33:30.198+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.198+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15906]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:33:30.202+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.201+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15906]: It took 0.00308s to build the Airflow DAG.
[2025-01-10T19:33:30.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:33:30.217+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.216+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:33:30.239+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:33:30.239+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:33:30.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-10T19:34:00.645+0000] {processor.py:157} INFO - Started process (PID=15992) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:34:00.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:34:00.648+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:34:00.673+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.673+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:34:00.820+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.820+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13425151000046753
[2025-01-10T19:34:00.821+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.820+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|15992]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:34:00.821+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.821+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:34:00.821+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.821+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:34:00.822+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.822+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:34:00.822+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.822+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|15992]: It took 0.149s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:34:00.825+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.824+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|15992]: It took 0.0025s to build the Airflow DAG.
[2025-01-10T19:34:00.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:34:00.839+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.838+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:34:00.867+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:00.866+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:34:00.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-10T19:34:31.292+0000] {processor.py:157} INFO - Started process (PID=16097) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:34:31.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:34:31.296+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:34:31.316+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.316+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:34:31.485+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.485+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.15521069100213936
[2025-01-10T19:34:31.485+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.485+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16097]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:34:31.486+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.486+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:34:31.486+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.486+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:34:31.487+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.487+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:34:31.487+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.487+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16097]: It took 0.171s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:34:31.491+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.491+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16097]: It took 0.00357s to build the Airflow DAG.
[2025-01-10T19:34:31.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:34:31.508+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.508+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:34:31.540+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:34:31.540+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:34:31.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.270 seconds
[2025-01-10T19:35:01.961+0000] {processor.py:157} INFO - Started process (PID=16183) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:35:01.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:35:01.965+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:01.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:35:01.991+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:01.991+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:35:02.133+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.133+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1300636720006878
[2025-01-10T19:35:02.134+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.134+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16183]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:35:02.134+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.134+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:35:02.135+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.135+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:35:02.135+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.135+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:35:02.136+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.135+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16183]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:35:02.138+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.138+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16183]: It took 0.00257s to build the Airflow DAG.
[2025-01-10T19:35:02.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:35:02.151+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.151+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:35:02.174+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:02.174+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:35:02.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-10T19:35:32.708+0000] {processor.py:157} INFO - Started process (PID=16269) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:35:32.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:35:32.712+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:35:32.735+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.734+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:35:32.902+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.902+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1545401170005789
[2025-01-10T19:35:32.903+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.902+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16269]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:35:32.903+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.903+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:35:32.904+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.904+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:35:32.904+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.904+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:35:32.905+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.905+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16269]: It took 0.17s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:35:32.908+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.908+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16269]: It took 0.00307s to build the Airflow DAG.
[2025-01-10T19:35:32.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:35:32.923+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.923+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:35:32.948+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:35:32.947+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:35:32.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-10T19:36:03.355+0000] {processor.py:157} INFO - Started process (PID=16374) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:36:03.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:36:03.359+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:36:03.385+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.385+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:36:03.533+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.532+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.13264966000133427
[2025-01-10T19:36:03.533+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.533+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16374]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:36:03.534+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.534+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:36:03.534+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.534+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:36:03.535+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.534+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:36:03.535+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.535+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16374]: It took 0.15s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:36:03.538+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.538+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16374]: It took 0.00313s to build the Airflow DAG.
[2025-01-10T19:36:03.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:36:03.553+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.553+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:36:03.575+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:03.575+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:36:03.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-10T19:36:33.906+0000] {processor.py:157} INFO - Started process (PID=16460) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:36:33.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:36:33.909+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:33.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:36:33.933+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:33.932+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:36:34.085+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.085+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1401548649992037
[2025-01-10T19:36:34.086+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.086+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16460]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:36:34.087+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.086+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:36:34.087+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.087+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:36:34.087+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.087+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:36:34.088+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.088+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16460]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:36:34.091+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.091+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16460]: It took 0.00306s to build the Airflow DAG.
[2025-01-10T19:36:34.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:36:34.104+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.104+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:36:34.126+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:36:34.126+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:36:34.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-10T19:37:04.635+0000] {processor.py:157} INFO - Started process (PID=16546) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:37:04.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:37:04.639+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:37:04.661+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.661+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:37:04.797+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.797+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1235485899997002
[2025-01-10T19:37:04.798+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.797+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16546]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:37:04.798+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.798+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:37:04.799+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.798+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:37:04.799+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.799+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:37:04.799+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.799+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16546]: It took 0.139s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:37:04.802+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.802+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16546]: It took 0.00299s to build the Airflow DAG.
[2025-01-10T19:37:04.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:37:04.816+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.815+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:37:04.838+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:04.838+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:37:04.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-10T19:37:35.237+0000] {processor.py:157} INFO - Started process (PID=16651) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:37:35.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:37:35.241+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:37:35.265+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.265+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:37:35.423+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.423+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1449946530010493
[2025-01-10T19:37:35.424+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.424+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16651]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:37:35.425+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.425+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:37:35.425+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.425+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:37:35.426+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.426+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:37:35.426+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.426+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16651]: It took 0.161s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:37:35.429+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.429+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16651]: It took 0.00292s to build the Airflow DAG.
[2025-01-10T19:37:35.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:37:35.443+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.443+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:37:35.465+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:37:35.465+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:37:35.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-10T19:38:05.806+0000] {processor.py:157} INFO - Started process (PID=16737) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:38:05.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:38:05.810+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:38:05.836+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.836+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:38:05.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.990+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14038807000179077
[2025-01-10T19:38:05.990+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.990+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16737]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:38:05.991+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.991+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:38:05.991+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.991+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:38:05.992+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.992+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:38:05.992+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.992+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16737]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:38:05.995+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:05.995+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16737]: It took 0.00299s to build the Airflow DAG.
[2025-01-10T19:38:05.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:38:06.009+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:06.009+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:38:06.030+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:06.030+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:38:06.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-10T19:38:36.406+0000] {processor.py:157} INFO - Started process (PID=16823) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:38:36.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:38:36.409+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:38:36.433+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.433+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:38:36.568+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.568+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12301295900033438
[2025-01-10T19:38:36.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.568+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16823]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:38:36.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.569+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:38:36.569+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.569+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:38:36.570+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.570+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:38:36.570+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.570+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16823]: It took 0.138s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:38:36.573+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.573+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16823]: It took 0.00244s to build the Airflow DAG.
[2025-01-10T19:38:36.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:38:36.586+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.586+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:38:36.609+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:38:36.609+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:38:36.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.223 seconds
[2025-01-10T19:39:07.076+0000] {processor.py:157} INFO - Started process (PID=16917) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:39:07.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:39:07.083+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:39:07.114+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.113+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:39:07.265+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.265+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1258049280004343
[2025-01-10T19:39:07.266+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.266+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|16917]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:39:07.266+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.266+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:39:07.267+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.266+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:39:07.267+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.267+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:39:07.267+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.267+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|16917]: It took 0.154s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:39:07.270+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.270+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|16917]: It took 0.00284s to build the Airflow DAG.
[2025-01-10T19:39:07.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:39:07.286+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.286+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:39:07.311+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:07.311+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:39:07.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-10T19:39:37.856+0000] {processor.py:157} INFO - Started process (PID=17014) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:39:37.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:39:37.860+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:37.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:39:37.881+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:37.880+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:39:38.014+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.014+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12056339099945035
[2025-01-10T19:39:38.015+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.014+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|17014]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:39:38.015+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.015+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:39:38.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.015+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:39:38.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.016+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:39:38.016+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.016+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|17014]: It took 0.136s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:39:38.020+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.020+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|17014]: It took 0.00349s to build the Airflow DAG.
[2025-01-10T19:39:38.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:39:38.034+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.034+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:39:38.056+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:39:38.056+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:39:38.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.223 seconds
[2025-01-10T19:40:08.463+0000] {processor.py:157} INFO - Started process (PID=17100) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:40:08.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:40:08.467+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:40:08.491+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.491+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:40:08.634+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.633+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12975536199883209
[2025-01-10T19:40:08.634+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.634+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|17100]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:40:08.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.634+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:40:08.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.635+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:40:08.635+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.635+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:40:08.636+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.636+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|17100]: It took 0.145s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:40:08.638+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.638+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|17100]: It took 0.0028s to build the Airflow DAG.
[2025-01-10T19:40:08.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:40:08.653+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.653+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:40:08.676+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:08.675+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:40:08.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-10T19:40:39.015+0000] {processor.py:157} INFO - Started process (PID=17206) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:40:39.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:40:39.021+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:40:39.043+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.043+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:40:39.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.184+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1274304310027219
[2025-01-10T19:40:39.184+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.184+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|17206]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:40:39.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.185+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:40:39.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.185+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:40:39.185+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.185+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:40:39.186+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.186+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|17206]: It took 0.143s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:40:39.188+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.188+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|17206]: It took 0.00247s to build the Airflow DAG.
[2025-01-10T19:40:39.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:40:39.201+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.201+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:40:39.224+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:40:39.224+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:40:39.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-10T19:41:09.653+0000] {processor.py:157} INFO - Started process (PID=17292) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:41:09.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:41:09.657+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:41:09.682+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.682+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:41:09.824+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.824+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.12897014999907697
[2025-01-10T19:41:09.825+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.824+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|17292]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:41:09.825+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.825+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:41:09.825+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.825+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:41:09.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.826+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:41:09.826+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.826+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|17292]: It took 0.144s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:41:09.829+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.829+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|17292]: It took 0.00258s to build the Airflow DAG.
[2025-01-10T19:41:09.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:41:09.842+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.842+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:41:09.865+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:09.864+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:41:09.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-10T19:41:40.763+0000] {processor.py:157} INFO - Started process (PID=17378) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:41:40.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T19:41:40.771+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:40.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:41:40.802+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:40.801+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T19:41:41.043+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.042+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2099056639999617
[2025-01-10T19:41:41.044+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.044+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|17378]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T19:41:41.045+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.045+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T19:41:41.046+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.046+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T19:41:41.047+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.047+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T19:41:41.048+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.047+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|17378]: It took 0.246s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T19:41:41.054+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.054+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|17378]: It took 0.00657s to build the Airflow DAG.
[2025-01-10T19:41:41.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T19:41:41.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.100+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T19:41:41.145+0000] {logging_mixin.py:151} INFO - [2025-01-10T19:41:41.145+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T19:41:41.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.430 seconds
[2025-01-10T23:59:43.749+0000] {processor.py:157} INFO - Started process (PID=17397) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T23:59:43.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-10T23:59:43.753+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:43.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T23:59:43.814+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:43.813+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-10T23:59:44.061+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.060+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22099674800119828
[2025-01-10T23:59:44.061+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.061+0000] {graph.py:519} INFO - Cosmos performance [3a8acc926ca7|17397]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 1192
[2025-01-10T23:59:44.062+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.062+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 5ee19ffabafa967868ef96a1741b6b1a,d41d8cd98f00b204e9800998ecf8427e
[2025-01-10T23:59:44.063+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.063+0000] {graph.py:444} INFO - Total nodes: 1
[2025-01-10T23:59:44.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.064+0000] {graph.py:445} INFO - Total filtered nodes: 1
[2025-01-10T23:59:44.064+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.064+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [3a8acc926ca7|17397]: It took 0.252s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-10T23:59:44.069+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.069+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [3a8acc926ca7|17397]: It took 0.00506s to build the Airflow DAG.
[2025-01-10T23:59:44.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-10T23:59:44.100+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.099+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-10T23:59:44.152+0000] {logging_mixin.py:151} INFO - [2025-01-10T23:59:44.151+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-10T00:00:00+00:00, run_after=2025-01-11T00:00:00+00:00
[2025-01-10T23:59:44.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.442 seconds
