[2025-01-07T17:05:26.070+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:05:26.072+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:05:26.074+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:05:26.073+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:05:26.200+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:05:26.354+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:05:26.354+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:05:26.410+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:05:26.409+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-06T17:05:26.409445+00:00, run_after=2025-01-07T17:05:26.409445+00:00
[2025-01-07T17:05:26.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.384 seconds
[2025-01-07T17:05:56.714+0000] {processor.py:153} INFO - Started process (PID=137) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:05:56.718+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:05:56.731+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:05:56.731+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:05:57.386+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:05:57.785+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:05:57.785+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:05:58.688+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:05:58.683+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:05:58.868+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 2.171 seconds
[2025-01-07T17:06:29.927+0000] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:06:29.930+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:06:29.934+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:06:29.932+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:06:30.110+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:06:30.226+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:06:30.226+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:06:30.347+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:06:30.347+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:06:30.465+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.551 seconds
[2025-01-07T17:07:01.160+0000] {processor.py:153} INFO - Started process (PID=288) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:07:01.161+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:07:01.162+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:07:01.162+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:07:01.190+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:07:01.219+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:07:01.219+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:07:01.253+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:07:01.253+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:07:01.281+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.125 seconds
[2025-01-07T17:07:31.340+0000] {processor.py:153} INFO - Started process (PID=368) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:07:31.341+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:07:31.342+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:07:31.342+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:07:31.378+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:07:31.412+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:07:31.412+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:07:31.448+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:07:31.448+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:07:31.476+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.141 seconds
[2025-01-07T17:08:02.192+0000] {processor.py:153} INFO - Started process (PID=448) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:08:02.193+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:08:02.195+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:08:02.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:08:02.260+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:08:02.324+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:08:02.324+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:08:02.388+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:08:02.388+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:08:02.427+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-07T17:08:32.695+0000] {processor.py:153} INFO - Started process (PID=538) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:08:32.697+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:08:32.699+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:08:32.698+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:08:32.750+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:08:32.799+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:08:32.799+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:08:32.858+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:08:32.857+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:08:32.894+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.206 seconds
[2025-01-07T17:09:03.125+0000] {processor.py:153} INFO - Started process (PID=629) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:09:03.128+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:09:03.130+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:09:03.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:09:03.205+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:09:03.285+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:09:03.284+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:09:03.392+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:09:03.392+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:09:03.466+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.348 seconds
[2025-01-07T17:09:34.302+0000] {processor.py:153} INFO - Started process (PID=709) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:09:34.304+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:09:34.305+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:09:34.305+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:09:34.337+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:09:34.375+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:09:34.374+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:09:34.415+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:09:34.415+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:09:34.458+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.163 seconds
[2025-01-07T17:10:05.163+0000] {processor.py:153} INFO - Started process (PID=789) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:10:05.164+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:10:05.166+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:10:05.165+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:10:05.197+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:10:05.230+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:10:05.230+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:10:05.277+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:10:05.277+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:10:05.313+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.156 seconds
[2025-01-07T17:10:36.071+0000] {processor.py:153} INFO - Started process (PID=869) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:10:36.072+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:10:36.073+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:10:36.073+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:10:36.104+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:10:36.132+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:10:36.132+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:10:36.165+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:10:36.165+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:10:36.196+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.129 seconds
[2025-01-07T17:11:06.227+0000] {processor.py:153} INFO - Started process (PID=948) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:11:06.229+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:11:06.229+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:11:06.229+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:11:06.256+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:11:06.282+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:11:06.282+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:11:06.314+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:11:06.314+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:11:06.336+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.112 seconds
[2025-01-07T17:11:36.808+0000] {processor.py:153} INFO - Started process (PID=1028) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:11:36.808+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:11:36.809+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:11:36.809+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:11:36.839+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:11:36.867+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:11:36.867+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:11:36.903+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:11:36.903+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:11:36.949+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.146 seconds
[2025-01-07T17:12:07.771+0000] {processor.py:153} INFO - Started process (PID=1128) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:12:07.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:12:07.773+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:12:07.773+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:12:07.810+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:12:07.852+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:12:07.852+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:12:07.891+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:12:07.890+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:12:07.930+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.164 seconds
[2025-01-07T17:12:38.751+0000] {processor.py:153} INFO - Started process (PID=1208) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:12:38.753+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:12:38.754+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:12:38.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:12:38.785+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:12:38.821+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:12:38.820+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:12:38.868+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:12:38.868+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:12:38.912+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.164 seconds
[2025-01-07T17:13:09.007+0000] {processor.py:153} INFO - Started process (PID=1288) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:13:09.008+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:13:09.009+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:13:09.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:13:09.047+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:13:09.084+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:13:09.084+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:13:09.126+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:13:09.125+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:13:09.164+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.160 seconds
[2025-01-07T17:13:39.644+0000] {processor.py:153} INFO - Started process (PID=1368) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:13:39.645+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:13:39.646+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:13:39.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:13:39.687+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:13:39.729+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:13:39.729+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:13:39.773+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:13:39.772+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:13:39.810+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.169 seconds
[2025-01-07T17:14:09.899+0000] {processor.py:153} INFO - Started process (PID=1468) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:14:09.900+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:14:09.901+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:14:09.901+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:14:09.931+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:14:09.960+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:14:09.959+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:14:09.992+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:14:09.991+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:14:10.017+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.121 seconds
[2025-01-07T17:14:40.317+0000] {processor.py:153} INFO - Started process (PID=1548) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:14:40.321+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:14:40.323+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:14:40.323+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:14:40.369+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:14:40.421+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:14:40.421+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:14:40.477+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:14:40.476+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:14:40.514+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.204 seconds
[2025-01-07T17:15:10.895+0000] {processor.py:153} INFO - Started process (PID=1628) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:15:10.896+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:15:10.897+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:15:10.897+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:15:10.928+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:15:10.957+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:15:10.957+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:15:10.990+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:15:10.990+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:15:11.021+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.131 seconds
[2025-01-07T17:15:41.499+0000] {processor.py:153} INFO - Started process (PID=1728) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:15:41.501+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:15:41.503+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:15:41.502+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:15:41.556+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:15:41.604+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:15:41.604+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:15:41.667+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:15:41.667+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:15:41.713+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.220 seconds
[2025-01-07T17:16:11.923+0000] {processor.py:153} INFO - Started process (PID=1808) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:16:11.924+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:16:11.925+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:16:11.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:16:11.954+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:16:11.981+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:16:11.981+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:16:12.010+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:16:12.010+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:16:12.034+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.114 seconds
[2025-01-07T17:16:42.389+0000] {processor.py:153} INFO - Started process (PID=1888) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:16:42.390+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:16:42.392+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:16:42.392+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:16:42.434+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:16:42.471+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:16:42.471+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:16:42.521+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:16:42.520+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:16:42.561+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.177 seconds
[2025-01-07T17:17:13.010+0000] {processor.py:153} INFO - Started process (PID=1968) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:17:13.010+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:17:13.012+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:17:13.011+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:17:13.046+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:17:13.079+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:17:13.079+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:17:13.116+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:17:13.116+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:17:13.150+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.144 seconds
[2025-01-07T17:17:43.863+0000] {processor.py:153} INFO - Started process (PID=2048) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:17:43.864+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:17:43.866+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:17:43.865+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:17:43.900+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:17:43.933+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:17:43.932+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:17:43.974+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:17:43.974+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:17:44.008+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.150 seconds
[2025-01-07T17:18:14.259+0000] {processor.py:153} INFO - Started process (PID=2148) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:18:14.260+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:18:14.261+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:18:14.261+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:18:14.300+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:18:14.340+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:18:14.340+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:18:14.390+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:18:14.390+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:18:14.433+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.180 seconds
[2025-01-07T17:18:44.528+0000] {processor.py:153} INFO - Started process (PID=2228) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:18:44.529+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:18:44.530+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:18:44.530+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:18:44.563+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:18:44.595+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:18:44.595+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:18:44.630+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:18:44.630+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:18:44.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.130 seconds
[2025-01-07T17:19:15.129+0000] {processor.py:153} INFO - Started process (PID=2308) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:19:15.131+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:19:15.132+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:19:15.132+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:19:15.180+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:19:15.222+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:19:15.222+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:19:15.262+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:19:15.262+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:19:15.296+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.173 seconds
[2025-01-07T17:19:45.854+0000] {processor.py:153} INFO - Started process (PID=2397) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:19:45.855+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:19:45.856+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:19:45.856+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:19:45.886+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:19:45.914+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:19:45.914+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:19:45.948+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:19:45.947+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:19:45.975+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.126 seconds
[2025-01-07T17:20:16.401+0000] {processor.py:153} INFO - Started process (PID=2488) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:20:16.402+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:20:16.403+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:20:16.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:20:16.434+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:20:16.463+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:20:16.463+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:20:16.494+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:20:16.494+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:20:16.518+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.121 seconds
[2025-01-07T17:20:46.803+0000] {processor.py:153} INFO - Started process (PID=2569) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:20:46.805+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:20:46.806+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:20:46.806+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:20:46.867+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:20:46.921+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:20:46.921+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:20:47.002+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:20:47.001+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:20:47.044+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-07T17:21:17.699+0000] {processor.py:153} INFO - Started process (PID=2649) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:21:17.701+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:21:17.703+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:21:17.703+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:21:17.757+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:21:17.817+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:21:17.817+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:21:17.870+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:21:17.869+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:21:17.908+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.216 seconds
[2025-01-07T17:21:48.053+0000] {processor.py:153} INFO - Started process (PID=2729) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:21:48.054+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:21:48.055+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:21:48.055+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:21:48.089+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:21:48.133+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:21:48.133+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:21:48.173+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:21:48.173+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:21:48.203+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.154 seconds
[2025-01-07T17:22:18.586+0000] {processor.py:153} INFO - Started process (PID=2809) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:22:18.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:22:18.589+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:22:18.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:22:18.615+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:22:18.637+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:22:18.637+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:22:18.662+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:22:18.662+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:22:18.680+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.098 seconds
[2025-01-07T17:22:48.847+0000] {processor.py:153} INFO - Started process (PID=2909) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:22:48.848+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:22:48.851+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:22:48.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:22:48.926+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:22:48.992+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:22:48.991+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:22:49.073+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:22:49.073+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:22:49.119+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-07T17:23:19.198+0000] {processor.py:153} INFO - Started process (PID=2989) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:23:19.199+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:23:19.201+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:23:19.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:23:19.245+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:23:19.298+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:23:19.298+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:23:19.383+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:23:19.383+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:23:19.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-07T17:23:49.702+0000] {processor.py:153} INFO - Started process (PID=3069) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:23:49.703+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:23:49.704+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:23:49.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:23:49.730+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:23:49.754+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:23:49.753+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:23:49.779+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:23:49.779+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:23:49.798+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.100 seconds
[2025-01-07T17:24:20.427+0000] {processor.py:153} INFO - Started process (PID=3149) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:24:20.428+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:24:20.430+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:24:20.430+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:24:20.549+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:24:20.600+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:24:20.599+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:24:20.662+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:24:20.662+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:24:20.708+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-07T17:24:50.956+0000] {processor.py:153} INFO - Started process (PID=3229) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:24:50.957+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:24:50.957+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:24:50.957+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:24:50.984+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:24:51.011+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:24:51.011+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:24:51.040+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:24:51.039+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:24:51.075+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.123 seconds
[2025-01-07T17:25:21.527+0000] {processor.py:153} INFO - Started process (PID=3309) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:25:21.529+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:25:21.530+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:25:21.530+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:25:21.570+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:25:21.613+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:25:21.613+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:25:21.662+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:25:21.662+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:25:21.685+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.162 seconds
[2025-01-07T17:25:52.425+0000] {processor.py:153} INFO - Started process (PID=3399) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:25:52.427+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:25:52.428+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:25:52.428+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:25:52.470+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:25:52.516+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:25:52.515+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:25:52.564+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:25:52.564+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:25:52.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.179 seconds
[2025-01-07T17:26:22.900+0000] {processor.py:153} INFO - Started process (PID=3490) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:26:22.902+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:26:22.903+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:26:22.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:26:22.957+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:26:22.997+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:26:22.997+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:26:23.046+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:26:23.046+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:26:23.071+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.177 seconds
[2025-01-07T17:26:53.534+0000] {processor.py:153} INFO - Started process (PID=3570) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:26:53.535+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:26:53.537+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:26:53.536+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:26:53.584+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:26:53.627+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:26:53.627+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:26:53.672+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:26:53.672+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:26:53.714+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.186 seconds
[2025-01-07T17:27:24.644+0000] {processor.py:153} INFO - Started process (PID=3650) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:27:24.645+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:27:24.646+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:27:24.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:27:24.672+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:27:24.699+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:27:24.699+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:27:24.736+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:27:24.736+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:27:24.763+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.122 seconds
[2025-01-07T17:27:55.086+0000] {processor.py:153} INFO - Started process (PID=3730) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:27:55.088+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:27:55.090+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:27:55.089+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:27:55.141+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:27:55.189+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:27:55.188+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:27:55.242+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:27:55.242+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:27:55.278+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.205 seconds
[2025-01-07T17:28:25.606+0000] {processor.py:153} INFO - Started process (PID=3810) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:28:25.608+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:28:25.610+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:28:25.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:28:25.670+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:28:25.726+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:28:25.726+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:28:25.789+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:28:25.788+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:28:25.831+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-07T17:28:56.844+0000] {processor.py:153} INFO - Started process (PID=3899) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:28:56.846+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:28:56.847+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:28:56.847+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:28:56.890+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:28:56.932+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:28:56.932+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:28:57.001+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:28:57.000+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:28:57.042+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.207 seconds
[2025-01-07T17:29:27.215+0000] {processor.py:153} INFO - Started process (PID=3978) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:29:27.217+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:29:27.221+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:29:27.220+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:29:27.287+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:29:27.354+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:29:27.353+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:29:27.434+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:29:27.433+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:29:27.479+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.271 seconds
[2025-01-07T17:29:58.469+0000] {processor.py:153} INFO - Started process (PID=4058) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:29:58.470+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:29:58.472+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:29:58.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:29:58.507+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:29:58.540+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:29:58.540+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:29:58.576+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:29:58.576+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:29:58.604+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.138 seconds
[2025-01-07T17:30:10.851+0000] {processor.py:153} INFO - Started process (PID=4109) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:10.853+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:30:10.854+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:10.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:11.905+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:11.887+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 72, in <module>
    dbt_task = create_dbt_task(dag)
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in create_dbt_task
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:30:11.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:11.966+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.121 seconds
[2025-01-07T17:30:28.300+0000] {processor.py:153} INFO - Started process (PID=4137) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:28.301+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:30:28.303+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:28.303+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:28.748+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:28.737+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 72, in <module>
    dbt_task = create_dbt_task(dag)
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in create_dbt_task
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:30:28.751+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:28.807+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.514 seconds
[2025-01-07T17:30:33.421+0000] {processor.py:153} INFO - Started process (PID=4164) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:33.424+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:30:33.427+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:33.426+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:33.754+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:33.748+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 72, in <module>
    dbt_task = create_dbt_task(dag)
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in create_dbt_task
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:30:33.755+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:33.789+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.381 seconds
[2025-01-07T17:30:50.955+0000] {processor.py:153} INFO - Started process (PID=4211) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:50.957+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:30:50.959+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:50.959+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:51.319+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:51.314+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 72, in <module>
    dbt_task = create_dbt_task(dag)
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in create_dbt_task
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:30:51.320+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:51.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.403 seconds
[2025-01-07T17:30:57.061+0000] {processor.py:153} INFO - Started process (PID=4212) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:57.062+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:30:57.064+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:57.063+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:57.343+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:30:57.336+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 72, in <module>
    dbt_task = create_dbt_task(dag)
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in create_dbt_task
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:30:57.344+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:30:57.379+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-07T17:31:27.898+0000] {processor.py:153} INFO - Started process (PID=4292) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:31:27.900+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:31:27.902+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:31:27.901+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:31:28.232+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:31:28.223+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 72, in <module>
    dbt_task = create_dbt_task(dag)
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in create_dbt_task
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:31:28.234+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:31:28.292+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.399 seconds
[2025-01-07T17:31:58.703+0000] {processor.py:153} INFO - Started process (PID=4372) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:31:58.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:31:58.708+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:31:58.708+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:31:59.140+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:31:59.047+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 72, in <module>
    dbt_task = create_dbt_task(dag)
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in create_dbt_task
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:31:59.149+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:31:59.223+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.525 seconds
[2025-01-07T17:32:27.331+0000] {processor.py:153} INFO - Started process (PID=4452) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:32:27.332+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:32:27.334+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:32:27.333+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:32:27.914+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:32:27.908+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:32:27.915+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:32:27.942+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.620 seconds
[2025-01-07T17:32:38.956+0000] {processor.py:153} INFO - Started process (PID=4483) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:32:38.957+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:32:38.959+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:32:38.959+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:32:39.451+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:32:39.445+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:32:39.452+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:32:39.484+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.536 seconds
[2025-01-07T17:33:09.770+0000] {processor.py:153} INFO - Started process (PID=4561) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:33:09.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:33:09.773+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:33:09.773+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:33:09.974+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:33:09.969+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T17:33:09.975+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:33:10.006+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-07T17:33:37.615+0000] {processor.py:153} INFO - Started process (PID=4626) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:33:37.616+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:33:37.617+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:33:37.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:33:37.679+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:33:37.804+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:33:37.803+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:33:37.856+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:33:37.855+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:33:37.905+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.294 seconds
[2025-01-07T17:34:07.976+0000] {processor.py:153} INFO - Started process (PID=4706) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:07.977+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:34:07.978+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:07.978+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:08.018+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:08.059+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:08.059+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:34:08.101+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:08.101+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:34:08.128+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.157 seconds
[2025-01-07T17:34:38.870+0000] {processor.py:153} INFO - Started process (PID=4786) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:38.871+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:34:38.872+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:38.872+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:38.904+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:38.930+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:38.930+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:34:38.978+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:38.978+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:34:39.010+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.144 seconds
[2025-01-07T17:34:51.375+0000] {processor.py:153} INFO - Started process (PID=4833) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:51.377+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:34:51.378+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:51.378+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:51.601+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:34:51.645+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:51.645+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:34:51.712+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:34:51.712+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:34:51.759+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.393 seconds
[2025-01-07T17:35:22.327+0000] {processor.py:153} INFO - Started process (PID=4913) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:35:22.329+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:35:22.330+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:35:22.330+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:35:22.504+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:35:22.539+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:35:22.538+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:35:22.581+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:35:22.581+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:35:22.620+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-07T17:35:53.106+0000] {processor.py:153} INFO - Started process (PID=4993) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:35:53.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:35:53.109+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:35:53.109+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:35:53.296+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:35:53.330+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:35:53.329+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:35:53.383+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:35:53.382+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:35:53.458+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.358 seconds
[2025-01-07T17:36:24.282+0000] {processor.py:153} INFO - Started process (PID=5073) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:36:24.284+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:36:24.285+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:36:24.285+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:36:24.472+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:36:24.508+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:36:24.508+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:36:24.547+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:36:24.546+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:36:24.573+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.300 seconds
[2025-01-07T17:36:55.087+0000] {processor.py:153} INFO - Started process (PID=5153) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:36:55.088+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:36:55.089+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:36:55.089+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:36:55.260+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:36:55.300+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:36:55.299+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:36:55.343+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:36:55.343+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:36:55.381+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.299 seconds
[2025-01-07T17:37:25.416+0000] {processor.py:153} INFO - Started process (PID=5242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:37:25.417+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:37:25.418+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:37:25.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:37:25.668+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:37:25.703+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:37:25.703+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:37:25.750+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:37:25.750+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:37:25.800+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.389 seconds
[2025-01-07T17:37:55.882+0000] {processor.py:153} INFO - Started process (PID=5333) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:37:55.883+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:37:55.884+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:37:55.884+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:37:56.058+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:37:56.105+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:37:56.104+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:37:56.165+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:37:56.165+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:37:56.203+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-07T17:38:26.307+0000] {processor.py:153} INFO - Started process (PID=5413) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:38:26.312+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:38:26.315+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:38:26.315+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:38:26.715+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:38:26.812+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:38:26.811+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:38:26.912+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:38:26.912+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:38:26.962+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.666 seconds
[2025-01-07T17:38:57.637+0000] {processor.py:153} INFO - Started process (PID=5493) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:38:57.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:38:57.640+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:38:57.639+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:38:57.837+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:38:57.891+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:38:57.891+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:38:57.999+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:38:57.999+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:38:58.055+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.424 seconds
[2025-01-07T17:39:28.570+0000] {processor.py:153} INFO - Started process (PID=5573) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:39:28.572+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:39:28.573+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:39:28.573+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:39:28.729+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:39:28.765+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:39:28.764+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:39:28.812+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:39:28.812+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:39:28.848+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-07T17:39:58.883+0000] {processor.py:153} INFO - Started process (PID=5653) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:39:58.884+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:39:58.885+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:39:58.885+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:39:59.021+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:39:59.060+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:39:59.060+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:39:59.106+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:39:59.106+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:39:59.157+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.278 seconds
[2025-01-07T17:40:29.351+0000] {processor.py:153} INFO - Started process (PID=5733) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:40:29.352+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:40:29.353+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:40:29.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:40:29.473+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:40:29.500+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:40:29.500+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:40:29.528+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:40:29.528+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:40:29.560+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.212 seconds
[2025-01-07T17:41:00.101+0000] {processor.py:153} INFO - Started process (PID=5813) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:41:00.102+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:41:00.104+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:41:00.104+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:41:00.302+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:41:00.338+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:41:00.338+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:41:00.393+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:41:00.392+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:41:00.428+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.334 seconds
[2025-01-07T17:41:30.538+0000] {processor.py:153} INFO - Started process (PID=5892) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:41:30.539+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:41:30.541+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:41:30.541+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:41:30.764+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:41:30.809+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:41:30.809+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:41:30.883+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:41:30.882+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:41:30.924+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.391 seconds
[2025-01-07T17:42:01.416+0000] {processor.py:153} INFO - Started process (PID=5972) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:42:01.417+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:42:01.418+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:42:01.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:42:01.624+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:42:01.664+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:42:01.664+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:42:01.713+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:42:01.713+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:42:01.746+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.334 seconds
[2025-01-07T17:42:32.410+0000] {processor.py:153} INFO - Started process (PID=6052) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:42:32.411+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:42:32.412+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:42:32.412+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:42:32.619+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:42:32.666+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:42:32.666+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:42:32.724+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:42:32.723+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:42:32.763+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.357 seconds
[2025-01-07T17:43:02.989+0000] {processor.py:153} INFO - Started process (PID=6132) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:02.990+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:02.991+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:02.991+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:03.151+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:03.185+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:03.185+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:43:03.216+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:03.216+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:43:03.242+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-07T17:43:23.308+0000] {processor.py:153} INFO - Started process (PID=6183) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:23.310+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:23.311+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:23.311+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:23.594+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:23.645+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:23.645+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:43:23.717+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:23.717+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:43:23.778+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.476 seconds
[2025-01-07T17:43:30.586+0000] {processor.py:153} INFO - Started process (PID=6213) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:30.587+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:30.589+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:30.588+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:30.618+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:30.617+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4
    from airflow, import DAG
                ^
SyntaxError: invalid syntax
[2025-01-07T17:43:30.619+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:30.647+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.065 seconds
[2025-01-07T17:43:33.699+0000] {processor.py:153} INFO - Started process (PID=6214) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:33.700+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:33.701+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:33.701+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:33.729+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:33.728+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4
    from airflow. import DAG
                       ^
SyntaxError: invalid syntax
[2025-01-07T17:43:33.730+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:33.752+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.058 seconds
[2025-01-07T17:43:35.737+0000] {processor.py:153} INFO - Started process (PID=6215) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:35.738+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:35.739+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:35.739+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:35.758+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:35.757+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4
    from airflow. import DAG
                       ^
SyntaxError: invalid syntax
[2025-01-07T17:43:35.759+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:35.788+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.058 seconds
[2025-01-07T17:43:37.822+0000] {processor.py:153} INFO - Started process (PID=6216) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:37.823+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:37.824+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:37.824+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:37.868+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:37.863+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4, in <module>
    from airflow.dags import DAG
ModuleNotFoundError: No module named 'airflow.dags'
[2025-01-07T17:43:37.869+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:37.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.075 seconds
[2025-01-07T17:43:47.775+0000] {processor.py:153} INFO - Started process (PID=6246) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:47.777+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:47.779+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:47.778+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:47.828+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:47.823+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4, in <module>
    from airflow.dags import DA
ModuleNotFoundError: No module named 'airflow.dags'
[2025-01-07T17:43:47.830+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:47.865+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.097 seconds
[2025-01-07T17:43:50.190+0000] {processor.py:153} INFO - Started process (PID=6251) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:50.192+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:50.193+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:50.193+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:50.233+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:50.228+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4, in <module>
    from airflow.dags import DAG
ModuleNotFoundError: No module named 'airflow.dags'
[2025-01-07T17:43:50.235+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:50.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.083 seconds
[2025-01-07T17:43:54.187+0000] {processor.py:153} INFO - Started process (PID=6269) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:54.189+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:43:54.192+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:54.191+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:54.557+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:43:54.548+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 22, in <module>
    with DAG(
NameError: name 'DAG' is not defined
[2025-01-07T17:43:54.564+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:43:54.616+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.439 seconds
[2025-01-07T17:44:07.161+0000] {processor.py:153} INFO - Started process (PID=6299) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:07.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:44:07.163+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:07.163+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:07.200+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:07.193+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4, in <module>
    from airflow.dags import DAG
ModuleNotFoundError: No module named 'airflow.dags'
[2025-01-07T17:44:07.203+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:07.228+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.071 seconds
[2025-01-07T17:44:13.343+0000] {processor.py:153} INFO - Started process (PID=6320) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:13.345+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:44:13.346+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:13.346+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:13.831+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:13.944+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:13.943+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:44:14.001+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:14.001+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:44:14.052+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.718 seconds
[2025-01-07T17:44:44.770+0000] {processor.py:153} INFO - Started process (PID=6401) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:44.771+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:44:44.773+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:44.772+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:44.981+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:44:45.026+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:45.026+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:44:45.081+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:44:45.080+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:44:45.118+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.355 seconds
[2025-01-07T17:45:15.201+0000] {processor.py:153} INFO - Started process (PID=6481) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:45:15.203+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:45:15.204+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:45:15.204+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:45:15.338+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:45:15.371+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:45:15.371+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:45:15.434+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:45:15.433+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:45:15.472+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.277 seconds
[2025-01-07T17:45:46.003+0000] {processor.py:153} INFO - Started process (PID=6562) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:45:46.005+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:45:46.007+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:45:46.007+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:45:46.241+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:45:46.280+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:45:46.280+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:45:46.345+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:45:46.345+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:45:46.385+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.390 seconds
[2025-01-07T17:46:16.606+0000] {processor.py:153} INFO - Started process (PID=6642) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:46:16.607+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:46:16.608+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:46:16.608+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:46:16.748+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:46:16.783+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:46:16.783+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:46:16.821+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:46:16.820+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:46:16.846+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-07T17:46:46.882+0000] {processor.py:153} INFO - Started process (PID=6731) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:46:46.883+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:46:46.884+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:46:46.884+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:46:47.028+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:46:47.063+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:46:47.063+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:46:47.116+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:46:47.115+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:46:47.153+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-07T17:47:17.358+0000] {processor.py:153} INFO - Started process (PID=6822) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:47:17.359+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:47:17.360+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:47:17.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:47:17.546+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:47:17.588+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:47:17.588+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:47:17.649+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:47:17.649+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:47:17.689+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.337 seconds
[2025-01-07T17:47:47.801+0000] {processor.py:153} INFO - Started process (PID=6902) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:47:47.803+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:47:47.805+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:47:47.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:47:48.070+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:47:48.151+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:47:48.151+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:47:48.242+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:47:48.242+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:47:48.305+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.515 seconds
[2025-01-07T17:48:18.638+0000] {processor.py:153} INFO - Started process (PID=6982) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:18.639+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:48:18.640+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:18.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:18.830+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:18.883+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:18.883+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:48:18.951+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:18.951+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:48:18.991+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.358 seconds
[2025-01-07T17:48:23.235+0000] {processor.py:153} INFO - Started process (PID=6994) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:23.237+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:48:23.239+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:23.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:23.517+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:23.507+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 22, in <module>
    with DAG(
NameError: name 'DAG' is not defined
[2025-01-07T17:48:23.520+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:23.557+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-07T17:48:29.444+0000] {processor.py:153} INFO - Started process (PID=7012) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:29.446+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:48:29.448+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:29.447+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:29.503+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:29.501+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4
    from airflow
               ^
SyntaxError: invalid syntax
[2025-01-07T17:48:29.504+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:29.546+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.109 seconds
[2025-01-07T17:48:32.989+0000] {processor.py:153} INFO - Started process (PID=7037) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:32.991+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:48:32.993+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:32.993+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:33.040+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:33.039+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4
    from airflow import
                      ^
SyntaxError: invalid syntax
[2025-01-07T17:48:33.041+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:33.087+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.105 seconds
[2025-01-07T17:48:35.826+0000] {processor.py:153} INFO - Started process (PID=7045) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:35.827+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:48:35.829+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:35.829+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:35.881+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:35.876+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 4, in <module>
    from airflow import D
ImportError: cannot import name 'D' from 'airflow' (/home/airflow/.local/lib/python3.7/site-packages/airflow/__init__.py)
[2025-01-07T17:48:35.883+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:35.921+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.101 seconds
[2025-01-07T17:48:38.914+0000] {processor.py:153} INFO - Started process (PID=7046) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:38.915+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:48:38.916+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:38.916+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:39.127+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:48:39.180+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:39.179+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:48:39.234+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:48:39.234+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:48:39.266+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.356 seconds
[2025-01-07T17:49:09.467+0000] {processor.py:153} INFO - Started process (PID=7126) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:09.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:49:09.471+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:09.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:09.707+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:09.743+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:09.743+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:49:09.795+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:09.795+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:49:09.831+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.371 seconds
[2025-01-07T17:49:39.997+0000] {processor.py:153} INFO - Started process (PID=7207) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:39.999+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:49:40.000+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:40.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:40.193+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:40.229+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:40.229+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:49:40.274+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:40.274+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:49:40.302+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.318 seconds
[2025-01-07T17:49:49.149+0000] {processor.py:153} INFO - Started process (PID=7228) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:49.151+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:49:49.152+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:49.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:49.496+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:49:49.543+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:49.542+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:49:49.601+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:49:49.601+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:49:49.650+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.507 seconds
[2025-01-07T17:50:05.398+0000] {processor.py:153} INFO - Started process (PID=7281) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:05.399+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:50:05.401+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:05.400+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:05.677+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:05.727+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:05.726+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:50:05.790+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:05.790+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:50:05.835+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.442 seconds
[2025-01-07T17:50:13.805+0000] {processor.py:153} INFO - Started process (PID=7309) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:13.807+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:50:13.808+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:13.808+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:13.975+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:14.012+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:14.011+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:50:14.057+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:14.057+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:50:14.112+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.311 seconds
[2025-01-07T17:50:44.291+0000] {processor.py:153} INFO - Started process (PID=7389) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:44.293+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:50:44.294+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:44.294+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:44.557+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:50:44.606+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:44.606+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:50:44.648+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:50:44.648+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:50:44.686+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.401 seconds
[2025-01-07T17:51:14.830+0000] {processor.py:153} INFO - Started process (PID=7469) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:51:14.832+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:51:14.840+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:51:14.840+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:51:15.127+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:51:15.172+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:51:15.171+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:51:15.223+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:51:15.222+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:51:15.269+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.448 seconds
[2025-01-07T17:51:45.466+0000] {processor.py:153} INFO - Started process (PID=7549) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:51:45.467+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:51:45.468+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:51:45.468+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:51:45.614+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:51:45.650+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:51:45.649+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:51:45.693+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:51:45.693+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:51:45.728+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-07T17:52:16.084+0000] {processor.py:153} INFO - Started process (PID=7629) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:52:16.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:52:16.087+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:52:16.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:52:16.324+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:52:16.368+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:52:16.368+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:52:16.422+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:52:16.422+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:52:16.457+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.377 seconds
[2025-01-07T17:52:46.709+0000] {processor.py:153} INFO - Started process (PID=7709) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:52:46.713+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:52:46.716+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:52:46.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:52:47.038+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:52:47.097+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:52:47.097+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:52:47.213+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:52:47.212+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:52:47.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.570 seconds
[2025-01-07T17:53:18.255+0000] {processor.py:153} INFO - Started process (PID=7789) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:18.256+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:53:18.257+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:18.257+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:18.406+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:18.443+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:18.443+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:53:18.505+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:18.504+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:53:18.532+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-07T17:53:35.528+0000] {processor.py:153} INFO - Started process (PID=7826) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:35.530+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:53:35.531+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:35.531+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:35.581+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:35.579+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 20
    'retry_delay': timedelta(minutes=5),
                ^
SyntaxError: invalid syntax
[2025-01-07T17:53:35.583+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:35.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.106 seconds
[2025-01-07T17:53:37.604+0000] {processor.py:153} INFO - Started process (PID=7834) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:37.629+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:53:37.634+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:37.633+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:37.941+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:53:37.982+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:37.981+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:53:38.029+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:53:38.029+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:53:38.080+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.485 seconds
[2025-01-07T17:54:08.647+0000] {processor.py:153} INFO - Started process (PID=7914) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:54:08.649+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:54:08.650+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:54:08.650+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:54:08.863+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:54:08.909+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:54:08.909+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:54:08.958+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:54:08.957+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:54:08.990+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.351 seconds
[2025-01-07T17:54:39.178+0000] {processor.py:153} INFO - Started process (PID=8005) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:54:39.179+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:54:39.181+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:54:39.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:54:39.364+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:54:39.400+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:54:39.400+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:54:39.442+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:54:39.441+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:54:39.483+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.311 seconds
[2025-01-07T17:55:09.596+0000] {processor.py:153} INFO - Started process (PID=8095) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:55:09.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:55:09.600+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:55:09.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:55:09.880+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:55:09.930+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:55:09.930+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:55:09.993+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:55:09.993+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:55:10.032+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.443 seconds
[2025-01-07T17:55:40.163+0000] {processor.py:153} INFO - Started process (PID=8176) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:55:40.164+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:55:40.165+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:55:40.165+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:55:40.337+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:55:40.375+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:55:40.375+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:55:40.419+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:55:40.419+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:55:40.456+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-07T17:56:10.568+0000] {processor.py:153} INFO - Started process (PID=8255) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:56:10.571+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:56:10.573+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:56:10.573+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:56:10.866+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:56:10.932+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:56:10.932+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:56:11.002+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:56:11.002+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:56:11.037+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.477 seconds
[2025-01-07T17:56:41.117+0000] {processor.py:153} INFO - Started process (PID=8335) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:56:41.120+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:56:41.122+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:56:41.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:56:41.463+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:56:41.538+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:56:41.537+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:56:41.619+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:56:41.618+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:56:41.661+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.552 seconds
[2025-01-07T17:57:12.157+0000] {processor.py:153} INFO - Started process (PID=8416) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:57:12.175+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:57:12.180+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:57:12.179+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:57:12.525+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:57:12.591+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:57:12.591+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:57:12.741+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:57:12.741+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:57:12.812+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.666 seconds
[2025-01-07T17:57:43.393+0000] {processor.py:153} INFO - Started process (PID=8496) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:57:43.395+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:57:43.397+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:57:43.397+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:57:43.558+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:57:43.593+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:57:43.593+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:57:43.637+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:57:43.636+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:57:43.665+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-07T17:58:13.725+0000] {processor.py:153} INFO - Started process (PID=8586) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:13.726+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:58:13.727+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:13.727+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:13.859+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:13.888+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:13.888+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:58:13.918+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:13.918+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:58:13.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-07T17:58:44.792+0000] {processor.py:153} INFO - Started process (PID=8677) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:44.793+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:58:44.794+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:44.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:44.907+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:44.934+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:44.934+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:58:44.960+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:44.959+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:58:44.980+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.193 seconds
[2025-01-07T17:58:56.002+0000] {processor.py:153} INFO - Started process (PID=8712) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:56.003+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:58:56.004+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:56.003+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:56.116+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:58:56.140+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:56.140+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:58:56.166+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:58:56.166+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:58:56.192+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.193 seconds
[2025-01-07T17:59:26.314+0000] {processor.py:153} INFO - Started process (PID=8792) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:59:26.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:59:26.317+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:59:26.317+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:59:26.446+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:59:26.473+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:59:26.473+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:59:26.500+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:59:26.499+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:59:26.520+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.212 seconds
[2025-01-07T17:59:56.551+0000] {processor.py:153} INFO - Started process (PID=8892) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:59:56.552+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T17:59:56.553+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:59:56.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:59:56.760+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T17:59:56.789+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:59:56.789+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T17:59:56.821+0000] {logging_mixin.py:137} INFO - [2025-01-07T17:59:56.821+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T17:05:26.409445+00:00, run_after=2025-01-08T17:05:26.409445+00:00
[2025-01-07T17:59:56.844+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.298 seconds
[2025-01-07T18:00:06.477+0000] {processor.py:153} INFO - Started process (PID=8910) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:06.478+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:00:06.479+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:06.479+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:06.630+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:06.625+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T18:00:06.631+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:06.649+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.175 seconds
[2025-01-07T18:00:14.804+0000] {processor.py:153} INFO - Started process (PID=8938) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:14.806+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:00:14.807+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:14.807+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:14.971+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:14.967+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T18:00:14.972+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:14.991+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.192 seconds
[2025-01-07T18:00:23.148+0000] {processor.py:153} INFO - Started process (PID=8974) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:23.149+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:00:23.150+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:23.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:23.279+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:23.273+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T18:00:23.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:23.298+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.153 seconds
[2025-01-07T18:00:24.158+0000] {processor.py:153} INFO - Started process (PID=8975) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:24.159+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:00:24.160+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:24.160+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:24.307+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:24.301+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T18:00:24.308+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:24.326+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.171 seconds
[2025-01-07T18:00:55.193+0000] {processor.py:153} INFO - Started process (PID=9055) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:55.194+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:00:55.195+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:55.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:55.326+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:00:55.321+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_project.yml
[2025-01-07T18:00:55.326+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:00:55.343+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.153 seconds
[2025-01-07T18:01:20.937+0000] {processor.py:153} INFO - Started process (PID=9135) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:20.938+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:01:20.939+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:20.939+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:21.077+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:21.071+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stoc/dbt_project.yml
[2025-01-07T18:01:21.078+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:21.095+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.161 seconds
[2025-01-07T18:01:24.145+0000] {processor.py:153} INFO - Started process (PID=9156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:24.146+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:01:24.147+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:24.147+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:24.297+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:24.291+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T18:01:24.298+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:24.320+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.179 seconds
[2025-01-07T18:01:28.176+0000] {processor.py:153} INFO - Started process (PID=9157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:28.176+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:01:28.177+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:28.177+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:28.310+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:28.306+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T18:01:28.311+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:28.330+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.158 seconds
[2025-01-07T18:01:58.662+0000] {processor.py:153} INFO - Started process (PID=9238) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:58.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:01:58.664+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:58.664+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:58.776+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:01:58.771+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T18:01:58.777+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:01:58.794+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.134 seconds
[2025-01-07T18:02:19.401+0000] {processor.py:153} INFO - Started process (PID=9309) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:19.402+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:02:19.403+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:19.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:19.569+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:19.558+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],  # Specify the dbt command (e.g., 'run', 'test', 'docs generate', etc.)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:02:19.570+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:19.591+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.194 seconds
[2025-01-07T18:02:20.778+0000] {processor.py:153} INFO - Started process (PID=9313) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:20.779+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:02:20.780+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:20.780+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:21.009+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:21.003+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    catchup=False
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T18:02:21.010+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:21.039+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-07T18:02:26.393+0000] {processor.py:153} INFO - Started process (PID=9320) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:26.395+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:02:26.397+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:26.397+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:26.574+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:26.569+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],  # Specify the dbt command (e.g., 'run', 'test', 'docs generate', etc.)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:02:26.575+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:26.601+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.212 seconds
[2025-01-07T18:02:30.459+0000] {processor.py:153} INFO - Started process (PID=9341) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:30.460+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:02:30.462+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:30.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:30.607+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:02:30.601+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:02:30.607+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:02:30.627+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.173 seconds
[2025-01-07T18:03:01.288+0000] {processor.py:153} INFO - Started process (PID=9420) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:03:01.289+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:03:01.290+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:03:01.290+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:03:01.400+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:03:01.394+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:03:01.400+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:03:01.432+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.148 seconds
[2025-01-07T18:05:24.138+0000] {processor.py:153} INFO - Started process (PID=63) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:05:24.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:05:24.144+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:05:24.143+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:05:24.862+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:05:24.805+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:05:24.863+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:05:24.903+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.773 seconds
[2025-01-07T18:05:55.066+0000] {processor.py:153} INFO - Started process (PID=145) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:05:55.067+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:05:55.068+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:05:55.068+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:05:55.184+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:05:55.176+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:05:55.185+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:05:55.205+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.142 seconds
[2025-01-07T18:06:00.949+0000] {processor.py:153} INFO - Started process (PID=204) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:00.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:06:00.952+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:00.951+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:01.109+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:01.105+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:06:01.110+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:01.139+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.195 seconds
[2025-01-07T18:06:06.004+0000] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:06.005+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:06:06.006+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:06.006+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:06.032+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:06.031+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 29
    schedule=@daily,
             ^
SyntaxError: invalid syntax
[2025-01-07T18:06:06.033+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:06.053+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.052 seconds
[2025-01-07T18:06:36.561+0000] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:36.562+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:06:36.563+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:36.563+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:36.578+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:36.577+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 29
    schedule=@daily,
             ^
SyntaxError: invalid syntax
[2025-01-07T18:06:36.578+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:36.606+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.048 seconds
[2025-01-07T18:06:59.479+0000] {processor.py:153} INFO - Started process (PID=343) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:59.481+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:06:59.482+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:59.482+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:59.732+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:06:59.705+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:06:59.735+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:06:59.782+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.311 seconds
[2025-01-07T18:07:30.691+0000] {processor.py:153} INFO - Started process (PID=423) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:07:30.692+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:07:30.693+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:07:30.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:07:30.827+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:07:30.821+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:07:30.828+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:07:30.851+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.162 seconds
[2025-01-07T18:07:39.737+0000] {processor.py:153} INFO - Started process (PID=467) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:07:39.738+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:07:39.739+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:07:39.739+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:07:39.871+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:07:39.867+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:07:39.872+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:07:39.900+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.166 seconds
[2025-01-07T18:08:10.473+0000] {processor.py:153} INFO - Started process (PID=547) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:08:10.474+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:08:10.475+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:08:10.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:08:10.588+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:08:10.582+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:08:10.589+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:08:10.616+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.145 seconds
[2025-01-07T18:10:48.302+0000] {processor.py:153} INFO - Started process (PID=62) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:10:48.303+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:10:48.304+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:10:48.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:10:48.801+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:10:48.797+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:10:48.802+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:10:48.827+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.532 seconds
[2025-01-07T18:11:19.137+0000] {processor.py:153} INFO - Started process (PID=142) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:11:19.138+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:11:19.139+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:11:19.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:11:19.260+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:11:19.254+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:11:19.261+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:11:19.290+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.156 seconds
[2025-01-07T18:11:49.625+0000] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:11:49.626+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:11:49.627+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:11:49.627+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:11:49.763+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:11:49.758+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:11:49.764+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:11:49.787+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.166 seconds
[2025-01-07T18:12:19.896+0000] {processor.py:153} INFO - Started process (PID=322) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:12:19.897+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:12:19.898+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:12:19.898+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:12:20.015+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:12:20.009+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 51, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'profile_config'
[2025-01-07T18:12:20.015+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:12:20.041+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.148 seconds
[2025-01-07T18:12:31.005+0000] {processor.py:153} INFO - Started process (PID=382) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:12:31.006+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:12:31.008+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:12:31.007+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:12:31.175+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:12:31.169+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:12:31.176+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:12:31.204+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.203 seconds
[2025-01-07T18:13:01.251+0000] {processor.py:153} INFO - Started process (PID=462) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:01.252+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:13:01.253+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:01.253+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:01.367+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:01.361+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:13:01.367+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:01.385+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.137 seconds
[2025-01-07T18:13:31.597+0000] {processor.py:153} INFO - Started process (PID=542) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:31.598+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:13:31.599+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:31.599+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:31.734+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:31.729+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:13:31.735+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:31.756+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.163 seconds
[2025-01-07T18:13:48.763+0000] {processor.py:153} INFO - Started process (PID=583) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:48.764+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:13:48.765+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:48.765+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:48.905+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:48.899+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:13:48.905+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:48.923+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.163 seconds
[2025-01-07T18:13:53.351+0000] {processor.py:153} INFO - Started process (PID=602) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:53.353+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:13:53.356+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:53.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:53.582+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:53.576+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:13:53.583+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:53.601+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-07T18:13:56.230+0000] {processor.py:153} INFO - Started process (PID=624) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:56.231+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:13:56.232+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:56.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:56.263+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:56.262+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 27
    profile_name="default",   or whichever profile name you want to use#
                               ^
SyntaxError: invalid syntax
[2025-01-07T18:13:56.265+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:56.284+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.056 seconds
[2025-01-07T18:13:58.325+0000] {processor.py:153} INFO - Started process (PID=645) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:58.326+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:13:58.327+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:58.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:58.455+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:13:58.448+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:13:58.456+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:13:58.474+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.152 seconds
[2025-01-07T18:14:00.343+0000] {processor.py:153} INFO - Started process (PID=646) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:00.344+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:14:00.345+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:00.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:00.475+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:00.469+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:14:00.475+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:00.494+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.154 seconds
[2025-01-07T18:14:31.469+0000] {processor.py:153} INFO - Started process (PID=726) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:31.470+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:14:31.471+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:31.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:31.580+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:31.577+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:14:31.581+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:31.597+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.132 seconds
[2025-01-07T18:14:43.616+0000] {processor.py:153} INFO - Started process (PID=747) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:43.617+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:14:43.618+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:43.618+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:43.649+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:43.648+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 7
    from
        ^
SyntaxError: invalid syntax
[2025-01-07T18:14:43.650+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:43.669+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.056 seconds
[2025-01-07T18:14:50.657+0000] {processor.py:153} INFO - Started process (PID=768) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:50.658+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:14:50.659+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:50.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:50.793+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:50.787+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 6, in <module>
    from cosmos import ProfileConfi
ImportError: cannot import name 'ProfileConfi' from 'cosmos' (/home/airflow/.local/lib/python3.7/site-packages/cosmos/__init__.py)
[2025-01-07T18:14:50.794+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:50.812+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.158 seconds
[2025-01-07T18:14:55.142+0000] {processor.py:153} INFO - Started process (PID=794) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:55.144+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:14:55.145+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:55.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:55.285+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:14:55.280+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:14:55.286+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:14:55.305+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.166 seconds
[2025-01-07T18:15:25.874+0000] {processor.py:153} INFO - Started process (PID=893) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:15:25.876+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:15:25.876+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:15:25.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:15:26.000+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:15:25.994+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:15:26.000+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:15:26.022+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.151 seconds
[2025-01-07T18:15:56.253+0000] {processor.py:153} INFO - Started process (PID=974) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:15:56.254+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:15:56.256+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:15:56.255+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:15:56.450+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:15:56.441+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:15:56.452+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:15:56.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-07T18:16:26.513+0000] {processor.py:153} INFO - Started process (PID=1052) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:16:26.514+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:16:26.515+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:16:26.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:16:26.636+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:16:26.631+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:16:26.637+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:16:26.655+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.145 seconds
[2025-01-07T18:16:56.993+0000] {processor.py:153} INFO - Started process (PID=1152) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:16:56.994+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:16:56.995+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:16:56.995+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:16:57.101+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:16:57.095+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:16:57.102+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:16:57.123+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.134 seconds
[2025-01-07T18:17:27.931+0000] {processor.py:153} INFO - Started process (PID=1232) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:17:27.933+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:17:27.934+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:17:27.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:17:28.055+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:17:28.050+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:17:28.056+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:17:28.077+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.149 seconds
[2025-01-07T18:17:58.820+0000] {processor.py:153} INFO - Started process (PID=1331) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:17:58.821+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:17:58.822+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:17:58.822+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:17:58.932+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:17:58.927+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:17:58.932+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:17:58.951+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.134 seconds
[2025-01-07T18:18:29.058+0000] {processor.py:153} INFO - Started process (PID=1400) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:18:29.062+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:18:29.066+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:18:29.065+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:18:29.431+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:18:29.422+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:18:29.432+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:18:29.473+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.431 seconds
[2025-01-07T18:40:42.196+0000] {processor.py:153} INFO - Started process (PID=80) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:40:42.198+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:40:42.200+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:40:42.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:40:42.786+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:40:42.770+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:40:42.787+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:40:42.847+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.660 seconds
[2025-01-07T18:41:13.299+0000] {processor.py:153} INFO - Started process (PID=160) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:41:13.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:41:13.301+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:41:13.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:41:13.426+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:41:13.421+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:41:13.427+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:41:13.449+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.153 seconds
[2025-01-07T18:41:43.693+0000] {processor.py:153} INFO - Started process (PID=240) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:41:43.695+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:41:43.695+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:41:43.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:41:43.851+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:41:43.845+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:41:43.851+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:41:43.874+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.185 seconds
[2025-01-07T18:42:14.137+0000] {processor.py:153} INFO - Started process (PID=321) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:14.138+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:42:14.139+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:42:14.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:14.249+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:42:14.243+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:42:14.249+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:14.266+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.132 seconds
[2025-01-07T18:42:44.509+0000] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:44.511+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:42:44.513+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:42:44.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:44.689+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:42:44.684+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 57, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:42:44.689+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:44.712+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.211 seconds
[2025-01-07T18:42:51.593+0000] {processor.py:153} INFO - Started process (PID=454) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:51.594+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:42:51.595+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:42:51.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:51.736+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:42:51.730+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:42:51.737+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:42:51.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.168 seconds
[2025-01-07T18:43:21.979+0000] {processor.py:153} INFO - Started process (PID=534) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:43:21.980+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:43:21.981+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:43:21.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:43:22.137+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:43:22.133+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:43:22.138+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:43:22.166+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.191 seconds
[2025-01-07T18:43:52.396+0000] {processor.py:153} INFO - Started process (PID=623) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:43:52.398+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:43:52.399+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:43:52.399+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:43:52.673+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:43:52.667+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:43:52.674+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:43:52.707+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.316 seconds
[2025-01-07T18:44:22.909+0000] {processor.py:153} INFO - Started process (PID=719) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:22.909+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:44:22.910+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:44:22.910+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:23.014+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:44:23.008+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:44:23.015+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:23.034+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.128 seconds
[2025-01-07T18:44:53.498+0000] {processor.py:153} INFO - Started process (PID=799) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:53.499+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:44:53.500+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:44:53.499+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:53.610+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:44:53.603+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 58, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:44:53.611+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:53.630+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.135 seconds
[2025-01-07T18:44:53.799+0000] {processor.py:153} INFO - Started process (PID=804) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:53.801+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:44:53.802+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:44:53.802+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:53.978+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:44:53.971+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:44:53.979+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:44:54.002+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.206 seconds
[2025-01-07T18:45:24.223+0000] {processor.py:153} INFO - Started process (PID=880) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:45:24.224+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:45:24.225+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:45:24.225+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:45:24.330+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:45:24.324+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:45:24.331+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:45:24.348+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.128 seconds
[2025-01-07T18:45:29.953+0000] {processor.py:153} INFO - Started process (PID=912) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:45:29.954+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:45:29.955+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:45:29.955+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:45:30.077+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:45:30.070+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:45:30.077+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:45:30.094+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.145 seconds
[2025-01-07T18:46:00.135+0000] {processor.py:153} INFO - Started process (PID=992) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:46:00.136+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:46:00.137+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:46:00.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:46:00.270+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:46:00.266+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:46:00.270+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:46:00.291+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.158 seconds
[2025-01-07T18:46:30.476+0000] {processor.py:153} INFO - Started process (PID=1072) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:46:30.477+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:46:30.478+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:46:30.478+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:46:30.585+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:46:30.579+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:46:30.585+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:46:30.603+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.130 seconds
[2025-01-07T18:47:00.907+0000] {processor.py:153} INFO - Started process (PID=1172) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:47:00.908+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:47:00.910+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:47:00.909+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:47:01.052+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:47:01.046+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:47:01.053+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:47:01.076+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.172 seconds
[2025-01-07T18:47:31.297+0000] {processor.py:153} INFO - Started process (PID=1252) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:47:31.299+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:47:31.300+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:47:31.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:47:31.410+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:47:31.405+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:47:31.410+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:47:31.427+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.133 seconds
[2025-01-07T18:48:01.852+0000] {processor.py:153} INFO - Started process (PID=1332) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:48:01.853+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:48:01.856+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:48:01.855+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:48:02.057+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:48:02.044+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:48:02.059+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:48:02.095+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-07T18:48:32.329+0000] {processor.py:153} INFO - Started process (PID=1421) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:48:32.331+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:48:32.332+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:48:32.332+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:48:32.501+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:48:32.495+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:48:32.502+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:48:32.535+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.211 seconds
[2025-01-07T18:49:02.744+0000] {processor.py:153} INFO - Started process (PID=1519) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:49:02.745+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:49:02.746+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:49:02.746+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:49:02.855+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:49:02.849+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:49:02.856+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:49:02.874+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.133 seconds
[2025-01-07T18:49:33.727+0000] {processor.py:153} INFO - Started process (PID=1600) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:49:33.729+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T18:49:33.731+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:49:33.730+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:49:33.837+0000] {logging_mixin.py:137} INFO - [2025-01-07T18:49:33.831+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_args=["run"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 377, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'project_dir'
[2025-01-07T18:49:33.837+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T18:49:33.860+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.138 seconds
[2025-01-07T20:53:40.256+0000] {processor.py:153} INFO - Started process (PID=12720) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:53:40.258+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:53:40.259+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:53:40.259+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:53:40.462+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:53:40.457+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:53:40.465+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:53:40.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-07T20:54:10.957+0000] {processor.py:153} INFO - Started process (PID=12801) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:54:10.958+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:54:10.959+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:54:10.958+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:54:11.096+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:54:11.089+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:54:11.098+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:54:11.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.170 seconds
[2025-01-07T20:54:37.272+0000] {processor.py:153} INFO - Started process (PID=12869) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:54:37.273+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:54:37.275+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:54:37.275+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:54:37.455+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:54:37.451+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:54:37.457+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:54:37.485+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-07T20:55:07.968+0000] {processor.py:153} INFO - Started process (PID=12949) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:55:07.969+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:55:07.970+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:55:07.970+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:55:08.089+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:55:08.085+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:55:08.090+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:55:08.114+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.150 seconds
[2025-01-07T20:55:38.388+0000] {processor.py:153} INFO - Started process (PID=13050) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:55:38.389+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:55:38.390+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:55:38.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:55:38.528+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:55:38.522+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:55:38.530+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:55:38.550+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.165 seconds
[2025-01-07T20:56:09.532+0000] {processor.py:153} INFO - Started process (PID=13130) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:56:09.533+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:56:09.534+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:56:09.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:56:09.712+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:56:09.708+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:56:09.714+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:56:09.741+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.216 seconds
[2025-01-07T20:56:39.838+0000] {processor.py:153} INFO - Started process (PID=13217) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:56:39.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:56:39.841+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:56:39.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:56:40.053+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:56:40.047+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:56:40.055+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:56:40.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.255 seconds
[2025-01-07T20:57:10.204+0000] {processor.py:153} INFO - Started process (PID=13310) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:57:10.205+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:57:10.206+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:57:10.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:57:10.332+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:57:10.326+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:57:10.334+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:57:10.355+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.154 seconds
[2025-01-07T20:57:41.323+0000] {processor.py:153} INFO - Started process (PID=13390) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:57:41.325+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:57:41.326+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:57:41.325+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:57:41.443+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:57:41.438+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:57:41.445+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:57:41.470+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.151 seconds
[2025-01-07T20:58:11.600+0000] {processor.py:153} INFO - Started process (PID=13491) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:58:11.601+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:58:11.602+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:58:11.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:58:11.753+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:58:11.747+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:58:11.754+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:58:11.776+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.179 seconds
[2025-01-07T20:58:42.079+0000] {processor.py:153} INFO - Started process (PID=13570) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:58:42.081+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:58:42.082+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:58:42.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:58:42.251+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:58:42.247+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:58:42.252+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:58:42.271+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.198 seconds
[2025-01-07T20:59:13.153+0000] {processor.py:153} INFO - Started process (PID=13650) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:59:13.153+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:59:13.154+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:59:13.154+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:59:13.276+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:59:13.272+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:59:13.277+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:59:13.297+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.148 seconds
[2025-01-07T20:59:43.674+0000] {processor.py:153} INFO - Started process (PID=13750) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:59:43.675+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T20:59:43.677+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:59:43.676+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:59:43.924+0000] {logging_mixin.py:137} INFO - [2025-01-07T20:59:43.909+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T20:59:43.926+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T20:59:43.975+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-07T21:00:14.101+0000] {processor.py:153} INFO - Started process (PID=13830) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:00:14.102+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:00:14.103+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:00:14.103+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:00:14.275+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:00:14.268+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:00:14.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:00:14.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-07T21:00:44.495+0000] {processor.py:153} INFO - Started process (PID=13910) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:00:44.496+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:00:44.497+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:00:44.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:00:44.603+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:00:44.599+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:00:44.605+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:00:44.625+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.134 seconds
[2025-01-07T21:01:14.704+0000] {processor.py:153} INFO - Started process (PID=13999) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:01:14.705+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:01:14.706+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:01:14.706+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:01:14.813+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:01:14.809+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:01:14.814+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:01:14.832+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.132 seconds
[2025-01-07T21:01:45.220+0000] {processor.py:153} INFO - Started process (PID=14090) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:01:45.221+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:01:45.222+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:01:45.222+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:01:45.321+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:01:45.317+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:01:45.323+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:01:45.342+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.125 seconds
[2025-01-07T21:02:15.790+0000] {processor.py:153} INFO - Started process (PID=14170) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:02:15.791+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:02:15.791+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:02:15.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:02:15.894+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:02:15.889+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:02:15.896+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:02:15.914+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.129 seconds
[2025-01-07T21:02:46.047+0000] {processor.py:153} INFO - Started process (PID=14270) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:02:46.048+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:02:46.049+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:02:46.049+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:02:46.170+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:02:46.165+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:02:46.172+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:02:46.191+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.147 seconds
[2025-01-07T21:03:16.327+0000] {processor.py:153} INFO - Started process (PID=14350) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:03:16.328+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:03:16.329+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:03:16.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:03:16.452+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:03:16.447+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:03:16.453+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:03:16.473+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.149 seconds
[2025-01-07T21:03:46.687+0000] {processor.py:153} INFO - Started process (PID=14450) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:03:46.688+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:03:46.689+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:03:46.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:03:46.808+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:03:46.803+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:03:46.810+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:03:46.829+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.146 seconds
[2025-01-07T21:04:16.910+0000] {processor.py:153} INFO - Started process (PID=14532) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:04:16.911+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:04:16.911+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:04:16.911+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:04:17.018+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:04:17.014+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:04:17.020+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:04:17.039+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.132 seconds
[2025-01-07T21:04:47.817+0000] {processor.py:153} INFO - Started process (PID=14632) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:04:47.818+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:04:47.819+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:04:47.819+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:04:47.946+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:04:47.940+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:04:47.948+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:04:47.970+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.156 seconds
[2025-01-07T21:05:18.212+0000] {processor.py:153} INFO - Started process (PID=14712) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:05:18.213+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:05:18.214+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:05:18.214+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:05:18.376+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:05:18.371+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:05:18.379+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:05:18.410+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.203 seconds
[2025-01-07T21:05:48.787+0000] {processor.py:153} INFO - Started process (PID=14792) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:05:48.788+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:05:48.789+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:05:48.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:05:48.942+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:05:48.937+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:05:48.944+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:05:48.973+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.189 seconds
[2025-01-07T21:06:19.104+0000] {processor.py:153} INFO - Started process (PID=14872) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:06:19.105+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:06:19.106+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:06:19.106+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:06:19.295+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:06:19.289+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:06:19.297+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:06:19.323+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-07T21:06:49.409+0000] {processor.py:153} INFO - Started process (PID=14972) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:06:49.410+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:06:49.411+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:06:49.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:06:49.547+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:06:49.541+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:06:49.549+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:06:49.572+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.167 seconds
[2025-01-07T21:07:20.275+0000] {processor.py:153} INFO - Started process (PID=15052) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:07:20.277+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:07:20.278+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:07:20.278+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:07:20.486+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:07:20.481+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:07:20.488+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:07:20.527+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-07T21:07:50.693+0000] {processor.py:153} INFO - Started process (PID=15132) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:07:50.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:07:50.695+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:07:50.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:07:50.838+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:07:50.832+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:07:50.840+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:07:50.861+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.173 seconds
[2025-01-07T21:08:21.172+0000] {processor.py:153} INFO - Started process (PID=15231) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:08:21.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:08:21.174+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:08:21.174+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:08:21.300+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:08:21.294+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:08:21.302+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:08:21.323+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.155 seconds
[2025-01-07T21:08:51.832+0000] {processor.py:153} INFO - Started process (PID=15311) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:08:51.833+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:08:51.833+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:08:51.833+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:08:51.976+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:08:51.971+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:08:51.978+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:08:52.000+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.172 seconds
[2025-01-07T21:09:22.255+0000] {processor.py:153} INFO - Started process (PID=15400) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:09:22.255+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:09:22.256+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:09:22.256+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:09:22.405+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:09:22.399+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:09:22.407+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:09:22.430+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.179 seconds
[2025-01-07T21:09:52.832+0000] {processor.py:153} INFO - Started process (PID=15491) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:09:52.833+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:09:52.834+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:09:52.834+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:09:52.972+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:09:52.967+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:09:52.973+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:09:52.995+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.165 seconds
[2025-01-07T21:10:23.337+0000] {processor.py:153} INFO - Started process (PID=15571) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:10:23.338+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:10:23.339+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:10:23.339+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:10:23.471+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:10:23.466+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:10:23.473+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:10:23.494+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.161 seconds
[2025-01-07T21:10:54.129+0000] {processor.py:153} INFO - Started process (PID=15660) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:10:54.130+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:10:54.131+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:10:54.131+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:10:54.298+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:10:54.293+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:10:54.301+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:10:54.330+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.205 seconds
[2025-01-07T21:11:24.396+0000] {processor.py:153} INFO - Started process (PID=15751) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:11:24.397+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:11:24.398+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:11:24.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:11:24.534+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:11:24.527+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:11:24.536+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:11:24.558+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.166 seconds
[2025-01-07T21:11:55.121+0000] {processor.py:153} INFO - Started process (PID=15832) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:11:55.122+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:11:55.123+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:11:55.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:11:55.253+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:11:55.248+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:11:55.254+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:11:55.276+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.158 seconds
[2025-01-07T21:12:26.061+0000] {processor.py:153} INFO - Started process (PID=15919) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:12:26.062+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:12:26.063+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:12:26.063+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:12:26.216+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:12:26.211+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:12:26.218+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:12:26.247+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.190 seconds
[2025-01-07T21:12:56.468+0000] {processor.py:153} INFO - Started process (PID=16012) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:12:56.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:12:56.470+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:12:56.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:12:56.609+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:12:56.604+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:12:56.611+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:12:56.635+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.170 seconds
[2025-01-07T21:13:27.294+0000] {processor.py:153} INFO - Started process (PID=16092) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:13:27.295+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:13:27.295+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:13:27.295+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:13:27.430+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:13:27.425+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:13:27.432+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:13:27.460+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.170 seconds
[2025-01-07T21:13:57.793+0000] {processor.py:153} INFO - Started process (PID=16181) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:13:57.794+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:13:57.794+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:13:57.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:13:57.917+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:13:57.912+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:13:57.919+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:13:57.943+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.154 seconds
[2025-01-07T21:14:05.455+0000] {processor.py:153} INFO - Started process (PID=16220) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:05.456+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:05.457+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:05.457+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:05.639+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:05.633+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:14:05.640+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:05.665+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.214 seconds
[2025-01-07T21:14:08.539+0000] {processor.py:153} INFO - Started process (PID=16221) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:08.541+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:08.543+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:08.543+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:08.741+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:08.736+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:14:08.743+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:08.768+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.236 seconds
[2025-01-07T21:14:09.735+0000] {processor.py:153} INFO - Started process (PID=16222) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:09.736+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:09.737+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:09.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:09.900+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:09.894+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:14:09.901+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:09.925+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.196 seconds
[2025-01-07T21:14:10.836+0000] {processor.py:153} INFO - Started process (PID=16232) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:10.838+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:10.840+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:10.839+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:11.176+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:11.170+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:14:11.178+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:11.213+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.384 seconds
[2025-01-07T21:14:13.001+0000] {processor.py:153} INFO - Started process (PID=16244) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:13.003+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:13.004+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:13.004+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:13.281+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:13.275+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 23, in __init__
    DAG.__init__(self, *args, **airflow_kwargs(**kwargs))
TypeError: __init__() missing 1 required positional argument: 'dag_id'
[2025-01-07T21:14:13.285+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:13.329+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-07T21:14:20.320+0000] {processor.py:153} INFO - Started process (PID=16245) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:20.321+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:20.322+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:20.322+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:20.502+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:20.496+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:14:20.502+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:20.540+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-07T21:14:22.431+0000] {processor.py:153} INFO - Started process (PID=16246) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:22.432+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:22.433+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:22.433+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:22.642+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:22.637+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:14:22.643+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:22.669+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-07T21:14:28.884+0000] {processor.py:153} INFO - Started process (PID=16284) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:28.885+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:28.887+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:28.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:29.120+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:29.115+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:14:29.121+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:29.148+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-07T21:14:32.466+0000] {processor.py:153} INFO - Started process (PID=16300) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:32.468+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:14:32.470+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:32.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:32.710+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:14:32.704+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:14:32.711+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:14:32.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.283 seconds
[2025-01-07T21:15:02.967+0000] {processor.py:153} INFO - Started process (PID=16378) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:15:02.969+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:15:02.970+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:15:02.970+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:15:03.163+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:15:03.158+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:15:03.164+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:15:03.202+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-07T21:15:33.366+0000] {processor.py:153} INFO - Started process (PID=16458) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:15:33.368+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:15:33.370+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:15:33.370+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:15:33.646+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:15:33.631+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:15:33.648+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:15:33.692+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.336 seconds
[2025-01-07T21:16:03.916+0000] {processor.py:153} INFO - Started process (PID=16537) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:16:03.918+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:16:03.920+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:16:03.919+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:16:04.160+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:16:04.154+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:16:04.161+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:16:04.204+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-07T21:16:34.411+0000] {processor.py:153} INFO - Started process (PID=16625) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:16:34.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:16:34.419+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:16:34.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:16:34.750+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:16:34.742+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:16:34.752+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:16:34.825+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.431 seconds
[2025-01-07T21:17:04.950+0000] {processor.py:153} INFO - Started process (PID=16705) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:17:04.952+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:17:04.954+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:17:04.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:17:05.400+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:17:05.341+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:17:05.402+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:17:05.467+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.528 seconds
[2025-01-07T21:17:35.552+0000] {processor.py:153} INFO - Started process (PID=16793) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:17:35.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:17:35.554+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:17:35.554+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:17:35.660+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:17:35.655+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:17:35.661+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:17:35.679+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.131 seconds
[2025-01-07T21:18:05.889+0000] {processor.py:153} INFO - Started process (PID=16873) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:18:05.890+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:18:05.891+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:18:05.891+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:18:05.997+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:18:05.991+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:18:05.998+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:18:06.017+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.131 seconds
[2025-01-07T21:18:36.056+0000] {processor.py:153} INFO - Started process (PID=16962) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:18:36.057+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:18:36.058+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:18:36.058+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:18:36.173+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:18:36.168+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:18:36.174+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:18:36.194+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.141 seconds
[2025-01-07T21:19:06.385+0000] {processor.py:153} INFO - Started process (PID=17053) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:19:06.386+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:19:06.388+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:19:06.387+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:19:06.545+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:19:06.539+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:19:06.546+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:19:06.570+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.189 seconds
[2025-01-07T21:19:37.346+0000] {processor.py:153} INFO - Started process (PID=17133) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:19:37.347+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:19:37.348+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:19:37.348+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:19:37.480+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:19:37.475+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:19:37.481+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:19:37.504+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.161 seconds
[2025-01-07T21:20:08.256+0000] {processor.py:153} INFO - Started process (PID=17234) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:08.257+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:20:08.258+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:08.258+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:08.377+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:08.372+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml
[2025-01-07T21:20:08.377+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:08.396+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.145 seconds
[2025-01-07T21:20:17.462+0000] {processor.py:153} INFO - Started process (PID=17256) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:17.463+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:20:17.464+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:17.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:17.630+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:17.626+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/ddbt_stock_project/dbt_project.yml
[2025-01-07T21:20:17.631+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:17.658+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.203 seconds
[2025-01-07T21:20:19.510+0000] {processor.py:153} INFO - Started process (PID=17270) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:19.511+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:20:19.513+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:19.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:19.714+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:19.708+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:20:19.714+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:19.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
[2025-01-07T21:20:49.792+0000] {processor.py:153} INFO - Started process (PID=17350) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:49.793+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:20:49.794+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:49.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:49.906+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:20:49.901+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:20:49.907+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:20:49.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.138 seconds
[2025-01-07T21:21:20.004+0000] {processor.py:153} INFO - Started process (PID=17430) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:21:20.005+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:21:20.005+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:21:20.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:21:20.118+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:21:20.113+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:21:20.119+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:21:20.144+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.144 seconds
[2025-01-07T21:21:50.461+0000] {processor.py:153} INFO - Started process (PID=17511) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:21:50.462+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:21:50.463+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:21:50.463+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:21:50.599+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:21:50.594+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:21:50.599+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:21:50.631+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.173 seconds
[2025-01-07T21:22:18.059+0000] {processor.py:153} INFO - Started process (PID=17611) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:18.061+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:22:18.062+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:22:18.062+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:18.224+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:22:18.219+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at Khaled/Desktop/stock_market-projectairflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:22:18.225+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:18.251+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.195 seconds
[2025-01-07T21:22:19.096+0000] {processor.py:153} INFO - Started process (PID=17612) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:19.098+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:22:19.099+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:22:19.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:19.297+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:22:19.292+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at Khaled/Desktop/stock_market-project/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:22:19.298+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:19.330+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-07T21:22:49.704+0000] {processor.py:153} INFO - Started process (PID=17692) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:49.705+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:22:49.706+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:22:49.706+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:49.846+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:22:49.842+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at Khaled/Desktop/stock_market-project/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:22:49.847+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:22:49.870+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.170 seconds
[2025-01-07T21:23:19.976+0000] {processor.py:153} INFO - Started process (PID=17772) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:23:19.977+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:23:19.978+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:23:19.978+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:23:20.095+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:23:20.090+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at Khaled/Desktop/stock_market-project/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:23:20.096+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:23:20.121+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.149 seconds
[2025-01-07T21:23:33.092+0000] {processor.py:153} INFO - Started process (PID=17793) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:23:33.093+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:23:33.094+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:23:33.094+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:23:33.254+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:23:33.247+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:23:33.255+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:23:33.279+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.191 seconds
[2025-01-07T21:24:03.889+0000] {processor.py:153} INFO - Started process (PID=17893) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:03.890+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:24:03.891+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:03.891+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:04.146+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:04.141+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:24:04.147+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:04.186+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.305 seconds
[2025-01-07T21:24:32.510+0000] {processor.py:153} INFO - Started process (PID=17973) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:32.511+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:24:32.512+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:32.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:32.702+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:32.696+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt.dbt_stock_project/dbt_project.yml/dbt_project.yml
[2025-01-07T21:24:32.703+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:32.759+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-07T21:24:49.619+0000] {processor.py:153} INFO - Started process (PID=18033) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:49.621+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:24:49.622+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:49.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:49.804+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:49.798+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:24:49.804+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:49.827+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.212 seconds
[2025-01-07T21:24:51.746+0000] {processor.py:153} INFO - Started process (PID=18034) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:51.749+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:24:51.753+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:51.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:51.980+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:51.975+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/ddbt_stock_project/dbt_project.yml
[2025-01-07T21:24:51.981+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:52.009+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-07T21:24:52.882+0000] {processor.py:153} INFO - Started process (PID=18035) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:52.884+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:24:52.885+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:52.885+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:53.070+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:24:53.064+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:24:53.071+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:24:53.112+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.234 seconds
[2025-01-07T21:25:23.222+0000] {processor.py:153} INFO - Started process (PID=18135) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:25:23.223+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:25:23.224+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:25:23.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:25:23.346+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:25:23.340+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:25:23.346+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:25:23.366+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.148 seconds
[2025-01-07T21:25:53.901+0000] {processor.py:153} INFO - Started process (PID=18215) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:25:53.903+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:25:53.905+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:25:53.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:25:54.088+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:25:54.081+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:25:54.089+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:25:54.148+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-07T21:26:25.120+0000] {processor.py:153} INFO - Started process (PID=18304) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:26:25.121+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:26:25.122+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:26:25.122+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:26:25.298+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:26:25.289+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:26:25.299+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:26:25.327+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.210 seconds
[2025-01-07T21:26:55.369+0000] {processor.py:153} INFO - Started process (PID=18395) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:26:55.370+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:26:55.371+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:26:55.371+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:26:55.479+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:26:55.474+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:26:55.480+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:26:55.497+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.131 seconds
[2025-01-07T21:27:26.242+0000] {processor.py:153} INFO - Started process (PID=18482) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:27:26.242+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:27:26.244+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:27:26.244+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:27:26.376+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:27:26.371+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:27:26.377+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:27:26.401+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.163 seconds
[2025-01-07T21:27:56.819+0000] {processor.py:153} INFO - Started process (PID=18576) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:27:56.820+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:27:56.821+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:27:56.821+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:27:56.938+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:27:56.932+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:27:56.938+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:27:56.965+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.149 seconds
[2025-01-07T21:28:27.682+0000] {processor.py:153} INFO - Started process (PID=18656) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:28:27.683+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:28:27.684+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:28:27.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:28:27.797+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:28:27.792+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:28:27.798+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:28:27.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.137 seconds
[2025-01-07T21:28:58.427+0000] {processor.py:153} INFO - Started process (PID=18756) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:28:58.428+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:28:58.429+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:28:58.429+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:28:58.535+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:28:58.529+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:28:58.535+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:28:58.561+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.136 seconds
[2025-01-07T21:29:29.368+0000] {processor.py:153} INFO - Started process (PID=18837) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:29:29.370+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:29:29.371+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:29:29.371+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:29:29.486+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:29:29.480+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:29:29.486+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:29:29.512+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.147 seconds
[2025-01-07T21:29:59.589+0000] {processor.py:153} INFO - Started process (PID=18937) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:29:59.590+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:29:59.591+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:29:59.591+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:29:59.715+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:29:59.710+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:29:59.716+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:29:59.735+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.149 seconds
[2025-01-07T21:30:30.008+0000] {processor.py:153} INFO - Started process (PID=19017) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:30:30.009+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:30:30.010+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:30:30.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:30:30.138+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:30:30.133+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /usr/local/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:30:30.139+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:30:30.161+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.156 seconds
[2025-01-07T21:30:52.034+0000] {processor.py:153} INFO - Started process (PID=19080) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:30:52.035+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:30:52.036+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:30:52.036+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:30:52.219+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:30:52.216+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:30:52.220+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:30:52.248+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-07T21:31:22.605+0000] {processor.py:153} INFO - Started process (PID=19162) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:31:22.606+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:31:22.607+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:31:22.607+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:31:22.788+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:31:22.782+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:31:22.789+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:31:22.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-07T21:31:53.207+0000] {processor.py:153} INFO - Started process (PID=19238) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:31:53.209+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:31:53.211+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:31:53.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:31:53.545+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:31:53.535+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:31:53.547+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:31:53.600+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.402 seconds
[2025-01-07T21:32:24.514+0000] {processor.py:153} INFO - Started process (PID=19318) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:32:24.515+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:32:24.517+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:32:24.517+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:32:24.658+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:32:24.653+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:32:24.659+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:32:24.680+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.170 seconds
[2025-01-07T21:32:54.823+0000] {processor.py:153} INFO - Started process (PID=19418) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:32:54.824+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:32:54.825+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:32:54.825+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:32:54.934+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:32:54.928+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:32:54.935+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:32:54.954+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.135 seconds
[2025-01-07T21:33:25.223+0000] {processor.py:153} INFO - Started process (PID=19498) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:33:25.226+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:33:25.229+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:33:25.229+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:33:25.774+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:33:25.766+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:33:25.776+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:33:25.826+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.619 seconds
[2025-01-07T21:33:56.314+0000] {processor.py:153} INFO - Started process (PID=19578) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:33:56.315+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:33:56.316+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:33:56.315+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:33:56.432+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:33:56.427+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:33:56.434+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:33:56.468+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.158 seconds
[2025-01-07T21:34:27.153+0000] {processor.py:153} INFO - Started process (PID=19678) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:34:27.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:34:27.155+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:34:27.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:34:27.288+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:34:27.283+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:34:27.289+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:34:27.314+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.166 seconds
[2025-01-07T21:34:57.449+0000] {processor.py:153} INFO - Started process (PID=19758) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:34:57.450+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:34:57.452+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:34:57.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:34:57.616+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:34:57.611+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:34:57.617+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:34:57.644+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.199 seconds
[2025-01-07T21:35:28.209+0000] {processor.py:153} INFO - Started process (PID=19838) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:35:28.210+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:35:28.212+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:35:28.212+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:35:28.324+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:35:28.320+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:35:28.325+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:35:28.345+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.139 seconds
[2025-01-07T21:35:59.224+0000] {processor.py:153} INFO - Started process (PID=19938) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:35:59.225+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:35:59.226+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:35:59.226+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:35:59.331+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:35:59.325+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:35:59.332+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:35:59.352+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.131 seconds
[2025-01-07T21:36:30.168+0000] {processor.py:153} INFO - Started process (PID=20018) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:36:30.169+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:36:30.170+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:36:30.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:36:30.284+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:36:30.279+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:36:30.285+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:36:30.303+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.138 seconds
[2025-01-07T21:37:00.468+0000] {processor.py:153} INFO - Started process (PID=20119) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:37:00.468+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:37:00.469+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:37:00.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:37:00.575+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:37:00.570+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:37:00.575+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:37:00.594+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.130 seconds
[2025-01-07T21:37:30.749+0000] {processor.py:153} INFO - Started process (PID=20198) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:37:30.750+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:37:30.751+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:37:30.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:37:30.858+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:37:30.854+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:37:30.859+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:37:30.877+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.132 seconds
[2025-01-07T21:38:01.464+0000] {processor.py:153} INFO - Started process (PID=20287) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:38:01.465+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:38:01.466+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:38:01.466+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:38:01.589+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:38:01.583+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:38:01.590+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:38:01.624+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.163 seconds
[2025-01-07T21:38:31.832+0000] {processor.py:153} INFO - Started process (PID=20378) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:38:31.833+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:38:31.834+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:38:31.834+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:38:32.025+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:38:32.018+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:38:32.026+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:38:32.052+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.224 seconds
[2025-01-07T21:39:02.452+0000] {processor.py:153} INFO - Started process (PID=20458) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:02.454+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:39:02.458+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:02.458+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:02.642+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:02.637+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:39:02.643+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:02.661+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.218 seconds
[2025-01-07T21:39:25.119+0000] {processor.py:153} INFO - Started process (PID=20532) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:25.120+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:39:25.121+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:25.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:25.150+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:25.149+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56
    "C:\Users\Khaled\Khaled\Desktop\stock_market-project\airflow\dbtdbt_stock_project",
    ^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2025-01-07T21:39:25.151+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:25.176+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.060 seconds
[2025-01-07T21:39:30.176+0000] {processor.py:153} INFO - Started process (PID=20542) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:30.177+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:39:30.184+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:30.184+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:30.259+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:30.258+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56
    "C:\Users\Khaled\Khaled\Desktop\stock_market-project\airflow\dbt\dbt_stock_project",
    ^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2025-01-07T21:39:30.260+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:30.293+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.124 seconds
[2025-01-07T21:39:51.491+0000] {processor.py:153} INFO - Started process (PID=20601) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:51.493+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:39:51.494+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:51.494+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:51.640+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:39:51.635+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:39:51.640+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:39:51.663+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.174 seconds
[2025-01-07T21:40:20.968+0000] {processor.py:153} INFO - Started process (PID=20681) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:20.969+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:40:20.970+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:20.970+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:21.000+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:20.999+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56
    "C:\Users\Khaled\Khaled\Desktop\stock_market-project\airflow\dbt",
    ^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2025-01-07T21:40:21.001+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:21.037+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.073 seconds
[2025-01-07T21:40:31.176+0000] {processor.py:153} INFO - Started process (PID=20714) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:31.177+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:40:31.178+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:31.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:31.344+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:31.339+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:40:31.345+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:31.368+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.198 seconds
[2025-01-07T21:40:32.927+0000] {processor.py:153} INFO - Started process (PID=20721) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:32.928+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:40:32.929+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:32.929+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:32.949+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:32.948+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56
    "C:\Users\Khaled\Khaled\Desktop\stock_market-project\airflow\dbt",
    ^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2025-01-07T21:40:32.950+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:32.987+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.064 seconds
[2025-01-07T21:40:36.253+0000] {processor.py:153} INFO - Started process (PID=20742) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:36.254+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:40:36.255+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:36.255+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:36.289+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:36.288+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56
    "\Users\Khaled\Khaled\Desktop\stock_market-project\airflow\dbt",
    ^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \UXXXXXXXX escape
[2025-01-07T21:40:36.290+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:36.316+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.067 seconds
[2025-01-07T21:40:47.202+0000] {processor.py:153} INFO - Started process (PID=20764) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:47.204+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:40:47.205+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:47.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:47.394+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:47.388+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T21:40:47.395+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:47.426+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-07T21:40:59.425+0000] {processor.py:153} INFO - Started process (PID=20797) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:59.426+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:40:59.427+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:59.427+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:59.449+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:40:59.448+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56
    "C:\Users\Khaled\Khaled\Desktop\stock_market-project\airflow\dbt",
    ^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
[2025-01-07T21:40:59.450+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:40:59.480+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.060 seconds
[2025-01-07T21:41:04.296+0000] {processor.py:153} INFO - Started process (PID=20824) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:04.298+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:41:04.299+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:41:04.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:04.594+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:41:04.589+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at C:/Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:41:04.595+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:04.625+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.335 seconds
[2025-01-07T21:41:12.924+0000] {processor.py:153} INFO - Started process (PID=20846) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:12.926+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:41:12.927+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:41:12.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:13.193+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:41:13.164+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:41:13.195+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:13.227+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.310 seconds
[2025-01-07T21:41:44.234+0000] {processor.py:153} INFO - Started process (PID=20946) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:44.235+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:41:44.236+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:41:44.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:44.351+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:41:44.345+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:41:44.352+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:41:44.378+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.147 seconds
[2025-01-07T21:42:14.510+0000] {processor.py:153} INFO - Started process (PID=21026) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:42:14.511+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:42:14.512+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:42:14.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:42:14.632+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:42:14.627+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:42:14.633+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:42:14.658+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.151 seconds
[2025-01-07T21:42:44.776+0000] {processor.py:153} INFO - Started process (PID=21106) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:42:44.777+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:42:44.777+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:42:44.777+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:42:44.894+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:42:44.890+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:42:44.894+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:42:44.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.154 seconds
[2025-01-07T21:43:15.077+0000] {processor.py:153} INFO - Started process (PID=21206) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:43:15.079+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:43:15.080+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:43:15.080+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:43:15.211+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:43:15.206+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:43:15.212+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:43:15.231+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.157 seconds
[2025-01-07T21:43:45.823+0000] {processor.py:153} INFO - Started process (PID=21286) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:43:45.824+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:43:45.825+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:43:45.825+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:43:46.015+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:43:46.010+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:43:46.015+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:43:46.042+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-07T21:44:16.883+0000] {processor.py:153} INFO - Started process (PID=21386) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:44:16.884+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:44:16.885+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:44:16.885+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:44:17.000+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:44:16.996+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:44:17.001+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:44:17.021+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.142 seconds
[2025-01-07T21:44:47.553+0000] {processor.py:153} INFO - Started process (PID=21466) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:44:47.554+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:44:47.555+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:44:47.555+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:44:47.700+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:44:47.695+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:44:47.701+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:44:47.726+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.178 seconds
[2025-01-07T21:45:18.287+0000] {processor.py:153} INFO - Started process (PID=21546) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:45:18.289+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:45:18.291+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:45:18.291+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:45:18.455+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:45:18.450+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:45:18.456+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:45:18.486+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.204 seconds
[2025-01-07T21:45:48.762+0000] {processor.py:153} INFO - Started process (PID=21646) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:45:48.763+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:45:48.764+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:45:48.764+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:45:48.879+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:45:48.874+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:45:48.880+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:45:48.904+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.146 seconds
[2025-01-07T21:46:19.530+0000] {processor.py:153} INFO - Started process (PID=21726) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:46:19.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:46:19.532+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:46:19.532+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:46:19.647+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:46:19.642+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:46:19.648+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:46:19.666+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.140 seconds
[2025-01-07T21:46:50.019+0000] {processor.py:153} INFO - Started process (PID=21806) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:46:50.020+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:46:50.020+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:46:50.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:46:50.133+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:46:50.127+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:46:50.134+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:46:50.160+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.144 seconds
[2025-01-07T21:47:20.686+0000] {processor.py:153} INFO - Started process (PID=21906) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:47:20.687+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:47:20.689+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:47:20.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:47:20.811+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:47:20.806+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:47:20.811+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:47:20.837+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.155 seconds
[2025-01-07T21:47:51.270+0000] {processor.py:153} INFO - Started process (PID=21986) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:47:51.272+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:47:51.273+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:47:51.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:47:51.385+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:47:51.381+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:47:51.386+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:47:51.410+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.143 seconds
[2025-01-07T21:48:21.587+0000] {processor.py:153} INFO - Started process (PID=22066) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:48:21.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:48:21.589+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:48:21.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:48:21.727+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:48:21.721+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:48:21.728+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:48:21.749+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.165 seconds
[2025-01-07T21:48:52.089+0000] {processor.py:153} INFO - Started process (PID=22166) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:48:52.091+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:48:52.092+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:48:52.092+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:48:52.260+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:48:52.255+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:48:52.261+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:48:52.292+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.215 seconds
[2025-01-07T21:49:22.410+0000] {processor.py:153} INFO - Started process (PID=22246) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:49:22.412+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:49:22.413+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:49:22.413+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:49:22.605+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:49:22.599+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:49:22.606+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:49:22.641+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-07T21:49:52.692+0000] {processor.py:153} INFO - Started process (PID=22326) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:49:52.693+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:49:52.695+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:49:52.694+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:49:52.882+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:49:52.876+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:49:52.882+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:49:52.912+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-07T21:50:23.260+0000] {processor.py:153} INFO - Started process (PID=22426) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:50:23.262+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:50:23.263+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:50:23.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:50:23.432+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:50:23.425+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:50:23.432+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:50:23.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.199 seconds
[2025-01-07T21:50:53.921+0000] {processor.py:153} INFO - Started process (PID=22506) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:50:53.922+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:50:53.923+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:50:53.923+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:50:54.044+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:50:54.039+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:50:54.045+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:50:54.072+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.154 seconds
[2025-01-07T21:51:24.160+0000] {processor.py:153} INFO - Started process (PID=22586) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:51:24.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:51:24.163+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:51:24.163+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:51:24.315+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:51:24.308+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:51:24.316+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:51:24.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.188 seconds
[2025-01-07T21:51:54.826+0000] {processor.py:153} INFO - Started process (PID=22687) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:51:54.827+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:51:54.828+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:51:54.828+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:51:54.974+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:51:54.968+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:51:54.975+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:51:54.994+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.171 seconds
[2025-01-07T21:52:25.100+0000] {processor.py:153} INFO - Started process (PID=22767) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:52:25.102+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:52:25.104+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:52:25.104+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:52:25.228+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:52:25.222+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:52:25.229+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:52:25.256+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.159 seconds
[2025-01-07T21:52:55.587+0000] {processor.py:153} INFO - Started process (PID=22847) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:52:55.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:52:55.589+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:52:55.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:52:55.717+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:52:55.711+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:52:55.718+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:52:55.740+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.157 seconds
[2025-01-07T21:53:26.698+0000] {processor.py:153} INFO - Started process (PID=22947) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:53:26.699+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:53:26.700+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:53:26.700+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:53:26.849+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:53:26.843+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:53:26.850+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:53:26.878+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.184 seconds
[2025-01-07T21:53:57.779+0000] {processor.py:153} INFO - Started process (PID=23027) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:53:57.781+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:53:57.782+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:53:57.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:53:57.903+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:53:57.897+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:53:57.903+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:53:57.929+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.152 seconds
[2025-01-07T21:54:28.124+0000] {processor.py:153} INFO - Started process (PID=23107) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:54:28.126+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:54:28.127+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:54:28.126+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:54:28.250+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:54:28.244+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:54:28.250+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:54:28.278+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.157 seconds
[2025-01-07T21:54:59.100+0000] {processor.py:153} INFO - Started process (PID=23207) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:54:59.101+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:54:59.102+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:54:59.102+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:54:59.214+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:54:59.208+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:54:59.215+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:54:59.241+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.143 seconds
[2025-01-07T21:55:29.871+0000] {processor.py:153} INFO - Started process (PID=23287) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:55:29.872+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:55:29.874+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:55:29.874+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:55:30.018+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:55:30.012+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:55:30.019+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:55:30.042+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.175 seconds
[2025-01-07T21:56:00.694+0000] {processor.py:153} INFO - Started process (PID=23376) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:56:00.695+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:56:00.696+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:56:00.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:56:00.841+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:56:00.837+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:56:00.841+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:56:00.871+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.180 seconds
[2025-01-07T21:56:31.157+0000] {processor.py:153} INFO - Started process (PID=23467) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:56:31.159+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:56:31.160+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:56:31.160+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:56:31.299+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:56:31.294+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:56:31.300+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:56:31.318+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.164 seconds
[2025-01-07T21:57:01.839+0000] {processor.py:153} INFO - Started process (PID=23547) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:57:01.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:57:01.841+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:57:01.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:57:01.980+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:57:01.974+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:57:01.981+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:57:02.010+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.175 seconds
[2025-01-07T21:57:32.421+0000] {processor.py:153} INFO - Started process (PID=23647) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:57:32.422+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:57:32.423+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:57:32.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:57:32.572+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:57:32.566+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:57:32.572+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:57:32.597+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.179 seconds
[2025-01-07T21:58:02.976+0000] {processor.py:153} INFO - Started process (PID=23727) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:58:02.978+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:58:02.982+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:58:02.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:58:03.216+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:58:03.210+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:58:03.217+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:58:03.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.285 seconds
[2025-01-07T21:58:33.658+0000] {processor.py:153} INFO - Started process (PID=23807) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:58:33.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:58:33.660+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:58:33.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:58:33.803+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:58:33.797+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:58:33.803+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:58:33.825+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.170 seconds
[2025-01-07T21:59:04.002+0000] {processor.py:153} INFO - Started process (PID=23907) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:59:04.004+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:59:04.005+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:59:04.004+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:59:04.129+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:59:04.124+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:59:04.130+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:59:04.150+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.151 seconds
[2025-01-07T21:59:34.447+0000] {processor.py:153} INFO - Started process (PID=23987) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:59:34.447+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T21:59:34.448+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:59:34.448+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:59:34.567+0000] {logging_mixin.py:137} INFO - [2025-01-07T21:59:34.561+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T21:59:34.568+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T21:59:34.586+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.144 seconds
[2025-01-07T22:00:05.093+0000] {processor.py:153} INFO - Started process (PID=24067) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:00:05.094+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:00:05.096+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:00:05.095+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:00:05.231+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:00:05.225+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T22:00:05.232+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:00:05.252+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.163 seconds
[2025-01-07T22:00:35.726+0000] {processor.py:153} INFO - Started process (PID=24167) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:00:35.728+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:00:35.729+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:00:35.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:00:35.926+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:00:35.920+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T22:00:35.927+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:00:35.951+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-07T22:01:06.209+0000] {processor.py:153} INFO - Started process (PID=24247) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:01:06.210+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:01:06.210+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:01:06.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:01:06.320+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:01:06.314+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /Users/Khaled/Khaled/Desktop/stock_market-project/airflow/dbt/dbt_project.yml
[2025-01-07T22:01:06.321+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:01:06.340+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.134 seconds
[2025-01-07T22:01:13.404+0000] {processor.py:153} INFO - Started process (PID=24248) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:01:13.405+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:01:13.406+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:01:13.406+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:01:13.594+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:01:13.591+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 106, in __init__
    project_config.validate_project()
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/config.py", line 82, in validate_project
    raise CosmosValueError(f"Could not find {name} at {project_yml_path}")
cosmos.exceptions.CosmosValueError: Could not find dbt_project.yml at /opt/airflow/dbt/dbt_stock_project/dbt_project.yml
[2025-01-07T22:01:13.595+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:01:13.614+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.216 seconds
[2025-01-07T22:02:30.533+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:02:30.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:02:30.535+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:02:30.535+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:02:30.932+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:02:30,932] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:02:31.157+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:02:31,157] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:02:31.158+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:02:31,158] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:02:31.168+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:02:31.159+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:02:31.169+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:02:31.193+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.666 seconds
[2025-01-07T22:03:01.550+0000] {processor.py:153} INFO - Started process (PID=141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:03:01.550+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:03:01.551+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:03:01.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:03:01.659+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:03:01,658] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:03:01.704+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:03:01,704] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:03:01.706+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:03:01,705] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:03:01.714+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:03:01.707+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:03:01.715+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:03:01.732+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.186 seconds
[2025-01-07T22:03:31.839+0000] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:03:31.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:03:31.842+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:03:31.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:03:32.017+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:03:32,017] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:03:32.076+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:03:32,076] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:03:32.076+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:03:32,076] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:03:32.083+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:03:32.078+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:03:32.085+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:03:32.111+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.279 seconds
[2025-01-07T22:04:02.601+0000] {processor.py:153} INFO - Started process (PID=321) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:02.602+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:04:02.603+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:02.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:02.750+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:04:02,750] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:04:02.808+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:04:02,808] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:04:02.809+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:04:02,809] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:04:02.816+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:02.810+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:04:02.817+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:02.840+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.244 seconds
[2025-01-07T22:04:12.732+0000] {processor.py:153} INFO - Started process (PID=368) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:12.733+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:04:12.734+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:12.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:12.957+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:12.951+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 23, in <module>
    'retry_delay': timedelta(minutes=5),
NameError: name 'timedelta' is not defined
[2025-01-07T22:04:12.959+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:12.996+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
[2025-01-07T22:04:37.406+0000] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:37.407+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:04:37.409+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:37.409+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:37.687+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:37.683+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 23, in <module>
    'retry_delay': timedelta(minutes=5),
NameError: name 'timedelta' is not defined
[2025-01-07T22:04:37.689+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:37.724+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-07T22:04:48.316+0000] {processor.py:153} INFO - Started process (PID=462) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:48.317+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:04:48.318+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:48.318+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:48.466+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:04:48.461+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 23, in <module>
    'retry_delay': timedelta(minutes=5),
NameError: name 'timedelta' is not defined
[2025-01-07T22:04:48.468+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:04:48.496+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.184 seconds
[2025-01-07T22:05:12.665+0000] {processor.py:153} INFO - Started process (PID=542) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:12.666+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:05:12.667+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:05:12.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:12.683+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:05:12.682+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 36
    start_date=start_date=datetime.utcnow() - timedelta(days=1),
                         ^
SyntaxError: invalid syntax
[2025-01-07T22:05:12.684+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:12.706+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.045 seconds
[2025-01-07T22:05:24.781+0000] {processor.py:153} INFO - Started process (PID=563) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:24.782+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:05:24.783+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:05:24.783+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:24.798+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:05:24.797+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 36
    start_date=start_date=datetime.utcnow() - timedelta(days=1),
                         ^
SyntaxError: invalid syntax
[2025-01-07T22:05:24.798+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:24.826+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.047 seconds
[2025-01-07T22:05:39.959+0000] {processor.py:153} INFO - Started process (PID=623) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:39.960+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:05:39.961+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:05:39.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:40.111+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:05:40,111] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:05:40.164+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:05:40,163] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:05:40.164+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:05:40,164] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:05:40.173+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:05:40.166+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:05:40.173+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:05:40.196+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.242 seconds
[2025-01-07T22:06:02.177+0000] {processor.py:153} INFO - Started process (PID=664) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:06:02.179+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:06:02.180+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:06:02.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:06:02.473+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:06:02,473] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:06:02.531+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:06:02,531] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:06:02.531+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:06:02,531] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:06:02.540+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:06:02.533+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:06:02.541+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:06:02.575+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.403 seconds
[2025-01-07T22:06:33.292+0000] {processor.py:153} INFO - Started process (PID=744) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:06:33.295+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:06:33.298+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:06:33.297+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:06:33.505+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:06:33,504] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:06:33.569+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:06:33,569] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:06:33.570+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:06:33,570] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:06:33.578+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:06:33.572+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:06:33.579+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:06:33.617+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.332 seconds
[2025-01-07T22:07:49.319+0000] {processor.py:153} INFO - Started process (PID=62) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:07:49.320+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:07:49.322+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:07:49.322+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:07:49.751+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:07:49,751] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:07:49.811+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:07:49,811] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:07:49.812+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:07:49,812] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:07:49.820+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:07:49.813+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:07:49.821+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:07:49.845+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.532 seconds
[2025-01-07T22:08:20.615+0000] {processor.py:153} INFO - Started process (PID=141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:08:20.616+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:08:20.617+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:08:20.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:08:20.742+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:08:20,742] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:08:20.814+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:08:20,814] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:08:20.815+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:08:20,814] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:08:20.822+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:08:20.816+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:08:20.823+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:08:20.863+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.252 seconds
[2025-01-07T22:08:50.934+0000] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:08:50.935+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:08:50.936+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:08:50.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:08:51.099+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:08:51,099] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:08:51.147+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:08:51,147] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:08:51.148+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:08:51,148] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:08:51.155+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:08:51.149+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:08:51.156+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:08:51.179+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.249 seconds
[2025-01-07T22:09:21.653+0000] {processor.py:153} INFO - Started process (PID=322) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:09:21.654+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:09:21.655+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:09:21.655+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:09:21.793+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:09:21,792] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:09:21.847+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:09:21,847] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:09:21.848+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:09:21,848] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:09:21.856+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:09:21.850+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:09:21.857+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:09:21.878+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.230 seconds
[2025-01-07T22:09:52.338+0000] {processor.py:153} INFO - Started process (PID=402) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:09:52.339+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:09:52.340+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:09:52.340+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:09:52.480+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:09:52,480] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:09:52.530+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:09:52,530] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:09:52.531+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:09:52,530] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:09:52.539+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:09:52.532+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:09:52.540+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:09:52.566+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-07T22:10:23.188+0000] {processor.py:153} INFO - Started process (PID=482) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:23.189+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:10:23.190+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:10:23.190+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:23.343+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:23,343] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:10:23.417+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:23,417] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:10:23.418+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:23,418] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:10:23.427+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:10:23.420+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:10:23.428+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:23.458+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.273 seconds
[2025-01-07T22:10:40.741+0000] {processor.py:153} INFO - Started process (PID=551) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:40.742+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:10:40.744+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:10:40.743+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:40.963+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:40,963] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:10:41.022+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:41,022] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:10:41.023+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:41,022] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:10:41.031+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:10:41.025+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:10:41.031+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:41.064+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.327 seconds
[2025-01-07T22:10:54.169+0000] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:54.171+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:10:54.173+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:10:54.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:54.436+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:54,436] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:10:54.511+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:54,511] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:10:54.512+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:10:54,512] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:10:54.522+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:10:54.514+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:10:54.524+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:10:54.557+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.396 seconds
[2025-01-07T22:12:15.205+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:12:15.207+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:12:15.209+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:12:15.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:12:15.670+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:12:15,670] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:12:15.743+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:12:15,743] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:12:15.744+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:12:15,744] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:12:15.752+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:12:15.745+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:12:15.752+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:12:15.780+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.581 seconds
[2025-01-07T22:12:45.951+0000] {processor.py:153} INFO - Started process (PID=141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:12:45.952+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:12:45.953+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:12:45.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:12:46.067+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:12:46,067] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:12:46.120+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:12:46,120] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:12:46.120+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:12:46,120] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:12:46.128+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:12:46.122+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:12:46.128+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:12:46.148+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.200 seconds
[2025-01-07T22:13:16.313+0000] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:13:16.314+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:13:16.315+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:13:16.315+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:13:16.496+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:13:16,496] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:13:16.544+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:13:16,543] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:13:16.544+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:13:16,544] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:13:16.552+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:13:16.546+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:13:16.553+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:13:16.576+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.267 seconds
[2025-01-07T22:13:46.892+0000] {processor.py:153} INFO - Started process (PID=321) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:13:46.893+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:13:46.894+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:13:46.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:13:47.009+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:13:47,008] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:13:47.059+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:13:47,058] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:13:47.059+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:13:47,059] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:13:47.069+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:13:47.061+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:13:47.070+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:13:47.092+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.203 seconds
[2025-01-07T22:14:17.133+0000] {processor.py:153} INFO - Started process (PID=402) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:14:17.134+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:14:17.135+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:14:17.135+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:14:17.249+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:14:17,248] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:14:17.300+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:14:17,300] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:14:17.301+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:14:17,300] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:14:17.309+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:14:17.302+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:14:17.309+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:14:17.332+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.202 seconds
[2025-01-07T22:14:47.904+0000] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:14:47.905+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:14:47.906+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:14:47.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:14:48.064+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:14:48,064] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:14:48.116+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:14:48,116] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:14:48.116+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:14:48,116] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:14:48.126+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:14:48.118+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:14:48.127+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:14:48.150+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.253 seconds
[2025-01-07T22:15:18.308+0000] {processor.py:153} INFO - Started process (PID=582) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:15:18.309+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:15:18.310+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:15:18.310+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:15:18.420+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:15:18,420] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:15:18.466+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:15:18,466] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:15:18.466+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:15:18,466] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:15:18.472+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:15:18.468+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:15:18.473+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:15:18.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.186 seconds
[2025-01-07T22:15:48.664+0000] {processor.py:153} INFO - Started process (PID=661) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:15:48.665+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:15:48.666+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:15:48.666+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:15:48.792+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:15:48,792] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:15:48.844+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:15:48,844] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:15:48.844+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:15:48,844] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:15:48.851+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:15:48.846+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:15:48.852+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:15:48.873+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-07T22:16:19.021+0000] {processor.py:153} INFO - Started process (PID=761) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:16:19.022+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:16:19.023+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:16:19.023+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:16:19.153+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:16:19,153] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:16:19.198+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:16:19,198] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:16:19.199+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:16:19,199] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:16:19.205+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:16:19.200+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:16:19.205+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:16:19.224+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.207 seconds
[2025-01-07T22:16:49.918+0000] {processor.py:153} INFO - Started process (PID=841) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:16:49.919+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:16:49.920+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:16:49.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:16:50.041+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:16:50,041] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:16:50.099+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:16:50,098] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:16:50.099+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:16:50,099] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:16:50.107+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:16:50.101+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:16:50.107+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:16:50.125+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.210 seconds
[2025-01-07T22:17:20.463+0000] {processor.py:153} INFO - Started process (PID=920) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:17:20.464+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:17:20.465+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:17:20.465+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:17:20.597+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:17:20,597] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:17:20.662+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:17:20,662] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:17:20.663+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:17:20,663] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:17:20.672+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:17:20.664+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:17:20.673+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:17:20.716+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.257 seconds
[2025-01-07T22:17:51.163+0000] {processor.py:153} INFO - Started process (PID=1020) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:17:51.164+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:17:51.165+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:17:51.165+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:17:51.316+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:17:51,316] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:17:51.372+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:17:51,371] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:17:51.372+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:17:51,372] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:17:51.380+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:17:51.374+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:17:51.381+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:17:51.404+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.245 seconds
[2025-01-07T22:18:21.608+0000] {processor.py:153} INFO - Started process (PID=1102) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:18:21.609+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:18:21.610+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:18:21.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:18:21.748+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:18:21,748] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:18:21.792+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:18:21,792] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:18:21.792+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:18:21,792] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:18:21.799+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:18:21.794+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:18:21.799+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:18:21.821+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-07T22:18:52.325+0000] {processor.py:153} INFO - Started process (PID=1181) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:18:52.326+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:18:52.327+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:18:52.326+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:18:52.450+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:18:52,449] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:18:52.498+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:18:52,498] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:18:52.498+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:18:52,498] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:18:52.506+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:18:52.500+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:18:52.507+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:18:52.526+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.205 seconds
[2025-01-07T22:19:23.214+0000] {processor.py:153} INFO - Started process (PID=1271) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:23.219+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:19:23.221+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:19:23.220+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:23.385+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:23,385] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:19:23.432+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:23,432] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:19:23.433+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:23,433] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:19:23.440+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:19:23.434+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:19:23.441+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:23.464+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.256 seconds
[2025-01-07T22:19:54.286+0000] {processor.py:153} INFO - Started process (PID=1363) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:54.288+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:19:54.289+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:19:54.289+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:54.440+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:54,440] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:19:54.495+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:54,495] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:19:54.496+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:54,496] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:19:54.504+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:19:54.497+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:19:54.505+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:54.527+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.247 seconds
[2025-01-07T22:19:59.438+0000] {processor.py:153} INFO - Started process (PID=1403) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:59.440+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:19:59.441+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:19:59.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:59.641+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:59,641] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:19:59.701+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:59,701] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:19:59.701+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:19:59,701] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:19:59.710+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:19:59.703+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:19:59.711+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:19:59.745+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.313 seconds
[2025-01-07T22:20:05.822+0000] {processor.py:153} INFO - Started process (PID=1424) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:05.823+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:20:05.824+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:05.824+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:06.016+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:06,016] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:20:06.066+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:06,066] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:20:06.067+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:06,066] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:20:06.075+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:06.068+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:20:06.076+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:06.101+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-07T22:20:09.161+0000] {processor.py:153} INFO - Started process (PID=1425) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:09.163+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:20:09.164+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:09.164+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:09.197+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:09.195+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 35
    start_date=datetime(2025, , 1),
                              ^
SyntaxError: invalid syntax
[2025-01-07T22:20:09.198+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:09.237+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.082 seconds
[2025-01-07T22:20:10.284+0000] {processor.py:153} INFO - Started process (PID=1426) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:10.285+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:20:10.286+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:10.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:10.549+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:10,549] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:20:10.604+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:10,603] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:20:10.604+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:10,604] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:20:10.612+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:10.606+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:20:10.613+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:10.643+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.363 seconds
[2025-01-07T22:20:40.800+0000] {processor.py:153} INFO - Started process (PID=1506) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:40.801+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:20:40.802+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:40.802+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:40.941+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:40,941] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:20:40.994+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:40,994] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:20:40.995+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:20:40,995] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:20:41.003+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:20:40.996+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:20:41.004+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:20:41.027+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.232 seconds
[2025-01-07T22:22:06.777+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:22:06.779+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:22:06.780+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:22:06.780+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:22:07.217+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:22:07,217] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:22:07.277+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:22:07,276] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:22:07.277+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:22:07,277] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:22:07.285+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:22:07.279+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:22:07.286+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:22:07.313+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.540 seconds
[2025-01-07T22:22:38.130+0000] {processor.py:153} INFO - Started process (PID=141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:22:38.131+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:22:38.132+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:22:38.132+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:22:38.266+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:22:38,266] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:22:38.321+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:22:38,321] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:22:38.321+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:22:38,321] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:22:38.328+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:22:38.323+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:22:38.328+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:22:38.345+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.217 seconds
[2025-01-07T22:23:08.403+0000] {processor.py:153} INFO - Started process (PID=228) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:23:08.404+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:23:08.405+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:23:08.405+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:23:08.618+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:23:08,618] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:23:08.682+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:23:08,681] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:23:08.682+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:23:08,682] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:23:08.692+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:23:08.684+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:23:08.693+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:23:08.721+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.322 seconds
[2025-01-07T22:23:39.365+0000] {processor.py:153} INFO - Started process (PID=321) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:23:39.366+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:23:39.367+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:23:39.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:23:39.476+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:23:39,476] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:23:39.516+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:23:39,516] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:23:39.517+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:23:39,517] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:23:39.524+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:23:39.518+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:23:39.524+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:23:39.541+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.180 seconds
[2025-01-07T22:24:09.819+0000] {processor.py:153} INFO - Started process (PID=401) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:24:09.820+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:24:09.821+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:24:09.821+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:24:09.970+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:24:09,970] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:24:10.021+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:24:10,021] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:24:10.022+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:24:10,022] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:24:10.030+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:24:10.023+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:24:10.030+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:24:10.058+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-07T22:24:40.854+0000] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:24:40.855+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:24:40.856+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:24:40.855+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:24:41.035+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:24:41,035] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:24:41.080+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:24:41,080] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:24:41.080+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:24:41,080] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:24:41.087+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:24:41.082+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:24:41.088+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:24:41.113+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.263 seconds
[2025-01-07T22:25:11.495+0000] {processor.py:153} INFO - Started process (PID=581) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:11.496+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:25:11.497+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:11.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:11.612+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:25:11,612] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:25:11.651+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:25:11,651] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:25:11.652+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:25:11,652] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:25:11.658+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:11.653+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 59, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:25:11.659+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:11.679+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.189 seconds
[2025-01-07T22:25:29.633+0000] {processor.py:153} INFO - Started process (PID=641) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:29.635+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:25:29.636+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:29.635+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:29.652+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:29.651+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 44
    task_id=f"sync_data_connection_{i+1}",
          ^
SyntaxError: invalid syntax
[2025-01-07T22:25:29.653+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:29.681+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.052 seconds
[2025-01-07T22:25:31.659+0000] {processor.py:153} INFO - Started process (PID=642) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:31.660+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:25:31.661+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:31.661+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:31.676+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:31.675+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 44
    task_id=f"sync_data_connection_{i+1}",
          ^
SyntaxError: invalid syntax
[2025-01-07T22:25:31.677+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:31.702+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.046 seconds
[2025-01-07T22:25:35.687+0000] {processor.py:153} INFO - Started process (PID=663) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:35.688+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:25:35.689+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:35.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:35.705+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:35.704+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 44
    task_id=f"sync_data_connection_{i+1}",
          ^
SyntaxError: invalid syntax
[2025-01-07T22:25:35.705+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:35.724+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.040 seconds
[2025-01-07T22:25:37.703+0000] {processor.py:153} INFO - Started process (PID=664) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:37.704+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:25:37.705+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:37.705+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:37.856+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:25:37,856] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:25:37.903+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:25:37,903] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:25:37.904+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:25:37,904] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:25:37.912+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:25:37.905+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:25:37.913+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:25:37.937+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.237 seconds
[2025-01-07T22:26:08.036+0000] {processor.py:153} INFO - Started process (PID=744) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:26:08.037+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:26:08.038+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:26:08.038+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:26:08.164+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:26:08,164] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:26:08.217+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:26:08,217] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:26:08.217+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:26:08,217] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:26:08.225+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:26:08.219+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:26:08.226+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:26:08.244+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.211 seconds
[2025-01-07T22:26:20.801+0000] {processor.py:153} INFO - Started process (PID=804) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:26:20.803+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:26:20.804+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:26:20.804+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:26:21.384+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:26:21,384] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:26:21.452+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:26:21,452] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:26:21.453+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:26:21,453] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:26:21.462+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:26:21.455+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:26:21.462+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:26:21.494+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.700 seconds
[2025-01-07T22:27:56.524+0000] {processor.py:153} INFO - Started process (PID=62) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:27:56.525+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:27:56.527+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:27:56.526+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:27:57.045+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:27:57,044] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:27:57.117+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:27:57,117] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:27:57.118+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:27:57,118] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:27:57.132+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:27:57.121+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:27:57.133+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:27:57.163+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.644 seconds
[2025-01-07T22:28:27.595+0000] {processor.py:153} INFO - Started process (PID=142) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:28:27.596+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:28:27.597+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:28:27.597+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:28:27.711+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:28:27,711] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:28:27.754+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:28:27,754] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:28:27.755+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:28:27,754] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:28:27.761+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:28:27.756+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:28:27.762+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:28:27.781+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.189 seconds
[2025-01-07T22:28:57.871+0000] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:28:57.872+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:28:57.873+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:28:57.873+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:28:58.009+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:28:58,009] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:28:58.060+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:28:58,060] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:28:58.061+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:28:58,061] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:28:58.069+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:28:58.062+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:28:58.070+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:28:58.095+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-07T22:29:28.238+0000] {processor.py:153} INFO - Started process (PID=322) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:29:28.239+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:29:28.240+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:29:28.240+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:29:28.367+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:29:28,367] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:29:28.416+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:29:28,416] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:29:28.417+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:29:28,416] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:29:28.425+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:29:28.418+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:29:28.426+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:29:28.450+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.215 seconds
[2025-01-07T22:29:58.721+0000] {processor.py:153} INFO - Started process (PID=402) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:29:58.722+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:29:58.723+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:29:58.722+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:29:58.872+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:29:58,872] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:29:58.930+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:29:58,930] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:29:58.930+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:29:58,930] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:29:58.937+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:29:58.932+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:29:58.938+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:29:58.957+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.240 seconds
[2025-01-07T22:30:29.470+0000] {processor.py:153} INFO - Started process (PID=482) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:30:29.472+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:30:29.473+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:30:29.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:30:29.581+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:30:29,581] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:30:29.623+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:30:29,623] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:30:29.624+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:30:29,624] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:30:29.630+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:30:29.625+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:30:29.630+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:30:29.648+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.181 seconds
[2025-01-07T22:31:00.348+0000] {processor.py:153} INFO - Started process (PID=571) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:31:00.349+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:31:00.350+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:31:00.350+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:31:00.514+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:31:00,514] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:31:00.574+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:31:00,574] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:31:00.574+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:31:00,574] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:31:00.582+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:31:00.576+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:31:00.583+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:31:00.613+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-07T22:31:30.676+0000] {processor.py:153} INFO - Started process (PID=662) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:31:30.678+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:31:30.679+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:31:30.679+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:31:30.813+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:31:30,813] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:31:30.865+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:31:30,865] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:31:30.866+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:31:30,866] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:31:30.874+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:31:30.867+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:31:30.875+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:31:30.893+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.223 seconds
[2025-01-07T22:32:01.489+0000] {processor.py:153} INFO - Started process (PID=742) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:32:01.490+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:32:01.491+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:32:01.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:32:01.732+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:32:01,732] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:32:01.783+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:32:01,782] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:32:01.783+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:32:01,783] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:32:01.790+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:32:01.784+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:32:01.790+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:32:01.810+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.324 seconds
[2025-01-07T22:32:32.046+0000] {processor.py:153} INFO - Started process (PID=831) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:32:32.051+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:32:32.052+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:32:32.051+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:32:32.486+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:32:32,486] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:32:32.534+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:32:32,534] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:32:32.535+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:32:32,535] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:32:32.543+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:32:32.536+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:32:32.544+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:32:32.573+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.530 seconds
[2025-01-07T22:33:02.800+0000] {processor.py:153} INFO - Started process (PID=922) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:33:02.801+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:33:02.802+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:33:02.802+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:33:02.907+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:33:02,907] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:33:02.950+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:33:02,950] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:33:02.950+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:33:02,950] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:33:02.958+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:33:02.952+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:33:02.959+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:33:02.981+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.184 seconds
[2025-01-07T22:33:33.560+0000] {processor.py:153} INFO - Started process (PID=1002) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:33:33.561+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:33:33.562+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:33:33.562+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:33:33.681+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:33:33,681] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:33:33.729+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:33:33,729] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:33:33.729+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:33:33,729] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:33:33.735+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:33:33.730+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:33:33.736+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:33:33.752+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.198 seconds
[2025-01-07T22:34:03.929+0000] {processor.py:153} INFO - Started process (PID=1102) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:34:03.930+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:34:03.931+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:34:03.931+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:34:04.058+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:34:04,058] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:34:04.098+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:34:04,098] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:34:04.099+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:34:04,099] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:34:04.106+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:34:04.100+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:34:04.106+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:34:04.124+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.199 seconds
[2025-01-07T22:34:34.263+0000] {processor.py:153} INFO - Started process (PID=1182) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:34:34.264+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:34:34.265+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:34:34.265+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:34:34.404+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:34:34,403] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:34:34.464+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:34:34,464] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:34:34.465+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:34:34,465] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:34:34.473+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:34:34.467+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:34:34.474+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:34:34.494+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-07T22:35:04.820+0000] {processor.py:153} INFO - Started process (PID=1271) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:35:04.821+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:35:04.821+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:35:04.821+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:35:04.996+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:35:04,996] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:35:05.043+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:35:05,043] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:35:05.044+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:35:05,044] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:35:05.052+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:35:05.046+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:35:05.052+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:35:05.075+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-07T22:35:35.757+0000] {processor.py:153} INFO - Started process (PID=1362) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:35:35.758+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:35:35.759+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:35:35.759+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:35:35.896+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:35:35,895] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:35:35.953+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:35:35,953] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:35:35.954+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:35:35,953] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:35:35.961+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:35:35.955+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:35:35.962+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:35:35.988+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.235 seconds
[2025-01-07T22:36:06.268+0000] {processor.py:153} INFO - Started process (PID=1442) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:06.270+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:36:06.273+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:36:06.272+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:06.411+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:06,411] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:36:06.466+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:06,466] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:36:06.467+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:06,467] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:36:06.473+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:36:06.468+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 61, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:36:06.474+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:06.493+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.229 seconds
[2025-01-07T22:36:33.004+0000] {processor.py:153} INFO - Started process (PID=1529) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:33.006+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:36:33.007+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:36:33.007+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:33.196+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:33,195] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:36:33.248+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:33,248] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:36:33.249+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:33,249] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:36:33.258+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:36:33.250+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:36:33.259+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:33.284+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.284 seconds
[2025-01-07T22:36:48.714+0000] {processor.py:153} INFO - Started process (PID=1602) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:48.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:36:48.716+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:36:48.716+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:48.880+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:48,880] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:36:48.924+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:48,924] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:36:48.925+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:36:48,924] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:36:48.931+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:36:48.926+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:36:48.932+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:36:48.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-07T22:37:19.409+0000] {processor.py:153} INFO - Started process (PID=1682) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:37:19.410+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:37:19.411+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:37:19.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:37:19.526+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:37:19,526] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:37:19.572+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:37:19,572] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:37:19.573+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:37:19,573] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:37:19.579+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:37:19.574+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:37:19.580+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:37:19.598+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.193 seconds
[2025-01-07T22:37:49.681+0000] {processor.py:153} INFO - Started process (PID=1762) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:37:49.682+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:37:49.683+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:37:49.683+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:37:49.806+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:37:49,806] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:37:49.852+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:37:49,852] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:37:49.853+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:37:49,853] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:37:49.861+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:37:49.854+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:37:49.862+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:37:49.891+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.212 seconds
[2025-01-07T22:38:59.228+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:38:59.230+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:38:59.231+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:38:59.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:38:59.742+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:38:59,742] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:38:59.803+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:38:59,803] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:38:59.803+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:38:59,803] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:38:59.813+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:38:59.805+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:38:59.814+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:38:59.846+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.624 seconds
[2025-01-07T22:39:30.058+0000] {processor.py:153} INFO - Started process (PID=141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:39:30.059+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:39:30.060+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:39:30.059+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:39:30.200+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:39:30,200] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:39:30.248+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:39:30,248] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:39:30.249+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:39:30,249] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:39:30.256+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:39:30.250+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:39:30.257+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:39:30.276+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.222 seconds
[2025-01-07T22:40:01.103+0000] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:01.104+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:40:01.105+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:40:01.105+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:01.282+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:01,281] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:40:01.340+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:01,340] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:40:01.341+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:01,341] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:40:01.349+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:40:01.342+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 60, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:40:01.350+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:01.375+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.276 seconds
[2025-01-07T22:40:02.670+0000] {processor.py:153} INFO - Started process (PID=254) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:02.671+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:40:02.673+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:40:02.672+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:02.896+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:02,896] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:40:02.945+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:02,944] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:40:02.945+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:02,945] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:40:02.954+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:40:02.947+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:40:02.956+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:02.988+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-07T22:40:33.889+0000] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:33.890+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:40:33.890+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:40:33.890+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:34.002+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:34,002] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:40:34.051+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:34,051] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:40:34.051+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:40:34,051] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:40:34.058+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:40:34.053+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:40:34.059+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:40:34.077+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.191 seconds
[2025-01-07T22:42:03.597+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:42:03.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:42:03.600+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:42:03.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:42:04.045+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:42:04,044] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:42:04.104+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:42:04,103] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:42:04.104+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:42:04,104] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:42:04.113+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:42:04.106+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:42:04.114+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:42:04.140+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.548 seconds
[2025-01-07T22:42:35.006+0000] {processor.py:153} INFO - Started process (PID=141) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:42:35.007+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:42:35.008+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:42:35.008+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:42:35.187+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:42:35,187] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:42:35.233+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:42:35,233] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:42:35.234+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:42:35,234] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:42:35.240+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:42:35.235+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:42:35.241+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:42:35.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.261 seconds
[2025-01-07T22:43:05.350+0000] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:43:05.351+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:43:05.352+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:43:05.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:43:05.510+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:43:05,510] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:43:05.556+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:43:05,555] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:43:05.556+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:43:05,556] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:43:05.562+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:43:05.558+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:43:05.563+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:43:05.585+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-07T22:43:35.919+0000] {processor.py:153} INFO - Started process (PID=321) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:43:35.921+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:43:35.922+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:43:35.922+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:43:36.088+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:43:36,087] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:43:36.150+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:43:36,150] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:43:36.151+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:43:36,150] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:43:36.159+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:43:36.153+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:43:36.160+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:43:36.195+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.281 seconds
[2025-01-07T22:44:06.981+0000] {processor.py:153} INFO - Started process (PID=401) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:06.981+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:44:06.982+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:06.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:07.084+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:07,084] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:44:07.141+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:07,141] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:44:07.142+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:07,142] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:44:07.151+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:07.144+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_executable_path=f"{os.environ['AIRFLOW_HOME']}/venv/bin/dbt"
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/dag.py", line 25, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/converter.py", line 173, in __init__
    emit_datasets=emit_datasets,
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/airflow/graph.py", line 175, in build_airflow_graph
    task = create_airflow_task(task_meta, dag, task_group=model_task_group)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/core/airflow.py", line 33, in get_airflow_task
    **task.arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 278, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/local.py", line 66, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/cosmos/operators/base.py", line 135, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2025-01-07T22:44:07.152+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:07.173+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.196 seconds
[2025-01-07T22:44:35.274+0000] {processor.py:153} INFO - Started process (PID=481) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:35.277+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:44:35.278+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:35.278+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:35.471+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:35,471] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:44:35.530+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:35,530] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:44:35.530+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:35,530] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:44:35.542+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:35.632+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:35.632+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:44:35.670+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:35.669+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:44:35.732+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.471 seconds
[2025-01-07T22:44:42.392+0000] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:42.393+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:44:42.394+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:42.393+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:42.557+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:42,557] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:44:42.614+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:42,614] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:44:42.615+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:42,615] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:44:42.627+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:42.643+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:42.642+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:44:42.677+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:42.677+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:44:42.712+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-07T22:44:44.472+0000] {processor.py:153} INFO - Started process (PID=542) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:44.473+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:44:44.474+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:44.474+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:44.639+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:44,639] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:44:44.691+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:44,691] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:44:44.692+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:44:44,692] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:44:44.702+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:44:44.717+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:44.717+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:44:44.758+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:44:44.758+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:44:44.814+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.347 seconds
[2025-01-07T22:46:03.652+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:46:03.653+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:46:03.655+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:46:03.655+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:46:04.065+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:46:04,065] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:46:04.123+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:46:04,123] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:46:04.123+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:46:04,123] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:46:04.139+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:46:04.232+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:46:04.232+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:46:04.275+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:46:04.275+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:46:04.325+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.679 seconds
[2025-01-07T22:46:34.667+0000] {processor.py:153} INFO - Started process (PID=142) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:46:34.668+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:46:34.669+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:46:34.669+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:46:34.795+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:46:34,795] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:46:34.843+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:46:34,843] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:46:34.844+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:46:34,844] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:46:34.852+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:46:34.877+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:46:34.876+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:46:34.911+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:46:34.910+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:46:34.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-07T22:47:05.719+0000] {processor.py:153} INFO - Started process (PID=231) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:05.720+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:05.721+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:05.721+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:05.869+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:05,868] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:05.922+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:05,922] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:05.923+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:05,922] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:05.932+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:05.966+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:05.965+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:06.009+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:06.009+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:06.045+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-07T22:47:09.876+0000] {processor.py:153} INFO - Started process (PID=273) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:09.877+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:09.878+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:09.878+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:10.037+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:10,037] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:10.092+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:10,091] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:10.092+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:10,092] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:10.107+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:10.136+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:10.136+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:10.173+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:10.173+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:10.214+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.341 seconds
[2025-01-07T22:47:14.720+0000] {processor.py:153} INFO - Started process (PID=283) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:14.721+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:14.722+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:14.722+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:14.902+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:14,902] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:15.002+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:15,001] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:15.003+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:15,003] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:15.029+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:15.145+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:15.143+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:15.259+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:15.258+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:15.340+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.624 seconds
[2025-01-07T22:47:15.787+0000] {processor.py:153} INFO - Started process (PID=284) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:15.789+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:15.790+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:15.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:16.065+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:16,064] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:16.124+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:16,124] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:16.125+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:16,125] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:16.141+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:16.183+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:16.183+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:16.228+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:16.228+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:16.281+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.502 seconds
[2025-01-07T22:47:19.818+0000] {processor.py:153} INFO - Started process (PID=294) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:19.820+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:19.821+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:19.821+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:20.049+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:20,048] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:20.155+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:20,155] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:20.158+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:20,157] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:20.194+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:20.253+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:20.253+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:20.311+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:20.311+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:20.367+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.554 seconds
[2025-01-07T22:47:22.370+0000] {processor.py:153} INFO - Started process (PID=306) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:22.372+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:22.373+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:22.373+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:22.581+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:22,581] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:22.635+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:22,635] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:22.636+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:22,636] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:22.650+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:22.686+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:22.686+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:22.739+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:22.739+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:22.785+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.420 seconds
[2025-01-07T22:47:23.435+0000] {processor.py:153} INFO - Started process (PID=307) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:23.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:23.437+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:23.437+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:23.614+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:23,613] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:23.662+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:23,662] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:23.663+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:23,663] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:23.673+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:23.711+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:23.710+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:23.753+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:23.753+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:23.794+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.364 seconds
[2025-01-07T22:47:28.468+0000] {processor.py:153} INFO - Started process (PID=308) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:28.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:28.470+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:28.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:28.653+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:28,652] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:28.706+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:28,705] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:28.706+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:28,706] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:28.724+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:28.760+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:28.760+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:28.801+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:28.801+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:28.842+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.379 seconds
[2025-01-07T22:47:47.173+0000] {processor.py:153} INFO - Started process (PID=368) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:47.174+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:47:47.175+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:47.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:47.333+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:47,333] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:47:47.385+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:47,385] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:47:47.385+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:47:47,385] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:47:47.396+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:47:47.430+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:47.429+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:47:47.472+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:47:47.472+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:47:47.519+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.350 seconds
[2025-01-07T22:48:17.764+0000] {processor.py:153} INFO - Started process (PID=468) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:17.765+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:48:17.766+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:17.766+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:17.917+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:17,916] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:48:17.968+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:17,967] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:48:17.968+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:17,968] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:48:17.979+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:18.010+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:18.010+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:48:18.045+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:18.044+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:48:18.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-07T22:48:48.207+0000] {processor.py:153} INFO - Started process (PID=548) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:48.208+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:48:48.208+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:48.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:48.321+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:48,321] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:48:48.367+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:48,367] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:48:48.367+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:48,367] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:48:48.374+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:48.396+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:48.396+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:48:48.424+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:48.423+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:48:48.449+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.246 seconds
[2025-01-07T22:48:54.333+0000] {processor.py:153} INFO - Started process (PID=549) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:54.334+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:48:54.335+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:54.334+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:54.478+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:54,478] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:48:54.531+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:54,531] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:48:54.532+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:48:54,532] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:48:54.542+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:48:54.637+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:54.637+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:48:54.682+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:48:54.682+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:48:54.730+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.401 seconds
[2025-01-07T22:49:55.297+0000] {processor.py:153} INFO - Started process (PID=61) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:49:55.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:49:55.304+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:49:55.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:49:55.877+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:49:55,877] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:49:55.941+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:49:55,940] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:49:55.941+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:49:55,941] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:49:55.954+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:49:56.052+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:49:56.052+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:49:56.097+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:49:56.097+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:49:56.136+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.845 seconds
[2025-01-07T22:50:26.736+0000] {processor.py:153} INFO - Started process (PID=142) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:50:26.737+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:50:26.738+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:50:26.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:50:26.843+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:50:26,843] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:50:26.886+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:50:26,886] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:50:26.887+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:50:26,886] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:50:26.896+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:50:26.919+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:50:26.919+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:50:26.946+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:50:26.946+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:50:26.973+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-07T22:50:57.124+0000] {processor.py:153} INFO - Started process (PID=243) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:50:57.125+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:50:57.127+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:50:57.126+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:50:57.292+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:50:57,291] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:50:57.340+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:50:57,340] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:50:57.341+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:50:57,340] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:50:57.355+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:50:57.394+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:50:57.394+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:50:57.476+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:50:57.476+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:50:57.528+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.409 seconds
[2025-01-07T22:51:27.831+0000] {processor.py:153} INFO - Started process (PID=322) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:51:27.832+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:51:27.833+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:51:27.833+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:51:27.937+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:51:27,937] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:51:27.986+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:51:27,986] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:51:27.987+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:51:27,986] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:51:27.994+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:51:28.019+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:51:28.018+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:51:28.045+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:51:28.045+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:51:28.071+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.243 seconds
[2025-01-07T22:51:58.451+0000] {processor.py:153} INFO - Started process (PID=402) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:51:58.452+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:51:58.452+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:51:58.452+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:51:58.562+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:51:58,562] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:51:58.621+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:51:58,620] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:51:58.621+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:51:58,621] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:51:58.630+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:51:58.654+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:51:58.654+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:51:58.683+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:51:58.682+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:51:58.713+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.265 seconds
[2025-01-07T22:52:29.197+0000] {processor.py:153} INFO - Started process (PID=502) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:52:29.198+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:52:29.199+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:52:29.199+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:52:29.314+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:52:29,314] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:52:29.358+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:52:29,358] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:52:29.359+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:52:29,359] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:52:29.367+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:52:29.392+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:52:29.392+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:52:29.424+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:52:29.424+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:52:29.453+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.259 seconds
[2025-01-07T22:52:59.617+0000] {processor.py:153} INFO - Started process (PID=583) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:52:59.618+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:52:59.618+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:52:59.618+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:52:59.728+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:52:59,728] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:52:59.770+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:52:59,770] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:52:59.771+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:52:59,771] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:52:59.778+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:52:59.801+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:52:59.801+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:52:59.831+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:52:59.830+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:52:59.854+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.241 seconds
[2025-01-07T22:53:30.001+0000] {processor.py:153} INFO - Started process (PID=672) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:53:30.001+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:53:30.002+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:53:30.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:53:30.114+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:53:30,114] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:53:30.159+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:53:30,159] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:53:30.160+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:53:30,160] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:53:30.168+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:53:30.201+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:53:30.201+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:53:30.231+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:53:30.231+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:53:30.259+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.262 seconds
[2025-01-07T22:54:00.345+0000] {processor.py:153} INFO - Started process (PID=763) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:54:00.346+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:54:00.347+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:54:00.347+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:54:00.450+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:54:00,450] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:54:00.488+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:54:00,488] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:54:00.489+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:54:00,489] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:54:00.498+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:54:00.521+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:54:00.521+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:54:00.547+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:54:00.547+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:54:00.571+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.228 seconds
[2025-01-07T22:54:30.736+0000] {processor.py:153} INFO - Started process (PID=844) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:54:30.737+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:54:30.738+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:54:30.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:54:30.861+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:54:30,861] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:54:30.918+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:54:30,918] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:54:30.918+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:54:30,918] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:54:30.927+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:54:30.955+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:54:30.955+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:54:30.989+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:54:30.989+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:54:31.021+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.289 seconds
[2025-01-07T22:55:01.104+0000] {processor.py:153} INFO - Started process (PID=945) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:55:01.105+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:55:01.106+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:55:01.106+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:55:01.323+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:55:01,323] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:55:01.370+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:55:01,369] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:55:01.370+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:55:01,370] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:55:01.382+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:55:01.420+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:55:01.420+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:55:01.464+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:55:01.464+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:55:01.498+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.397 seconds
[2025-01-07T22:55:31.606+0000] {processor.py:153} INFO - Started process (PID=1026) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:55:31.608+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:55:31.609+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:55:31.609+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:55:31.722+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:55:31,722] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:55:31.767+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:55:31,767] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:55:31.768+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:55:31,768] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:55:31.780+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:55:31.805+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:55:31.805+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:55:31.840+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:55:31.840+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:55:31.870+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.268 seconds
[2025-01-07T22:56:01.986+0000] {processor.py:153} INFO - Started process (PID=1104) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:56:01.987+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:56:01.988+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:56:01.988+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:56:02.116+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:56:02,116] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:56:02.169+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:56:02,169] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:56:02.169+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:56:02,169] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:56:02.179+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:56:02.208+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:56:02.208+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:56:02.243+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:56:02.243+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:56:02.276+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.293 seconds
[2025-01-07T22:56:32.440+0000] {processor.py:153} INFO - Started process (PID=1205) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:56:32.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:56:32.443+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:56:32.442+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:56:32.587+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:56:32,586] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:56:32.643+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:56:32,643] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:56:32.644+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:56:32,644] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:56:32.655+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:56:32.717+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:56:32.716+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:56:32.815+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:56:32.815+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:56:32.845+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.410 seconds
[2025-01-07T22:57:02.970+0000] {processor.py:153} INFO - Started process (PID=1284) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:57:02.971+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:57:02.971+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:57:02.971+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:57:03.071+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:57:03,071] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:57:03.117+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:57:03,117] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:57:03.118+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:57:03,118] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:57:03.125+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:57:03.148+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:57:03.148+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:57:03.174+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:57:03.174+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:57:03.199+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.233 seconds
[2025-01-07T22:57:34.004+0000] {processor.py:153} INFO - Started process (PID=1364) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:57:34.005+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:57:34.006+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:57:34.006+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:57:34.110+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:57:34,110] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:57:34.156+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:57:34,156] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:57:34.157+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:57:34,157] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:57:34.164+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:57:34.186+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:57:34.186+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:57:34.212+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:57:34.212+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:57:34.239+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.238 seconds
[2025-01-07T22:58:04.826+0000] {processor.py:153} INFO - Started process (PID=1464) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:58:04.827+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:58:04.828+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:58:04.827+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:58:04.933+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:58:04,933] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:58:04.975+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:58:04,975] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:58:04.976+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:58:04,976] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:58:04.984+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:58:05.008+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:58:05.008+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:58:05.035+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:58:05.035+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:58:05.062+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.239 seconds
[2025-01-07T22:58:35.966+0000] {processor.py:153} INFO - Started process (PID=1544) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:58:35.967+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:58:35.968+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:58:35.968+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:58:36.091+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:58:36,091] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:58:36.136+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:58:36,136] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:58:36.136+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:58:36,136] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:58:36.149+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:58:36.175+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:58:36.175+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:58:36.206+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:58:36.206+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:58:36.236+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.275 seconds
[2025-01-07T22:59:06.321+0000] {processor.py:153} INFO - Started process (PID=1644) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:59:06.322+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:59:06.323+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:59:06.323+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:59:06.483+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:59:06,483] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:59:06.530+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:59:06,530] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:59:06.531+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:59:06,531] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:59:06.541+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:59:06.571+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:59:06.571+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:59:06.615+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:59:06.615+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:59:06.646+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.330 seconds
[2025-01-07T22:59:36.753+0000] {processor.py:153} INFO - Started process (PID=1724) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:59:36.754+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T22:59:36.754+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:59:36.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:59:36.863+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:59:36,863] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T22:59:36.901+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:59:36,901] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T22:59:36.902+0000] {logging_mixin.py:137} WARNING - [2025-01-07 22:59:36,902] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T22:59:36.909+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T22:59:36.936+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:59:36.936+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T22:59:36.969+0000] {logging_mixin.py:137} INFO - [2025-01-07T22:59:36.969+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T22:59:37.007+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.258 seconds
[2025-01-07T23:00:07.201+0000] {processor.py:153} INFO - Started process (PID=1804) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T23:00:07.202+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T23:00:07.202+0000] {logging_mixin.py:137} INFO - [2025-01-07T23:00:07.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T23:00:07.322+0000] {logging_mixin.py:137} WARNING - [2025-01-07 23:00:07,322] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T23:00:07.365+0000] {logging_mixin.py:137} WARNING - [2025-01-07 23:00:07,365] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T23:00:07.365+0000] {logging_mixin.py:137} WARNING - [2025-01-07 23:00:07,365] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T23:00:07.373+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T23:00:07.397+0000] {logging_mixin.py:137} INFO - [2025-01-07T23:00:07.396+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T23:00:07.424+0000] {logging_mixin.py:137} INFO - [2025-01-07T23:00:07.424+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T23:00:07.451+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.254 seconds
[2025-01-07T23:00:37.608+0000] {processor.py:153} INFO - Started process (PID=1905) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T23:00:37.608+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-07T23:00:37.609+0000] {logging_mixin.py:137} INFO - [2025-01-07T23:00:37.609+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T23:00:37.736+0000] {logging_mixin.py:137} WARNING - [2025-01-07 23:00:37,736] {graph.py:217} INFO - (astronomer-cosmos) - Trying to parse the dbt project `dbt_stock_project` using a custom Cosmos method...
[2025-01-07T23:00:37.782+0000] {logging_mixin.py:137} WARNING - [2025-01-07 23:00:37,782] {graph.py:245} INFO - (astronomer-cosmos) - Total nodes: 1
[2025-01-07T23:00:37.783+0000] {logging_mixin.py:137} WARNING - [2025-01-07 23:00:37,783] {graph.py:246} INFO - (astronomer-cosmos) - Total filtered nodes: 1
[2025-01-07T23:00:37.791+0000] {processor.py:753} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-07T23:00:37.817+0000] {logging_mixin.py:137} INFO - [2025-01-07T23:00:37.817+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2025-01-07T23:00:37.846+0000] {logging_mixin.py:137} INFO - [2025-01-07T23:00:37.846+0000] {dag.py:3441} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-07T00:00:00+00:00, run_after=2025-01-08T00:00:00+00:00
[2025-01-07T23:00:37.874+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.269 seconds
