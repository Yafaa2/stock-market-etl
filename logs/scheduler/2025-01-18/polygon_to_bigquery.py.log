[2025-01-18T00:11:03.542+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:11:03.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:11:03.560+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:03.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:11:03.818+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:03.817+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:11:07.694+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:07.693+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 3.8117623800000047
[2025-01-18T00:11:07.695+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:07.695+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-18T00:11:07.696+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:07.696+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-18T00:11:07.710+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:07.710+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-18T00:11:07.743+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:07.742+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-18T00:11:07.750+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:07.749+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-18T00:11:07.751+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:07.751+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpc18bway6 --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-18T00:11:33.607+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:33.606+0000] {timeout.py:68} ERROR - Process timed out, PID: 90
[2025-01-18T00:11:33.647+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:33.611+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/polygon_to_bigquery.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/polygon_to_bigquery.py", line 56, in <module>
    dbt_transformation = DbtTaskGroup(
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/airflow/task_group.py", line 28, in __init__
    DbtToAirflowConverter.__init__(self, *args, **specific_kwargs(**kwargs))
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/converter.py", line 261, in __init__
    self.dbt_graph.load(method=render_config.load_method, execution_mode=execution_config.execution_mode)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 434, in load
    self.load_via_dbt_ls()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 493, in load_via_dbt_ls
    self.load_via_dbt_ls_without_cache()
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 612, in load_via_dbt_ls_without_cache
    nodes = self.run_dbt_ls(dbt_cmd, self.project_path, tmpdir_path, env)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 474, in run_dbt_ls
    stdout = run_command(ls_command, tmp_dir, env_vars)
  File "/home/airflow/.local/lib/python3.8/site-packages/cosmos/dbt/graph.py", line 174, in run_command
    stdout, stderr = process.communicate()
  File "/usr/local/lib/python3.8/subprocess.py", line 1028, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
  File "/usr/local/lib/python3.8/subprocess.py", line 1884, in _communicate
    ready = selector.select(timeout)
  File "/usr/local/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/polygon_to_bigquery.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 90
[2025-01-18T00:11:33.662+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:11:34.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 30.586 seconds
[2025-01-18T00:11:34.172+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:11:34.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:11:34.183+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:34.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:11:34.357+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:34.356+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:11:35.367+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:35.367+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.8506181679999969
[2025-01-18T00:11:35.368+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:35.368+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-18T00:11:35.370+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:35.370+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-18T00:11:35.414+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:35.414+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-18T00:11:35.438+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:35.437+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-18T00:11:35.444+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:35.443+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'dependencies.yml', 'packages.yml'}
[2025-01-18T00:11:35.445+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:35.445+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmplrk0xboi --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-18T00:11:57.531+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.530+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23767806200000052
[2025-01-18T00:11:57.544+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.543+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-18T00:11:57.565+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.564+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:11:57.567+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.567+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:11:57.569+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.568+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|184]: It took 23.2s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-18T00:11:57.596+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.596+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|184]: It took 0.0278s to build the Airflow DAG.
[2025-01-18T00:11:57.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:11:57.706+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.705+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_4', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '663e9fea-7ce6-4097-b671-b672165268bf'}
[2025-01-18T00:11:57.776+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.775+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_4, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001157
[2025-01-18T00:11:57.808+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_4 scheduled__2025-01-16T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2025-01-18T00:11:57.815+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.814+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '6f74cd83-5299-4131-b55c-315aad442664'}
[2025-01-18T00:11:57.841+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.841+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001157
[2025-01-18T00:11:57.849+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 scheduled__2025-01-16T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2025-01-18T00:11:57.855+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.854+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '0127f6a3-0b1c-4543-89a5-1018e8ace7d5'}
[2025-01-18T00:11:57.877+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.876+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001157
[2025-01-18T00:11:57.886+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 scheduled__2025-01-16T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2025-01-18T00:11:57.895+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.894+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '52b83911-e373-442b-8670-f40f8e96d9e1'}
[2025-01-18T00:11:57.926+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.926+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001157
[2025-01-18T00:11:57.934+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 scheduled__2025-01-16T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2025-01-18T00:11:57.940+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.940+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_5', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'b5744d0c-1d2b-4d47-853d-35963890350e'}
[2025-01-18T00:11:57.968+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.968+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_5, execution_date=20250116T000000, start_date=20250117T175827, end_date=20250118T001157
[2025-01-18T00:11:57.984+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_5 scheduled__2025-01-16T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2025-01-18T00:11:57.992+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:57.992+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_4', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '663e9fea-7ce6-4097-b671-b672165268bf'}
[2025-01-18T00:11:58.023+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.022+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_4, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001158
[2025-01-18T00:11:58.033+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_4 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.040+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.040+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '6f74cd83-5299-4131-b55c-315aad442664'}
[2025-01-18T00:11:58.067+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.066+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001158
[2025-01-18T00:11:58.077+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.083+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.083+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '0127f6a3-0b1c-4543-89a5-1018e8ace7d5'}
[2025-01-18T00:11:58.122+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.122+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001158
[2025-01-18T00:11:58.130+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.141+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.140+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '52b83911-e373-442b-8670-f40f8e96d9e1'}
[2025-01-18T00:11:58.177+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.177+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001158
[2025-01-18T00:11:58.185+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.194+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.193+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_5', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'b5744d0c-1d2b-4d47-853d-35963890350e'}
[2025-01-18T00:11:58.222+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.221+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_5, execution_date=20250116T000000, start_date=20250117T175827, end_date=20250118T001158
[2025-01-18T00:11:58.234+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_5 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.241+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.240+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_4', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '663e9fea-7ce6-4097-b671-b672165268bf'}
[2025-01-18T00:11:58.277+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.277+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_4, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001158
[2025-01-18T00:11:58.291+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_4 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.300+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.299+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '6f74cd83-5299-4131-b55c-315aad442664'}
[2025-01-18T00:11:58.336+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.336+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001158
[2025-01-18T00:11:58.343+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.355+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.354+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '0127f6a3-0b1c-4543-89a5-1018e8ace7d5'}
[2025-01-18T00:11:58.395+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.395+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001158
[2025-01-18T00:11:58.407+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.412+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.412+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '52b83911-e373-442b-8670-f40f8e96d9e1'}
[2025-01-18T00:11:58.486+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.486+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001158
[2025-01-18T00:11:58.507+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.517+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.517+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_5', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'b5744d0c-1d2b-4d47-853d-35963890350e'}
[2025-01-18T00:11:58.552+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.552+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_5, execution_date=20250116T000000, start_date=20250117T175827, end_date=20250118T001158
[2025-01-18T00:11:58.567+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_5 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:11:58.650+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.650+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:11:58.839+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:11:58.839+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:11:58.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 24.783 seconds
[2025-01-18T00:12:29.173+0000] {processor.py:157} INFO - Started process (PID=352) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:12:29.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:12:29.177+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:12:29.246+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.246+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:12:29.511+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.510+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23697476200001688
[2025-01-18T00:12:29.512+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.512+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|352]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:12:29.514+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.514+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:12:29.514+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.514+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:12:29.515+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.515+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:12:29.515+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.515+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|352]: It took 0.269s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:12:29.524+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.524+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|352]: It took 0.00841s to build the Airflow DAG.
[2025-01-18T00:12:29.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:12:29.553+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.553+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_4', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '663e9fea-7ce6-4097-b671-b672165268bf'}
[2025-01-18T00:12:29.601+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.601+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_4, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001229
[2025-01-18T00:12:29.623+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_4 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.627+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.626+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '6f74cd83-5299-4131-b55c-315aad442664'}
[2025-01-18T00:12:29.645+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.644+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001229
[2025-01-18T00:12:29.649+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.652+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.652+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '0127f6a3-0b1c-4543-89a5-1018e8ace7d5'}
[2025-01-18T00:12:29.668+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.668+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001229
[2025-01-18T00:12:29.672+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.675+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.674+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '52b83911-e373-442b-8670-f40f8e96d9e1'}
[2025-01-18T00:12:29.687+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.687+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001229
[2025-01-18T00:12:29.692+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.696+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.695+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_5', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'b5744d0c-1d2b-4d47-853d-35963890350e'}
[2025-01-18T00:12:29.711+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.711+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_5, execution_date=20250116T000000, start_date=20250117T175827, end_date=20250118T001229
[2025-01-18T00:12:29.724+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_5 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.728+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.728+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_4', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '663e9fea-7ce6-4097-b671-b672165268bf'}
[2025-01-18T00:12:29.745+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.745+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_4, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001229
[2025-01-18T00:12:29.749+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_4 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.752+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.752+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '6f74cd83-5299-4131-b55c-315aad442664'}
[2025-01-18T00:12:29.767+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.767+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250116T000000, start_date=20250117T175828, end_date=20250118T001229
[2025-01-18T00:12:29.774+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.777+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.777+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '0127f6a3-0b1c-4543-89a5-1018e8ace7d5'}
[2025-01-18T00:12:29.794+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.794+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001229
[2025-01-18T00:12:29.798+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.801+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.801+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '52b83911-e373-442b-8670-f40f8e96d9e1'}
[2025-01-18T00:12:29.814+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.814+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250116T000000, start_date=20250117T175816, end_date=20250118T001229
[2025-01-18T00:12:29.817+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.820+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.819+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_5', 'Run Id': 'scheduled__2025-01-16T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'b5744d0c-1d2b-4d47-853d-35963890350e'}
[2025-01-18T00:12:29.831+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.831+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_5, execution_date=20250116T000000, start_date=20250117T175827, end_date=20250118T001229
[2025-01-18T00:12:29.834+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_5 scheduled__2025-01-16T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:12:29.851+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.851+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:12:29.875+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:29.874+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:12:29.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.730 seconds
[2025-01-18T00:12:59.965+0000] {processor.py:157} INFO - Started process (PID=430) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:12:59.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:12:59.973+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:12:59.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:13:00.035+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.034+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:13:00.372+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.371+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.30146885999999995
[2025-01-18T00:13:00.373+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.372+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|430]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:13:00.374+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.374+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:13:00.375+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.375+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:13:00.376+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.376+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:13:00.377+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.376+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|430]: It took 0.343s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:13:00.385+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.385+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|430]: It took 0.00881s to build the Airflow DAG.
[2025-01-18T00:13:00.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:13:00.424+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.424+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:13:00.485+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:13:00.485+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:13:00.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.570 seconds
[2025-01-18T00:14:23.789+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:14:23.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:14:23.798+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:23.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:14:23.843+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:23.842+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:14:24.143+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.143+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.270951636999996
[2025-01-18T00:14:24.144+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.144+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|78]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:14:24.146+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.145+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:14:24.146+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.146+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:14:24.147+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.147+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:14:24.148+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.148+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|78]: It took 0.306s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:14:24.162+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.161+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|78]: It took 0.0134s to build the Airflow DAG.
[2025-01-18T00:14:24.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:14:24.208+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.208+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:14:24.261+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:24.261+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:14:24.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.521 seconds
[2025-01-18T00:14:54.651+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:14:54.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:14:54.656+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:14:54.686+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.685+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:14:54.963+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.963+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2609688290000065
[2025-01-18T00:14:54.964+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.963+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|156]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:14:54.965+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.965+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:14:54.965+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.965+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:14:54.966+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.966+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:14:54.967+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.967+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|156]: It took 0.281s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:14:54.975+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:54.975+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|156]: It took 0.00825s to build the Airflow DAG.
[2025-01-18T00:14:54.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:14:55.002+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:55.001+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:14:55.049+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:14:55.049+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:14:55.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.436 seconds
[2025-01-18T00:15:25.224+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:15:25.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:15:25.229+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:15:25.263+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.263+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:15:25.496+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.496+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21158754500000043
[2025-01-18T00:15:25.497+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.497+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|242]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:15:25.498+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.498+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:15:25.498+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.498+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:15:25.499+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.499+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:15:25.500+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.499+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|242]: It took 0.237s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:15:25.508+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.508+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|242]: It took 0.00832s to build the Airflow DAG.
[2025-01-18T00:15:25.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:15:25.533+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.533+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:15:25.567+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:25.567+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:15:25.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.413 seconds
[2025-01-18T00:15:55.905+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:15:55.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:15:55.913+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:55.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:15:55.961+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:55.960+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:15:56.378+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.378+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.38711194199999
[2025-01-18T00:15:56.380+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.379+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|328]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:15:56.382+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.381+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:15:56.383+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.383+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:15:56.384+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.383+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:15:56.385+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.384+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|328]: It took 0.424s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:15:56.394+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.394+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|328]: It took 0.0096s to build the Airflow DAG.
[2025-01-18T00:15:56.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:15:56.430+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.430+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:15:56.488+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:15:56.488+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:15:56.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.629 seconds
[2025-01-18T00:16:27.309+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:16:27.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:16:27.324+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:16:27.375+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.374+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:16:27.949+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.948+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.546777923999997
[2025-01-18T00:16:27.950+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.950+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|414]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:16:27.952+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.952+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:16:27.954+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.953+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:16:27.956+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.955+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:16:27.957+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.957+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|414]: It took 0.583s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:16:27.970+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:27.969+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|414]: It took 0.013s to build the Airflow DAG.
[2025-01-18T00:16:27.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:16:28.067+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:28.065+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:16:28.172+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:28.171+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:16:28.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.962 seconds
[2025-01-18T00:16:58.467+0000] {processor.py:157} INFO - Started process (PID=495) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:16:58.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:16:58.474+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:16:58.522+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.522+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:16:58.931+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.930+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.37787134600000627
[2025-01-18T00:16:58.932+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.931+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|495]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:16:58.933+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.933+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:16:58.934+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.933+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:16:58.935+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.934+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:16:58.936+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.935+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|495]: It took 0.414s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:16:58.945+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.945+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|495]: It took 0.00934s to build the Airflow DAG.
[2025-01-18T00:16:58.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:16:58.983+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:58.983+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:16:59.049+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:16:59.049+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:16:59.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.635 seconds
[2025-01-18T00:17:29.557+0000] {processor.py:157} INFO - Started process (PID=585) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:17:29.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:17:29.563+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:29.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:17:29.604+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:29.604+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:17:29.999+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:29.999+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3647985539999752
[2025-01-18T00:17:30.000+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.000+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|585]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:17:30.006+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.005+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:17:30.007+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.006+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:17:30.008+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.007+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:17:30.009+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.009+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|585]: It took 0.405s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:17:30.023+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.022+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|585]: It took 0.0139s to build the Airflow DAG.
[2025-01-18T00:17:30.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:17:30.075+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.075+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:17:30.158+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:17:30.158+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:17:30.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.684 seconds
[2025-01-18T00:18:00.384+0000] {processor.py:157} INFO - Started process (PID=665) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:18:00.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:18:00.389+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:18:00.421+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.420+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:18:00.652+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.652+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21249789399999486
[2025-01-18T00:18:00.653+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.653+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|665]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:18:00.654+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.654+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:18:00.654+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.654+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:18:00.655+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.655+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:18:00.655+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.655+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|665]: It took 0.235s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:18:00.660+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.660+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|665]: It took 0.00502s to build the Airflow DAG.
[2025-01-18T00:18:00.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:18:00.682+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.682+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:18:00.714+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:00.713+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:18:00.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.366 seconds
[2025-01-18T00:18:31.475+0000] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:18:31.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:18:31.479+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:18:31.509+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.508+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:18:31.788+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.788+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2618599359999507
[2025-01-18T00:18:31.790+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.789+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|751]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:18:31.792+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.791+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:18:31.793+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.793+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:18:31.794+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.793+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:18:31.795+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.794+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|751]: It took 0.286s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:18:31.802+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.801+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|751]: It took 0.00708s to build the Airflow DAG.
[2025-01-18T00:18:31.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:18:31.826+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.826+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:18:31.871+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:18:31.870+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:18:31.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.431 seconds
[2025-01-18T00:19:02.353+0000] {processor.py:157} INFO - Started process (PID=837) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:19:02.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:19:02.359+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:19:02.393+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.392+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:19:02.658+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.658+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24333407199998192
[2025-01-18T00:19:02.659+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.659+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|837]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:19:02.660+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.660+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:19:02.661+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.660+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:19:02.661+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.661+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:19:02.662+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.662+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|837]: It took 0.27s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:19:02.669+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.668+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|837]: It took 0.00662s to build the Airflow DAG.
[2025-01-18T00:19:02.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:19:02.693+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.692+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:19:02.753+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:02.753+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:19:02.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.444 seconds
[2025-01-18T00:19:33.046+0000] {processor.py:157} INFO - Started process (PID=912) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:19:33.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:19:33.050+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:19:33.078+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.078+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:19:33.413+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.413+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.31829155200000514
[2025-01-18T00:19:33.414+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.414+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|912]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:19:33.415+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.415+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:19:33.416+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.416+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:19:33.417+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.417+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:19:33.418+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.417+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|912]: It took 0.34s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:19:33.426+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.425+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|912]: It took 0.00819s to build the Airflow DAG.
[2025-01-18T00:19:33.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:19:33.453+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.453+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:19:33.494+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:19:33.494+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:19:33.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.477 seconds
[2025-01-18T00:20:03.603+0000] {processor.py:157} INFO - Started process (PID=997) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:20:03.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:20:03.606+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:20:03.635+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.635+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:20:03.900+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.900+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24750073200004863
[2025-01-18T00:20:03.901+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.900+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|997]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:20:03.902+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.902+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:20:03.902+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.902+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:20:03.903+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.903+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:20:03.903+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.903+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|997]: It took 0.269s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:20:03.910+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.910+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|997]: It took 0.00674s to build the Airflow DAG.
[2025-01-18T00:20:03.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:20:03.935+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.934+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:20:03.968+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:03.968+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:20:03.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.395 seconds
[2025-01-18T00:20:34.071+0000] {processor.py:157} INFO - Started process (PID=1078) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:20:34.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:20:34.075+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:20:34.103+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.103+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:20:34.302+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.301+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1821304680000253
[2025-01-18T00:20:34.302+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.302+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1078]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:20:34.303+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.303+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:20:34.304+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.303+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:20:34.304+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.304+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:20:34.304+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.304+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1078]: It took 0.201s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:20:34.309+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.309+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1078]: It took 0.00476s to build the Airflow DAG.
[2025-01-18T00:20:34.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:20:34.329+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.328+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:20:34.364+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:20:34.364+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:20:34.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.325 seconds
[2025-01-18T00:21:04.982+0000] {processor.py:157} INFO - Started process (PID=1162) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:21:04.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:21:04.985+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:04.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:21:05.016+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.016+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:21:05.309+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.308+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2757209659999944
[2025-01-18T00:21:05.309+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.309+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1162]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:21:05.311+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.310+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:21:05.311+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.311+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:21:05.312+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.312+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:21:05.312+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.312+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1162]: It took 0.297s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:21:05.318+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.318+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1162]: It took 0.00579s to build the Airflow DAG.
[2025-01-18T00:21:05.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:21:05.342+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.342+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:21:05.385+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:21:05.385+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:21:05.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.433 seconds
[2025-01-18T00:31:57.463+0000] {processor.py:157} INFO - Started process (PID=109) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:31:57.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:31:57.516+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:57.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:31:57.600+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:57.600+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:31:59.873+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:59.872+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 2.017199027999993
[2025-01-18T00:31:59.883+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:59.882+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|109]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:31:59.891+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:59.890+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:31:59.894+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:59.892+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:31:59.899+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:59.899+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:31:59.903+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:59.902+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|109]: It took 2.3s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:31:59.936+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:31:59.935+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|109]: It took 0.0333s to build the Airflow DAG.
[2025-01-18T00:31:59.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:32:00.111+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:00.111+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:32:00.387+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:00.387+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:32:00.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 3.035 seconds
[2025-01-18T00:32:06.164+0000] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:32:06.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:32:06.172+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:32:06.209+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.209+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:32:06.448+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.448+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21903695099999254
[2025-01-18T00:32:06.449+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.449+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|147]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:32:06.450+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.450+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:32:06.451+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.451+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:32:06.452+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.451+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:32:06.452+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.452+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|147]: It took 0.243s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:32:06.458+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.458+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|147]: It took 0.00604s to build the Airflow DAG.
[2025-01-18T00:32:06.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:32:06.488+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.488+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_1', 'Run Id': 'scheduled__2025-01-17T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'fbf601c2-cd3d-48c6-958d-7fa3f4133969'}
[2025-01-18T00:32:06.530+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.530+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_1, execution_date=20250117T000000, start_date=20250118T002117, end_date=20250118T003206
[2025-01-18T00:32:06.548+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_1 scheduled__2025-01-17T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:32:06.551+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.551+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_5', 'Run Id': 'scheduled__2025-01-17T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'da145f5a-4f7c-429d-95f6-612624ebad7b'}
[2025-01-18T00:32:06.572+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.571+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_5, execution_date=20250117T000000, start_date=20250118T002119, end_date=20250118T003206
[2025-01-18T00:32:06.577+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_5 scheduled__2025-01-17T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:32:06.581+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.581+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_2', 'Run Id': 'scheduled__2025-01-17T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': 'c3ef0bc0-356b-4b1b-81df-c32c8bbcfe16'}
[2025-01-18T00:32:06.601+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.601+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_2, execution_date=20250117T000000, start_date=20250118T002117, end_date=20250118T003206
[2025-01-18T00:32:06.607+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_2 scheduled__2025-01-17T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:32:06.622+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.621+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_3', 'Run Id': 'scheduled__2025-01-17T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '72f5ec4d-d6b5-4b4b-98d9-7ce666dc8e90'}
[2025-01-18T00:32:06.647+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.647+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_3, execution_date=20250117T000000, start_date=20250118T002117, end_date=20250118T003206
[2025-01-18T00:32:06.654+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_3 scheduled__2025-01-17T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:32:06.659+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.659+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'PolygonAPI_to_BigQuery', 'Task Id': 'sync_data_connection_4', 'Run Id': 'scheduled__2025-01-17T00:00:00+00:00', 'Hostname': 'a7a323ab681c', 'External Executor Id': '5ed80247-076e-45f7-80d8-2ec827fea8fc'}
[2025-01-18T00:32:06.683+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.682+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_data_connection_4, execution_date=20250117T000000, start_date=20250118T002117, end_date=20250118T003206
[2025-01-18T00:32:06.689+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: PolygonAPI_to_BigQuery.sync_data_connection_4 scheduled__2025-01-17T00:00:00+00:00 [failed]> in state failed
[2025-01-18T00:32:06.722+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.721+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:32:06.779+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:06.778+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:32:06.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.649 seconds
[2025-01-18T00:32:36.951+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:32:36.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:32:36.957+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:36.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:32:36.985+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:36.985+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:32:37.209+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.209+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20236662599999988
[2025-01-18T00:32:37.209+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.209+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|234]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:32:37.211+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.210+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:32:37.212+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.212+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:32:37.212+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.212+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:32:37.213+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.213+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|234]: It took 0.227s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:32:37.219+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.219+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|234]: It took 0.00621s to build the Airflow DAG.
[2025-01-18T00:32:37.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:32:37.238+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.238+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:32:37.268+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:32:37.268+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:32:37.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.352 seconds
[2025-01-18T00:33:50.064+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:33:50.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:33:50.068+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:33:50.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:33:50.090+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:33:50.090+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:54:41.455+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:54:41.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:54:41.461+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:41.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:54:41.495+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:41.494+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:54:42.756+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.756+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 1.2371197200000026
[2025-01-18T00:54:42.757+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.756+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|78]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:54:42.758+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.758+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:54:42.758+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.758+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:54:42.759+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.759+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:54:42.759+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.759+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|78]: It took 1.26s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:54:42.767+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.767+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|78]: It took 0.00807s to build the Airflow DAG.
[2025-01-18T00:54:42.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:54:42.793+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.793+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:54:42.832+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:54:42.832+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:54:42.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.415 seconds
[2025-01-18T00:55:13.022+0000] {processor.py:157} INFO - Started process (PID=170) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:55:13.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:55:13.029+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:55:13.061+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.061+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:55:13.580+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.580+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.49011558399999444
[2025-01-18T00:55:13.582+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.581+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|170]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:55:13.585+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.585+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:55:13.590+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.590+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:55:13.591+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.591+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:55:13.592+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.592+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|170]: It took 0.531s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:55:13.616+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.616+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|170]: It took 0.0239s to build the Airflow DAG.
[2025-01-18T00:55:13.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:55:13.656+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.655+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:55:13.725+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:13.724+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:55:13.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.792 seconds
[2025-01-18T00:55:44.645+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:55:44.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:55:44.650+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:55:44.675+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.675+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:55:44.895+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.895+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.20290054200000895
[2025-01-18T00:55:44.896+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.896+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|251]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:55:44.898+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.897+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:55:44.898+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.898+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:55:44.899+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.899+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:55:44.900+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.900+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|251]: It took 0.225s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:55:44.910+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.909+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|251]: It took 0.00928s to build the Airflow DAG.
[2025-01-18T00:55:44.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:55:44.945+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.945+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:55:44.993+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:55:44.993+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:55:45.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.392 seconds
[2025-01-18T00:56:15.141+0000] {processor.py:157} INFO - Started process (PID=338) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:56:15.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:56:15.147+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:56:15.185+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.184+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:56:15.476+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.476+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2641327219999994
[2025-01-18T00:56:15.477+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.477+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|338]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:56:15.478+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.478+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:56:15.479+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.479+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:56:15.479+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.479+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:56:15.480+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.480+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|338]: It took 0.296s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:56:15.487+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.486+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|338]: It took 0.00659s to build the Airflow DAG.
[2025-01-18T00:56:15.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:56:15.518+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.518+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:56:15.577+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:15.577+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:56:15.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.478 seconds
[2025-01-18T00:56:45.715+0000] {processor.py:157} INFO - Started process (PID=424) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:56:45.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:56:45.722+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:45.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:56:45.765+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:45.765+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:56:46.105+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.105+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.30891341800000305
[2025-01-18T00:56:46.106+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.106+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|424]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:56:46.108+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.107+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:56:46.108+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.108+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:56:46.109+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.109+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:56:46.110+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.109+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|424]: It took 0.345s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:56:46.116+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.115+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|424]: It took 0.00599s to build the Airflow DAG.
[2025-01-18T00:56:46.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:56:46.139+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.138+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:56:46.178+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:56:46.178+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:56:46.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.499 seconds
[2025-01-18T00:57:16.936+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:57:16.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:57:16.941+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:16.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:57:16.972+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:16.972+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:57:17.248+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.247+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.25322753599999714
[2025-01-18T00:57:17.249+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.248+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|499]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:57:17.251+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.250+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:57:17.251+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.251+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:57:17.252+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.252+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:57:17.253+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.253+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|499]: It took 0.282s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:57:17.263+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.262+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|499]: It took 0.00941s to build the Airflow DAG.
[2025-01-18T00:57:17.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:57:17.295+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.295+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:57:17.353+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:17.352+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:57:17.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.457 seconds
[2025-01-18T00:57:47.606+0000] {processor.py:157} INFO - Started process (PID=579) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:57:47.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:57:47.614+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:47.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:57:47.660+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:47.660+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:57:48.005+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.004+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.31326195500000154
[2025-01-18T00:57:48.006+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.006+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|579]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:57:48.007+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.007+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:57:48.008+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.008+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:57:48.009+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.009+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:57:48.010+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.010+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|579]: It took 0.35s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:57:48.019+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.018+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|579]: It took 0.00866s to build the Airflow DAG.
[2025-01-18T00:57:48.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:57:48.053+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.052+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:57:48.134+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:57:48.133+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:57:48.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.574 seconds
[2025-01-18T00:58:19.094+0000] {processor.py:157} INFO - Started process (PID=667) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:58:19.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:58:19.105+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:58:19.157+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.157+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:58:19.540+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.539+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3422564809999926
[2025-01-18T00:58:19.540+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.540+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|667]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:58:19.542+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.541+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:58:19.542+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.542+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:58:19.543+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.543+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:58:19.545+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.544+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|667]: It took 0.388s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:58:19.557+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.556+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|667]: It took 0.0117s to build the Airflow DAG.
[2025-01-18T00:58:19.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:58:19.593+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.592+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:58:19.651+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:19.650+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:58:19.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.599 seconds
[2025-01-18T00:58:51.930+0000] {processor.py:157} INFO - Started process (PID=745) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:58:51.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:58:52.040+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:52.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:58:52.408+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:52.407+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:58:53.944+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:53.943+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 1.4547901690000344
[2025-01-18T00:58:53.949+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:53.948+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|745]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:58:53.953+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:53.952+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:58:53.955+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:53.954+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:58:53.957+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:53.956+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:58:53.962+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:53.961+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|745]: It took 1.55s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:58:54.089+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:54.088+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|745]: It took 0.127s to build the Airflow DAG.
[2025-01-18T00:58:54.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:58:54.204+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:54.203+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:58:54.559+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:58:54.558+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:58:54.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 2.842 seconds
[2025-01-18T00:59:25.115+0000] {processor.py:157} INFO - Started process (PID=832) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:59:25.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:59:25.126+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:59:25.225+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.224+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:59:25.795+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.795+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.5131687060000445
[2025-01-18T00:59:25.797+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.796+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|832]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:59:25.805+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.804+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:59:25.808+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.807+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:59:25.809+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.808+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:59:25.810+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.810+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|832]: It took 0.591s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:59:25.842+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.841+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|832]: It took 0.0314s to build the Airflow DAG.
[2025-01-18T00:59:25.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:59:25.929+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:25.928+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:59:26.009+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:26.008+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:59:26.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.996 seconds
[2025-01-18T00:59:56.400+0000] {processor.py:157} INFO - Started process (PID=910) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:59:56.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T00:59:56.408+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:59:56.458+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.458+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T00:59:56.780+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.779+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2904780630000232
[2025-01-18T00:59:56.782+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.781+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|910]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T00:59:56.783+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.783+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T00:59:56.784+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.783+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T00:59:56.784+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.784+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T00:59:56.785+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.785+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|910]: It took 0.328s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T00:59:56.793+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.793+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|910]: It took 0.0081s to build the Airflow DAG.
[2025-01-18T00:59:56.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T00:59:56.818+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.817+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T00:59:56.857+0000] {logging_mixin.py:151} INFO - [2025-01-18T00:59:56.856+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T00:59:56.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.486 seconds
[2025-01-18T01:00:27.268+0000] {processor.py:157} INFO - Started process (PID=996) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:00:27.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T01:00:27.274+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:00:27.303+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.302+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T01:00:27.559+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.558+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23045308300004308
[2025-01-18T01:00:27.559+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.559+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|996]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T01:00:27.561+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.561+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T01:00:27.562+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.561+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T01:00:27.562+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.562+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T01:00:27.563+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.563+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|996]: It took 0.26s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T01:00:27.570+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.569+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|996]: It took 0.00683s to build the Airflow DAG.
[2025-01-18T01:00:27.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:00:27.596+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.596+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T01:00:27.652+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:27.652+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T01:00:27.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.428 seconds
[2025-01-18T01:00:57.786+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:00:57.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T01:00:57.792+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:57.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:00:57.827+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:57.826+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T01:00:58.108+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.107+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.25905439000001707
[2025-01-18T01:00:58.109+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.108+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1082]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T01:00:58.110+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.110+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T01:00:58.112+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.111+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T01:00:58.113+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.112+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T01:00:58.114+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.113+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1082]: It took 0.287s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T01:00:58.122+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.122+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1082]: It took 0.00836s to build the Airflow DAG.
[2025-01-18T01:00:58.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:00:58.157+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.157+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T01:00:58.207+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:00:58.207+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T01:00:58.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.474 seconds
[2025-01-18T01:01:28.342+0000] {processor.py:157} INFO - Started process (PID=1157) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:01:28.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T01:01:28.347+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:01:28.373+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.373+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T01:01:28.764+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.763+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.37095694999999296
[2025-01-18T01:01:28.765+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.765+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1157]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T01:01:28.774+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.773+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T01:01:28.775+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.774+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T01:01:28.776+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.775+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T01:01:28.776+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.776+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1157]: It took 0.404s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T01:01:28.788+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.787+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1157]: It took 0.0111s to build the Airflow DAG.
[2025-01-18T01:01:28.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:01:28.829+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.829+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T01:01:28.886+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:28.885+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T01:01:28.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.580 seconds
[2025-01-18T01:01:59.580+0000] {processor.py:157} INFO - Started process (PID=1255) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:01:59.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T01:01:59.583+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:01:59.608+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.608+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T01:01:59.814+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.813+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.19069882200000166
[2025-01-18T01:01:59.814+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.814+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1255]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T01:01:59.815+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.815+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T01:01:59.815+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.815+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T01:01:59.816+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.816+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T01:01:59.816+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.816+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1255]: It took 0.208s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T01:01:59.820+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.820+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1255]: It took 0.0039s to build the Airflow DAG.
[2025-01-18T01:01:59.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T01:01:59.837+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.837+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T01:01:59.865+0000] {logging_mixin.py:151} INFO - [2025-01-18T01:01:59.865+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T01:01:59.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.307 seconds
[2025-01-18T13:40:25.393+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:40:25.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:40:25.402+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:25.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:40:25.449+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:25.448+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:40:27.284+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.284+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 1.8064920110000031
[2025-01-18T13:40:27.286+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.285+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|78]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:40:27.288+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.288+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:40:27.291+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.290+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:40:27.293+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.293+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:40:27.294+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.294+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|78]: It took 1.85s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:40:27.310+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.309+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|78]: It took 0.0154s to build the Airflow DAG.
[2025-01-18T13:40:27.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:40:27.361+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.361+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:40:27.435+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:27.434+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:40:27.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 2.108 seconds
[2025-01-18T13:40:57.688+0000] {processor.py:157} INFO - Started process (PID=160) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:40:57.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:40:57.692+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:40:57.714+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.714+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:40:57.927+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.927+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.198997011000003
[2025-01-18T13:40:57.928+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.927+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|160]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:40:57.929+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.929+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:40:57.930+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.929+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:40:57.930+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.930+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:40:57.931+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.931+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|160]: It took 0.217s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:40:57.938+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.937+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|160]: It took 0.00662s to build the Airflow DAG.
[2025-01-18T13:40:57.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:40:57.959+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.959+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:40:57.998+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:40:57.998+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:40:58.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.339 seconds
[2025-01-18T13:41:28.169+0000] {processor.py:157} INFO - Started process (PID=247) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:41:28.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:41:28.175+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:41:28.212+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.212+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:41:28.446+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.446+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2104817839999953
[2025-01-18T13:41:28.447+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.447+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|247]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:41:28.448+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.448+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:41:28.449+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.449+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:41:28.450+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.449+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:41:28.450+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.450+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|247]: It took 0.238s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:41:28.457+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.457+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|247]: It took 0.00716s to build the Airflow DAG.
[2025-01-18T13:41:28.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:41:28.481+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.481+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:41:28.525+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:28.525+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:41:28.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.389 seconds
[2025-01-18T13:41:58.679+0000] {processor.py:157} INFO - Started process (PID=334) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:41:58.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:41:58.693+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:58.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:41:58.763+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:58.761+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:41:59.168+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.167+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3679273529999989
[2025-01-18T13:41:59.169+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.169+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|334]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:41:59.171+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.171+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:41:59.173+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.172+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:41:59.174+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.173+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:41:59.175+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.174+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|334]: It took 0.414s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:41:59.188+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.188+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|334]: It took 0.0131s to build the Airflow DAG.
[2025-01-18T13:41:59.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:41:59.248+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.247+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:41:59.322+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:41:59.321+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:41:59.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.770 seconds
[2025-01-18T13:42:29.916+0000] {processor.py:157} INFO - Started process (PID=401) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:42:29.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:42:29.922+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:29.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:42:29.952+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:29.952+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:42:30.334+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.333+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3554196420000153
[2025-01-18T13:42:30.334+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.334+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|401]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:42:30.337+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.337+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:42:30.338+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.338+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:42:30.339+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.339+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:42:30.340+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.340+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|401]: It took 0.388s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:42:30.349+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.349+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|401]: It took 0.00926s to build the Airflow DAG.
[2025-01-18T13:42:30.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:42:30.389+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.389+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:42:30.447+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:42:30.446+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:42:30.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.573 seconds
[2025-01-18T13:43:00.727+0000] {processor.py:157} INFO - Started process (PID=487) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:43:00.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:43:00.735+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:00.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:43:00.788+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:00.788+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:43:01.194+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.194+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.3734304940000186
[2025-01-18T13:43:01.195+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.195+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|487]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:43:01.205+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.204+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:43:01.206+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.206+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:43:01.207+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.207+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:43:01.209+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.208+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|487]: It took 0.421s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:43:01.218+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.218+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|487]: It took 0.00976s to build the Airflow DAG.
[2025-01-18T13:43:01.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:43:01.310+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.310+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:43:01.458+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:01.458+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:43:01.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.825 seconds
[2025-01-18T13:43:31.648+0000] {processor.py:157} INFO - Started process (PID=562) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:43:31.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:43:31.665+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:31.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:43:31.719+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:31.719+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:43:32.518+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.518+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.7502595300000223
[2025-01-18T13:43:32.519+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.519+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|562]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:43:32.521+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.521+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:43:32.522+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.522+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:43:32.524+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.524+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:43:32.525+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.525+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|562]: It took 0.806s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:43:32.537+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.537+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|562]: It took 0.0125s to build the Airflow DAG.
[2025-01-18T13:43:32.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:43:32.617+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.617+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:43:32.727+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:43:32.723+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:43:32.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 1.169 seconds
[2025-01-18T13:44:03.211+0000] {processor.py:157} INFO - Started process (PID=641) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:44:03.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:44:03.215+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:44:03.243+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.242+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:44:03.484+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.484+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22554467399999112
[2025-01-18T13:44:03.485+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.485+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|641]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:44:03.486+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.486+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:44:03.487+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.487+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:44:03.488+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.487+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:44:03.488+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.488+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|641]: It took 0.246s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:44:03.494+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.494+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|641]: It took 0.00612s to build the Airflow DAG.
[2025-01-18T13:44:03.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:44:03.516+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.516+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:44:03.557+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:03.556+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:44:03.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.379 seconds
[2025-01-18T13:44:34.506+0000] {processor.py:157} INFO - Started process (PID=729) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:44:34.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:44:34.509+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:44:34.535+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.535+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:44:34.770+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.770+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.21996908500000245
[2025-01-18T13:44:34.771+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.771+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|729]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:44:34.772+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.772+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:44:34.773+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.773+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:44:34.774+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.773+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:44:34.774+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.774+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|729]: It took 0.24s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:44:34.780+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.780+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|729]: It took 0.00599s to build the Airflow DAG.
[2025-01-18T13:44:34.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:44:34.802+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.802+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:44:34.841+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:44:34.840+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:44:34.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.368 seconds
[2025-01-18T13:45:05.123+0000] {processor.py:157} INFO - Started process (PID=815) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:45:05.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:45:05.129+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:45:05.165+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.164+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:45:05.472+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.472+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2837687030000211
[2025-01-18T13:45:05.473+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.473+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|815]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:45:05.475+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.475+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:45:05.476+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.476+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:45:05.477+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.477+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:45:05.478+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.478+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|815]: It took 0.314s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:45:05.488+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.488+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|815]: It took 0.00986s to build the Airflow DAG.
[2025-01-18T13:45:05.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:45:05.525+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.525+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:45:05.590+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:05.590+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:45:05.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.511 seconds
[2025-01-18T13:45:36.397+0000] {processor.py:157} INFO - Started process (PID=902) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:45:36.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:45:36.403+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:45:36.441+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.441+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:45:36.650+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.650+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.18828614199998128
[2025-01-18T13:45:36.651+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.650+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|902]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:45:36.652+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.652+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:45:36.652+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.652+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:45:36.653+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.653+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:45:36.653+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.653+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|902]: It took 0.212s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:45:36.658+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.658+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|902]: It took 0.00499s to build the Airflow DAG.
[2025-01-18T13:45:36.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:45:36.677+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.677+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:45:36.714+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:45:36.714+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:45:36.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.346 seconds
[2025-01-18T13:46:06.908+0000] {processor.py:157} INFO - Started process (PID=989) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:46:06.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:46:06.912+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:06.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:46:06.938+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:06.938+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:46:07.183+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.183+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.22977673000002596
[2025-01-18T13:46:07.183+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.183+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|989]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:46:07.184+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.184+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:46:07.185+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.185+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:46:07.186+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.185+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:46:07.186+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.186+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|989]: It took 0.248s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:46:07.192+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.192+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|989]: It took 0.00613s to build the Airflow DAG.
[2025-01-18T13:46:07.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:46:07.215+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.214+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:46:07.251+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:07.250+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:46:07.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.374 seconds
[2025-01-18T13:46:37.324+0000] {processor.py:157} INFO - Started process (PID=1077) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:46:37.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:46:37.328+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:46:37.349+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.348+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:46:37.503+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.503+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1387773129999914
[2025-01-18T13:46:37.503+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.503+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1077]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:46:37.504+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.504+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:46:37.504+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.504+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:46:37.504+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.504+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:46:37.505+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.505+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1077]: It took 0.156s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:46:37.508+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.508+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1077]: It took 0.00348s to build the Airflow DAG.
[2025-01-18T13:46:37.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:46:37.521+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.521+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:46:37.543+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:46:37.543+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:46:37.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.260 seconds
[2025-01-18T13:47:07.744+0000] {processor.py:157} INFO - Started process (PID=1163) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:47:07.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:47:07.749+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:07.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:47:07.778+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:07.778+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:47:08.021+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.020+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2257598119999784
[2025-01-18T13:47:08.022+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.021+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1163]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:47:08.023+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.023+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:47:08.024+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.024+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:47:08.025+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.025+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:47:08.026+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.026+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1163]: It took 0.248s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:47:08.035+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.035+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1163]: It took 0.00934s to build the Airflow DAG.
[2025-01-18T13:47:08.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:47:08.064+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:47:08.115+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:08.114+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:47:08.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.415 seconds
[2025-01-18T13:47:39.110+0000] {processor.py:157} INFO - Started process (PID=1249) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:47:39.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:47:39.117+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:47:39.157+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.156+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:47:39.432+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.431+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24906478600001947
[2025-01-18T13:47:39.432+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.432+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1249]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:47:39.434+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.434+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:47:39.434+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.434+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:47:39.435+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.435+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:47:39.436+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.436+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1249]: It took 0.28s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:47:39.446+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.445+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1249]: It took 0.00947s to build the Airflow DAG.
[2025-01-18T13:47:39.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:47:39.472+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.472+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:47:39.514+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:47:39.514+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:47:39.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.434 seconds
[2025-01-18T13:48:10.079+0000] {processor.py:157} INFO - Started process (PID=1323) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:48:10.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:48:10.088+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:48:10.162+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.161+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:48:10.665+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.665+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.44674272399998927
[2025-01-18T13:48:10.666+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.666+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1323]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:48:10.668+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.668+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:48:10.669+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.669+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:48:10.670+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.670+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:48:10.671+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.671+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1323]: It took 0.51s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:48:10.687+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.686+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1323]: It took 0.0153s to build the Airflow DAG.
[2025-01-18T13:48:10.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:48:10.731+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.730+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:48:10.833+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:10.833+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:48:10.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.820 seconds
[2025-01-18T13:48:41.740+0000] {processor.py:157} INFO - Started process (PID=1404) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:48:41.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:48:41.744+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:41.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:48:41.774+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:41.774+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:48:42.040+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.040+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24728183600007014
[2025-01-18T13:48:42.041+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.040+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1404]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:48:42.042+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.042+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:48:42.043+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.042+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:48:42.043+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.043+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:48:42.044+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.044+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1404]: It took 0.27s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:48:42.051+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.051+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1404]: It took 0.00739s to build the Airflow DAG.
[2025-01-18T13:48:42.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:48:42.073+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.073+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:48:42.120+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:48:42.119+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:48:42.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.417 seconds
[2025-01-18T13:49:12.541+0000] {processor.py:157} INFO - Started process (PID=1491) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:49:12.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:49:12.544+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:49:12.566+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.566+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:49:12.824+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.823+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.24504960399997344
[2025-01-18T13:49:12.825+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.824+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1491]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:49:12.826+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.826+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:49:12.827+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.827+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:49:12.828+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.828+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:49:12.829+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.829+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1491]: It took 0.263s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:49:12.837+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.837+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1491]: It took 0.00821s to build the Airflow DAG.
[2025-01-18T13:49:12.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:49:12.865+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.865+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:49:12.908+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:12.907+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:49:12.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.394 seconds
[2025-01-18T13:49:43.512+0000] {processor.py:157} INFO - Started process (PID=1577) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:49:43.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:49:43.516+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:49:43.540+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.539+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:49:43.792+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.791+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.23762363699995603
[2025-01-18T13:49:43.793+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.792+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1577]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 4326
[2025-01-18T13:49:43.794+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.794+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - 803788524eb62bcb4e58a5e64edef543,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:49:43.795+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.795+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:49:43.796+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.796+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:49:43.797+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.797+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1577]: It took 0.257s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:49:43.805+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.804+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1577]: It took 0.00764s to build the Airflow DAG.
[2025-01-18T13:49:43.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:49:43.836+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.836+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:49:43.881+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:49:43.881+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:49:43.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.395 seconds
[2025-01-18T13:50:14.411+0000] {processor.py:157} INFO - Started process (PID=1664) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:50:14.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:50:14.415+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:50:14.443+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.442+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:50:14.685+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.685+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2262179599999854
[2025-01-18T13:50:14.686+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.686+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-18T13:50:14.687+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.686+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-18T13:50:14.694+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.694+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-18T13:50:14.705+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.705+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-18T13:50:14.708+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.708+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-18T13:50:14.708+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:14.708+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpswgwqc5w --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-18T13:50:25.982+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:25.981+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.1874151830000983
[2025-01-18T13:50:25.987+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:25.987+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-18T13:50:25.995+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:25.995+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:50:25.995+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:25.995+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:50:25.996+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:25.996+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1664]: It took 11.6s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-18T13:50:26.002+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:26.002+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1664]: It took 0.00617s to build the Airflow DAG.
[2025-01-18T13:50:26.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:50:26.020+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:26.020+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:50:26.050+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:26.049+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:50:26.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 11.669 seconds
[2025-01-18T13:50:56.698+0000] {processor.py:157} INFO - Started process (PID=1830) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:50:56.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:50:56.705+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:50:56.734+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.734+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:50:56.987+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.987+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2343009889999621
[2025-01-18T13:50:56.988+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.988+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1830]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 3933
[2025-01-18T13:50:56.990+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.990+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - f5a29b686a5b388e87cf51f9107979ad,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:50:56.991+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.991+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:50:56.991+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.991+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:50:56.992+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.992+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1830]: It took 0.258s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:50:56.998+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:56.998+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1830]: It took 0.00595s to build the Airflow DAG.
[2025-01-18T13:50:57.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:50:57.026+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:57.025+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:50:57.072+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:50:57.071+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:50:57.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.415 seconds
[2025-01-18T13:51:27.249+0000] {processor.py:157} INFO - Started process (PID=1916) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:51:27.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T13:51:27.252+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:51:27.271+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.271+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T13:51:27.488+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.488+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2043479249999791
[2025-01-18T13:51:27.488+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.488+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|1916]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 3933
[2025-01-18T13:51:27.489+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.489+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - f5a29b686a5b388e87cf51f9107979ad,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T13:51:27.489+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.489+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T13:51:27.490+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.490+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T13:51:27.490+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.490+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|1916]: It took 0.219s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T13:51:27.494+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.494+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|1916]: It took 0.00367s to build the Airflow DAG.
[2025-01-18T13:51:27.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T13:51:27.508+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.508+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T13:51:27.528+0000] {logging_mixin.py:151} INFO - [2025-01-18T13:51:27.528+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T13:51:27.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.308 seconds
[2025-01-18T15:08:45.041+0000] {processor.py:157} INFO - Started process (PID=16155) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T15:08:45.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T15:08:45.044+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T15:08:45.073+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.073+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T15:08:45.294+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.293+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.2066334499995719
[2025-01-18T15:08:45.294+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.294+0000] {graph.py:529} INFO - Cosmos performance: Cache miss for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - skipped
[2025-01-18T15:08:45.295+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.295+0000] {graph.py:560} INFO - Trying to parse the dbt project in `/opt/airflow/dbt/dbt_stock_project` using dbt ls...
[2025-01-18T15:08:45.299+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.299+0000] {graph.py:579} INFO - Partial parse is enabled and the latest partial parse file is /tmp/cosmos/PolygonAPI_to_BigQuery__dbt_transformation/target/partial_parse.msgpack
[2025-01-18T15:08:45.304+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.304+0000] {config.py:342} INFO - Using user-supplied profiles.yml at /opt/airflow/dbt/profiles/profiles.yml
[2025-01-18T15:08:45.306+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.306+0000] {project.py:36} INFO - Project /opt/airflow/dbt/dbt_stock_project does not have {'packages.yml', 'dependencies.yml'}
[2025-01-18T15:08:45.306+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:45.306+0000] {graph.py:164} INFO - Running command: `/home/airflow/.local/bin/dbt ls --output json --project-dir /tmp/tmpdxox3sa0 --profiles-dir /opt/airflow/dbt/profiles --profile default --target dev`
[2025-01-18T15:08:50.909+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.908+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14953487899947504
[2025-01-18T15:08:50.914+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.913+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-01-18T15:08:50.920+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.920+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T15:08:50.921+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.921+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T15:08:50.922+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.922+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16155]: It took 5.85s to parse the dbt project for DAG using LoadMode.DBT_LS
[2025-01-18T15:08:50.927+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.927+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16155]: It took 0.00553s to build the Airflow DAG.
[2025-01-18T15:08:50.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T15:08:50.941+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.941+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T15:08:50.964+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:08:50.964+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T15:08:50.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 5.945 seconds
[2025-01-18T15:09:21.820+0000] {processor.py:157} INFO - Started process (PID=16281) to work on /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T15:09:21.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/polygon_to_bigquery.py for tasks to queue
[2025-01-18T15:09:21.824+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:21.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T15:09:21.845+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:21.845+0000] {graph.py:502} INFO - Trying to parse the dbt project using dbt ls cache cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation...
[2025-01-18T15:09:22.007+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.007+0000] {cache.py:320} INFO - Cosmos performance: time to calculate cache identifier cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation for current version: 0.14968459300052928
[2025-01-18T15:09:22.007+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.007+0000] {graph.py:519} INFO - Cosmos performance [09297a4a3d23|16281]: The cache size for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation is 3933
[2025-01-18T15:09:22.008+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.008+0000] {graph.py:527} INFO - Cosmos performance: Cache hit for cosmos_cache__PolygonAPI_to_BigQuery__dbt_transformation - c95360fdf93438bbae376b0a6e74e4eb,d41d8cd98f00b204e9800998ecf8427e
[2025-01-18T15:09:22.008+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.008+0000] {graph.py:444} INFO - Total nodes: 8
[2025-01-18T15:09:22.009+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.009+0000] {graph.py:445} INFO - Total filtered nodes: 8
[2025-01-18T15:09:22.009+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.009+0000] {converter.py:265} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) -  [09297a4a3d23|16281]: It took 0.164s to parse the dbt project for DAG using LoadMode.DBT_LS_CACHE
[2025-01-18T15:09:22.013+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.013+0000] {converter.py:309} INFO - Cosmos performance (PolygonAPI_to_BigQuery__dbt_transformation) - [09297a4a3d23|16281]: It took 0.0038s to build the Airflow DAG.
[2025-01-18T15:09:22.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['PolygonAPI_to_BigQuery']) retrieved from /opt/airflow/dags/polygon_to_bigquery.py
[2025-01-18T15:09:22.029+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.029+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-01-18T15:09:22.051+0000] {logging_mixin.py:151} INFO - [2025-01-18T15:09:22.050+0000] {dag.py:3677} INFO - Setting next_dagrun for PolygonAPI_to_BigQuery to 2025-01-18T00:00:00+00:00, run_after=2025-01-19T00:00:00+00:00
[2025-01-18T15:09:22.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/polygon_to_bigquery.py took 0.250 seconds
