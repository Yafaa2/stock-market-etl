[2024-12-04T18:12:36.185+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: PolygonAPI_to_BigQuery.sync_polygon_data scheduled__2024-12-04T17:00:00+00:00 [queued]>
[2024-12-04T18:12:36.245+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: PolygonAPI_to_BigQuery.sync_polygon_data scheduled__2024-12-04T17:00:00+00:00 [queued]>
[2024-12-04T18:12:36.248+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-12-04T18:12:36.250+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2024-12-04T18:12:36.250+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-12-04T18:12:36.331+0000] {taskinstance.py:1300} INFO - Executing <Task(AirbyteTriggerSyncOperator): sync_polygon_data> on 2024-12-04 17:00:00+00:00
[2024-12-04T18:12:36.345+0000] {standard_task_runner.py:55} INFO - Started process 24272 to run task
[2024-12-04T18:12:36.352+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'PolygonAPI_to_BigQuery', 'sync_polygon_data', 'scheduled__2024-12-04T17:00:00+00:00', '--job-id', '57', '--raw', '--subdir', 'DAGS_FOLDER/polygon_to_BigQuery_sync.py', '--cfg-path', '/tmp/tmpcczjehzg']
[2024-12-04T18:12:36.353+0000] {standard_task_runner.py:83} INFO - Job 57: Subtask sync_polygon_data
[2024-12-04T18:12:36.570+0000] {task_command.py:388} INFO - Running <TaskInstance: PolygonAPI_to_BigQuery.sync_polygon_data scheduled__2024-12-04T17:00:00+00:00 [running]> on host 1b9e534b4855
[2024-12-04T18:12:36.827+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=PolygonAPI_to_BigQuery
AIRFLOW_CTX_TASK_ID=sync_polygon_data
AIRFLOW_CTX_EXECUTION_DATE=2024-12-04T17:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-12-04T17:00:00+00:00
[2024-12-04T18:12:36.851+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T19:18:51.934+0000] {local_task_job.py:273} WARNING - State of this instance has been externally set to up_for_retry. Terminating instance.
[2024-12-04T19:18:51.938+0000] {process_utils.py:133} INFO - Sending Signals.SIGTERM to group 24272. PIDs of all processes in the group: [24272]
[2024-12-04T19:18:51.939+0000] {process_utils.py:84} INFO - Sending the signal Signals.SIGTERM to group 24272
[2024-12-04T19:18:51.940+0000] {taskinstance.py:1479} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-12-04T19:18:51.942+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/airbyte/operators/airbyte.py", line 74, in execute
    job_object = self.hook.submit_sync_connection(connection_id=self.connection_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/airbyte/hooks/airbyte.py", line 95, in submit_sync_connection
    headers={"accept": "application/json"},
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/http/hooks/http.py", line 151, in run
    return self.run_and_check(session, prepped_request, extra_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/http/hooks/http.py", line 201, in run_and_check
    response = session.send(prepped_request, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.7/http/client.py", line 1373, in getresponse
    response.begin()
  File "/usr/local/lib/python3.7/http/client.py", line 319, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.7/http/client.py", line 280, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1480, in signal_handler
    self.task.on_kill()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/airbyte/operators/airbyte.py", line 87, in on_kill
    if self.job_id:
AttributeError: 'AirbyteTriggerSyncOperator' object has no attribute 'job_id'
[2024-12-04T19:18:51.969+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_polygon_data, execution_date=20241204T170000, start_date=20241204T181236, end_date=20241204T191851
[2024-12-04T19:18:51.995+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 57 for task sync_polygon_data ('AirbyteTriggerSyncOperator' object has no attribute 'job_id'; 24272)
[2024-12-04T19:18:52.032+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=24272, status='terminated', exitcode=1, started='18:12:35') (24272) terminated with exit code 1
