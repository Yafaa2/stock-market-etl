[2024-12-04T04:40:01.288+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: PolygonAPI_to_BigQuery.sync_polygon_data scheduled__2024-12-04T03:00:00+00:00 [queued]>
[2024-12-04T04:40:01.314+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: PolygonAPI_to_BigQuery.sync_polygon_data scheduled__2024-12-04T03:00:00+00:00 [queued]>
[2024-12-04T04:40:01.315+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-12-04T04:40:01.316+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2024-12-04T04:40:01.316+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-12-04T04:40:01.383+0000] {taskinstance.py:1300} INFO - Executing <Task(AirbyteTriggerSyncOperator): sync_polygon_data> on 2024-12-04 03:00:00+00:00
[2024-12-04T04:40:01.390+0000] {standard_task_runner.py:55} INFO - Started process 2466 to run task
[2024-12-04T04:40:01.397+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'PolygonAPI_to_BigQuery', 'sync_polygon_data', 'scheduled__2024-12-04T03:00:00+00:00', '--job-id', '46', '--raw', '--subdir', 'DAGS_FOLDER/polygon_to_BigQuery_sync.py', '--cfg-path', '/tmp/tmpjnxdym6r']
[2024-12-04T04:40:01.398+0000] {standard_task_runner.py:83} INFO - Job 46: Subtask sync_polygon_data
[2024-12-04T04:40:01.556+0000] {task_command.py:388} INFO - Running <TaskInstance: PolygonAPI_to_BigQuery.sync_polygon_data scheduled__2024-12-04T03:00:00+00:00 [running]> on host 1b9e534b4855
[2024-12-04T04:40:01.808+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=PolygonAPI_to_BigQuery
AIRFLOW_CTX_TASK_ID=sync_polygon_data
AIRFLOW_CTX_EXECUTION_DATE=2024-12-04T03:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-12-04T03:00:00+00:00
[2024-12-04T04:40:01.846+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T04:40:02.625+0000] {airbyte.py:77} INFO - Job 28 was submitted to Airbyte Server
[2024-12-04T04:40:02.626+0000] {airbyte.py:79} INFO - Waiting for job 28 to complete
[2024-12-04T04:40:05.639+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:24.209+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:30.934+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:34.148+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:37.378+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:40.556+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:43.621+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:46.815+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:50.013+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:53.203+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:28:56.348+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T12:29:16.494+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T13:20:21.115+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T13:20:24.213+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T13:20:27.287+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T13:20:28.023+0000] {local_task_job.py:273} WARNING - State of this instance has been externally set to up_for_retry. Terminating instance.
[2024-12-04T13:20:28.024+0000] {process_utils.py:133} INFO - Sending Signals.SIGTERM to group 2466. PIDs of all processes in the group: [2466]
[2024-12-04T13:20:28.025+0000] {process_utils.py:84} INFO - Sending the signal Signals.SIGTERM to group 2466
[2024-12-04T13:20:28.026+0000] {taskinstance.py:1479} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-12-04T13:20:28.026+0000] {airbyte.py:88} INFO - on_kill: cancel the airbyte Job 28
[2024-12-04T13:20:28.034+0000] {base.py:73} INFO - Using connection ID 'airbyte_to_bigquery' for task execution.
[2024-12-04T13:20:28.454+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/airbyte/operators/airbyte.py", line 80, in execute
    self.hook.wait_for_job(job_id=self.job_id, wait_seconds=self.wait_seconds, timeout=self.timeout)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/airbyte/hooks/airbyte.py", line 67, in wait_for_job
    time.sleep(wait_seconds)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1481, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2024-12-04T13:20:28.461+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=PolygonAPI_to_BigQuery, task_id=sync_polygon_data, execution_date=20241204T030000, start_date=20241204T044001, end_date=20241204T132028
[2024-12-04T13:20:28.479+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 46 for task sync_polygon_data (Task received SIGTERM signal; 2466)
[2024-12-04T13:20:28.520+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=2466, status='terminated', exitcode=1, started='04:40:00') (2466) terminated with exit code 1
